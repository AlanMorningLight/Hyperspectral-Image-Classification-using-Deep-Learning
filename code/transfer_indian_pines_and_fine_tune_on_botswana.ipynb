{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_indian_pines_and_fine_tune_on_botswana.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "STppFn_nhvYi",
        "outputId": "07a4b0d3-f96b-4b38-fe04-561801cc6344"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NsWimZvhqNW"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification/code')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBRyZQ0MhrSs"
      },
      "source": [
        "from utils import *\n",
        "import scipy.io as sio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAWER3kezHmg"
      },
      "source": [
        "#  Load Target Dataset - Botswana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cRTmsNsymp3"
      },
      "source": [
        "uBotswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/code/Datasets/Botswana.mat')\n",
        "gt_Botswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/code/Datasets/Botswana_gt.mat')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egv2O79ry9fd"
      },
      "source": [
        "data = uBotswana['Botswana']\n",
        "ground_truth = gt_Botswana['Botswana_gt']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkk-yPpzRSH",
        "outputId": "478e1e61-813d-4b45-9977-d3304692ad68"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1476, 256, 145)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grlLMWu8zSu5",
        "outputId": "f0f4e5f1-771a-4afd-e273-af4da4d463e6"
      },
      "source": [
        "ground_truth.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1476, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9yKgNo4j2b"
      },
      "source": [
        "# Distribution of Samples in target dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "AYdydfZF4gwC",
        "outputId": "dee1ea78-5393-4b2c-8416-d466e0c96ee3"
      },
      "source": [
        "class_distribution = pd.DataFrame(np.unique(ground_truth, return_counts = True))\n",
        "class_distribution = class_distribution.transpose()\n",
        "class_distribution.columns = ['class','samples']\n",
        "class_distribution"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>374608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class  samples\n",
              "0       0   374608\n",
              "1       1      270\n",
              "2       2      101\n",
              "3       3      251\n",
              "4       4      215\n",
              "5       5      269\n",
              "6       6      269\n",
              "7       7      259\n",
              "8       8      203\n",
              "9       9      314\n",
              "10     10      248\n",
              "11     11      305\n",
              "12     12      181\n",
              "13     13      268\n",
              "14     14       95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsaQ_1FH4pa8",
        "outputId": "6c386cad-d7e1-4564-ae24-3531531ac72d"
      },
      "source": [
        "classes , counts = np.unique(ground_truth, return_counts = True)\n",
        "classes = classes[1:] ## Not considering background\n",
        "classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCUWkZcyzVK9"
      },
      "source": [
        "# Load saved source model trained on Indian Pines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkvxK5MgCa0s",
        "outputId": "30c2100e-c559-4b9e-bee8-f95f18daef83"
      },
      "source": [
        "cm = transfer_learning(source_dataset = 'indian_pines',\n",
        "                      target_dataset = 'botswana',\n",
        "                      data = data,\n",
        "                      ground_truth = ground_truth, \n",
        "                      source_training_size = 200,\n",
        "                      training_samples_from_each_class = 30,\n",
        "                      test_samples_from_each_class = 10,\n",
        "                      classes = classes,\n",
        "                      overlap_ratio = 1,\n",
        "                      channels = 64,\n",
        "                      cube_size = 20,\n",
        "                      learning_rate = 0.0001,\n",
        "                      epochs = 50,\n",
        "                      batch_size = 20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 5, 5, 128)    0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 128)          0           activation_4[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 68,864\n",
            "Trainable params: 67,968\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n",
            "Class Samples :  [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n",
            "Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n",
            "Total number of samples is 3144.\n",
            "\n",
            "unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "Total number of samples in training set is 420.\n",
            "Samples per class in training set: [30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n",
            "\n",
            "unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "Total number of samples in test set is 140.\n",
            "Samples per class in test set: [10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
            "\n",
            "\n",
            "\n",
            "X_train_transfer => (420, 128)\n",
            "X_test_transfer  => (140, 128)\n",
            "y_train => (420, 14)\n",
            "y_test  => (140, 14)\n",
            "\n",
            "Model: \"fine_tune\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "fc_256 (Dense)               (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "fc14 (Dense)                 (None, 14)                3598      \n",
            "=================================================================\n",
            "Total params: 36,622\n",
            "Trainable params: 36,622\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 3.0985 - categorical_accuracy: 0.0500\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.13571, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2.8974 - categorical_accuracy: 0.0714 - val_loss: 2.7380 - val_categorical_accuracy: 0.1357\n",
            "Epoch 2/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.8265 - categorical_accuracy: 0.0500\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.13571 to 0.14286, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.6727 - categorical_accuracy: 0.1333 - val_loss: 2.6210 - val_categorical_accuracy: 0.1429\n",
            "Epoch 3/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.6944 - categorical_accuracy: 0.0500\n",
            "Epoch 00003: val_categorical_accuracy did not improve from 0.14286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.5873 - categorical_accuracy: 0.0857 - val_loss: 2.5613 - val_categorical_accuracy: 0.0786\n",
            "Epoch 4/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.5271 - categorical_accuracy: 0.1000\n",
            "Epoch 00004: val_categorical_accuracy did not improve from 0.14286\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.5309 - categorical_accuracy: 0.0952 - val_loss: 2.5145 - val_categorical_accuracy: 0.1357\n",
            "Epoch 5/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.5750 - categorical_accuracy: 0.1000\n",
            "Epoch 00005: val_categorical_accuracy improved from 0.14286 to 0.15000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.4845 - categorical_accuracy: 0.1476 - val_loss: 2.4767 - val_categorical_accuracy: 0.1500\n",
            "Epoch 6/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.4278 - categorical_accuracy: 0.2000\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.15000\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.4450 - categorical_accuracy: 0.1452 - val_loss: 2.4416 - val_categorical_accuracy: 0.1500\n",
            "Epoch 7/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.4128 - categorical_accuracy: 0.0500\n",
            "Epoch 00007: val_categorical_accuracy improved from 0.15000 to 0.16429, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.4110 - categorical_accuracy: 0.1762 - val_loss: 2.4107 - val_categorical_accuracy: 0.1643\n",
            "Epoch 8/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.4805 - categorical_accuracy: 0.1000\n",
            "Epoch 00008: val_categorical_accuracy improved from 0.16429 to 0.20714, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2.3792 - categorical_accuracy: 0.2143 - val_loss: 2.3793 - val_categorical_accuracy: 0.2071\n",
            "Epoch 9/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3896 - categorical_accuracy: 0.2000\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.20714\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.3458 - categorical_accuracy: 0.2190 - val_loss: 2.3518 - val_categorical_accuracy: 0.1929\n",
            "Epoch 10/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.2597 - categorical_accuracy: 0.2000\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.20714 to 0.22143, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2.3166 - categorical_accuracy: 0.2238 - val_loss: 2.3260 - val_categorical_accuracy: 0.2214\n",
            "Epoch 11/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.1763 - categorical_accuracy: 0.3000\n",
            "Epoch 00011: val_categorical_accuracy improved from 0.22143 to 0.25000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.2912 - categorical_accuracy: 0.2286 - val_loss: 2.3014 - val_categorical_accuracy: 0.2500\n",
            "Epoch 12/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3964 - categorical_accuracy: 0.2500\n",
            "Epoch 00012: val_categorical_accuracy did not improve from 0.25000\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.2659 - categorical_accuracy: 0.2452 - val_loss: 2.2772 - val_categorical_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3177 - categorical_accuracy: 0.2000\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.25000\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.2403 - categorical_accuracy: 0.2500 - val_loss: 2.2549 - val_categorical_accuracy: 0.2357\n",
            "Epoch 14/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3149 - categorical_accuracy: 0.2500\n",
            "Epoch 00014: val_categorical_accuracy improved from 0.25000 to 0.25714, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.2172 - categorical_accuracy: 0.2667 - val_loss: 2.2330 - val_categorical_accuracy: 0.2571\n",
            "Epoch 15/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3168 - categorical_accuracy: 0.1500\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.25714\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.1941 - categorical_accuracy: 0.2762 - val_loss: 2.2123 - val_categorical_accuracy: 0.2357\n",
            "Epoch 16/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3315 - categorical_accuracy: 0.2000\n",
            "Epoch 00016: val_categorical_accuracy improved from 0.25714 to 0.27143, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.1722 - categorical_accuracy: 0.3024 - val_loss: 2.1924 - val_categorical_accuracy: 0.2714\n",
            "Epoch 17/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.3062 - categorical_accuracy: 0.3500\n",
            "Epoch 00017: val_categorical_accuracy improved from 0.27143 to 0.27857, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.1524 - categorical_accuracy: 0.3095 - val_loss: 2.1734 - val_categorical_accuracy: 0.2786\n",
            "Epoch 18/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.1097 - categorical_accuracy: 0.3500\n",
            "Epoch 00018: val_categorical_accuracy improved from 0.27857 to 0.30000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.1330 - categorical_accuracy: 0.3000 - val_loss: 2.1551 - val_categorical_accuracy: 0.3000\n",
            "Epoch 19/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.2282 - categorical_accuracy: 0.3000\n",
            "Epoch 00019: val_categorical_accuracy improved from 0.30000 to 0.32143, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2.1136 - categorical_accuracy: 0.3310 - val_loss: 2.1372 - val_categorical_accuracy: 0.3214\n",
            "Epoch 20/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.9928 - categorical_accuracy: 0.4000\n",
            "Epoch 00020: val_categorical_accuracy did not improve from 0.32143\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.0959 - categorical_accuracy: 0.3524 - val_loss: 2.1201 - val_categorical_accuracy: 0.3000\n",
            "Epoch 21/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.9508 - categorical_accuracy: 0.3000\n",
            "Epoch 00021: val_categorical_accuracy did not improve from 0.32143\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.0771 - categorical_accuracy: 0.3762 - val_loss: 2.1037 - val_categorical_accuracy: 0.3143\n",
            "Epoch 22/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.1916 - categorical_accuracy: 0.3500\n",
            "Epoch 00022: val_categorical_accuracy improved from 0.32143 to 0.34286, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2.0617 - categorical_accuracy: 0.3548 - val_loss: 2.0875 - val_categorical_accuracy: 0.3429\n",
            "Epoch 23/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0593 - categorical_accuracy: 0.3500\n",
            "Epoch 00023: val_categorical_accuracy did not improve from 0.34286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.0444 - categorical_accuracy: 0.3595 - val_loss: 2.0717 - val_categorical_accuracy: 0.3214\n",
            "Epoch 24/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.9953 - categorical_accuracy: 0.4500\n",
            "Epoch 00024: val_categorical_accuracy did not improve from 0.34286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.0268 - categorical_accuracy: 0.4071 - val_loss: 2.0559 - val_categorical_accuracy: 0.3286\n",
            "Epoch 25/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0869 - categorical_accuracy: 0.4000\n",
            "Epoch 00025: val_categorical_accuracy did not improve from 0.34286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2.0117 - categorical_accuracy: 0.4119 - val_loss: 2.0404 - val_categorical_accuracy: 0.3357\n",
            "Epoch 26/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.9275 - categorical_accuracy: 0.5500\n",
            "Epoch 00026: val_categorical_accuracy did not improve from 0.34286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.9968 - categorical_accuracy: 0.4119 - val_loss: 2.0255 - val_categorical_accuracy: 0.3429\n",
            "Epoch 27/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0509 - categorical_accuracy: 0.3500\n",
            "Epoch 00027: val_categorical_accuracy improved from 0.34286 to 0.36429, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.9812 - categorical_accuracy: 0.4262 - val_loss: 2.0112 - val_categorical_accuracy: 0.3643\n",
            "Epoch 28/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0941 - categorical_accuracy: 0.3500\n",
            "Epoch 00028: val_categorical_accuracy improved from 0.36429 to 0.38571, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.9674 - categorical_accuracy: 0.3929 - val_loss: 1.9967 - val_categorical_accuracy: 0.3857\n",
            "Epoch 29/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.9191 - categorical_accuracy: 0.4000\n",
            "Epoch 00029: val_categorical_accuracy did not improve from 0.38571\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.9512 - categorical_accuracy: 0.3976 - val_loss: 1.9820 - val_categorical_accuracy: 0.3714\n",
            "Epoch 30/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.8516 - categorical_accuracy: 0.4500\n",
            "Epoch 00030: val_categorical_accuracy did not improve from 0.38571\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.9361 - categorical_accuracy: 0.4190 - val_loss: 1.9670 - val_categorical_accuracy: 0.3786\n",
            "Epoch 31/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7876 - categorical_accuracy: 0.3500\n",
            "Epoch 00031: val_categorical_accuracy improved from 0.38571 to 0.44286, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.9197 - categorical_accuracy: 0.4500 - val_loss: 1.9531 - val_categorical_accuracy: 0.4429\n",
            "Epoch 32/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7840 - categorical_accuracy: 0.5500\n",
            "Epoch 00032: val_categorical_accuracy improved from 0.44286 to 0.46429, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.9074 - categorical_accuracy: 0.5000 - val_loss: 1.9393 - val_categorical_accuracy: 0.4643\n",
            "Epoch 33/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0491 - categorical_accuracy: 0.4500\n",
            "Epoch 00033: val_categorical_accuracy did not improve from 0.46429\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.8932 - categorical_accuracy: 0.4524 - val_loss: 1.9264 - val_categorical_accuracy: 0.4071\n",
            "Epoch 34/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7969 - categorical_accuracy: 0.7000\n",
            "Epoch 00034: val_categorical_accuracy did not improve from 0.46429\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.8810 - categorical_accuracy: 0.4524 - val_loss: 1.9133 - val_categorical_accuracy: 0.4214\n",
            "Epoch 35/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.6903 - categorical_accuracy: 0.6000\n",
            "Epoch 00035: val_categorical_accuracy improved from 0.46429 to 0.47857, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.8695 - categorical_accuracy: 0.4833 - val_loss: 1.9012 - val_categorical_accuracy: 0.4786\n",
            "Epoch 36/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.6697 - categorical_accuracy: 0.5000\n",
            "Epoch 00036: val_categorical_accuracy improved from 0.47857 to 0.50000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.8571 - categorical_accuracy: 0.5429 - val_loss: 1.8890 - val_categorical_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7736 - categorical_accuracy: 0.6000\n",
            "Epoch 00037: val_categorical_accuracy did not improve from 0.50000\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.8442 - categorical_accuracy: 0.5310 - val_loss: 1.8764 - val_categorical_accuracy: 0.4929\n",
            "Epoch 38/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7683 - categorical_accuracy: 0.6500\n",
            "Epoch 00038: val_categorical_accuracy improved from 0.50000 to 0.53571, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.8325 - categorical_accuracy: 0.5548 - val_loss: 1.8654 - val_categorical_accuracy: 0.5357\n",
            "Epoch 39/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.5888 - categorical_accuracy: 0.5500\n",
            "Epoch 00039: val_categorical_accuracy did not improve from 0.53571\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.8205 - categorical_accuracy: 0.5548 - val_loss: 1.8539 - val_categorical_accuracy: 0.5143\n",
            "Epoch 40/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.8748 - categorical_accuracy: 0.6000\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.53571\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.8084 - categorical_accuracy: 0.5643 - val_loss: 1.8422 - val_categorical_accuracy: 0.5286\n",
            "Epoch 41/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7971 - categorical_accuracy: 0.4500\n",
            "Epoch 00041: val_categorical_accuracy improved from 0.53571 to 0.54286, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.7973 - categorical_accuracy: 0.5690 - val_loss: 1.8313 - val_categorical_accuracy: 0.5429\n",
            "Epoch 42/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.6000 - categorical_accuracy: 0.7500\n",
            "Epoch 00042: val_categorical_accuracy improved from 0.54286 to 0.57857, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.7851 - categorical_accuracy: 0.6119 - val_loss: 1.8203 - val_categorical_accuracy: 0.5786\n",
            "Epoch 43/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.8527 - categorical_accuracy: 0.6500\n",
            "Epoch 00043: val_categorical_accuracy did not improve from 0.57857\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.7737 - categorical_accuracy: 0.6143 - val_loss: 1.8085 - val_categorical_accuracy: 0.5643\n",
            "Epoch 44/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.8732 - categorical_accuracy: 0.6500\n",
            "Epoch 00044: val_categorical_accuracy improved from 0.57857 to 0.59286, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.7617 - categorical_accuracy: 0.6476 - val_loss: 1.7978 - val_categorical_accuracy: 0.5929\n",
            "Epoch 45/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7473 - categorical_accuracy: 0.6000\n",
            "Epoch 00045: val_categorical_accuracy did not improve from 0.59286\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.7525 - categorical_accuracy: 0.6714 - val_loss: 1.7874 - val_categorical_accuracy: 0.5571\n",
            "Epoch 46/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7720 - categorical_accuracy: 0.7000\n",
            "Epoch 00046: val_categorical_accuracy improved from 0.59286 to 0.60714, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.7414 - categorical_accuracy: 0.6905 - val_loss: 1.7772 - val_categorical_accuracy: 0.6071\n",
            "Epoch 47/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.7060 - categorical_accuracy: 0.9000\n",
            "Epoch 00047: val_categorical_accuracy did not improve from 0.60714\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 1.7291 - categorical_accuracy: 0.6833 - val_loss: 1.7665 - val_categorical_accuracy: 0.6071\n",
            "Epoch 48/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.8983 - categorical_accuracy: 0.6000\n",
            "Epoch 00048: val_categorical_accuracy improved from 0.60714 to 0.63571, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.7194 - categorical_accuracy: 0.7048 - val_loss: 1.7558 - val_categorical_accuracy: 0.6357\n",
            "Epoch 49/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.6263 - categorical_accuracy: 0.5500\n",
            "Epoch 00049: val_categorical_accuracy did not improve from 0.63571\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 1.7091 - categorical_accuracy: 0.6881 - val_loss: 1.7460 - val_categorical_accuracy: 0.6071\n",
            "Epoch 50/50\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 1.4086 - categorical_accuracy: 0.8500\n",
            "Epoch 00050: val_categorical_accuracy improved from 0.63571 to 0.65000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class.h5\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6991 - categorical_accuracy: 0.7310 - val_loss: 1.7368 - val_categorical_accuracy: 0.6500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.7368 - categorical_accuracy: 0.6500\n",
            "Test accuracy on target dataset = 0.6499999761581421\n",
            "5/5 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "kiUu9sP3QZt-",
        "outputId": "d732be73-d1e6-4cd6-fa6e-b990df494a0c"
      },
      "source": [
        "cm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>classfication_accuracies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Samples</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n",
              "0              10   0   0   0   0  ...   0   0   0   0                     100.0\n",
              "1               0   9   0   0   1  ...   0   0   0   0                      90.0\n",
              "2               0   0   5   0   0  ...   0   0   0   0                      50.0\n",
              "3               0   9   0   1   0  ...   0   0   0   0                      10.0\n",
              "4               0   1   0   0   9  ...   0   0   0   0                      90.0\n",
              "5               0   9   0   0   1  ...   0   0   0   0                       0.0\n",
              "6               7   0   0   0   0  ...   0   0   0   0                      30.0\n",
              "7               0   0   0   0   0  ...   0   0   0   0                     100.0\n",
              "8               0   7   0   0   0  ...   0   0   0   0                      30.0\n",
              "9               0   0   0   0   0  ...   0   0   1   0                      90.0\n",
              "10              0   0   0   0   0  ...   2   8   0   0                      20.0\n",
              "11              0   0   0   0   0  ...   0  10   0   0                     100.0\n",
              "12              0   0   0   0   0  ...   0   0  10   0                     100.0\n",
              "13              0   0   0   0   0  ...   0   0   0  10                     100.0\n",
              "Total Samples  10  10  10  10  10  ...  10  10  10  10                         -\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELmDXaPiFI6"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq9pzsvkjzTY"
      },
      "source": [
        "source_model = load_model('/content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/sub_models/indian_pines _with_200_samples_from_each_class_in_training_set.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7WIaczlPA_"
      },
      "source": [
        "source_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_gANYnrll4d"
      },
      "source": [
        "def model_transfer(input_shape, classes):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = Dense(256, input_dim = X_input.shape, activation='relu', name = 'fc_256',\n",
        "              kernel_initializer = glorot_uniform(seed = 0))(X_input)\n",
        "    X = Dense(classes, input_dim = X.shape, activation='softmax', name='fc' + str(classes),\n",
        "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name = \"model_transfer\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0d_bMoVxlO5"
      },
      "source": [
        "X_train, X_test, y_train, y_test, counts_test_set, class_samples = sample_extraction(classes, \n",
        "                                                                                    cube_size = 20, \n",
        "                                                                                    data = data, \n",
        "                                                                                    ground_truth = ground_truth, \n",
        "                                                                                    cubes = [], \n",
        "                                                                                    output_class = [], \n",
        "                                                                                    training_samples_from_each_class = 30,\n",
        "                                                                                    overlap_ratio = 1, \n",
        "                                                                                    channels = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNphlVTi32w_"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5jgEldP4_dh"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-h1Eps5Jp7"
      },
      "source": [
        "X_train_transfer = source_model.predict(X_train)\n",
        "X_test_transfer = source_model.predict(X_test)\n",
        "print('X_train_transfer => ' + str(X_train_transfer.shape) + '\\n' +\n",
        "      'X_test_transfer  => ' + str(X_test_transfer.shape) + '\\n' +\n",
        "      'y_train => ' + str(y_train.shape) + '\\n' +\n",
        "      'y_test  => ' + str(y_test.shape) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TA22-wG5x9A"
      },
      "source": [
        "target_model = model_transfer(input_shape = X_train_transfer[0].shape, classes = len(y_train[0]))\n",
        "target_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtMeTvfN6QVQ"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/My Drive/Hyperspectral_Image_Classification/code/Trained_models/transferred_models/fine_tune_on_botswana.h5',\n",
        "                                    monitor = 'val_categorical_accuracy', \n",
        "                                    verbose = 1, \n",
        "                                    save_best_only = True)\n",
        "target_model.compile(optimizer = keras.optimizers.SGD(lr = 0.0001, \n",
        "                                                      decay = 1e-5, \n",
        "                                                      momentum = 0.9, \n",
        "                                                      nesterov = True),\n",
        "                    loss = 'categorical_crossentropy', \n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "target_model.fit(X_train_transfer, y_train, \n",
        "                 epochs = 100, \n",
        "                 batch_size = 20,\n",
        "                 validation_data = (X_test_transfer, y_test), \n",
        "                 verbose = 1, \n",
        "                 callbacks = [model_checkpoint])\n",
        "\n",
        "preds = target_model.evaluate(X_test_transfer, y_test)\n",
        "print(\"Test Accuracy = \" + str(preds[1]))\n",
        "y_pred = target_model.predict(X_test_transfer, verbose = 1)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "\n",
        "print(confusion_matrix)\n",
        "print(counts_test_set)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mD74LcS_aKo"
      },
      "source": [
        "import pandas as pd\n",
        "d = pd.DataFrame(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jM_Q9_-qn0a"
      },
      "source": [
        "d.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hm_bLA7qz-U"
      },
      "source": [
        "d.index = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVC_77uyn_E"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9RMzWzLq5LN"
      },
      "source": [
        "counts_test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRqMIQVgtIJ6"
      },
      "source": [
        "d = d.append(pd.DataFrame(counts_test_set.reshape(1,-1), columns = list(d)), ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ORBN6IpzE1k"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19-4Se_etc_C"
      },
      "source": [
        "d = d.rename(index={d.index[-1]: 'Total Samples'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOM7aTVFvGcE"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfzGxtm4yIqy"
      },
      "source": [
        "correct_predictions = np.diag(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjmqRfdvKvzL"
      },
      "source": [
        "correct_predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x5fwYxrKyuz"
      },
      "source": [
        "counts_test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWzmyd3LDVz"
      },
      "source": [
        "np.divide(correct_predictions/counts_test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTf2xLTIOz4L"
      },
      "source": [
        "classification_accuracies = np.round((correct_predictions / counts_test_set) * 100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Pkao5ln0RamH",
        "outputId": "e95d9950-950d-421d-87a8-85bb42607b2b"
      },
      "source": [
        "d['classfication_accuracies'] = np.round(classification_accuracies,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-86c3635b1a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classfication_accuracies'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_accuracies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mround_\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mround_\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3597\u001b[0m     \u001b[0maround\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msee\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3598\u001b[0m     \"\"\"\n\u001b[0;32m-> 3599\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maround\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36maround\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \"\"\"\n\u001b[0;32m-> 3224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'round'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Call _wrapit from within the except clause to ensure a potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# exception has a traceback chain.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0JbXBaMSFUm"
      },
      "source": [
        "classification_accuracies = np.append(classification_accuracies, '-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XClccgjwb-Fg",
        "outputId": "0fb3c997-90db-43bb-f168-cb83134dd6bb"
      },
      "source": [
        "classification_accuracies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 84.17,  98.59,  53.85,  29.73,  33.05,  17.99,  86.46,   1.16,\n",
              "        24.3 ,  98.17,  79.27, 100.  ,  58.77,  75.38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "FVphm5quaxN7",
        "outputId": "5a48f0d0-0192-418c-fb6a-14c36c1e3e7f"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>classfication_accuracies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>202</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84.16666666666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>98.59154929577466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53.84615384615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>29.72972972972973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>79</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>33.054393305439326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>17.99163179916318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>198</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86.46288209606988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1.1560693641618496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>24.295774647887324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>214</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>98.1651376146789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>79.26829268292683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>124</td>\n",
              "      <td>0</td>\n",
              "      <td>58.767772511848335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>75.38461538461539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Samples</th>\n",
              "      <td>240</td>\n",
              "      <td>71</td>\n",
              "      <td>221</td>\n",
              "      <td>185</td>\n",
              "      <td>239</td>\n",
              "      <td>239</td>\n",
              "      <td>229</td>\n",
              "      <td>173</td>\n",
              "      <td>284</td>\n",
              "      <td>218</td>\n",
              "      <td>246</td>\n",
              "      <td>103</td>\n",
              "      <td>211</td>\n",
              "      <td>65</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 1   2    3    4  ...   12   13  14  classfication_accuracies\n",
              "0              202  14    0    0  ...    0    0   0         84.16666666666667\n",
              "1                0  70    0    0  ...    0    0   0         98.59154929577466\n",
              "2                2   0  119   42  ...    0    0   0         53.84615384615385\n",
              "3                0   0   20   55  ...    0   30   0         29.72972972972973\n",
              "4               16  43    0    5  ...   16   36   0        33.054393305439326\n",
              "5                0  35    0    2  ...   45   99   0         17.99163179916318\n",
              "6               31   0    0    0  ...    0    0   0         86.46288209606988\n",
              "7                0   0   14    0  ...  134   12   0        1.1560693641618496\n",
              "8                0  82    0   63  ...    0   66   0        24.295774647887324\n",
              "9                0   0    0    0  ...    0    0   0          98.1651376146789\n",
              "10               0   0    0    0  ...    0    0   0         79.26829268292683\n",
              "11               0   0    0    0  ...  103    0   0                     100.0\n",
              "12               0   0    0    0  ...   87  124   0        58.767772511848335\n",
              "13               0  13    0    0  ...    0    0  49         75.38461538461539\n",
              "Total Samples  240  71  221  185  ...  103  211  65                         -\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3_C43FbH6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}