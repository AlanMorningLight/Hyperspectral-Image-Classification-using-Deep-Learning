{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, BatchNormalization, Flatten, Conv3D, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick samples belonging to all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_samples_from_class(Class, cube_size, data, ground_truth, cubes, output_class, overlap_ratio, channels):\n",
    "    \n",
    "    ## Get row and column position from ground truth image for class\n",
    "    class_indices = np.where(ground_truth == Class)\n",
    "    \n",
    "    ## Remove border position class samples\n",
    "    class_cube_positions = [[class_indices[0][i], class_indices[1][i]] for i in range(len(class_indices[0])) \n",
    "                        if len(ground_truth) - np.ceil(cube_size / 2) > class_indices[0][i] > np.ceil(cube_size / 2) \n",
    "                        and len(ground_truth[0]) - np.ceil(cube_size / 2) > class_indices[1][i] > np.ceil(cube_size / 2)]\n",
    "    \n",
    "    #print('Length of class positions', len(class_cube_positions))\n",
    "    \n",
    "    extracted_cubes = [[class_cube_positions[0][0], class_cube_positions[0][1]]]\n",
    "    \n",
    "    ## Form the first cube for this class\n",
    "    cubes.append(np.array(data[:channels, \n",
    "                        class_cube_positions[0][0] - int(cube_size / 2):class_cube_positions[0][0] + int(cube_size / 2),\n",
    "                       (class_cube_positions[0][1] - int(cube_size / 2)):class_cube_positions[0][1] + int(cube_size / 2)]))\n",
    "    \n",
    "    ## Output class value\n",
    "    output_class.append(Class)\n",
    "        \n",
    "    ## Pick cube/sample if it satisfies the criteria for the overlap ratio\n",
    "    for i in range(1, len(class_cube_positions)):\n",
    "        \n",
    "        distance_vector = [] ## Calculate distance from existing sample to the next candiddate cube sample\n",
    "        \n",
    "        for k in range(len(extracted_cubes)):\n",
    "            \n",
    "            distance = math.sqrt((class_cube_positions[i][0] - extracted_cubes[k][0]) ** 2 + \n",
    "                                 (class_cube_positions[i][1] - extracted_cubes[k][1]) ** 2)\n",
    "            \n",
    "            distance_vector.append(distance)\n",
    "            \n",
    "        if np.min(distance_vector) > int(cube_size * (1 - overlap_ratio)):\n",
    "            \n",
    "            cubes.append(np.array(data[:channels, \n",
    "                             class_cube_positions[i][0] - int(cube_size / 2):class_cube_positions[i][0] + int(cube_size / 2),\n",
    "                            (class_cube_positions[i][1] - int(cube_size / 2)):class_cube_positions[i][1] + int(cube_size / 2)]))\n",
    "            \n",
    "            output_class.append(Class)\n",
    "            extracted_cubes.append([class_cube_positions[i][0], class_cube_positions[i][1]])\n",
    "            \n",
    "    return cubes, output_class, extracted_cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect and combine samples from all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples_from_all_classes(classes, cube_size, data, ground_truth, cubes, output_class, overlap_ratio, channels):\n",
    "    \n",
    "    class_samples = []\n",
    "    \n",
    "    for Class in classes:\n",
    "        cubes, output_class, extracted_cubes = pick_samples_from_class(Class, cube_size, data, ground_truth, cubes, \n",
    "                                                                       output_class,overlap_ratio, channels)\n",
    "        class_samples.append(len(extracted_cubes))\n",
    "    \n",
    "    cubes = np.array(cubes)\n",
    "    output_class = np.array(output_class)\n",
    "    \n",
    "    return cubes, output_class, class_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_test_set(for_training_set, class_samples, cubes, output_class):\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "\n",
    "    train_and_test_from_each_class = [0]\n",
    "    for_test = 0\n",
    "\n",
    "    ## (for_train) samples from each class for the training set, rest of the samples from that class to the test set\n",
    "    for i in range(len(class_samples)):\n",
    "\n",
    "        train_and_test_from_each_class.append(for_training_set + for_test)\n",
    "        train_and_test_from_each_class.append(class_samples[i] + for_test)\n",
    "\n",
    "        for_test = class_samples[i] + for_test\n",
    "\n",
    "    for i in range(1, len(train_and_test_from_each_class)):\n",
    "        if i % 2 != 0:\n",
    "            for j in range(train_and_test_from_each_class[i - 1], train_and_test_from_each_class[i]):\n",
    "                X_train.append(cubes[j])\n",
    "                Y_train.append(output_class[j])\n",
    "        else:\n",
    "            for k in range(train_and_test_from_each_class[i - 1], train_and_test_from_each_class[i]):\n",
    "                X_test.append(cubes[k])\n",
    "                Y_test.append(output_class[k])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    ## Shuffle Training Set\n",
    "    samples_train = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(samples_train)\n",
    "\n",
    "    X_train = X_train[samples_train]\n",
    "    Y_train = Y_train[samples_train]\n",
    "\n",
    "    ## Shuffle Test Set\n",
    "    samples_test = np.arange(X_test.shape[0])\n",
    "    np.random.shuffle(samples_test)\n",
    "\n",
    "    X_test = X_test[samples_test]\n",
    "    Y_test = Y_test[samples_test]\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=4)\n",
    "    X_test = np.expand_dims(X_test, axis=4)\n",
    "\n",
    "    values, counts = np.unique(Y_test, return_counts=True)\n",
    "\n",
    "    print(\"Samples per class: \" + str(class_samples) + '\\n'\n",
    "          \"Total number of samples is \" + str(np.sum(class_samples)) + '.\\n')\n",
    "\n",
    "    print(\"unique classes in test: \" + str(values) + '\\n'\n",
    "          \"Total number of samples in test set is \" + str(np.sum(counts)) + '.\\n'\n",
    "          \"Samples per class in test set: \" + str(counts) + '\\n')\n",
    "\n",
    "    ## one hot encode labels\n",
    "    onehot_encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "    Y_train = Y_train.reshape(len(Y_train), 1)\n",
    "    Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "\n",
    "    Y_train = onehot_encoder.fit_transform(Y_train)\n",
    "    Y_test = onehot_encoder.fit_transform(Y_test)\n",
    "    \n",
    "    print('Training set shape',X_train.shape)\n",
    "    print('Training labels', Y_train.shape)\n",
    "    print('Test set shape', X_test.shape)\n",
    "    print('Test set labels', Y_test.shape)\n",
    "\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, counts, class_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_training(classes, cube_size, data, ground_truth, cubes, output_class, for_training_set,\n",
    "                              overlap_ratio, channels):\n",
    "    \n",
    "    cubes, output_class, class_samples = collect_samples_from_all_classes(classes, \n",
    "                                                                      cube_size, \n",
    "                                                                      data,  \n",
    "                                                                      ground_truth, \n",
    "                                                                      cubes, \n",
    "                                                                      output_class , \n",
    "                                                                      overlap_ratio, \n",
    "                                                                      channels)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test, class_samples, counts = training_and_test_set(for_training_set, \n",
    "                                                                                    class_samples, \n",
    "                                                                                    cubes,\n",
    "                                                                                    output_class)\n",
    "    return X_train, X_test, Y_train, Y_test, class_samples, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Hyperspectral Dataset - Pavia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "uPavia = sio.loadmat('PaviaU.mat')\n",
    "gt_uPavia = sio.loadmat('PaviaU_gt.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pavia = uPavia['paviaU']\n",
    "ground_truth = gt_uPavia['paviaU_gt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 340, 103)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pavia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.moveaxis(data_pavia, 2, 0) # channels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 610, 340)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 340)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>164624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  samples\n",
       "0      0   164624\n",
       "1      1     6631\n",
       "2      2    18649\n",
       "3      3     2099\n",
       "4      4     3064\n",
       "5      5     1345\n",
       "6      6     5029\n",
       "7      7     1330\n",
       "8      8     3682\n",
       "9      9      947"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = pd.DataFrame(np.unique(ground_truth, return_counts = True))\n",
    "class_distribution = class_distribution.transpose()\n",
    "class_distribution.columns = ['class','samples']\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes , counts = np.unique(ground_truth, return_counts = True)\n",
    "classes = classes[1:] ## Not considering background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: [5975, 15062, 1742, 2854, 1345, 5029, 1330, 3682, 940]\n",
      "Total number of samples is 37959.\n",
      "\n",
      "unique classes in test: [1 2 3 4 5 6 7 8 9]\n",
      "Total number of samples in test set is 32559.\n",
      "Samples per class in test set: [ 5375 14462  1142  2254   745  4429   730  3082   340]\n",
      "\n",
      "Training set shape (5400, 64, 20, 20, 1)\n",
      "Training labels (5400, 9)\n",
      "Test set shape (32559, 64, 20, 20, 1)\n",
      "Test set labels (32559, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, class_samples, counts = prepare_data_for_training(classes = classes, \n",
    "                                                                                cube_size = 20, \n",
    "                                                                                data = data, \n",
    "                                                                                ground_truth = ground_truth, \n",
    "                                                                                cubes = [], \n",
    "                                                                                output_class = [], \n",
    "                                                                                for_training_set = 600,\n",
    "                                                                                overlap_ratio = 1, \n",
    "                                                                                channels = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5375, 14462,  1142,  2254,   745,  4429,   730,  3082,   340])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_samples # samples extracted for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>samples</th>\n",
       "      <th>samples_extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6631</td>\n",
       "      <td>5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18649</td>\n",
       "      <td>14462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2099</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3064</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1345</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5029</td>\n",
       "      <td>4429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1330</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3682</td>\n",
       "      <td>3082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>947</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  samples  samples_extracted\n",
       "1      1     6631               5375\n",
       "2      2    18649              14462\n",
       "3      3     2099               1142\n",
       "4      4     3064               2254\n",
       "5      5     1345                745\n",
       "6      6     5029               4429\n",
       "7      7     1330                730\n",
       "8      8     3682               3082\n",
       "9      9      947                340"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = class_distribution[1:]\n",
    "class_distribution['samples_extracted'] = class_samples\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37959, 37959)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Total samples extracted\n",
    "len(cubes), len(output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
