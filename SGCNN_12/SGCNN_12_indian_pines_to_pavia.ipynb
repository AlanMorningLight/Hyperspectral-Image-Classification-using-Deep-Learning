{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SGCNN_12_indian_pines_to_botswana.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_nG8NlV-lz-"},"source":["## Set up google colab environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bq_kqWQtg0f","executionInfo":{"status":"ok","timestamp":1608667829317,"user_tz":480,"elapsed":28867,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0e3fd083-565b-420a-dd9a-9bd5d9537289"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK95udG-qHAy","executionInfo":{"status":"ok","timestamp":1608667832770,"user_tz":480,"elapsed":654,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn-wRAH4t3WY","executionInfo":{"status":"ok","timestamp":1608667838561,"user_tz":480,"elapsed":4812,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["from SGCNN_12_Utils import *\n","import scipy.io as sio"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky2Qzuw_qDdS"},"source":["## Load Indian Pines Dataset - Source"]},{"cell_type":"code","metadata":{"id":"svwF-yzh-l0N","executionInfo":{"status":"ok","timestamp":1608667847149,"user_tz":480,"elapsed":2834,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uIndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_corrected.mat')\n","gt_IndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_gt.mat')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLGpYj4P-l0N","executionInfo":{"status":"ok","timestamp":1608667850838,"user_tz":480,"elapsed":1102,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_source = uIndianPines['indian_pines_corrected']\n","ground_truth_source = gt_IndianPines['indian_pines_gt']"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHQe_Xhwza79","executionInfo":{"status":"ok","timestamp":1608667852073,"user_tz":480,"elapsed":505,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"e84bfd18-9a1c-4673-d765-cb9815903973"},"source":["data_source.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145, 200)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAjjOxj3qDdb","executionInfo":{"status":"ok","timestamp":1608667854223,"user_tz":480,"elapsed":1475,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"fe6a635e-3062-4fe8-82a1-faac8837395b"},"source":["ground_truth_source.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"wmLGB_VlWx6m"},"source":["# Load target dataset"]},{"cell_type":"code","metadata":{"id":"qu6T10joWpmQ","executionInfo":{"status":"ok","timestamp":1608667861906,"user_tz":480,"elapsed":3083,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uBotswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana.mat')\n","gt_Botswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana_gt.mat')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"09gPGGX8W2Us","executionInfo":{"status":"ok","timestamp":1608667861909,"user_tz":480,"elapsed":2080,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_target = uBotswana['Botswana']\n","ground_truth_target = gt_Botswana['Botswana_gt']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qG_LxbHeXBVQ","executionInfo":{"status":"ok","timestamp":1608667861909,"user_tz":480,"elapsed":1191,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"42e3e6a5-dd1b-453a-bb44-f4f18e5f997a"},"source":["data_target.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256, 145)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYillUc_XDKC","executionInfo":{"status":"ok","timestamp":1608667861910,"user_tz":480,"elapsed":509,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"61513430-5b35-472f-9ce2-6a70be3cb04e"},"source":["ground_truth_target.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"5WxjgWNGqDdc"},"source":["## Distrubution of samples for each class in Source"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"yFA7eqA7qDdd","executionInfo":{"status":"ok","timestamp":1608667864321,"user_tz":480,"elapsed":698,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"71d213c0-6f87-466b-ff3f-14b893fc2be9"},"source":["class_distribution_source = pd.DataFrame(np.unique(ground_truth_source, return_counts = True))\n","class_distribution_source = class_distribution_source.transpose()\n","class_distribution_source.columns = ['class','samples']\n","class_distribution_source"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>830</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>483</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>730</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>478</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>972</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2455</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>1265</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>386</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0    10776\n","1       1       46\n","2       2     1428\n","3       3      830\n","4       4      237\n","5       5      483\n","6       6      730\n","7       7       28\n","8       8      478\n","9       9       20\n","10     10      972\n","11     11     2455\n","12     12      593\n","13     13      205\n","14     14     1265\n","15     15      386\n","16     16       93"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zTsq-yPqDdd","executionInfo":{"status":"ok","timestamp":1608667866070,"user_tz":480,"elapsed":1510,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"2f55731a-47bf-47d4-a480-76200b82504d"},"source":["classes_source , counts_source = np.unique(ground_truth_source, return_counts = True)\n","classes_source = classes_source[[2,3,5,6,8,10,11,12,14]] ## Dropping classes with small number of samples\n","classes_source"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2,  3,  5,  6,  8, 10, 11, 12, 14], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"lwQmdin9Xmeg"},"source":["# Class distribution of samples in Target"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"8EjIMOQHXU3h","executionInfo":{"status":"ok","timestamp":1608667868054,"user_tz":480,"elapsed":1869,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"f321bac1-276b-4c12-f4b9-03d2a9d3ed1c"},"source":["class_distribution_target = pd.DataFrame(np.unique(ground_truth_target, return_counts = True))\n","class_distribution_target = class_distribution_target.transpose()\n","class_distribution_target.columns = ['class','samples']\n","class_distribution_target"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>374608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>270</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>215</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>259</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>203</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>314</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>248</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>305</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>268</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0   374608\n","1       1      270\n","2       2      101\n","3       3      251\n","4       4      215\n","5       5      269\n","6       6      269\n","7       7      259\n","8       8      203\n","9       9      314\n","10     10      248\n","11     11      305\n","12     12      181\n","13     13      268\n","14     14       95"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgE2FPXbXtt9","executionInfo":{"status":"ok","timestamp":1608667868372,"user_tz":480,"elapsed":1287,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"2e161e20-ca20-41a5-d371-17a13e05dceb"},"source":["classes_target , counts_target = np.unique(ground_truth_target, return_counts = True)\n","classes_target = classes_target[1:] ## Dropping classes with small number of samples\n","classes_target"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n","      dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"l_PESscnqDde"},"source":["## Source : Indian Pines\n","\n","## Train model for samples extracted with different overlap ratios and a percent of samples picked from each class to be present in the training set. \n","\n","## Model except the final fully connected layer is saved for transfer learning."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vc1sJwRqDdf","executionInfo":{"status":"ok","timestamp":1608672304351,"user_tz":480,"elapsed":4427146,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"18344b86-5432-44ae-f2b6-48b857dab6e5"},"source":["pretrain_results = pretrain_source_models(percentages = [60,70,80,90],\n","                                          classes = classes_source,\n","                                          cube_size = 20,\n","                                          overlap_ratios = [0.8,0.9,1],\n","                                          data = data_source,\n","                                          ground_truth = ground_truth_source,\n","                                          batch_size = 20,\n","                                          channels = 64,\n","                                          epochs = 100,\n","                                          Verbosity = 1,\n","                                          accuracies = [],\n","                                          learning_rate = 0.0001,\n","                                          source_dataset = 'indian_pines')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","conv2d_240 (Conv2D)             (None, 20, 20, 8)    584         conv2d_239[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_241 (Conv2D)             (None, 20, 20, 8)    584         lambda_102[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_244 (Conv2D)             (None, 20, 20, 8)    584         conv2d_243[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 20, 20, 64)   0           conv2d_229[0][0]                 \n","                                                                 conv2d_232[0][0]                 \n","                                                                 conv2d_233[0][0]                 \n","                                                                 conv2d_236[0][0]                 \n","                                                                 conv2d_237[0][0]                 \n","                                                                 conv2d_240[0][0]                 \n","                                                                 conv2d_241[0][0]                 \n","                                                                 conv2d_244[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 20, 20, 64)   256         concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 20, 20, 64)   0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_24 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_73[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_12 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_24[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_12 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_12[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_25 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 20, 20, 64)   256         tf.reshape_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 20, 20, 64)   0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_245 (Conv2D)             (None, 20, 20, 128)  8320        activation_74[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_246 (Conv2D)             (None, 20, 20, 128)  8320        input_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 20, 20, 128)  512         conv2d_245[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 20, 20, 128)  512         conv2d_246[0][0]                 \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 20, 20, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 20, 20, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 20, 20, 128)  0           activation_75[0][0]              \n","                                                                 activation_76[0][0]              \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 20, 20, 128)  0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_247 (Conv2D)             (None, 20, 20, 128)  16512       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 20, 20, 128)  512         conv2d_247[0][0]                 \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 20, 20, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","lambda_105 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_107 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_109 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_111 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_249 (Conv2D)             (None, 20, 20, 16)   2320        lambda_105[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_253 (Conv2D)             (None, 20, 20, 16)   2320        lambda_107[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_257 (Conv2D)             (None, 20, 20, 16)   2320        lambda_109[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_261 (Conv2D)             (None, 20, 20, 16)   2320        lambda_111[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_104 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_250 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_249[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_106 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_254 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_253[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_108 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_258 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_257[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_110 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_262 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_261[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_248 (Conv2D)             (None, 20, 20, 16)   2320        lambda_104[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_251 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_250[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_252 (Conv2D)             (None, 20, 20, 16)   2320        lambda_106[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_255 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_254[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_256 (Conv2D)             (None, 20, 20, 16)   2320        lambda_108[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_259 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_258[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_260 (Conv2D)             (None, 20, 20, 16)   2320        lambda_110[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_263 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_262[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 20, 20, 128)  0           conv2d_248[0][0]                 \n","                                                                 conv2d_251[0][0]                 \n","                                                                 conv2d_252[0][0]                 \n","                                                                 conv2d_255[0][0]                 \n","                                                                 conv2d_256[0][0]                 \n","                                                                 conv2d_259[0][0]                 \n","                                                                 conv2d_260[0][0]                 \n","                                                                 conv2d_263[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 20, 20, 128)  512         concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 20, 20, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_26 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_79[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_13 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_26[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_13 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_13[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_27 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 20, 20, 128)  512         tf.reshape_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 20, 20, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_264 (Conv2D)             (None, 20, 20, 256)  33024       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_265 (Conv2D)             (None, 20, 20, 256)  33024       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 20, 20, 256)  1024        conv2d_264[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 20, 20, 256)  1024        conv2d_265[0][0]                 \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 20, 20, 256)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 20, 20, 256)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 20, 20, 256)  0           activation_81[0][0]              \n","                                                                 activation_82[0][0]              \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 20, 20, 256)  0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_6 (Glo (None, 256)          0           activation_83[0][0]              \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","157/157 [==============================] - 8s 30ms/step - loss: 9.0704 - categorical_accuracy: 0.2760 - val_loss: 8.8874 - val_categorical_accuracy: 0.1959\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.19593, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","157/157 [==============================] - 4s 26ms/step - loss: 8.5732 - categorical_accuracy: 0.4083 - val_loss: 8.4655 - val_categorical_accuracy: 0.5382\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.19593 to 0.53817, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","157/157 [==============================] - 4s 25ms/step - loss: 8.3746 - categorical_accuracy: 0.5072 - val_loss: 8.1677 - val_categorical_accuracy: 0.6832\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.53817 to 0.68321, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","157/157 [==============================] - 4s 26ms/step - loss: 8.2062 - categorical_accuracy: 0.5749 - val_loss: 7.9963 - val_categorical_accuracy: 0.7608\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.68321 to 0.76081, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","157/157 [==============================] - 4s 25ms/step - loss: 8.0750 - categorical_accuracy: 0.6071 - val_loss: 7.8636 - val_categorical_accuracy: 0.7646\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.76081 to 0.76463, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","157/157 [==============================] - 4s 28ms/step - loss: 7.9414 - categorical_accuracy: 0.6539 - val_loss: 7.7577 - val_categorical_accuracy: 0.7684\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.76463 to 0.76845, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","157/157 [==============================] - 4s 25ms/step - loss: 7.8246 - categorical_accuracy: 0.6889 - val_loss: 7.6668 - val_categorical_accuracy: 0.7583\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.76845\n","Epoch 8/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.7229 - categorical_accuracy: 0.6928 - val_loss: 7.5904 - val_categorical_accuracy: 0.7634\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.76845\n","Epoch 9/100\n","157/157 [==============================] - 4s 25ms/step - loss: 7.6430 - categorical_accuracy: 0.7127 - val_loss: 7.5351 - val_categorical_accuracy: 0.7748\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.76845 to 0.77481, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 10/100\n","157/157 [==============================] - 4s 25ms/step - loss: 7.5515 - categorical_accuracy: 0.7316 - val_loss: 7.4805 - val_categorical_accuracy: 0.7672\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.77481\n","Epoch 11/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.4675 - categorical_accuracy: 0.7458 - val_loss: 7.3821 - val_categorical_accuracy: 0.7697\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.77481\n","Epoch 12/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.3831 - categorical_accuracy: 0.7660 - val_loss: 7.3478 - val_categorical_accuracy: 0.7532\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.77481\n","Epoch 13/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.3190 - categorical_accuracy: 0.7729 - val_loss: 7.2615 - val_categorical_accuracy: 0.7697\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.77481\n","Epoch 14/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.2518 - categorical_accuracy: 0.7914 - val_loss: 7.2374 - val_categorical_accuracy: 0.7570\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.77481\n","Epoch 15/100\n","157/157 [==============================] - 4s 26ms/step - loss: 7.1797 - categorical_accuracy: 0.7892 - val_loss: 7.2190 - val_categorical_accuracy: 0.7379\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.77481\n","Epoch 16/100\n","157/157 [==============================] - 4s 25ms/step - loss: 7.1239 - categorical_accuracy: 0.8015 - val_loss: 7.1670 - val_categorical_accuracy: 0.7557\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.77481\n","Epoch 17/100\n","157/157 [==============================] - 4s 24ms/step - loss: 7.0327 - categorical_accuracy: 0.8186 - val_loss: 7.0551 - val_categorical_accuracy: 0.7812\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.77481 to 0.78117, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","157/157 [==============================] - 4s 27ms/step - loss: 6.9728 - categorical_accuracy: 0.8279 - val_loss: 7.0639 - val_categorical_accuracy: 0.7443\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.78117\n","Epoch 19/100\n","157/157 [==============================] - 4s 26ms/step - loss: 6.9033 - categorical_accuracy: 0.8357 - val_loss: 7.0840 - val_categorical_accuracy: 0.7112\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.78117\n","Epoch 20/100\n","157/157 [==============================] - 4s 26ms/step - loss: 6.8570 - categorical_accuracy: 0.8314 - val_loss: 6.9425 - val_categorical_accuracy: 0.7697\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.78117\n","Epoch 21/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.7950 - categorical_accuracy: 0.8431 - val_loss: 6.8597 - val_categorical_accuracy: 0.7710\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.78117\n","Epoch 22/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.7611 - categorical_accuracy: 0.8379 - val_loss: 6.8413 - val_categorical_accuracy: 0.7735\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.78117\n","Epoch 23/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.6778 - categorical_accuracy: 0.8583 - val_loss: 7.0379 - val_categorical_accuracy: 0.6985\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.78117\n","Epoch 24/100\n","157/157 [==============================] - 4s 26ms/step - loss: 6.6588 - categorical_accuracy: 0.8531 - val_loss: 7.0405 - val_categorical_accuracy: 0.6870\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.78117\n","Epoch 25/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.5805 - categorical_accuracy: 0.8675 - val_loss: 6.7940 - val_categorical_accuracy: 0.7417\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.78117\n","Epoch 26/100\n","157/157 [==============================] - 4s 27ms/step - loss: 6.5578 - categorical_accuracy: 0.8496 - val_loss: 6.6663 - val_categorical_accuracy: 0.7684\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.78117\n","Epoch 27/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.5051 - categorical_accuracy: 0.8652 - val_loss: 6.6193 - val_categorical_accuracy: 0.7812\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.78117\n","Epoch 28/100\n","157/157 [==============================] - 4s 24ms/step - loss: 6.4313 - categorical_accuracy: 0.8707 - val_loss: 6.5601 - val_categorical_accuracy: 0.7875\n","\n","Epoch 00028: val_categorical_accuracy improved from 0.78117 to 0.78753, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 29/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.4173 - categorical_accuracy: 0.8602 - val_loss: 6.5573 - val_categorical_accuracy: 0.7659\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.78753\n","Epoch 30/100\n","157/157 [==============================] - 4s 24ms/step - loss: 6.3411 - categorical_accuracy: 0.8798 - val_loss: 6.7934 - val_categorical_accuracy: 0.7010\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.78753\n","Epoch 31/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.3076 - categorical_accuracy: 0.8883 - val_loss: 6.6965 - val_categorical_accuracy: 0.7099\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.78753\n","Epoch 32/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.2539 - categorical_accuracy: 0.8786 - val_loss: 6.4720 - val_categorical_accuracy: 0.7837\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.78753\n","Epoch 33/100\n","157/157 [==============================] - 4s 26ms/step - loss: 6.2301 - categorical_accuracy: 0.8898 - val_loss: 6.5508 - val_categorical_accuracy: 0.7392\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.78753\n","Epoch 34/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.1731 - categorical_accuracy: 0.8785 - val_loss: 6.5744 - val_categorical_accuracy: 0.6705\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.78753\n","Epoch 35/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.1053 - categorical_accuracy: 0.8981 - val_loss: 9.5429 - val_categorical_accuracy: 0.4758\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.78753\n","Epoch 36/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.0503 - categorical_accuracy: 0.9061 - val_loss: 6.7465 - val_categorical_accuracy: 0.6234\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.78753\n","Epoch 37/100\n","157/157 [==============================] - 4s 25ms/step - loss: 6.0228 - categorical_accuracy: 0.9026 - val_loss: 6.3328 - val_categorical_accuracy: 0.7443\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.78753\n","Epoch 38/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.9748 - categorical_accuracy: 0.9122 - val_loss: 6.2627 - val_categorical_accuracy: 0.7621\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.78753\n","Epoch 39/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.9333 - categorical_accuracy: 0.9124 - val_loss: 6.2457 - val_categorical_accuracy: 0.7494\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.78753\n","Epoch 40/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.8912 - categorical_accuracy: 0.9157 - val_loss: 6.4093 - val_categorical_accuracy: 0.7226\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.78753\n","Epoch 41/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.8396 - categorical_accuracy: 0.9217 - val_loss: 6.2304 - val_categorical_accuracy: 0.7417\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.78753\n","Epoch 42/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.8147 - categorical_accuracy: 0.9118 - val_loss: 6.6934 - val_categorical_accuracy: 0.7099\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.78753\n","Epoch 43/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.7740 - categorical_accuracy: 0.9239 - val_loss: 6.1187 - val_categorical_accuracy: 0.7634\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.78753\n","Epoch 44/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.7556 - categorical_accuracy: 0.9122 - val_loss: 6.8863 - val_categorical_accuracy: 0.6310\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.78753\n","Epoch 45/100\n","157/157 [==============================] - 4s 29ms/step - loss: 5.7082 - categorical_accuracy: 0.9169 - val_loss: 6.2015 - val_categorical_accuracy: 0.7328\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.78753\n","Epoch 46/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.6513 - categorical_accuracy: 0.9267 - val_loss: 6.4425 - val_categorical_accuracy: 0.6972\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.78753\n","Epoch 47/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.6126 - categorical_accuracy: 0.9324 - val_loss: 6.0704 - val_categorical_accuracy: 0.7341\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.78753\n","Epoch 48/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.5563 - categorical_accuracy: 0.9404 - val_loss: 8.2367 - val_categorical_accuracy: 0.5420\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.78753\n","Epoch 49/100\n","157/157 [==============================] - 4s 26ms/step - loss: 5.5276 - categorical_accuracy: 0.9422 - val_loss: 6.3609 - val_categorical_accuracy: 0.6985\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.78753\n","Epoch 50/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.5225 - categorical_accuracy: 0.9243 - val_loss: 5.9848 - val_categorical_accuracy: 0.7354\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.78753\n","Epoch 51/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.4660 - categorical_accuracy: 0.9396 - val_loss: 6.0942 - val_categorical_accuracy: 0.7112\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.78753\n","Epoch 52/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.4288 - categorical_accuracy: 0.9392 - val_loss: 6.0724 - val_categorical_accuracy: 0.6934\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.78753\n","Epoch 53/100\n","157/157 [==============================] - 4s 24ms/step - loss: 5.4109 - categorical_accuracy: 0.9238 - val_loss: 5.9231 - val_categorical_accuracy: 0.7265\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.78753\n","Epoch 54/100\n","157/157 [==============================] - 4s 24ms/step - loss: 5.3478 - categorical_accuracy: 0.9454 - val_loss: 5.9935 - val_categorical_accuracy: 0.7087\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.78753\n","Epoch 55/100\n","157/157 [==============================] - 4s 24ms/step - loss: 5.3257 - categorical_accuracy: 0.9362 - val_loss: 8.3504 - val_categorical_accuracy: 0.4987\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.78753\n","Epoch 56/100\n","157/157 [==============================] - 4s 23ms/step - loss: 5.2787 - categorical_accuracy: 0.9470 - val_loss: 5.9987 - val_categorical_accuracy: 0.6845\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.78753\n","Epoch 57/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.2439 - categorical_accuracy: 0.9474 - val_loss: 6.3886 - val_categorical_accuracy: 0.6374\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.78753\n","Epoch 58/100\n","157/157 [==============================] - 4s 23ms/step - loss: 5.2154 - categorical_accuracy: 0.9528 - val_loss: 6.1633 - val_categorical_accuracy: 0.6972\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.78753\n","Epoch 59/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.1715 - categorical_accuracy: 0.9515 - val_loss: 6.3519 - val_categorical_accuracy: 0.6692\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.78753\n","Epoch 60/100\n","157/157 [==============================] - 4s 25ms/step - loss: 5.1503 - categorical_accuracy: 0.9510 - val_loss: 6.1101 - val_categorical_accuracy: 0.6781\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.78753\n","Epoch 61/100\n","157/157 [==============================] - 4s 27ms/step - loss: 5.1371 - categorical_accuracy: 0.9460 - val_loss: 5.6782 - val_categorical_accuracy: 0.7366\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.78753\n","Epoch 62/100\n","157/157 [==============================] - 4s 24ms/step - loss: 5.1205 - categorical_accuracy: 0.9415 - val_loss: 5.7749 - val_categorical_accuracy: 0.6947\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.78753\n","Epoch 63/100\n","157/157 [==============================] - 4s 23ms/step - loss: 5.0623 - categorical_accuracy: 0.9476 - val_loss: 6.9339 - val_categorical_accuracy: 0.5573\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.78753\n","Epoch 64/100\n","157/157 [==============================] - 4s 24ms/step - loss: 5.0264 - categorical_accuracy: 0.9536 - val_loss: 7.0241 - val_categorical_accuracy: 0.5725\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.78753\n","Epoch 65/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.9820 - categorical_accuracy: 0.9587 - val_loss: 5.7483 - val_categorical_accuracy: 0.7265\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.78753\n","Epoch 66/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.9355 - categorical_accuracy: 0.9619 - val_loss: 6.3824 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.78753\n","Epoch 67/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.9406 - categorical_accuracy: 0.9491 - val_loss: 6.3784 - val_categorical_accuracy: 0.6260\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.78753\n","Epoch 68/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.9081 - categorical_accuracy: 0.9554 - val_loss: 5.7937 - val_categorical_accuracy: 0.6590\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.78753\n","Epoch 69/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.8769 - categorical_accuracy: 0.9552 - val_loss: 5.8098 - val_categorical_accuracy: 0.7201\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.78753\n","Epoch 70/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.8286 - categorical_accuracy: 0.9663 - val_loss: 5.5004 - val_categorical_accuracy: 0.7303\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.78753\n","Epoch 71/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.8398 - categorical_accuracy: 0.9544 - val_loss: 7.9351 - val_categorical_accuracy: 0.5598\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.78753\n","Epoch 72/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.7719 - categorical_accuracy: 0.9598 - val_loss: 5.8959 - val_categorical_accuracy: 0.6997\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.78753\n","Epoch 73/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.7501 - categorical_accuracy: 0.9627 - val_loss: 5.3593 - val_categorical_accuracy: 0.7583\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.78753\n","Epoch 74/100\n","157/157 [==============================] - 4s 25ms/step - loss: 4.7216 - categorical_accuracy: 0.9599 - val_loss: 5.3985 - val_categorical_accuracy: 0.7201\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.78753\n","Epoch 75/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.6949 - categorical_accuracy: 0.9622 - val_loss: 5.5792 - val_categorical_accuracy: 0.6934\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.78753\n","Epoch 76/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.6639 - categorical_accuracy: 0.9676 - val_loss: 5.2097 - val_categorical_accuracy: 0.7583\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.78753\n","Epoch 77/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.6317 - categorical_accuracy: 0.9682 - val_loss: 5.2342 - val_categorical_accuracy: 0.7316\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.78753\n","Epoch 78/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.6132 - categorical_accuracy: 0.9618 - val_loss: 5.9877 - val_categorical_accuracy: 0.6336\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.78753\n","Epoch 79/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.5848 - categorical_accuracy: 0.9646 - val_loss: 5.3725 - val_categorical_accuracy: 0.6985\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.78753\n","Epoch 80/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.5590 - categorical_accuracy: 0.9641 - val_loss: 7.7254 - val_categorical_accuracy: 0.5598\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.78753\n","Epoch 81/100\n","157/157 [==============================] - 4s 27ms/step - loss: 4.5224 - categorical_accuracy: 0.9709 - val_loss: 6.4312 - val_categorical_accuracy: 0.5573\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.78753\n","Epoch 82/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.5076 - categorical_accuracy: 0.9663 - val_loss: 5.5147 - val_categorical_accuracy: 0.6896\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.78753\n","Epoch 83/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.4701 - categorical_accuracy: 0.9659 - val_loss: 5.3044 - val_categorical_accuracy: 0.7468\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.78753\n","Epoch 84/100\n","157/157 [==============================] - 4s 25ms/step - loss: 4.4592 - categorical_accuracy: 0.9651 - val_loss: 6.5942 - val_categorical_accuracy: 0.5483\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.78753\n","Epoch 85/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.4284 - categorical_accuracy: 0.9645 - val_loss: 5.6285 - val_categorical_accuracy: 0.6819\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.78753\n","Epoch 86/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.3885 - categorical_accuracy: 0.9731 - val_loss: 5.5179 - val_categorical_accuracy: 0.6209\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.78753\n","Epoch 87/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.3581 - categorical_accuracy: 0.9741 - val_loss: 5.4757 - val_categorical_accuracy: 0.6641\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.78753\n","Epoch 88/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.3414 - categorical_accuracy: 0.9743 - val_loss: 5.0484 - val_categorical_accuracy: 0.7214\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.78753\n","Epoch 89/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.3041 - categorical_accuracy: 0.9759 - val_loss: 4.8615 - val_categorical_accuracy: 0.7710\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.78753\n","Epoch 90/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.2768 - categorical_accuracy: 0.9770 - val_loss: 7.7870 - val_categorical_accuracy: 0.5522\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.78753\n","Epoch 91/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.2623 - categorical_accuracy: 0.9738 - val_loss: 5.0185 - val_categorical_accuracy: 0.7188\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.78753\n","Epoch 92/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.2420 - categorical_accuracy: 0.9704 - val_loss: 5.3352 - val_categorical_accuracy: 0.6450\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.78753\n","Epoch 93/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.2126 - categorical_accuracy: 0.9755 - val_loss: 5.3365 - val_categorical_accuracy: 0.6654\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.78753\n","Epoch 94/100\n","157/157 [==============================] - 4s 25ms/step - loss: 4.1762 - categorical_accuracy: 0.9818 - val_loss: 5.3910 - val_categorical_accuracy: 0.6959\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.78753\n","Epoch 95/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.1666 - categorical_accuracy: 0.9757 - val_loss: 5.2708 - val_categorical_accuracy: 0.6603\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.78753\n","Epoch 96/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.1412 - categorical_accuracy: 0.9758 - val_loss: 5.2119 - val_categorical_accuracy: 0.6412\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.78753\n","Epoch 97/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.1300 - categorical_accuracy: 0.9690 - val_loss: 5.0172 - val_categorical_accuracy: 0.6819\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.78753\n","Epoch 98/100\n","157/157 [==============================] - 4s 24ms/step - loss: 4.1113 - categorical_accuracy: 0.9730 - val_loss: 4.9454 - val_categorical_accuracy: 0.7532\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.78753\n","Epoch 99/100\n","157/157 [==============================] - 4s 25ms/step - loss: 4.0798 - categorical_accuracy: 0.9746 - val_loss: 5.6815 - val_categorical_accuracy: 0.6387\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.78753\n","Epoch 100/100\n","157/157 [==============================] - 4s 23ms/step - loss: 4.0534 - categorical_accuracy: 0.9782 - val_loss: 4.7163 - val_categorical_accuracy: 0.7913\n","\n","Epoch 00100: val_categorical_accuracy improved from 0.78753 to 0.79135, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","25/25 [==============================] - 1s 10ms/step - loss: 4.7163 - categorical_accuracy: 0.7913\n","Test Accuracy =  79.0\n","25/25 [==============================] - 1s 8ms/step\n","Model: \"model_13\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_228 (Conv2D)             (None, 20, 20, 64)   4160        input_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 20, 20, 64)   256         conv2d_228[0][0]                 \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 20, 20, 64)   0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","lambda_97 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_99 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_101 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_103 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_230 (Conv2D)             (None, 20, 20, 8)    584         lambda_97[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_234 (Conv2D)             (None, 20, 20, 8)    584         lambda_99[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_238 (Conv2D)             (None, 20, 20, 8)    584         lambda_101[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_242 (Conv2D)             (None, 20, 20, 8)    584         lambda_103[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_96 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_231 (Conv2D)             (None, 20, 20, 8)    584         conv2d_230[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_98 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_235 (Conv2D)             (None, 20, 20, 8)    584         conv2d_234[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_100 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_239 (Conv2D)             (None, 20, 20, 8)    584         conv2d_238[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_102 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_243 (Conv2D)             (None, 20, 20, 8)    584         conv2d_242[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_229 (Conv2D)             (None, 20, 20, 8)    584         lambda_96[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_232 (Conv2D)             (None, 20, 20, 8)    584         conv2d_231[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_233 (Conv2D)             (None, 20, 20, 8)    584         lambda_98[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_236 (Conv2D)             (None, 20, 20, 8)    584         conv2d_235[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_237 (Conv2D)             (None, 20, 20, 8)    584         lambda_100[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_240 (Conv2D)             (None, 20, 20, 8)    584         conv2d_239[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_241 (Conv2D)             (None, 20, 20, 8)    584         lambda_102[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_244 (Conv2D)             (None, 20, 20, 8)    584         conv2d_243[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 20, 20, 64)   0           conv2d_229[0][0]                 \n","                                                                 conv2d_232[0][0]                 \n","                                                                 conv2d_233[0][0]                 \n","                                                                 conv2d_236[0][0]                 \n","                                                                 conv2d_237[0][0]                 \n","                                                                 conv2d_240[0][0]                 \n","                                                                 conv2d_241[0][0]                 \n","                                                                 conv2d_244[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 20, 20, 64)   256         concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 20, 20, 64)   0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_24 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_73[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_12 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_24[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_12 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_12[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_25 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 20, 20, 64)   256         tf.reshape_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 20, 20, 64)   0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_245 (Conv2D)             (None, 20, 20, 128)  8320        activation_74[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_246 (Conv2D)             (None, 20, 20, 128)  8320        input_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 20, 20, 128)  512         conv2d_245[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 20, 20, 128)  512         conv2d_246[0][0]                 \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 20, 20, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 20, 20, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 20, 20, 128)  0           activation_75[0][0]              \n","                                                                 activation_76[0][0]              \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 20, 20, 128)  0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_247 (Conv2D)             (None, 20, 20, 128)  16512       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 20, 20, 128)  512         conv2d_247[0][0]                 \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 20, 20, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","lambda_105 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_107 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_109 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_111 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_249 (Conv2D)             (None, 20, 20, 16)   2320        lambda_105[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_253 (Conv2D)             (None, 20, 20, 16)   2320        lambda_107[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_257 (Conv2D)             (None, 20, 20, 16)   2320        lambda_109[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_261 (Conv2D)             (None, 20, 20, 16)   2320        lambda_111[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_104 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_250 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_249[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_106 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_254 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_253[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_108 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_258 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_257[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_110 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_262 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_261[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_248 (Conv2D)             (None, 20, 20, 16)   2320        lambda_104[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_251 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_250[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_252 (Conv2D)             (None, 20, 20, 16)   2320        lambda_106[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_255 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_254[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_256 (Conv2D)             (None, 20, 20, 16)   2320        lambda_108[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_259 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_258[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_260 (Conv2D)             (None, 20, 20, 16)   2320        lambda_110[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_263 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_262[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 20, 20, 128)  0           conv2d_248[0][0]                 \n","                                                                 conv2d_251[0][0]                 \n","                                                                 conv2d_252[0][0]                 \n","                                                                 conv2d_255[0][0]                 \n","                                                                 conv2d_256[0][0]                 \n","                                                                 conv2d_259[0][0]                 \n","                                                                 conv2d_260[0][0]                 \n","                                                                 conv2d_263[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 20, 20, 128)  512         concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 20, 20, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_26 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_79[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_13 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_26[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_13 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_13[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_27 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 20, 20, 128)  512         tf.reshape_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 20, 20, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_264 (Conv2D)             (None, 20, 20, 256)  33024       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_265 (Conv2D)             (None, 20, 20, 256)  33024       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 20, 20, 256)  1024        conv2d_264[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 20, 20, 256)  1024        conv2d_265[0][0]                 \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 20, 20, 256)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 20, 20, 256)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 20, 20, 256)  0           activation_81[0][0]              \n","                                                                 activation_82[0][0]              \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 20, 20, 256)  0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_6 (Glo (None, 256)          0           activation_83[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 0.9 and 90 percent samples from each class in training set \n","==============================================================================================================\n","\n","Samples per class: [683, 263, 162, 365, 179, 417, 1099, 210, 540]\n","Total number of samples is 3918.\n","\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in training set is 3523.\n","Samples per class in training set: [614 236 145 328 161 375 989 189 486]\n","\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in test set is 395.\n","Samples per class in test set: [ 69  27  17  37  18  42 110  21  54]\n","\n","X_train => (3523, 20, 20, 64)\n","X_test  => (395, 20, 20, 64)\n","y_train => (3523, 9)\n","y_test  => (395, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_266 (Conv2D)             (None, 20, 20, 64)   4160        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 20, 20, 64)   256         conv2d_266[0][0]                 \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 20, 20, 64)   0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","lambda_113 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_115 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_117 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_119 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_268 (Conv2D)             (None, 20, 20, 8)    584         lambda_113[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_272 (Conv2D)             (None, 20, 20, 8)    584         lambda_115[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_276 (Conv2D)             (None, 20, 20, 8)    584         lambda_117[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_280 (Conv2D)             (None, 20, 20, 8)    584         lambda_119[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_112 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_269 (Conv2D)             (None, 20, 20, 8)    584         conv2d_268[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_114 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_273 (Conv2D)             (None, 20, 20, 8)    584         conv2d_272[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_116 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_277 (Conv2D)             (None, 20, 20, 8)    584         conv2d_276[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_118 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_281 (Conv2D)             (None, 20, 20, 8)    584         conv2d_280[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_267 (Conv2D)             (None, 20, 20, 8)    584         lambda_112[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_270 (Conv2D)             (None, 20, 20, 8)    584         conv2d_269[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_271 (Conv2D)             (None, 20, 20, 8)    584         lambda_114[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_274 (Conv2D)             (None, 20, 20, 8)    584         conv2d_273[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_275 (Conv2D)             (None, 20, 20, 8)    584         lambda_116[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_278 (Conv2D)             (None, 20, 20, 8)    584         conv2d_277[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_279 (Conv2D)             (None, 20, 20, 8)    584         lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_282 (Conv2D)             (None, 20, 20, 8)    584         conv2d_281[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 20, 20, 64)   0           conv2d_267[0][0]                 \n","                                                                 conv2d_270[0][0]                 \n","                                                                 conv2d_271[0][0]                 \n","                                                                 conv2d_274[0][0]                 \n","                                                                 conv2d_275[0][0]                 \n","                                                                 conv2d_278[0][0]                 \n","                                                                 conv2d_279[0][0]                 \n","                                                                 conv2d_282[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 20, 20, 64)   256         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 20, 20, 64)   0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_28 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_85[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_14 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_28[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_14 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_14[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_29 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 20, 20, 64)   256         tf.reshape_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 20, 20, 64)   0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_283 (Conv2D)             (None, 20, 20, 128)  8320        activation_86[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_284 (Conv2D)             (None, 20, 20, 128)  8320        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 20, 20, 128)  512         conv2d_283[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 20, 20, 128)  512         conv2d_284[0][0]                 \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 20, 20, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 20, 20, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 20, 20, 128)  0           activation_87[0][0]              \n","                                                                 activation_88[0][0]              \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 20, 20, 128)  0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_285 (Conv2D)             (None, 20, 20, 128)  16512       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 20, 20, 128)  512         conv2d_285[0][0]                 \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 20, 20, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","lambda_121 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_123 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_125 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_127 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_287 (Conv2D)             (None, 20, 20, 16)   2320        lambda_121[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_291 (Conv2D)             (None, 20, 20, 16)   2320        lambda_123[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_295 (Conv2D)             (None, 20, 20, 16)   2320        lambda_125[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_299 (Conv2D)             (None, 20, 20, 16)   2320        lambda_127[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_120 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_288 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_287[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_122 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_292 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_291[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_124 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_296 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_295[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_126 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_300 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_299[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_286 (Conv2D)             (None, 20, 20, 16)   2320        lambda_120[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_289 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_288[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_290 (Conv2D)             (None, 20, 20, 16)   2320        lambda_122[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_293 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_292[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_294 (Conv2D)             (None, 20, 20, 16)   2320        lambda_124[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_297 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_296[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_298 (Conv2D)             (None, 20, 20, 16)   2320        lambda_126[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_301 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_300[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 20, 20, 128)  0           conv2d_286[0][0]                 \n","                                                                 conv2d_289[0][0]                 \n","                                                                 conv2d_290[0][0]                 \n","                                                                 conv2d_293[0][0]                 \n","                                                                 conv2d_294[0][0]                 \n","                                                                 conv2d_297[0][0]                 \n","                                                                 conv2d_298[0][0]                 \n","                                                                 conv2d_301[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 20, 20, 128)  512         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 20, 20, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_30 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_91[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_15 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_30[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_15 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_15[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_31 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 20, 20, 128)  512         tf.reshape_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 20, 20, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_302 (Conv2D)             (None, 20, 20, 256)  33024       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_303 (Conv2D)             (None, 20, 20, 256)  33024       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 20, 20, 256)  1024        conv2d_302[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 20, 20, 256)  1024        conv2d_303[0][0]                 \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 20, 20, 256)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 20, 20, 256)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 20, 20, 256)  0           activation_93[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 20, 20, 256)  0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_7 (Glo (None, 256)          0           activation_95[0][0]              \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_7[0][0] \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","177/177 [==============================] - 7s 26ms/step - loss: 9.3680 - categorical_accuracy: 0.1946 - val_loss: 8.8444 - val_categorical_accuracy: 0.4152\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.41519, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","177/177 [==============================] - 4s 24ms/step - loss: 8.5844 - categorical_accuracy: 0.4517 - val_loss: 8.4070 - val_categorical_accuracy: 0.6051\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.41519 to 0.60506, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","177/177 [==============================] - 4s 21ms/step - loss: 8.3758 - categorical_accuracy: 0.5180 - val_loss: 8.2113 - val_categorical_accuracy: 0.6228\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.60506 to 0.62278, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","177/177 [==============================] - 4s 24ms/step - loss: 8.2044 - categorical_accuracy: 0.5473 - val_loss: 8.0234 - val_categorical_accuracy: 0.6759\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.62278 to 0.67595, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","177/177 [==============================] - 4s 22ms/step - loss: 8.0562 - categorical_accuracy: 0.5815 - val_loss: 7.9036 - val_categorical_accuracy: 0.6911\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.67595 to 0.69114, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","177/177 [==============================] - 4s 22ms/step - loss: 7.9355 - categorical_accuracy: 0.6204 - val_loss: 7.7871 - val_categorical_accuracy: 0.7291\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.69114 to 0.72911, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","177/177 [==============================] - 4s 22ms/step - loss: 7.8151 - categorical_accuracy: 0.6417 - val_loss: 7.6824 - val_categorical_accuracy: 0.7494\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.72911 to 0.74937, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","177/177 [==============================] - 4s 23ms/step - loss: 7.7135 - categorical_accuracy: 0.6774 - val_loss: 7.5742 - val_categorical_accuracy: 0.7367\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.74937\n","Epoch 9/100\n","177/177 [==============================] - 4s 23ms/step - loss: 7.6001 - categorical_accuracy: 0.6941 - val_loss: 7.5488 - val_categorical_accuracy: 0.7241\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.74937\n","Epoch 10/100\n","177/177 [==============================] - 4s 21ms/step - loss: 7.5030 - categorical_accuracy: 0.7191 - val_loss: 7.4781 - val_categorical_accuracy: 0.7139\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.74937\n","Epoch 11/100\n","177/177 [==============================] - 4s 23ms/step - loss: 7.4186 - categorical_accuracy: 0.7267 - val_loss: 7.3403 - val_categorical_accuracy: 0.7367\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.74937\n","Epoch 12/100\n","177/177 [==============================] - 4s 24ms/step - loss: 7.3541 - categorical_accuracy: 0.7453 - val_loss: 7.2495 - val_categorical_accuracy: 0.7392\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.74937\n","Epoch 13/100\n","177/177 [==============================] - 4s 22ms/step - loss: 7.2741 - categorical_accuracy: 0.7408 - val_loss: 7.2259 - val_categorical_accuracy: 0.7367\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.74937\n","Epoch 14/100\n","177/177 [==============================] - 4s 23ms/step - loss: 7.1779 - categorical_accuracy: 0.7543 - val_loss: 7.1863 - val_categorical_accuracy: 0.7418\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.74937\n","Epoch 15/100\n","177/177 [==============================] - 4s 22ms/step - loss: 7.1025 - categorical_accuracy: 0.7658 - val_loss: 7.1042 - val_categorical_accuracy: 0.7266\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.74937\n","Epoch 16/100\n","177/177 [==============================] - 4s 25ms/step - loss: 7.0453 - categorical_accuracy: 0.7784 - val_loss: 7.1080 - val_categorical_accuracy: 0.6911\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.74937\n","Epoch 17/100\n","177/177 [==============================] - 4s 25ms/step - loss: 6.9633 - categorical_accuracy: 0.8012 - val_loss: 6.9462 - val_categorical_accuracy: 0.7671\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.74937 to 0.76709, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","177/177 [==============================] - 4s 23ms/step - loss: 6.9360 - categorical_accuracy: 0.7803 - val_loss: 6.8609 - val_categorical_accuracy: 0.7747\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.76709 to 0.77468, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","177/177 [==============================] - 4s 23ms/step - loss: 6.8333 - categorical_accuracy: 0.8071 - val_loss: 6.8255 - val_categorical_accuracy: 0.7772\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.77468 to 0.77722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 20/100\n","177/177 [==============================] - 4s 21ms/step - loss: 6.7990 - categorical_accuracy: 0.8083 - val_loss: 6.9292 - val_categorical_accuracy: 0.7114\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.77722\n","Epoch 21/100\n","177/177 [==============================] - 4s 22ms/step - loss: 6.7158 - categorical_accuracy: 0.8247 - val_loss: 6.7411 - val_categorical_accuracy: 0.7873\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.77722 to 0.78734, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 22/100\n","177/177 [==============================] - 4s 23ms/step - loss: 6.6601 - categorical_accuracy: 0.8317 - val_loss: 6.7141 - val_categorical_accuracy: 0.7671\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.78734\n","Epoch 23/100\n","177/177 [==============================] - 4s 24ms/step - loss: 6.5978 - categorical_accuracy: 0.8330 - val_loss: 6.6048 - val_categorical_accuracy: 0.7873\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.78734\n","Epoch 24/100\n","177/177 [==============================] - 4s 22ms/step - loss: 6.5125 - categorical_accuracy: 0.8484 - val_loss: 6.7712 - val_categorical_accuracy: 0.6886\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.78734\n","Epoch 25/100\n","177/177 [==============================] - 4s 23ms/step - loss: 6.5042 - categorical_accuracy: 0.8416 - val_loss: 6.7571 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.78734\n","Epoch 26/100\n","177/177 [==============================] - 4s 24ms/step - loss: 6.4109 - categorical_accuracy: 0.8598 - val_loss: 6.5652 - val_categorical_accuracy: 0.7063\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.78734\n","Epoch 27/100\n","177/177 [==============================] - 4s 22ms/step - loss: 6.3387 - categorical_accuracy: 0.8744 - val_loss: 6.4718 - val_categorical_accuracy: 0.7443\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.78734\n","Epoch 28/100\n","177/177 [==============================] - 4s 24ms/step - loss: 6.3145 - categorical_accuracy: 0.8676 - val_loss: 6.5205 - val_categorical_accuracy: 0.7291\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.78734\n","Epoch 29/100\n","177/177 [==============================] - 4s 22ms/step - loss: 6.2442 - categorical_accuracy: 0.8726 - val_loss: 6.5522 - val_categorical_accuracy: 0.6835\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.78734\n","Epoch 30/100\n","177/177 [==============================] - 4s 24ms/step - loss: 6.2249 - categorical_accuracy: 0.8687 - val_loss: 7.6237 - val_categorical_accuracy: 0.4253\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.78734\n","Epoch 31/100\n","177/177 [==============================] - 4s 22ms/step - loss: 6.1463 - categorical_accuracy: 0.8840 - val_loss: 6.9233 - val_categorical_accuracy: 0.5063\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.78734\n","Epoch 32/100\n","177/177 [==============================] - 4s 24ms/step - loss: 6.0928 - categorical_accuracy: 0.8852 - val_loss: 6.2042 - val_categorical_accuracy: 0.7772\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.78734\n","Epoch 33/100\n","177/177 [==============================] - 4s 23ms/step - loss: 6.0549 - categorical_accuracy: 0.8905 - val_loss: 6.3459 - val_categorical_accuracy: 0.7519\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.78734\n","Epoch 34/100\n","177/177 [==============================] - 4s 24ms/step - loss: 5.9667 - categorical_accuracy: 0.9023 - val_loss: 6.3943 - val_categorical_accuracy: 0.6557\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.78734\n","Epoch 35/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.9524 - categorical_accuracy: 0.8951 - val_loss: 6.6448 - val_categorical_accuracy: 0.5671\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.78734\n","Epoch 36/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.8951 - categorical_accuracy: 0.9055 - val_loss: 6.0724 - val_categorical_accuracy: 0.7772\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.78734\n","Epoch 37/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.8635 - categorical_accuracy: 0.9032 - val_loss: 6.3597 - val_categorical_accuracy: 0.6152\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.78734\n","Epoch 38/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.8018 - categorical_accuracy: 0.9109 - val_loss: 6.0953 - val_categorical_accuracy: 0.7266\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.78734\n","Epoch 39/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.7782 - categorical_accuracy: 0.8940 - val_loss: 6.0151 - val_categorical_accuracy: 0.8456\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.78734 to 0.84557, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 40/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.7078 - categorical_accuracy: 0.9132 - val_loss: 8.1315 - val_categorical_accuracy: 0.4228\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.84557\n","Epoch 41/100\n","177/177 [==============================] - 4s 25ms/step - loss: 5.6948 - categorical_accuracy: 0.9039 - val_loss: 5.9545 - val_categorical_accuracy: 0.7671\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.84557\n","Epoch 42/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.6391 - categorical_accuracy: 0.9138 - val_loss: 5.9008 - val_categorical_accuracy: 0.8253\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.84557\n","Epoch 43/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.6010 - categorical_accuracy: 0.9075 - val_loss: 5.7363 - val_categorical_accuracy: 0.8304\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.84557\n","Epoch 44/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.5782 - categorical_accuracy: 0.9085 - val_loss: 7.0979 - val_categorical_accuracy: 0.5038\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.84557\n","Epoch 45/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.5130 - categorical_accuracy: 0.9189 - val_loss: 5.9539 - val_categorical_accuracy: 0.8025\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.84557\n","Epoch 46/100\n","177/177 [==============================] - 4s 23ms/step - loss: 5.4754 - categorical_accuracy: 0.9225 - val_loss: 9.6786 - val_categorical_accuracy: 0.3544\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.84557\n","Epoch 47/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.4554 - categorical_accuracy: 0.9151 - val_loss: 5.8011 - val_categorical_accuracy: 0.7443\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.84557\n","Epoch 48/100\n","177/177 [==============================] - 4s 24ms/step - loss: 5.3950 - categorical_accuracy: 0.9174 - val_loss: 5.5499 - val_categorical_accuracy: 0.8025\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.84557\n","Epoch 49/100\n","177/177 [==============================] - 4s 23ms/step - loss: 5.3627 - categorical_accuracy: 0.9184 - val_loss: 9.2464 - val_categorical_accuracy: 0.3899\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.84557\n","Epoch 50/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.3048 - categorical_accuracy: 0.9343 - val_loss: 15.1022 - val_categorical_accuracy: 0.2658\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.84557\n","Epoch 51/100\n","177/177 [==============================] - 4s 21ms/step - loss: 5.2733 - categorical_accuracy: 0.9265 - val_loss: 5.4493 - val_categorical_accuracy: 0.8177\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.84557\n","Epoch 52/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.2249 - categorical_accuracy: 0.9326 - val_loss: 6.1104 - val_categorical_accuracy: 0.6481\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.84557\n","Epoch 53/100\n","177/177 [==============================] - 4s 22ms/step - loss: 5.1930 - categorical_accuracy: 0.9355 - val_loss: 5.4927 - val_categorical_accuracy: 0.7646\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.84557\n","Epoch 54/100\n","177/177 [==============================] - 4s 23ms/step - loss: 5.1695 - categorical_accuracy: 0.9306 - val_loss: 5.3520 - val_categorical_accuracy: 0.8430\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.84557\n","Epoch 55/100\n","177/177 [==============================] - 4s 21ms/step - loss: 5.1170 - categorical_accuracy: 0.9353 - val_loss: 11.7398 - val_categorical_accuracy: 0.3443\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.84557\n","Epoch 56/100\n","177/177 [==============================] - 4s 21ms/step - loss: 5.0932 - categorical_accuracy: 0.9381 - val_loss: 5.4457 - val_categorical_accuracy: 0.7747\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.84557\n","Epoch 57/100\n","177/177 [==============================] - 4s 23ms/step - loss: 5.0549 - categorical_accuracy: 0.9420 - val_loss: 9.7740 - val_categorical_accuracy: 0.3949\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.84557\n","Epoch 58/100\n","177/177 [==============================] - 4s 21ms/step - loss: 5.0058 - categorical_accuracy: 0.9470 - val_loss: 5.2083 - val_categorical_accuracy: 0.8127\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.84557\n","Epoch 59/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.9743 - categorical_accuracy: 0.9421 - val_loss: 7.6911 - val_categorical_accuracy: 0.4076\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.84557\n","Epoch 60/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.9350 - categorical_accuracy: 0.9398 - val_loss: 10.4881 - val_categorical_accuracy: 0.3519\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.84557\n","Epoch 61/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.8957 - categorical_accuracy: 0.9496 - val_loss: 5.0915 - val_categorical_accuracy: 0.8253\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.84557\n","Epoch 62/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.8785 - categorical_accuracy: 0.9431 - val_loss: 6.3119 - val_categorical_accuracy: 0.5544\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.84557\n","Epoch 63/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.8326 - categorical_accuracy: 0.9477 - val_loss: 5.1701 - val_categorical_accuracy: 0.8329\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.84557\n","Epoch 64/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.8023 - categorical_accuracy: 0.9502 - val_loss: 6.9422 - val_categorical_accuracy: 0.4835\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.84557\n","Epoch 65/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.7634 - categorical_accuracy: 0.9539 - val_loss: 5.0569 - val_categorical_accuracy: 0.7975\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.84557\n","Epoch 66/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.7453 - categorical_accuracy: 0.9474 - val_loss: 6.4301 - val_categorical_accuracy: 0.5722\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.84557\n","Epoch 67/100\n","177/177 [==============================] - 4s 23ms/step - loss: 4.7077 - categorical_accuracy: 0.9502 - val_loss: 5.3493 - val_categorical_accuracy: 0.7316\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.84557\n","Epoch 68/100\n","177/177 [==============================] - 4s 24ms/step - loss: 4.6828 - categorical_accuracy: 0.9476 - val_loss: 7.5773 - val_categorical_accuracy: 0.4278\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.84557\n","Epoch 69/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.6545 - categorical_accuracy: 0.9466 - val_loss: 5.0783 - val_categorical_accuracy: 0.7924\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.84557\n","Epoch 70/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.6025 - categorical_accuracy: 0.9600 - val_loss: 6.4533 - val_categorical_accuracy: 0.5797\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.84557\n","Epoch 71/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.5838 - categorical_accuracy: 0.9580 - val_loss: 6.3306 - val_categorical_accuracy: 0.5949\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.84557\n","Epoch 72/100\n","177/177 [==============================] - 4s 23ms/step - loss: 4.5227 - categorical_accuracy: 0.9668 - val_loss: 4.8830 - val_categorical_accuracy: 0.8051\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.84557\n","Epoch 73/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.5212 - categorical_accuracy: 0.9553 - val_loss: 5.1081 - val_categorical_accuracy: 0.6684\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.84557\n","Epoch 74/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.4948 - categorical_accuracy: 0.9569 - val_loss: 5.2744 - val_categorical_accuracy: 0.6962\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.84557\n","Epoch 75/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.4558 - categorical_accuracy: 0.9619 - val_loss: 6.5111 - val_categorical_accuracy: 0.5519\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.84557\n","Epoch 76/100\n","177/177 [==============================] - 4s 20ms/step - loss: 4.4466 - categorical_accuracy: 0.9508 - val_loss: 5.8710 - val_categorical_accuracy: 0.5367\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.84557\n","Epoch 77/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.3925 - categorical_accuracy: 0.9614 - val_loss: 9.7457 - val_categorical_accuracy: 0.3595\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.84557\n","Epoch 78/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.3687 - categorical_accuracy: 0.9615 - val_loss: 6.2734 - val_categorical_accuracy: 0.6608\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.84557\n","Epoch 79/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.3428 - categorical_accuracy: 0.9617 - val_loss: 5.2325 - val_categorical_accuracy: 0.7418\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.84557\n","Epoch 80/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.3140 - categorical_accuracy: 0.9634 - val_loss: 7.7422 - val_categorical_accuracy: 0.4278\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.84557\n","Epoch 81/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.2793 - categorical_accuracy: 0.9674 - val_loss: 5.1059 - val_categorical_accuracy: 0.6658\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.84557\n","Epoch 82/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.2479 - categorical_accuracy: 0.9715 - val_loss: 7.1496 - val_categorical_accuracy: 0.4278\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.84557\n","Epoch 83/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.2329 - categorical_accuracy: 0.9626 - val_loss: 6.2211 - val_categorical_accuracy: 0.5646\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.84557\n","Epoch 84/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.2038 - categorical_accuracy: 0.9626 - val_loss: 5.5748 - val_categorical_accuracy: 0.6203\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.84557\n","Epoch 85/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.1763 - categorical_accuracy: 0.9730 - val_loss: 5.0684 - val_categorical_accuracy: 0.6253\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.84557\n","Epoch 86/100\n","177/177 [==============================] - 4s 23ms/step - loss: 4.1462 - categorical_accuracy: 0.9665 - val_loss: 6.4787 - val_categorical_accuracy: 0.5595\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.84557\n","Epoch 87/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.1054 - categorical_accuracy: 0.9702 - val_loss: 5.8309 - val_categorical_accuracy: 0.6025\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.84557\n","Epoch 88/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.0843 - categorical_accuracy: 0.9743 - val_loss: 25.7747 - val_categorical_accuracy: 0.3241\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.84557\n","Epoch 89/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.0751 - categorical_accuracy: 0.9709 - val_loss: 5.0560 - val_categorical_accuracy: 0.6506\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.84557\n","Epoch 90/100\n","177/177 [==============================] - 4s 21ms/step - loss: 4.0414 - categorical_accuracy: 0.9651 - val_loss: 5.5514 - val_categorical_accuracy: 0.7291\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.84557\n","Epoch 91/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.0245 - categorical_accuracy: 0.9649 - val_loss: 4.4089 - val_categorical_accuracy: 0.8152\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.84557\n","Epoch 92/100\n","177/177 [==============================] - 4s 22ms/step - loss: 4.0094 - categorical_accuracy: 0.9647 - val_loss: 10.6825 - val_categorical_accuracy: 0.3468\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.84557\n","Epoch 93/100\n","177/177 [==============================] - 4s 23ms/step - loss: 3.9612 - categorical_accuracy: 0.9717 - val_loss: 6.9057 - val_categorical_accuracy: 0.4532\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.84557\n","Epoch 94/100\n","177/177 [==============================] - 4s 21ms/step - loss: 3.9336 - categorical_accuracy: 0.9731 - val_loss: 4.8017 - val_categorical_accuracy: 0.7114\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.84557\n","Epoch 95/100\n","177/177 [==============================] - 4s 24ms/step - loss: 3.9206 - categorical_accuracy: 0.9712 - val_loss: 4.5472 - val_categorical_accuracy: 0.8051\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.84557\n","Epoch 96/100\n","177/177 [==============================] - 4s 22ms/step - loss: 3.8971 - categorical_accuracy: 0.9692 - val_loss: 11.5342 - val_categorical_accuracy: 0.3544\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.84557\n","Epoch 97/100\n","177/177 [==============================] - 4s 23ms/step - loss: 3.8682 - categorical_accuracy: 0.9714 - val_loss: 4.2990 - val_categorical_accuracy: 0.8101\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.84557\n","Epoch 98/100\n","177/177 [==============================] - 4s 21ms/step - loss: 3.8531 - categorical_accuracy: 0.9650 - val_loss: 4.9030 - val_categorical_accuracy: 0.7823\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.84557\n","Epoch 99/100\n","177/177 [==============================] - 4s 21ms/step - loss: 3.8170 - categorical_accuracy: 0.9754 - val_loss: 13.9549 - val_categorical_accuracy: 0.3367\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.84557\n","Epoch 100/100\n","177/177 [==============================] - 4s 21ms/step - loss: 3.7946 - categorical_accuracy: 0.9707 - val_loss: 4.4327 - val_categorical_accuracy: 0.7418\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.84557\n","13/13 [==============================] - 1s 17ms/step - loss: 6.0151 - categorical_accuracy: 0.8456\n","Test Accuracy =  85.0\n","13/13 [==============================] - 1s 6ms/step\n","Model: \"model_15\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_266 (Conv2D)             (None, 20, 20, 64)   4160        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 20, 20, 64)   256         conv2d_266[0][0]                 \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 20, 20, 64)   0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","lambda_113 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_115 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_117 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_119 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_268 (Conv2D)             (None, 20, 20, 8)    584         lambda_113[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_272 (Conv2D)             (None, 20, 20, 8)    584         lambda_115[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_276 (Conv2D)             (None, 20, 20, 8)    584         lambda_117[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_280 (Conv2D)             (None, 20, 20, 8)    584         lambda_119[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_112 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_269 (Conv2D)             (None, 20, 20, 8)    584         conv2d_268[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_114 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_273 (Conv2D)             (None, 20, 20, 8)    584         conv2d_272[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_116 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_277 (Conv2D)             (None, 20, 20, 8)    584         conv2d_276[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_118 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_281 (Conv2D)             (None, 20, 20, 8)    584         conv2d_280[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_267 (Conv2D)             (None, 20, 20, 8)    584         lambda_112[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_270 (Conv2D)             (None, 20, 20, 8)    584         conv2d_269[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_271 (Conv2D)             (None, 20, 20, 8)    584         lambda_114[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_274 (Conv2D)             (None, 20, 20, 8)    584         conv2d_273[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_275 (Conv2D)             (None, 20, 20, 8)    584         lambda_116[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_278 (Conv2D)             (None, 20, 20, 8)    584         conv2d_277[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_279 (Conv2D)             (None, 20, 20, 8)    584         lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_282 (Conv2D)             (None, 20, 20, 8)    584         conv2d_281[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 20, 20, 64)   0           conv2d_267[0][0]                 \n","                                                                 conv2d_270[0][0]                 \n","                                                                 conv2d_271[0][0]                 \n","                                                                 conv2d_274[0][0]                 \n","                                                                 conv2d_275[0][0]                 \n","                                                                 conv2d_278[0][0]                 \n","                                                                 conv2d_279[0][0]                 \n","                                                                 conv2d_282[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 20, 20, 64)   256         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 20, 20, 64)   0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_28 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_85[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_14 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_28[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_14 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_14[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_29 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 20, 20, 64)   256         tf.reshape_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 20, 20, 64)   0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_283 (Conv2D)             (None, 20, 20, 128)  8320        activation_86[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_284 (Conv2D)             (None, 20, 20, 128)  8320        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 20, 20, 128)  512         conv2d_283[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 20, 20, 128)  512         conv2d_284[0][0]                 \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 20, 20, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 20, 20, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 20, 20, 128)  0           activation_87[0][0]              \n","                                                                 activation_88[0][0]              \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 20, 20, 128)  0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_285 (Conv2D)             (None, 20, 20, 128)  16512       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 20, 20, 128)  512         conv2d_285[0][0]                 \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 20, 20, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","lambda_121 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_123 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_125 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_127 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_287 (Conv2D)             (None, 20, 20, 16)   2320        lambda_121[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_291 (Conv2D)             (None, 20, 20, 16)   2320        lambda_123[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_295 (Conv2D)             (None, 20, 20, 16)   2320        lambda_125[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_299 (Conv2D)             (None, 20, 20, 16)   2320        lambda_127[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_120 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_288 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_287[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_122 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_292 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_291[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_124 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_296 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_295[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_126 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_300 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_299[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_286 (Conv2D)             (None, 20, 20, 16)   2320        lambda_120[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_289 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_288[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_290 (Conv2D)             (None, 20, 20, 16)   2320        lambda_122[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_293 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_292[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_294 (Conv2D)             (None, 20, 20, 16)   2320        lambda_124[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_297 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_296[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_298 (Conv2D)             (None, 20, 20, 16)   2320        lambda_126[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_301 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_300[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 20, 20, 128)  0           conv2d_286[0][0]                 \n","                                                                 conv2d_289[0][0]                 \n","                                                                 conv2d_290[0][0]                 \n","                                                                 conv2d_293[0][0]                 \n","                                                                 conv2d_294[0][0]                 \n","                                                                 conv2d_297[0][0]                 \n","                                                                 conv2d_298[0][0]                 \n","                                                                 conv2d_301[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 20, 20, 128)  512         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 20, 20, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_30 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_91[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_15 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_30[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_15 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_15[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_31 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 20, 20, 128)  512         tf.reshape_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 20, 20, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_302 (Conv2D)             (None, 20, 20, 256)  33024       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_303 (Conv2D)             (None, 20, 20, 256)  33024       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 20, 20, 256)  1024        conv2d_302[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 20, 20, 256)  1024        conv2d_303[0][0]                 \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 20, 20, 256)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 20, 20, 256)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 20, 20, 256)  0           activation_93[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 20, 20, 256)  0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_7 (Glo (None, 256)          0           activation_95[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 60 percent samples from each class in training set \n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples is 7906.\n","\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in training set is 4740.\n","Samples per class in training set: [ 820  313  193  438  213  502 1334  276  651]\n","\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in test set is 3166.\n","Samples per class in test set: [548 210 130 292 143 335 890 184 434]\n","\n","X_train => (4740, 20, 20, 64)\n","X_test  => (3166, 20, 20, 64)\n","y_train => (4740, 9)\n","y_test  => (3166, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model_16\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_304 (Conv2D)             (None, 20, 20, 64)   4160        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 20, 20, 64)   256         conv2d_304[0][0]                 \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 20, 20, 64)   0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","lambda_129 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_131 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_133 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_135 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_306 (Conv2D)             (None, 20, 20, 8)    584         lambda_129[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_310 (Conv2D)             (None, 20, 20, 8)    584         lambda_131[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_314 (Conv2D)             (None, 20, 20, 8)    584         lambda_133[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_318 (Conv2D)             (None, 20, 20, 8)    584         lambda_135[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_128 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_307 (Conv2D)             (None, 20, 20, 8)    584         conv2d_306[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_130 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_311 (Conv2D)             (None, 20, 20, 8)    584         conv2d_310[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_132 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_315 (Conv2D)             (None, 20, 20, 8)    584         conv2d_314[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_134 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_319 (Conv2D)             (None, 20, 20, 8)    584         conv2d_318[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_305 (Conv2D)             (None, 20, 20, 8)    584         lambda_128[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_308 (Conv2D)             (None, 20, 20, 8)    584         conv2d_307[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_309 (Conv2D)             (None, 20, 20, 8)    584         lambda_130[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_312 (Conv2D)             (None, 20, 20, 8)    584         conv2d_311[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_313 (Conv2D)             (None, 20, 20, 8)    584         lambda_132[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_316 (Conv2D)             (None, 20, 20, 8)    584         conv2d_315[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_317 (Conv2D)             (None, 20, 20, 8)    584         lambda_134[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_320 (Conv2D)             (None, 20, 20, 8)    584         conv2d_319[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 20, 20, 64)   0           conv2d_305[0][0]                 \n","                                                                 conv2d_308[0][0]                 \n","                                                                 conv2d_309[0][0]                 \n","                                                                 conv2d_312[0][0]                 \n","                                                                 conv2d_313[0][0]                 \n","                                                                 conv2d_316[0][0]                 \n","                                                                 conv2d_317[0][0]                 \n","                                                                 conv2d_320[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 20, 20, 64)   256         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 20, 20, 64)   0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_32 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_97[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_16 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_32[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_16 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_16[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_33 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 20, 20, 64)   256         tf.reshape_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 20, 20, 64)   0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_321 (Conv2D)             (None, 20, 20, 128)  8320        activation_98[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_322 (Conv2D)             (None, 20, 20, 128)  8320        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 20, 20, 128)  512         conv2d_321[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 20, 20, 128)  512         conv2d_322[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 20, 20, 128)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 20, 20, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 20, 20, 128)  0           activation_99[0][0]              \n","                                                                 activation_100[0][0]             \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 20, 20, 128)  0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_323 (Conv2D)             (None, 20, 20, 128)  16512       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 20, 20, 128)  512         conv2d_323[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 20, 20, 128)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","lambda_137 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_139 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_141 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_143 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_325 (Conv2D)             (None, 20, 20, 16)   2320        lambda_137[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_329 (Conv2D)             (None, 20, 20, 16)   2320        lambda_139[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_333 (Conv2D)             (None, 20, 20, 16)   2320        lambda_141[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_337 (Conv2D)             (None, 20, 20, 16)   2320        lambda_143[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_136 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_326 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_325[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_138 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_330 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_329[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_140 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_334 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_333[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_142 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_338 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_337[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_324 (Conv2D)             (None, 20, 20, 16)   2320        lambda_136[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_327 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_326[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_328 (Conv2D)             (None, 20, 20, 16)   2320        lambda_138[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_331 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_330[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_332 (Conv2D)             (None, 20, 20, 16)   2320        lambda_140[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_335 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_334[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_336 (Conv2D)             (None, 20, 20, 16)   2320        lambda_142[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_339 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_338[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 20, 20, 128)  0           conv2d_324[0][0]                 \n","                                                                 conv2d_327[0][0]                 \n","                                                                 conv2d_328[0][0]                 \n","                                                                 conv2d_331[0][0]                 \n","                                                                 conv2d_332[0][0]                 \n","                                                                 conv2d_335[0][0]                 \n","                                                                 conv2d_336[0][0]                 \n","                                                                 conv2d_339[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 20, 20, 128)  512         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 20, 20, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_34 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_103[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_17 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_34[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_17 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_17[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_35 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 20, 20, 128)  512         tf.reshape_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 20, 20, 128)  0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_340 (Conv2D)             (None, 20, 20, 256)  33024       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_341 (Conv2D)             (None, 20, 20, 256)  33024       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 20, 20, 256)  1024        conv2d_340[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 20, 20, 256)  1024        conv2d_341[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 20, 20, 256)  0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 20, 20, 256)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 20, 20, 256)  0           activation_105[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 20, 20, 256)  0           add_17[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_8 (Glo (None, 256)          0           activation_107[0][0]             \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_8[0][0] \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","237/237 [==============================] - 9s 26ms/step - loss: 9.2304 - categorical_accuracy: 0.2769 - val_loss: 8.8264 - val_categorical_accuracy: 0.3099\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.30985, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","237/237 [==============================] - 6s 23ms/step - loss: 8.4733 - categorical_accuracy: 0.5016 - val_loss: 8.3281 - val_categorical_accuracy: 0.5550\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.30985 to 0.55496, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","237/237 [==============================] - 6s 25ms/step - loss: 8.2206 - categorical_accuracy: 0.5685 - val_loss: 8.1301 - val_categorical_accuracy: 0.5641\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.55496 to 0.56412, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","237/237 [==============================] - 6s 24ms/step - loss: 8.0008 - categorical_accuracy: 0.6275 - val_loss: 7.9685 - val_categorical_accuracy: 0.6093\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.56412 to 0.60929, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","237/237 [==============================] - 6s 25ms/step - loss: 7.8516 - categorical_accuracy: 0.6526 - val_loss: 7.8337 - val_categorical_accuracy: 0.6191\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.60929 to 0.61908, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","237/237 [==============================] - 6s 23ms/step - loss: 7.6748 - categorical_accuracy: 0.6831 - val_loss: 7.6885 - val_categorical_accuracy: 0.6589\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.61908 to 0.65888, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","237/237 [==============================] - 6s 24ms/step - loss: 7.5389 - categorical_accuracy: 0.7106 - val_loss: 7.6438 - val_categorical_accuracy: 0.6153\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.65888\n","Epoch 8/100\n","237/237 [==============================] - 5s 23ms/step - loss: 7.3867 - categorical_accuracy: 0.7563 - val_loss: 7.4660 - val_categorical_accuracy: 0.6993\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.65888 to 0.69931, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 9/100\n","237/237 [==============================] - 6s 23ms/step - loss: 7.2745 - categorical_accuracy: 0.7698 - val_loss: 7.4015 - val_categorical_accuracy: 0.6911\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.69931\n","Epoch 10/100\n","237/237 [==============================] - 6s 23ms/step - loss: 7.1684 - categorical_accuracy: 0.7869 - val_loss: 7.4680 - val_categorical_accuracy: 0.6649\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.69931\n","Epoch 11/100\n","237/237 [==============================] - 5s 23ms/step - loss: 7.0671 - categorical_accuracy: 0.8087 - val_loss: 7.2824 - val_categorical_accuracy: 0.6804\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.69931\n","Epoch 12/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.9591 - categorical_accuracy: 0.8161 - val_loss: 7.1431 - val_categorical_accuracy: 0.7186\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.69931 to 0.71857, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 13/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.8596 - categorical_accuracy: 0.8306 - val_loss: 7.1962 - val_categorical_accuracy: 0.6819\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.71857\n","Epoch 14/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.7618 - categorical_accuracy: 0.8542 - val_loss: 7.0913 - val_categorical_accuracy: 0.6977\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.71857\n","Epoch 15/100\n","237/237 [==============================] - 6s 24ms/step - loss: 6.6747 - categorical_accuracy: 0.8549 - val_loss: 6.9544 - val_categorical_accuracy: 0.7287\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.71857 to 0.72868, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","237/237 [==============================] - 6s 24ms/step - loss: 6.6060 - categorical_accuracy: 0.8618 - val_loss: 6.9317 - val_categorical_accuracy: 0.7224\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.72868\n","Epoch 17/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.5022 - categorical_accuracy: 0.8780 - val_loss: 6.8933 - val_categorical_accuracy: 0.7028\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.72868\n","Epoch 18/100\n","237/237 [==============================] - 6s 24ms/step - loss: 6.4296 - categorical_accuracy: 0.8803 - val_loss: 6.9147 - val_categorical_accuracy: 0.6883\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.72868\n","Epoch 19/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.3523 - categorical_accuracy: 0.8917 - val_loss: 6.8199 - val_categorical_accuracy: 0.7236\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.72868\n","Epoch 20/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.2580 - categorical_accuracy: 0.9019 - val_loss: 6.8912 - val_categorical_accuracy: 0.6848\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.72868\n","Epoch 21/100\n","237/237 [==============================] - 5s 23ms/step - loss: 6.1883 - categorical_accuracy: 0.9143 - val_loss: 7.3671 - val_categorical_accuracy: 0.6229\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.72868\n","Epoch 22/100\n","237/237 [==============================] - 5s 22ms/step - loss: 6.1086 - categorical_accuracy: 0.9197 - val_loss: 6.5772 - val_categorical_accuracy: 0.7372\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.72868 to 0.73721, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 23/100\n","237/237 [==============================] - 6s 23ms/step - loss: 6.0670 - categorical_accuracy: 0.9103 - val_loss: 6.7066 - val_categorical_accuracy: 0.7205\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.73721\n","Epoch 24/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.9765 - categorical_accuracy: 0.9257 - val_loss: 6.6473 - val_categorical_accuracy: 0.6620\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.73721\n","Epoch 25/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.9054 - categorical_accuracy: 0.9319 - val_loss: 6.4517 - val_categorical_accuracy: 0.7277\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.73721\n","Epoch 26/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.8364 - categorical_accuracy: 0.9405 - val_loss: 6.4953 - val_categorical_accuracy: 0.7183\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.73721\n","Epoch 27/100\n","237/237 [==============================] - 5s 23ms/step - loss: 5.7606 - categorical_accuracy: 0.9508 - val_loss: 6.5717 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.73721\n","Epoch 28/100\n","237/237 [==============================] - 6s 23ms/step - loss: 5.7175 - categorical_accuracy: 0.9526 - val_loss: 6.3585 - val_categorical_accuracy: 0.7208\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.73721\n","Epoch 29/100\n","237/237 [==============================] - 6s 24ms/step - loss: 5.6545 - categorical_accuracy: 0.9517 - val_loss: 6.3080 - val_categorical_accuracy: 0.7195\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.73721\n","Epoch 30/100\n","237/237 [==============================] - 6s 24ms/step - loss: 5.5999 - categorical_accuracy: 0.9574 - val_loss: 6.5331 - val_categorical_accuracy: 0.6042\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.73721\n","Epoch 31/100\n","237/237 [==============================] - 6s 24ms/step - loss: 5.5323 - categorical_accuracy: 0.9564 - val_loss: 6.3463 - val_categorical_accuracy: 0.7192\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.73721\n","Epoch 32/100\n","237/237 [==============================] - 5s 23ms/step - loss: 5.4658 - categorical_accuracy: 0.9629 - val_loss: 6.2571 - val_categorical_accuracy: 0.6848\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.73721\n","Epoch 33/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.4371 - categorical_accuracy: 0.9611 - val_loss: 6.2878 - val_categorical_accuracy: 0.6974\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.73721\n","Epoch 34/100\n","237/237 [==============================] - 5s 23ms/step - loss: 5.3688 - categorical_accuracy: 0.9598 - val_loss: 6.3418 - val_categorical_accuracy: 0.5843\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.73721\n","Epoch 35/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.3277 - categorical_accuracy: 0.9610 - val_loss: 6.1530 - val_categorical_accuracy: 0.7126\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.73721\n","Epoch 36/100\n","237/237 [==============================] - 5s 22ms/step - loss: 5.2548 - categorical_accuracy: 0.9687 - val_loss: 5.9903 - val_categorical_accuracy: 0.7461\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.73721 to 0.74605, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 37/100\n","237/237 [==============================] - 6s 24ms/step - loss: 5.2028 - categorical_accuracy: 0.9747 - val_loss: 5.9768 - val_categorical_accuracy: 0.7419\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.74605\n","Epoch 38/100\n","237/237 [==============================] - 6s 23ms/step - loss: 5.1559 - categorical_accuracy: 0.9703 - val_loss: 7.1979 - val_categorical_accuracy: 0.6447\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.74605\n","Epoch 39/100\n","237/237 [==============================] - 5s 23ms/step - loss: 5.1337 - categorical_accuracy: 0.9671 - val_loss: 5.8835 - val_categorical_accuracy: 0.7546\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.74605 to 0.75458, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 40/100\n","237/237 [==============================] - 6s 23ms/step - loss: 5.0813 - categorical_accuracy: 0.9673 - val_loss: 5.9388 - val_categorical_accuracy: 0.7262\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.75458\n","Epoch 41/100\n","237/237 [==============================] - 5s 23ms/step - loss: 5.0147 - categorical_accuracy: 0.9751 - val_loss: 6.1651 - val_categorical_accuracy: 0.6980\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.75458\n","Epoch 42/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.9743 - categorical_accuracy: 0.9726 - val_loss: 6.8423 - val_categorical_accuracy: 0.6510\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.75458\n","Epoch 43/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.9193 - categorical_accuracy: 0.9785 - val_loss: 5.7538 - val_categorical_accuracy: 0.7416\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.75458\n","Epoch 44/100\n","237/237 [==============================] - 6s 24ms/step - loss: 4.8726 - categorical_accuracy: 0.9797 - val_loss: 6.0745 - val_categorical_accuracy: 0.6927\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.75458\n","Epoch 45/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.8438 - categorical_accuracy: 0.9702 - val_loss: 5.8892 - val_categorical_accuracy: 0.7230\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.75458\n","Epoch 46/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.7899 - categorical_accuracy: 0.9766 - val_loss: 5.6176 - val_categorical_accuracy: 0.7129\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.75458\n","Epoch 47/100\n","237/237 [==============================] - 6s 24ms/step - loss: 4.7404 - categorical_accuracy: 0.9810 - val_loss: 6.6753 - val_categorical_accuracy: 0.6112\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.75458\n","Epoch 48/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.6927 - categorical_accuracy: 0.9836 - val_loss: 5.5347 - val_categorical_accuracy: 0.7574\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.75458 to 0.75742, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 49/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.6588 - categorical_accuracy: 0.9812 - val_loss: 5.7498 - val_categorical_accuracy: 0.6563\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.75742\n","Epoch 50/100\n","237/237 [==============================] - 6s 24ms/step - loss: 4.6170 - categorical_accuracy: 0.9852 - val_loss: 6.0797 - val_categorical_accuracy: 0.6406\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.75742\n","Epoch 51/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.5770 - categorical_accuracy: 0.9839 - val_loss: 6.2371 - val_categorical_accuracy: 0.6658\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.75742\n","Epoch 52/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.5496 - categorical_accuracy: 0.9799 - val_loss: 5.4577 - val_categorical_accuracy: 0.7476\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.75742\n","Epoch 53/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.4935 - categorical_accuracy: 0.9837 - val_loss: 5.3613 - val_categorical_accuracy: 0.6883\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.75742\n","Epoch 54/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.4675 - categorical_accuracy: 0.9795 - val_loss: 5.7788 - val_categorical_accuracy: 0.6845\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.75742\n","Epoch 55/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.4095 - categorical_accuracy: 0.9874 - val_loss: 5.6171 - val_categorical_accuracy: 0.7173\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.75742\n","Epoch 56/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.3816 - categorical_accuracy: 0.9829 - val_loss: 5.2877 - val_categorical_accuracy: 0.7612\n","\n","Epoch 00056: val_categorical_accuracy improved from 0.75742 to 0.76121, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 57/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.3386 - categorical_accuracy: 0.9824 - val_loss: 6.1161 - val_categorical_accuracy: 0.6772\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.76121\n","Epoch 58/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.3086 - categorical_accuracy: 0.9844 - val_loss: 5.2002 - val_categorical_accuracy: 0.7416\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.76121\n","Epoch 59/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.2625 - categorical_accuracy: 0.9873 - val_loss: 5.4507 - val_categorical_accuracy: 0.7142\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.76121\n","Epoch 60/100\n","237/237 [==============================] - 6s 24ms/step - loss: 4.2312 - categorical_accuracy: 0.9860 - val_loss: 6.3751 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.76121\n","Epoch 61/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.1973 - categorical_accuracy: 0.9851 - val_loss: 5.0822 - val_categorical_accuracy: 0.7751\n","\n","Epoch 00061: val_categorical_accuracy improved from 0.76121 to 0.77511, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 62/100\n","237/237 [==============================] - 5s 23ms/step - loss: 4.1591 - categorical_accuracy: 0.9843 - val_loss: 5.4359 - val_categorical_accuracy: 0.6943\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.77511\n","Epoch 63/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.1208 - categorical_accuracy: 0.9855 - val_loss: 6.2230 - val_categorical_accuracy: 0.5963\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.77511\n","Epoch 64/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.0840 - categorical_accuracy: 0.9884 - val_loss: 5.4284 - val_categorical_accuracy: 0.6968\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.77511\n","Epoch 65/100\n","237/237 [==============================] - 5s 22ms/step - loss: 4.0463 - categorical_accuracy: 0.9903 - val_loss: 6.8402 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.77511\n","Epoch 66/100\n","237/237 [==============================] - 6s 23ms/step - loss: 4.0172 - categorical_accuracy: 0.9910 - val_loss: 5.0598 - val_categorical_accuracy: 0.6949\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.77511\n","Epoch 67/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.9779 - categorical_accuracy: 0.9913 - val_loss: 5.1079 - val_categorical_accuracy: 0.7372\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.77511\n","Epoch 68/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.9539 - categorical_accuracy: 0.9882 - val_loss: 5.7600 - val_categorical_accuracy: 0.6592\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.77511\n","Epoch 69/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.9211 - categorical_accuracy: 0.9888 - val_loss: 5.1180 - val_categorical_accuracy: 0.7255\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.77511\n","Epoch 70/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.8863 - categorical_accuracy: 0.9910 - val_loss: 5.3012 - val_categorical_accuracy: 0.6977\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.77511\n","Epoch 71/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.8622 - categorical_accuracy: 0.9864 - val_loss: 5.6816 - val_categorical_accuracy: 0.5840\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.77511\n","Epoch 72/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.8290 - categorical_accuracy: 0.9879 - val_loss: 5.4303 - val_categorical_accuracy: 0.5663\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.77511\n","Epoch 73/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.7903 - categorical_accuracy: 0.9896 - val_loss: 4.8818 - val_categorical_accuracy: 0.7214\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.77511\n","Epoch 74/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.7558 - categorical_accuracy: 0.9915 - val_loss: 5.2308 - val_categorical_accuracy: 0.5834\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.77511\n","Epoch 75/100\n","237/237 [==============================] - 6s 23ms/step - loss: 3.7260 - categorical_accuracy: 0.9926 - val_loss: 5.3708 - val_categorical_accuracy: 0.6949\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.77511\n","Epoch 76/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.7005 - categorical_accuracy: 0.9907 - val_loss: 5.0675 - val_categorical_accuracy: 0.7003\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.77511\n","Epoch 77/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.6709 - categorical_accuracy: 0.9913 - val_loss: 4.8410 - val_categorical_accuracy: 0.7284\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.77511\n","Epoch 78/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.6385 - categorical_accuracy: 0.9908 - val_loss: 5.2986 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.77511\n","Epoch 79/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.6029 - categorical_accuracy: 0.9936 - val_loss: 4.8390 - val_categorical_accuracy: 0.7009\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.77511\n","Epoch 80/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.5757 - categorical_accuracy: 0.9924 - val_loss: 4.7489 - val_categorical_accuracy: 0.6822\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.77511\n","Epoch 81/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.5471 - categorical_accuracy: 0.9946 - val_loss: 4.7738 - val_categorical_accuracy: 0.7091\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.77511\n","Epoch 82/100\n","237/237 [==============================] - 6s 23ms/step - loss: 3.5209 - categorical_accuracy: 0.9922 - val_loss: 4.7688 - val_categorical_accuracy: 0.7081\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.77511\n","Epoch 83/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.4916 - categorical_accuracy: 0.9940 - val_loss: 4.5206 - val_categorical_accuracy: 0.7230\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.77511\n","Epoch 84/100\n","237/237 [==============================] - 6s 23ms/step - loss: 3.4622 - categorical_accuracy: 0.9921 - val_loss: 5.6114 - val_categorical_accuracy: 0.5888\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.77511\n","Epoch 85/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.4398 - categorical_accuracy: 0.9923 - val_loss: 4.4206 - val_categorical_accuracy: 0.7716\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.77511\n","Epoch 86/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.4088 - categorical_accuracy: 0.9926 - val_loss: 4.3555 - val_categorical_accuracy: 0.7663\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.77511\n","Epoch 87/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.3792 - categorical_accuracy: 0.9950 - val_loss: 5.1678 - val_categorical_accuracy: 0.6826\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.77511\n","Epoch 88/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.3554 - categorical_accuracy: 0.9920 - val_loss: 4.9300 - val_categorical_accuracy: 0.6358\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.77511\n","Epoch 89/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.3331 - categorical_accuracy: 0.9904 - val_loss: 4.9363 - val_categorical_accuracy: 0.7142\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.77511\n","Epoch 90/100\n","237/237 [==============================] - 6s 24ms/step - loss: 3.2993 - categorical_accuracy: 0.9961 - val_loss: 5.0754 - val_categorical_accuracy: 0.6608\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.77511\n","Epoch 91/100\n","237/237 [==============================] - 6s 23ms/step - loss: 3.2720 - categorical_accuracy: 0.9949 - val_loss: 4.9293 - val_categorical_accuracy: 0.5600\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.77511\n","Epoch 92/100\n","237/237 [==============================] - 6s 23ms/step - loss: 3.2522 - categorical_accuracy: 0.9957 - val_loss: 6.6715 - val_categorical_accuracy: 0.5654\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.77511\n","Epoch 93/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.2238 - categorical_accuracy: 0.9934 - val_loss: 5.9538 - val_categorical_accuracy: 0.6620\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.77511\n","Epoch 94/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.2083 - categorical_accuracy: 0.9916 - val_loss: 5.3166 - val_categorical_accuracy: 0.5625\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.77511\n","Epoch 95/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.1746 - categorical_accuracy: 0.9933 - val_loss: 4.4202 - val_categorical_accuracy: 0.6883\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.77511\n","Epoch 96/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.1517 - categorical_accuracy: 0.9941 - val_loss: 4.3297 - val_categorical_accuracy: 0.7350\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.77511\n","Epoch 97/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.1271 - categorical_accuracy: 0.9931 - val_loss: 4.5986 - val_categorical_accuracy: 0.7227\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.77511\n","Epoch 98/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.0989 - categorical_accuracy: 0.9949 - val_loss: 4.1166 - val_categorical_accuracy: 0.7394\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.77511\n","Epoch 99/100\n","237/237 [==============================] - 5s 23ms/step - loss: 3.0741 - categorical_accuracy: 0.9943 - val_loss: 4.3576 - val_categorical_accuracy: 0.7189\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.77511\n","Epoch 100/100\n","237/237 [==============================] - 5s 22ms/step - loss: 3.0557 - categorical_accuracy: 0.9935 - val_loss: 4.7399 - val_categorical_accuracy: 0.7009\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.77511\n","99/99 [==============================] - 2s 10ms/step - loss: 5.0822 - categorical_accuracy: 0.7751\n","Test Accuracy =  78.0\n","99/99 [==============================] - 1s 7ms/step\n","Model: \"model_17\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_304 (Conv2D)             (None, 20, 20, 64)   4160        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 20, 20, 64)   256         conv2d_304[0][0]                 \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 20, 20, 64)   0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","lambda_129 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_131 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_133 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_135 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_306 (Conv2D)             (None, 20, 20, 8)    584         lambda_129[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_310 (Conv2D)             (None, 20, 20, 8)    584         lambda_131[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_314 (Conv2D)             (None, 20, 20, 8)    584         lambda_133[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_318 (Conv2D)             (None, 20, 20, 8)    584         lambda_135[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_128 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_307 (Conv2D)             (None, 20, 20, 8)    584         conv2d_306[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_130 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_311 (Conv2D)             (None, 20, 20, 8)    584         conv2d_310[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_132 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_315 (Conv2D)             (None, 20, 20, 8)    584         conv2d_314[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_134 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_319 (Conv2D)             (None, 20, 20, 8)    584         conv2d_318[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_305 (Conv2D)             (None, 20, 20, 8)    584         lambda_128[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_308 (Conv2D)             (None, 20, 20, 8)    584         conv2d_307[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_309 (Conv2D)             (None, 20, 20, 8)    584         lambda_130[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_312 (Conv2D)             (None, 20, 20, 8)    584         conv2d_311[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_313 (Conv2D)             (None, 20, 20, 8)    584         lambda_132[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_316 (Conv2D)             (None, 20, 20, 8)    584         conv2d_315[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_317 (Conv2D)             (None, 20, 20, 8)    584         lambda_134[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_320 (Conv2D)             (None, 20, 20, 8)    584         conv2d_319[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 20, 20, 64)   0           conv2d_305[0][0]                 \n","                                                                 conv2d_308[0][0]                 \n","                                                                 conv2d_309[0][0]                 \n","                                                                 conv2d_312[0][0]                 \n","                                                                 conv2d_313[0][0]                 \n","                                                                 conv2d_316[0][0]                 \n","                                                                 conv2d_317[0][0]                 \n","                                                                 conv2d_320[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 20, 20, 64)   256         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 20, 20, 64)   0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_32 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_97[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_16 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_32[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_16 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_16[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_33 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 20, 20, 64)   256         tf.reshape_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 20, 20, 64)   0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_321 (Conv2D)             (None, 20, 20, 128)  8320        activation_98[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_322 (Conv2D)             (None, 20, 20, 128)  8320        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 20, 20, 128)  512         conv2d_321[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 20, 20, 128)  512         conv2d_322[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 20, 20, 128)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 20, 20, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 20, 20, 128)  0           activation_99[0][0]              \n","                                                                 activation_100[0][0]             \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 20, 20, 128)  0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_323 (Conv2D)             (None, 20, 20, 128)  16512       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 20, 20, 128)  512         conv2d_323[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 20, 20, 128)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","lambda_137 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_139 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_141 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_143 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_325 (Conv2D)             (None, 20, 20, 16)   2320        lambda_137[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_329 (Conv2D)             (None, 20, 20, 16)   2320        lambda_139[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_333 (Conv2D)             (None, 20, 20, 16)   2320        lambda_141[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_337 (Conv2D)             (None, 20, 20, 16)   2320        lambda_143[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_136 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_326 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_325[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_138 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_330 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_329[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_140 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_334 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_333[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_142 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_338 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_337[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_324 (Conv2D)             (None, 20, 20, 16)   2320        lambda_136[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_327 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_326[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_328 (Conv2D)             (None, 20, 20, 16)   2320        lambda_138[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_331 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_330[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_332 (Conv2D)             (None, 20, 20, 16)   2320        lambda_140[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_335 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_334[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_336 (Conv2D)             (None, 20, 20, 16)   2320        lambda_142[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_339 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_338[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 20, 20, 128)  0           conv2d_324[0][0]                 \n","                                                                 conv2d_327[0][0]                 \n","                                                                 conv2d_328[0][0]                 \n","                                                                 conv2d_331[0][0]                 \n","                                                                 conv2d_332[0][0]                 \n","                                                                 conv2d_335[0][0]                 \n","                                                                 conv2d_336[0][0]                 \n","                                                                 conv2d_339[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 20, 20, 128)  512         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 20, 20, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_34 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_103[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_17 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_34[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_17 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_17[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_35 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 20, 20, 128)  512         tf.reshape_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 20, 20, 128)  0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_340 (Conv2D)             (None, 20, 20, 256)  33024       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_341 (Conv2D)             (None, 20, 20, 256)  33024       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 20, 20, 256)  1024        conv2d_340[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 20, 20, 256)  1024        conv2d_341[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 20, 20, 256)  0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 20, 20, 256)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 20, 20, 256)  0           activation_105[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 20, 20, 256)  0           add_17[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_8 (Glo (None, 256)          0           activation_107[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 70 percent samples from each class in training set \n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples is 7906.\n","\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in training set is 5530.\n","Samples per class in training set: [ 957  366  226  510  249  585 1556  322  759]\n","\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in test set is 2376.\n","Samples per class in test set: [411 157  97 220 107 252 668 138 326]\n","\n","X_train => (5530, 20, 20, 64)\n","X_test  => (2376, 20, 20, 64)\n","y_train => (5530, 9)\n","y_test  => (2376, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model_18\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_342 (Conv2D)             (None, 20, 20, 64)   4160        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 20, 20, 64)   256         conv2d_342[0][0]                 \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 20, 20, 64)   0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","lambda_145 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_147 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_149 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_151 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_344 (Conv2D)             (None, 20, 20, 8)    584         lambda_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_348 (Conv2D)             (None, 20, 20, 8)    584         lambda_147[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_352 (Conv2D)             (None, 20, 20, 8)    584         lambda_149[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_356 (Conv2D)             (None, 20, 20, 8)    584         lambda_151[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_144 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_345 (Conv2D)             (None, 20, 20, 8)    584         conv2d_344[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_146 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_349 (Conv2D)             (None, 20, 20, 8)    584         conv2d_348[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_148 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_353 (Conv2D)             (None, 20, 20, 8)    584         conv2d_352[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_150 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_357 (Conv2D)             (None, 20, 20, 8)    584         conv2d_356[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_343 (Conv2D)             (None, 20, 20, 8)    584         lambda_144[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_346 (Conv2D)             (None, 20, 20, 8)    584         conv2d_345[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_347 (Conv2D)             (None, 20, 20, 8)    584         lambda_146[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_350 (Conv2D)             (None, 20, 20, 8)    584         conv2d_349[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_351 (Conv2D)             (None, 20, 20, 8)    584         lambda_148[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_354 (Conv2D)             (None, 20, 20, 8)    584         conv2d_353[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_355 (Conv2D)             (None, 20, 20, 8)    584         lambda_150[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_358 (Conv2D)             (None, 20, 20, 8)    584         conv2d_357[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 20, 20, 64)   0           conv2d_343[0][0]                 \n","                                                                 conv2d_346[0][0]                 \n","                                                                 conv2d_347[0][0]                 \n","                                                                 conv2d_350[0][0]                 \n","                                                                 conv2d_351[0][0]                 \n","                                                                 conv2d_354[0][0]                 \n","                                                                 conv2d_355[0][0]                 \n","                                                                 conv2d_358[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 20, 20, 64)   256         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 20, 20, 64)   0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_36 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_109[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_18 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_36[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_18 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_18[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_37 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 20, 20, 64)   256         tf.reshape_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 20, 20, 64)   0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_359 (Conv2D)             (None, 20, 20, 128)  8320        activation_110[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_360 (Conv2D)             (None, 20, 20, 128)  8320        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 20, 20, 128)  512         conv2d_359[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 20, 20, 128)  512         conv2d_360[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 20, 20, 128)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 20, 20, 128)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 20, 20, 128)  0           activation_111[0][0]             \n","                                                                 activation_112[0][0]             \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 20, 20, 128)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_361 (Conv2D)             (None, 20, 20, 128)  16512       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 20, 20, 128)  512         conv2d_361[0][0]                 \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 20, 20, 128)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","lambda_153 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_155 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_157 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_159 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_363 (Conv2D)             (None, 20, 20, 16)   2320        lambda_153[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_367 (Conv2D)             (None, 20, 20, 16)   2320        lambda_155[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_371 (Conv2D)             (None, 20, 20, 16)   2320        lambda_157[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_375 (Conv2D)             (None, 20, 20, 16)   2320        lambda_159[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_152 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_364 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_363[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_154 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_368 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_367[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_156 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_372 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_371[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_158 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_376 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_375[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_362 (Conv2D)             (None, 20, 20, 16)   2320        lambda_152[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_365 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_364[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_366 (Conv2D)             (None, 20, 20, 16)   2320        lambda_154[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_369 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_368[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_370 (Conv2D)             (None, 20, 20, 16)   2320        lambda_156[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_373 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_372[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_374 (Conv2D)             (None, 20, 20, 16)   2320        lambda_158[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_377 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_376[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 20, 20, 128)  0           conv2d_362[0][0]                 \n","                                                                 conv2d_365[0][0]                 \n","                                                                 conv2d_366[0][0]                 \n","                                                                 conv2d_369[0][0]                 \n","                                                                 conv2d_370[0][0]                 \n","                                                                 conv2d_373[0][0]                 \n","                                                                 conv2d_374[0][0]                 \n","                                                                 conv2d_377[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 20, 20, 128)  512         concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 20, 20, 128)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_38 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_115[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_19 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_38[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_19 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_19[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_39 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 20, 20, 128)  512         tf.reshape_39[0][0]              \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 20, 20, 128)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_378 (Conv2D)             (None, 20, 20, 256)  33024       activation_116[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_379 (Conv2D)             (None, 20, 20, 256)  33024       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 20, 20, 256)  1024        conv2d_378[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 20, 20, 256)  1024        conv2d_379[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 20, 20, 256)  0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 20, 20, 256)  0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 20, 20, 256)  0           activation_117[0][0]             \n","                                                                 activation_118[0][0]             \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 20, 20, 256)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_9 (Glo (None, 256)          0           activation_119[0][0]             \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_9[0][0] \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","277/277 [==============================] - 10s 26ms/step - loss: 8.9233 - categorical_accuracy: 0.3615 - val_loss: 8.5474 - val_categorical_accuracy: 0.3102\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.31019, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","277/277 [==============================] - 6s 23ms/step - loss: 8.3755 - categorical_accuracy: 0.4911 - val_loss: 8.1715 - val_categorical_accuracy: 0.6949\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.31019 to 0.69487, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","277/277 [==============================] - 6s 23ms/step - loss: 8.1187 - categorical_accuracy: 0.5849 - val_loss: 7.9506 - val_categorical_accuracy: 0.6970\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.69487 to 0.69697, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","277/277 [==============================] - 6s 23ms/step - loss: 7.9189 - categorical_accuracy: 0.6508 - val_loss: 7.7912 - val_categorical_accuracy: 0.7193\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.69697 to 0.71928, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","277/277 [==============================] - 6s 23ms/step - loss: 7.7036 - categorical_accuracy: 0.6942 - val_loss: 7.6908 - val_categorical_accuracy: 0.6907\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.71928\n","Epoch 6/100\n","277/277 [==============================] - 6s 23ms/step - loss: 7.5573 - categorical_accuracy: 0.7089 - val_loss: 7.5581 - val_categorical_accuracy: 0.7071\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.71928\n","Epoch 7/100\n","277/277 [==============================] - 6s 22ms/step - loss: 7.4074 - categorical_accuracy: 0.7289 - val_loss: 7.5078 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.71928\n","Epoch 8/100\n","277/277 [==============================] - 6s 23ms/step - loss: 7.3034 - categorical_accuracy: 0.7297 - val_loss: 7.4187 - val_categorical_accuracy: 0.6886\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.71928\n","Epoch 9/100\n","277/277 [==============================] - 6s 23ms/step - loss: 7.1497 - categorical_accuracy: 0.7609 - val_loss: 7.2972 - val_categorical_accuracy: 0.7168\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.71928\n","Epoch 10/100\n","277/277 [==============================] - 6s 22ms/step - loss: 7.0375 - categorical_accuracy: 0.7841 - val_loss: 7.3792 - val_categorical_accuracy: 0.6662\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.71928\n","Epoch 11/100\n","277/277 [==============================] - 6s 22ms/step - loss: 6.9437 - categorical_accuracy: 0.7945 - val_loss: 7.2028 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.71928\n","Epoch 12/100\n","277/277 [==============================] - 6s 22ms/step - loss: 6.8281 - categorical_accuracy: 0.8253 - val_loss: 7.2467 - val_categorical_accuracy: 0.6696\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.71928\n","Epoch 13/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.7108 - categorical_accuracy: 0.8447 - val_loss: 7.1065 - val_categorical_accuracy: 0.6734\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.71928\n","Epoch 14/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.6126 - categorical_accuracy: 0.8617 - val_loss: 7.3826 - val_categorical_accuracy: 0.6414\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.71928\n","Epoch 15/100\n","277/277 [==============================] - 7s 24ms/step - loss: 6.5223 - categorical_accuracy: 0.8596 - val_loss: 7.1113 - val_categorical_accuracy: 0.6629\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.71928\n","Epoch 16/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.4244 - categorical_accuracy: 0.8793 - val_loss: 6.8770 - val_categorical_accuracy: 0.6654\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.71928\n","Epoch 17/100\n","277/277 [==============================] - 7s 24ms/step - loss: 6.3334 - categorical_accuracy: 0.8872 - val_loss: 6.8803 - val_categorical_accuracy: 0.6288\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.71928\n","Epoch 18/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.2380 - categorical_accuracy: 0.9041 - val_loss: 6.7674 - val_categorical_accuracy: 0.6991\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.71928\n","Epoch 19/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.1596 - categorical_accuracy: 0.9050 - val_loss: 7.1038 - val_categorical_accuracy: 0.6301\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.71928\n","Epoch 20/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.0716 - categorical_accuracy: 0.9149 - val_loss: 7.3303 - val_categorical_accuracy: 0.6082\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.71928\n","Epoch 21/100\n","277/277 [==============================] - 6s 23ms/step - loss: 6.0041 - categorical_accuracy: 0.9141 - val_loss: 7.0096 - val_categorical_accuracy: 0.5652\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.71928\n","Epoch 22/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.9214 - categorical_accuracy: 0.9257 - val_loss: 7.1813 - val_categorical_accuracy: 0.6368\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.71928\n","Epoch 23/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.8451 - categorical_accuracy: 0.9282 - val_loss: 7.2930 - val_categorical_accuracy: 0.6128\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.71928\n","Epoch 24/100\n","277/277 [==============================] - 6s 22ms/step - loss: 5.7601 - categorical_accuracy: 0.9421 - val_loss: 6.6391 - val_categorical_accuracy: 0.5808\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.71928\n","Epoch 25/100\n","277/277 [==============================] - 7s 24ms/step - loss: 5.7041 - categorical_accuracy: 0.9368 - val_loss: 7.3323 - val_categorical_accuracy: 0.6263\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.71928\n","Epoch 26/100\n","277/277 [==============================] - 7s 24ms/step - loss: 5.6275 - categorical_accuracy: 0.9425 - val_loss: 6.5828 - val_categorical_accuracy: 0.6578\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.71928\n","Epoch 27/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.5490 - categorical_accuracy: 0.9467 - val_loss: 6.9990 - val_categorical_accuracy: 0.6229\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.71928\n","Epoch 28/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.4968 - categorical_accuracy: 0.9498 - val_loss: 6.3883 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.71928\n","Epoch 29/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.4201 - categorical_accuracy: 0.9571 - val_loss: 7.7085 - val_categorical_accuracy: 0.5530\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.71928\n","Epoch 30/100\n","277/277 [==============================] - 6s 22ms/step - loss: 5.3783 - categorical_accuracy: 0.9459 - val_loss: 6.2863 - val_categorical_accuracy: 0.6982\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.71928\n","Epoch 31/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.3011 - categorical_accuracy: 0.9623 - val_loss: 6.5924 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.71928\n","Epoch 32/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.2500 - categorical_accuracy: 0.9515 - val_loss: 6.3990 - val_categorical_accuracy: 0.6397\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.71928\n","Epoch 33/100\n","277/277 [==============================] - 6s 22ms/step - loss: 5.1821 - categorical_accuracy: 0.9612 - val_loss: 6.2400 - val_categorical_accuracy: 0.6902\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.71928\n","Epoch 34/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.1247 - categorical_accuracy: 0.9666 - val_loss: 6.0178 - val_categorical_accuracy: 0.6978\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.71928\n","Epoch 35/100\n","277/277 [==============================] - 6s 23ms/step - loss: 5.0748 - categorical_accuracy: 0.9605 - val_loss: 6.3121 - val_categorical_accuracy: 0.6498\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.71928\n","Epoch 36/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.9974 - categorical_accuracy: 0.9676 - val_loss: 7.5988 - val_categorical_accuracy: 0.5572\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.71928\n","Epoch 37/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.9627 - categorical_accuracy: 0.9640 - val_loss: 5.9083 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.71928\n","Epoch 38/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.9047 - categorical_accuracy: 0.9682 - val_loss: 6.1300 - val_categorical_accuracy: 0.6675\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.71928\n","Epoch 39/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.8496 - categorical_accuracy: 0.9711 - val_loss: 6.1932 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.71928\n","Epoch 40/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.7845 - categorical_accuracy: 0.9762 - val_loss: 6.0638 - val_categorical_accuracy: 0.6713\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.71928\n","Epoch 41/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.7403 - categorical_accuracy: 0.9739 - val_loss: 5.7922 - val_categorical_accuracy: 0.6852\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.71928\n","Epoch 42/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.6941 - categorical_accuracy: 0.9758 - val_loss: 5.7423 - val_categorical_accuracy: 0.6132\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.71928\n","Epoch 43/100\n","277/277 [==============================] - 6s 22ms/step - loss: 4.6463 - categorical_accuracy: 0.9783 - val_loss: 6.3805 - val_categorical_accuracy: 0.6305\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.71928\n","Epoch 44/100\n","277/277 [==============================] - 7s 25ms/step - loss: 4.5781 - categorical_accuracy: 0.9843 - val_loss: 6.5127 - val_categorical_accuracy: 0.6208\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.71928\n","Epoch 45/100\n","277/277 [==============================] - 6s 22ms/step - loss: 4.5547 - categorical_accuracy: 0.9771 - val_loss: 5.7687 - val_categorical_accuracy: 0.6797\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.71928\n","Epoch 46/100\n","277/277 [==============================] - 7s 24ms/step - loss: 4.5008 - categorical_accuracy: 0.9794 - val_loss: 6.8802 - val_categorical_accuracy: 0.5644\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.71928\n","Epoch 47/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.4503 - categorical_accuracy: 0.9800 - val_loss: 7.2083 - val_categorical_accuracy: 0.5732\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.71928\n","Epoch 48/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.4033 - categorical_accuracy: 0.9820 - val_loss: 5.8088 - val_categorical_accuracy: 0.6587\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.71928\n","Epoch 49/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.3536 - categorical_accuracy: 0.9814 - val_loss: 6.6464 - val_categorical_accuracy: 0.6115\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.71928\n","Epoch 50/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.3270 - categorical_accuracy: 0.9797 - val_loss: 5.5261 - val_categorical_accuracy: 0.6759\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.71928\n","Epoch 51/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.2836 - categorical_accuracy: 0.9747 - val_loss: 5.6163 - val_categorical_accuracy: 0.6671\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.71928\n","Epoch 52/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.2397 - categorical_accuracy: 0.9790 - val_loss: 5.9001 - val_categorical_accuracy: 0.6726\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.71928\n","Epoch 53/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.1921 - categorical_accuracy: 0.9796 - val_loss: 5.2155 - val_categorical_accuracy: 0.7003\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.71928\n","Epoch 54/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.1435 - categorical_accuracy: 0.9826 - val_loss: 6.3615 - val_categorical_accuracy: 0.6359\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.71928\n","Epoch 55/100\n","277/277 [==============================] - 6s 22ms/step - loss: 4.1000 - categorical_accuracy: 0.9852 - val_loss: 5.3550 - val_categorical_accuracy: 0.6532\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.71928\n","Epoch 56/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.0647 - categorical_accuracy: 0.9839 - val_loss: 5.4911 - val_categorical_accuracy: 0.6873\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.71928\n","Epoch 57/100\n","277/277 [==============================] - 6s 23ms/step - loss: 4.0248 - categorical_accuracy: 0.9846 - val_loss: 6.0044 - val_categorical_accuracy: 0.6359\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.71928\n","Epoch 58/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.9759 - categorical_accuracy: 0.9888 - val_loss: 5.3513 - val_categorical_accuracy: 0.6587\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.71928\n","Epoch 59/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.9445 - categorical_accuracy: 0.9844 - val_loss: 5.7141 - val_categorical_accuracy: 0.6646\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.71928\n","Epoch 60/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.9039 - categorical_accuracy: 0.9874 - val_loss: 5.5703 - val_categorical_accuracy: 0.6519\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.71928\n","Epoch 61/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.8735 - categorical_accuracy: 0.9833 - val_loss: 7.9767 - val_categorical_accuracy: 0.4954\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.71928\n","Epoch 62/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.8336 - categorical_accuracy: 0.9867 - val_loss: 5.2280 - val_categorical_accuracy: 0.6662\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.71928\n","Epoch 63/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.7990 - categorical_accuracy: 0.9823 - val_loss: 4.5892 - val_categorical_accuracy: 0.7033\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.71928\n","Epoch 64/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.7535 - categorical_accuracy: 0.9904 - val_loss: 5.8027 - val_categorical_accuracy: 0.6347\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.71928\n","Epoch 65/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.7159 - categorical_accuracy: 0.9884 - val_loss: 5.5641 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.71928\n","Epoch 66/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.6817 - categorical_accuracy: 0.9914 - val_loss: 6.2168 - val_categorical_accuracy: 0.6157\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.71928\n","Epoch 67/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.6537 - categorical_accuracy: 0.9850 - val_loss: 4.7900 - val_categorical_accuracy: 0.6616\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.71928\n","Epoch 68/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.6199 - categorical_accuracy: 0.9862 - val_loss: 5.3395 - val_categorical_accuracy: 0.6730\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.71928\n","Epoch 69/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.5814 - categorical_accuracy: 0.9879 - val_loss: 5.7534 - val_categorical_accuracy: 0.6494\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.71928\n","Epoch 70/100\n","277/277 [==============================] - 7s 23ms/step - loss: 3.5409 - categorical_accuracy: 0.9908 - val_loss: 5.0767 - val_categorical_accuracy: 0.6574\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.71928\n","Epoch 71/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.5121 - categorical_accuracy: 0.9886 - val_loss: 5.2140 - val_categorical_accuracy: 0.6120\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.71928\n","Epoch 72/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.4811 - categorical_accuracy: 0.9867 - val_loss: 5.0881 - val_categorical_accuracy: 0.6717\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.71928\n","Epoch 73/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.4422 - categorical_accuracy: 0.9923 - val_loss: 5.4077 - val_categorical_accuracy: 0.6322\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.71928\n","Epoch 74/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.4144 - categorical_accuracy: 0.9898 - val_loss: 5.0658 - val_categorical_accuracy: 0.5644\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.71928\n","Epoch 75/100\n","277/277 [==============================] - 7s 24ms/step - loss: 3.3785 - categorical_accuracy: 0.9912 - val_loss: 5.0134 - val_categorical_accuracy: 0.6216\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.71928\n","Epoch 76/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.3505 - categorical_accuracy: 0.9918 - val_loss: 5.2647 - val_categorical_accuracy: 0.6372\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.71928\n","Epoch 77/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.3249 - categorical_accuracy: 0.9868 - val_loss: 4.8016 - val_categorical_accuracy: 0.6570\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.71928\n","Epoch 78/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.2883 - categorical_accuracy: 0.9889 - val_loss: 4.9537 - val_categorical_accuracy: 0.6646\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.71928\n","Epoch 79/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.2569 - categorical_accuracy: 0.9905 - val_loss: 4.9330 - val_categorical_accuracy: 0.6364\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.71928\n","Epoch 80/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.2277 - categorical_accuracy: 0.9897 - val_loss: 5.3123 - val_categorical_accuracy: 0.6705\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.71928\n","Epoch 81/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.1964 - categorical_accuracy: 0.9900 - val_loss: 7.1316 - val_categorical_accuracy: 0.5488\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.71928\n","Epoch 82/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.1703 - categorical_accuracy: 0.9909 - val_loss: 6.0223 - val_categorical_accuracy: 0.6136\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.71928\n","Epoch 83/100\n","277/277 [==============================] - 7s 24ms/step - loss: 3.1429 - categorical_accuracy: 0.9929 - val_loss: 6.3787 - val_categorical_accuracy: 0.5581\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.71928\n","Epoch 84/100\n","277/277 [==============================] - 6s 23ms/step - loss: 3.1099 - categorical_accuracy: 0.9913 - val_loss: 4.8871 - val_categorical_accuracy: 0.6477\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.71928\n","Epoch 85/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.0805 - categorical_accuracy: 0.9934 - val_loss: 4.7088 - val_categorical_accuracy: 0.5728\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.71928\n","Epoch 86/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.0559 - categorical_accuracy: 0.9907 - val_loss: 5.0869 - val_categorical_accuracy: 0.6898\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.71928\n","Epoch 87/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.0292 - categorical_accuracy: 0.9930 - val_loss: 4.4507 - val_categorical_accuracy: 0.6923\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.71928\n","Epoch 88/100\n","277/277 [==============================] - 6s 22ms/step - loss: 3.0036 - categorical_accuracy: 0.9919 - val_loss: 5.0132 - val_categorical_accuracy: 0.6380\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.71928\n","Epoch 89/100\n","277/277 [==============================] - 6s 23ms/step - loss: 2.9728 - categorical_accuracy: 0.9917 - val_loss: 5.2111 - val_categorical_accuracy: 0.6237\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.71928\n","Epoch 90/100\n","277/277 [==============================] - 6s 22ms/step - loss: 2.9495 - categorical_accuracy: 0.9914 - val_loss: 5.7565 - val_categorical_accuracy: 0.6250\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.71928\n","Epoch 91/100\n","277/277 [==============================] - 7s 25ms/step - loss: 2.9249 - categorical_accuracy: 0.9919 - val_loss: 5.3828 - val_categorical_accuracy: 0.6136\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.71928\n","Epoch 92/100\n","277/277 [==============================] - 7s 24ms/step - loss: 2.8950 - categorical_accuracy: 0.9912 - val_loss: 6.2931 - val_categorical_accuracy: 0.5657\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.71928\n","Epoch 93/100\n","277/277 [==============================] - 7s 24ms/step - loss: 2.8706 - categorical_accuracy: 0.9912 - val_loss: 6.2823 - val_categorical_accuracy: 0.5804\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.71928\n","Epoch 94/100\n","277/277 [==============================] - 7s 24ms/step - loss: 2.8441 - categorical_accuracy: 0.9924 - val_loss: 4.5378 - val_categorical_accuracy: 0.6696\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.71928\n","Epoch 95/100\n","277/277 [==============================] - 7s 25ms/step - loss: 2.8253 - categorical_accuracy: 0.9911 - val_loss: 4.6657 - val_categorical_accuracy: 0.6692\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.71928\n","Epoch 96/100\n","277/277 [==============================] - 6s 23ms/step - loss: 2.7942 - categorical_accuracy: 0.9916 - val_loss: 6.4535 - val_categorical_accuracy: 0.5829\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.71928\n","Epoch 97/100\n","277/277 [==============================] - 6s 23ms/step - loss: 2.7714 - categorical_accuracy: 0.9929 - val_loss: 4.3479 - val_categorical_accuracy: 0.5745\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.71928\n","Epoch 98/100\n","277/277 [==============================] - 7s 25ms/step - loss: 2.7507 - categorical_accuracy: 0.9896 - val_loss: 5.0873 - val_categorical_accuracy: 0.5295\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.71928\n","Epoch 99/100\n","277/277 [==============================] - 7s 24ms/step - loss: 2.7243 - categorical_accuracy: 0.9926 - val_loss: 4.0435 - val_categorical_accuracy: 0.7037\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.71928\n","Epoch 100/100\n","277/277 [==============================] - 6s 23ms/step - loss: 2.7019 - categorical_accuracy: 0.9932 - val_loss: 3.7097 - val_categorical_accuracy: 0.6932\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.71928\n","75/75 [==============================] - 1s 10ms/step - loss: 7.7912 - categorical_accuracy: 0.7193\n","Test Accuracy =  72.0\n","75/75 [==============================] - 1s 8ms/step\n","Model: \"model_19\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_342 (Conv2D)             (None, 20, 20, 64)   4160        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 20, 20, 64)   256         conv2d_342[0][0]                 \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 20, 20, 64)   0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","lambda_145 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_147 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_149 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_151 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_344 (Conv2D)             (None, 20, 20, 8)    584         lambda_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_348 (Conv2D)             (None, 20, 20, 8)    584         lambda_147[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_352 (Conv2D)             (None, 20, 20, 8)    584         lambda_149[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_356 (Conv2D)             (None, 20, 20, 8)    584         lambda_151[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_144 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_345 (Conv2D)             (None, 20, 20, 8)    584         conv2d_344[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_146 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_349 (Conv2D)             (None, 20, 20, 8)    584         conv2d_348[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_148 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_353 (Conv2D)             (None, 20, 20, 8)    584         conv2d_352[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_150 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_357 (Conv2D)             (None, 20, 20, 8)    584         conv2d_356[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_343 (Conv2D)             (None, 20, 20, 8)    584         lambda_144[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_346 (Conv2D)             (None, 20, 20, 8)    584         conv2d_345[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_347 (Conv2D)             (None, 20, 20, 8)    584         lambda_146[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_350 (Conv2D)             (None, 20, 20, 8)    584         conv2d_349[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_351 (Conv2D)             (None, 20, 20, 8)    584         lambda_148[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_354 (Conv2D)             (None, 20, 20, 8)    584         conv2d_353[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_355 (Conv2D)             (None, 20, 20, 8)    584         lambda_150[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_358 (Conv2D)             (None, 20, 20, 8)    584         conv2d_357[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 20, 20, 64)   0           conv2d_343[0][0]                 \n","                                                                 conv2d_346[0][0]                 \n","                                                                 conv2d_347[0][0]                 \n","                                                                 conv2d_350[0][0]                 \n","                                                                 conv2d_351[0][0]                 \n","                                                                 conv2d_354[0][0]                 \n","                                                                 conv2d_355[0][0]                 \n","                                                                 conv2d_358[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 20, 20, 64)   256         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 20, 20, 64)   0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_36 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_109[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_18 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_36[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_18 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_18[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_37 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 20, 20, 64)   256         tf.reshape_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 20, 20, 64)   0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_359 (Conv2D)             (None, 20, 20, 128)  8320        activation_110[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_360 (Conv2D)             (None, 20, 20, 128)  8320        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 20, 20, 128)  512         conv2d_359[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 20, 20, 128)  512         conv2d_360[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 20, 20, 128)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 20, 20, 128)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 20, 20, 128)  0           activation_111[0][0]             \n","                                                                 activation_112[0][0]             \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 20, 20, 128)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_361 (Conv2D)             (None, 20, 20, 128)  16512       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 20, 20, 128)  512         conv2d_361[0][0]                 \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 20, 20, 128)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","lambda_153 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_155 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_157 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_159 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_363 (Conv2D)             (None, 20, 20, 16)   2320        lambda_153[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_367 (Conv2D)             (None, 20, 20, 16)   2320        lambda_155[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_371 (Conv2D)             (None, 20, 20, 16)   2320        lambda_157[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_375 (Conv2D)             (None, 20, 20, 16)   2320        lambda_159[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_152 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_364 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_363[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_154 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_368 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_367[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_156 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_372 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_371[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_158 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_376 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_375[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_362 (Conv2D)             (None, 20, 20, 16)   2320        lambda_152[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_365 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_364[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_366 (Conv2D)             (None, 20, 20, 16)   2320        lambda_154[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_369 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_368[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_370 (Conv2D)             (None, 20, 20, 16)   2320        lambda_156[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_373 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_372[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_374 (Conv2D)             (None, 20, 20, 16)   2320        lambda_158[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_377 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_376[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 20, 20, 128)  0           conv2d_362[0][0]                 \n","                                                                 conv2d_365[0][0]                 \n","                                                                 conv2d_366[0][0]                 \n","                                                                 conv2d_369[0][0]                 \n","                                                                 conv2d_370[0][0]                 \n","                                                                 conv2d_373[0][0]                 \n","                                                                 conv2d_374[0][0]                 \n","                                                                 conv2d_377[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 20, 20, 128)  512         concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 20, 20, 128)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_38 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_115[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_19 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_38[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_19 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_19[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_39 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 20, 20, 128)  512         tf.reshape_39[0][0]              \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 20, 20, 128)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_378 (Conv2D)             (None, 20, 20, 256)  33024       activation_116[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_379 (Conv2D)             (None, 20, 20, 256)  33024       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 20, 20, 256)  1024        conv2d_378[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 20, 20, 256)  1024        conv2d_379[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 20, 20, 256)  0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 20, 20, 256)  0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 20, 20, 256)  0           activation_117[0][0]             \n","                                                                 activation_118[0][0]             \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 20, 20, 256)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_9 (Glo (None, 256)          0           activation_119[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 80 percent samples from each class in training set \n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples is 7906.\n","\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in training set is 6322.\n","Samples per class in training set: [1094  418  258  584  284  669 1779  368  868]\n","\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in test set is 1584.\n","Samples per class in test set: [274 105  65 146  72 168 445  92 217]\n","\n","X_train => (6322, 20, 20, 64)\n","X_test  => (1584, 20, 20, 64)\n","y_train => (6322, 9)\n","y_test  => (1584, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model_20\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_380 (Conv2D)             (None, 20, 20, 64)   4160        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 20, 20, 64)   256         conv2d_380[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 20, 20, 64)   0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","lambda_161 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_163 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_165 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_167 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_382 (Conv2D)             (None, 20, 20, 8)    584         lambda_161[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_386 (Conv2D)             (None, 20, 20, 8)    584         lambda_163[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_390 (Conv2D)             (None, 20, 20, 8)    584         lambda_165[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_394 (Conv2D)             (None, 20, 20, 8)    584         lambda_167[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_160 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_383 (Conv2D)             (None, 20, 20, 8)    584         conv2d_382[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_162 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_387 (Conv2D)             (None, 20, 20, 8)    584         conv2d_386[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_164 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_391 (Conv2D)             (None, 20, 20, 8)    584         conv2d_390[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_166 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_395 (Conv2D)             (None, 20, 20, 8)    584         conv2d_394[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_381 (Conv2D)             (None, 20, 20, 8)    584         lambda_160[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_384 (Conv2D)             (None, 20, 20, 8)    584         conv2d_383[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_385 (Conv2D)             (None, 20, 20, 8)    584         lambda_162[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_388 (Conv2D)             (None, 20, 20, 8)    584         conv2d_387[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_389 (Conv2D)             (None, 20, 20, 8)    584         lambda_164[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_392 (Conv2D)             (None, 20, 20, 8)    584         conv2d_391[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_393 (Conv2D)             (None, 20, 20, 8)    584         lambda_166[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_396 (Conv2D)             (None, 20, 20, 8)    584         conv2d_395[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 20, 20, 64)   0           conv2d_381[0][0]                 \n","                                                                 conv2d_384[0][0]                 \n","                                                                 conv2d_385[0][0]                 \n","                                                                 conv2d_388[0][0]                 \n","                                                                 conv2d_389[0][0]                 \n","                                                                 conv2d_392[0][0]                 \n","                                                                 conv2d_393[0][0]                 \n","                                                                 conv2d_396[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 20, 20, 64)   256         concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_121 (Activation)     (None, 20, 20, 64)   0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_40 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_121[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_20 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_40[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_20 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_20[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_41 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 20, 20, 64)   256         tf.reshape_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 20, 20, 64)   0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_397 (Conv2D)             (None, 20, 20, 128)  8320        activation_122[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_398 (Conv2D)             (None, 20, 20, 128)  8320        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 20, 20, 128)  512         conv2d_397[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 20, 20, 128)  512         conv2d_398[0][0]                 \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 20, 20, 128)  0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 20, 20, 128)  0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 20, 20, 128)  0           activation_123[0][0]             \n","                                                                 activation_124[0][0]             \n","__________________________________________________________________________________________________\n","activation_125 (Activation)     (None, 20, 20, 128)  0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_399 (Conv2D)             (None, 20, 20, 128)  16512       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 20, 20, 128)  512         conv2d_399[0][0]                 \n","__________________________________________________________________________________________________\n","activation_126 (Activation)     (None, 20, 20, 128)  0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","lambda_169 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_171 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_173 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_175 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_401 (Conv2D)             (None, 20, 20, 16)   2320        lambda_169[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_405 (Conv2D)             (None, 20, 20, 16)   2320        lambda_171[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_409 (Conv2D)             (None, 20, 20, 16)   2320        lambda_173[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_413 (Conv2D)             (None, 20, 20, 16)   2320        lambda_175[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_168 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_402 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_401[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_170 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_406 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_405[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_172 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_410 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_409[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_174 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_414 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_413[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_400 (Conv2D)             (None, 20, 20, 16)   2320        lambda_168[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_403 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_402[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_404 (Conv2D)             (None, 20, 20, 16)   2320        lambda_170[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_407 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_406[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_408 (Conv2D)             (None, 20, 20, 16)   2320        lambda_172[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_411 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_410[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_412 (Conv2D)             (None, 20, 20, 16)   2320        lambda_174[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_415 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_414[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 20, 20, 128)  0           conv2d_400[0][0]                 \n","                                                                 conv2d_403[0][0]                 \n","                                                                 conv2d_404[0][0]                 \n","                                                                 conv2d_407[0][0]                 \n","                                                                 conv2d_408[0][0]                 \n","                                                                 conv2d_411[0][0]                 \n","                                                                 conv2d_412[0][0]                 \n","                                                                 conv2d_415[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 20, 20, 128)  512         concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_127 (Activation)     (None, 20, 20, 128)  0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_42 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_127[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_21 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_42[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_21 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_21[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_43 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 20, 20, 128)  512         tf.reshape_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_128 (Activation)     (None, 20, 20, 128)  0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_416 (Conv2D)             (None, 20, 20, 256)  33024       activation_128[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_417 (Conv2D)             (None, 20, 20, 256)  33024       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 20, 20, 256)  1024        conv2d_416[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 20, 20, 256)  1024        conv2d_417[0][0]                 \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 20, 20, 256)  0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 20, 20, 256)  0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 20, 20, 256)  0           activation_129[0][0]             \n","                                                                 activation_130[0][0]             \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 20, 20, 256)  0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_10 (Gl (None, 256)          0           activation_131[0][0]             \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_10[0][0]\n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","317/317 [==============================] - 11s 24ms/step - loss: 8.9911 - categorical_accuracy: 0.3351 - val_loss: 8.6852 - val_categorical_accuracy: 0.3264\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.32639, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","317/317 [==============================] - 7s 21ms/step - loss: 8.3544 - categorical_accuracy: 0.4965 - val_loss: 8.0884 - val_categorical_accuracy: 0.5208\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.32639 to 0.52083, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","317/317 [==============================] - 7s 21ms/step - loss: 8.0438 - categorical_accuracy: 0.5991 - val_loss: 7.9080 - val_categorical_accuracy: 0.5556\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.52083 to 0.55556, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","317/317 [==============================] - 7s 22ms/step - loss: 7.8169 - categorical_accuracy: 0.6539 - val_loss: 7.6245 - val_categorical_accuracy: 0.7071\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.55556 to 0.70707, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","317/317 [==============================] - 7s 22ms/step - loss: 7.6184 - categorical_accuracy: 0.6886 - val_loss: 7.4516 - val_categorical_accuracy: 0.7386\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.70707 to 0.73864, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","317/317 [==============================] - 7s 22ms/step - loss: 7.4691 - categorical_accuracy: 0.6989 - val_loss: 7.3007 - val_categorical_accuracy: 0.7702\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.73864 to 0.77020, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","317/317 [==============================] - 7s 22ms/step - loss: 7.3243 - categorical_accuracy: 0.7169 - val_loss: 7.1737 - val_categorical_accuracy: 0.7778\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.77020 to 0.77778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","317/317 [==============================] - 7s 22ms/step - loss: 7.1763 - categorical_accuracy: 0.7500 - val_loss: 7.0879 - val_categorical_accuracy: 0.7753\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.77778\n","Epoch 9/100\n","317/317 [==============================] - 8s 24ms/step - loss: 7.0611 - categorical_accuracy: 0.7613 - val_loss: 7.0172 - val_categorical_accuracy: 0.7601\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.77778\n","Epoch 10/100\n","317/317 [==============================] - 7s 22ms/step - loss: 6.9258 - categorical_accuracy: 0.7951 - val_loss: 6.9008 - val_categorical_accuracy: 0.7797\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.77778 to 0.77967, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 11/100\n","317/317 [==============================] - 7s 23ms/step - loss: 6.8086 - categorical_accuracy: 0.8136 - val_loss: 6.8506 - val_categorical_accuracy: 0.7639\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.77967\n","Epoch 12/100\n","317/317 [==============================] - 7s 22ms/step - loss: 6.7000 - categorical_accuracy: 0.8307 - val_loss: 6.7513 - val_categorical_accuracy: 0.7746\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.77967\n","Epoch 13/100\n","317/317 [==============================] - 7s 22ms/step - loss: 6.6132 - categorical_accuracy: 0.8365 - val_loss: 6.6736 - val_categorical_accuracy: 0.7778\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.77967\n","Epoch 14/100\n","317/317 [==============================] - 7s 23ms/step - loss: 6.4939 - categorical_accuracy: 0.8534 - val_loss: 6.7174 - val_categorical_accuracy: 0.7203\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.77967\n","Epoch 15/100\n","317/317 [==============================] - 7s 23ms/step - loss: 6.3998 - categorical_accuracy: 0.8599 - val_loss: 6.5405 - val_categorical_accuracy: 0.7708\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.77967\n","Epoch 16/100\n","317/317 [==============================] - 7s 21ms/step - loss: 6.2915 - categorical_accuracy: 0.8669 - val_loss: 6.5787 - val_categorical_accuracy: 0.7146\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.77967\n","Epoch 17/100\n","317/317 [==============================] - 7s 23ms/step - loss: 6.1913 - categorical_accuracy: 0.8770 - val_loss: 6.4511 - val_categorical_accuracy: 0.7513\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.77967\n","Epoch 18/100\n","317/317 [==============================] - 7s 22ms/step - loss: 6.0945 - categorical_accuracy: 0.8890 - val_loss: 6.2986 - val_categorical_accuracy: 0.7942\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.77967 to 0.79419, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","317/317 [==============================] - 7s 22ms/step - loss: 6.0109 - categorical_accuracy: 0.8987 - val_loss: 6.2097 - val_categorical_accuracy: 0.8056\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.79419 to 0.80556, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 20/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.9180 - categorical_accuracy: 0.9039 - val_loss: 6.1684 - val_categorical_accuracy: 0.7917\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.80556\n","Epoch 21/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.8321 - categorical_accuracy: 0.9090 - val_loss: 6.1074 - val_categorical_accuracy: 0.7740\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.80556\n","Epoch 22/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.7558 - categorical_accuracy: 0.9095 - val_loss: 6.0220 - val_categorical_accuracy: 0.7828\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.80556\n","Epoch 23/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.6720 - categorical_accuracy: 0.9163 - val_loss: 6.1069 - val_categorical_accuracy: 0.7077\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.80556\n","Epoch 24/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.5888 - categorical_accuracy: 0.9229 - val_loss: 5.9284 - val_categorical_accuracy: 0.7677\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.80556\n","Epoch 25/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.5158 - categorical_accuracy: 0.9290 - val_loss: 5.8479 - val_categorical_accuracy: 0.7790\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.80556\n","Epoch 26/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.4381 - categorical_accuracy: 0.9339 - val_loss: 5.8475 - val_categorical_accuracy: 0.7355\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.80556\n","Epoch 27/100\n","317/317 [==============================] - 7s 23ms/step - loss: 5.3856 - categorical_accuracy: 0.9267 - val_loss: 5.6937 - val_categorical_accuracy: 0.8056\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.80556\n","Epoch 28/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.3037 - categorical_accuracy: 0.9382 - val_loss: 5.7343 - val_categorical_accuracy: 0.7247\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.80556\n","Epoch 29/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.2252 - categorical_accuracy: 0.9478 - val_loss: 5.6790 - val_categorical_accuracy: 0.7361\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.80556\n","Epoch 30/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.1719 - categorical_accuracy: 0.9400 - val_loss: 5.9739 - val_categorical_accuracy: 0.6105\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.80556\n","Epoch 31/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.0914 - categorical_accuracy: 0.9492 - val_loss: 5.9200 - val_categorical_accuracy: 0.6199\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.80556\n","Epoch 32/100\n","317/317 [==============================] - 7s 22ms/step - loss: 5.0292 - categorical_accuracy: 0.9508 - val_loss: 5.5978 - val_categorical_accuracy: 0.7146\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.80556\n","Epoch 33/100\n","317/317 [==============================] - 7s 23ms/step - loss: 4.9661 - categorical_accuracy: 0.9536 - val_loss: 5.9569 - val_categorical_accuracy: 0.6035\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.80556\n","Epoch 34/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.9026 - categorical_accuracy: 0.9542 - val_loss: 5.5288 - val_categorical_accuracy: 0.7058\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.80556\n","Epoch 35/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.8474 - categorical_accuracy: 0.9549 - val_loss: 5.7310 - val_categorical_accuracy: 0.5985\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.80556\n","Epoch 36/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.7814 - categorical_accuracy: 0.9568 - val_loss: 5.2444 - val_categorical_accuracy: 0.8112\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.80556 to 0.81124, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 37/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.7233 - categorical_accuracy: 0.9598 - val_loss: 5.3912 - val_categorical_accuracy: 0.7128\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.81124\n","Epoch 38/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.6706 - categorical_accuracy: 0.9610 - val_loss: 5.8837 - val_categorical_accuracy: 0.5568\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.81124\n","Epoch 39/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.6156 - categorical_accuracy: 0.9627 - val_loss: 5.0765 - val_categorical_accuracy: 0.8030\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.81124\n","Epoch 40/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.5629 - categorical_accuracy: 0.9593 - val_loss: 5.4008 - val_categorical_accuracy: 0.6692\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.81124\n","Epoch 41/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.4946 - categorical_accuracy: 0.9655 - val_loss: 5.7558 - val_categorical_accuracy: 0.5732\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.81124\n","Epoch 42/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.4518 - categorical_accuracy: 0.9635 - val_loss: 6.2086 - val_categorical_accuracy: 0.5638\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.81124\n","Epoch 43/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.3980 - categorical_accuracy: 0.9676 - val_loss: 6.3518 - val_categorical_accuracy: 0.5309\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.81124\n","Epoch 44/100\n","317/317 [==============================] - 7s 21ms/step - loss: 4.3518 - categorical_accuracy: 0.9651 - val_loss: 4.9352 - val_categorical_accuracy: 0.8011\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.81124\n","Epoch 45/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.2884 - categorical_accuracy: 0.9698 - val_loss: 6.7161 - val_categorical_accuracy: 0.4918\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.81124\n","Epoch 46/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.2449 - categorical_accuracy: 0.9670 - val_loss: 7.1594 - val_categorical_accuracy: 0.4091\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.81124\n","Epoch 47/100\n","317/317 [==============================] - 7s 23ms/step - loss: 4.1941 - categorical_accuracy: 0.9718 - val_loss: 5.2442 - val_categorical_accuracy: 0.6503\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.81124\n","Epoch 48/100\n","317/317 [==============================] - 7s 23ms/step - loss: 4.1470 - categorical_accuracy: 0.9715 - val_loss: 4.9431 - val_categorical_accuracy: 0.7134\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.81124\n","Epoch 49/100\n","317/317 [==============================] - 7s 23ms/step - loss: 4.1075 - categorical_accuracy: 0.9700 - val_loss: 4.7032 - val_categorical_accuracy: 0.7910\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.81124\n","Epoch 50/100\n","317/317 [==============================] - 7s 22ms/step - loss: 4.0624 - categorical_accuracy: 0.9713 - val_loss: 5.7080 - val_categorical_accuracy: 0.5423\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.81124\n","Epoch 51/100\n","317/317 [==============================] - 7s 23ms/step - loss: 4.0134 - categorical_accuracy: 0.9735 - val_loss: 5.3018 - val_categorical_accuracy: 0.6439\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.81124\n","Epoch 52/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.9609 - categorical_accuracy: 0.9745 - val_loss: 6.3314 - val_categorical_accuracy: 0.4867\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.81124\n","Epoch 53/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.9186 - categorical_accuracy: 0.9738 - val_loss: 4.6579 - val_categorical_accuracy: 0.7348\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.81124\n","Epoch 54/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.8982 - categorical_accuracy: 0.9674 - val_loss: 4.6045 - val_categorical_accuracy: 0.7601\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.81124\n","Epoch 55/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.8458 - categorical_accuracy: 0.9734 - val_loss: 4.7216 - val_categorical_accuracy: 0.7279\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.81124\n","Epoch 56/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.7880 - categorical_accuracy: 0.9771 - val_loss: 4.4558 - val_categorical_accuracy: 0.7847\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.81124\n","Epoch 57/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.7448 - categorical_accuracy: 0.9790 - val_loss: 6.4038 - val_categorical_accuracy: 0.4785\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.81124\n","Epoch 58/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.7008 - categorical_accuracy: 0.9824 - val_loss: 6.9066 - val_categorical_accuracy: 0.5442\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.81124\n","Epoch 59/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.6593 - categorical_accuracy: 0.9808 - val_loss: 4.7149 - val_categorical_accuracy: 0.6755\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.81124\n","Epoch 60/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.6269 - categorical_accuracy: 0.9811 - val_loss: 4.3707 - val_categorical_accuracy: 0.7734\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.81124\n","Epoch 61/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.5846 - categorical_accuracy: 0.9809 - val_loss: 4.1855 - val_categorical_accuracy: 0.7936\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.81124\n","Epoch 62/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.5392 - categorical_accuracy: 0.9811 - val_loss: 4.3466 - val_categorical_accuracy: 0.7462\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.81124\n","Epoch 63/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.4976 - categorical_accuracy: 0.9842 - val_loss: 4.5241 - val_categorical_accuracy: 0.6862\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.81124\n","Epoch 64/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.4627 - categorical_accuracy: 0.9857 - val_loss: 4.2554 - val_categorical_accuracy: 0.7500\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.81124\n","Epoch 65/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.4322 - categorical_accuracy: 0.9806 - val_loss: 6.9494 - val_categorical_accuracy: 0.3763\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.81124\n","Epoch 66/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.3917 - categorical_accuracy: 0.9849 - val_loss: 4.4477 - val_categorical_accuracy: 0.7241\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.81124\n","Epoch 67/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.3521 - categorical_accuracy: 0.9854 - val_loss: 6.6108 - val_categorical_accuracy: 0.4192\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.81124\n","Epoch 68/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.3232 - categorical_accuracy: 0.9842 - val_loss: 5.7075 - val_categorical_accuracy: 0.5758\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.81124\n","Epoch 69/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.2904 - categorical_accuracy: 0.9821 - val_loss: 5.7500 - val_categorical_accuracy: 0.5852\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.81124\n","Epoch 70/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.2566 - categorical_accuracy: 0.9824 - val_loss: 5.1887 - val_categorical_accuracy: 0.6187\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.81124\n","Epoch 71/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.2217 - categorical_accuracy: 0.9806 - val_loss: 3.8800 - val_categorical_accuracy: 0.8018\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.81124\n","Epoch 72/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.1842 - categorical_accuracy: 0.9860 - val_loss: 4.7615 - val_categorical_accuracy: 0.5442\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.81124\n","Epoch 73/100\n","317/317 [==============================] - 7s 23ms/step - loss: 3.1701 - categorical_accuracy: 0.9816 - val_loss: 4.3877 - val_categorical_accuracy: 0.6622\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.81124\n","Epoch 74/100\n","317/317 [==============================] - 7s 21ms/step - loss: 3.1293 - categorical_accuracy: 0.9827 - val_loss: 5.3827 - val_categorical_accuracy: 0.5587\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.81124\n","Epoch 75/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.0836 - categorical_accuracy: 0.9843 - val_loss: 4.0901 - val_categorical_accuracy: 0.7424\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.81124\n","Epoch 76/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.0474 - categorical_accuracy: 0.9880 - val_loss: 4.2489 - val_categorical_accuracy: 0.6635\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.81124\n","Epoch 77/100\n","317/317 [==============================] - 7s 22ms/step - loss: 3.0176 - categorical_accuracy: 0.9888 - val_loss: 4.7570 - val_categorical_accuracy: 0.5909\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.81124\n","Epoch 78/100\n","317/317 [==============================] - 7s 23ms/step - loss: 2.9838 - categorical_accuracy: 0.9891 - val_loss: 5.0511 - val_categorical_accuracy: 0.5979\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.81124\n","Epoch 79/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.9546 - categorical_accuracy: 0.9885 - val_loss: 3.8505 - val_categorical_accuracy: 0.7153\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.81124\n","Epoch 80/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.9225 - categorical_accuracy: 0.9881 - val_loss: 4.3428 - val_categorical_accuracy: 0.6269\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.81124\n","Epoch 81/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.8987 - categorical_accuracy: 0.9864 - val_loss: 3.7986 - val_categorical_accuracy: 0.7683\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.81124\n","Epoch 82/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.8653 - categorical_accuracy: 0.9896 - val_loss: 5.7128 - val_categorical_accuracy: 0.6913\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.81124\n","Epoch 83/100\n","317/317 [==============================] - 7s 23ms/step - loss: 2.8324 - categorical_accuracy: 0.9922 - val_loss: 4.0091 - val_categorical_accuracy: 0.7090\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.81124\n","Epoch 84/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.8085 - categorical_accuracy: 0.9904 - val_loss: 5.1936 - val_categorical_accuracy: 0.6143\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.81124\n","Epoch 85/100\n","317/317 [==============================] - 7s 23ms/step - loss: 2.7809 - categorical_accuracy: 0.9895 - val_loss: 4.3073 - val_categorical_accuracy: 0.6098\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.81124\n","Epoch 86/100\n","317/317 [==============================] - 7s 23ms/step - loss: 2.7634 - categorical_accuracy: 0.9848 - val_loss: 3.8539 - val_categorical_accuracy: 0.7759\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.81124\n","Epoch 87/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.7304 - categorical_accuracy: 0.9877 - val_loss: 4.0092 - val_categorical_accuracy: 0.6831\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.81124\n","Epoch 88/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.7016 - categorical_accuracy: 0.9883 - val_loss: 4.3216 - val_categorical_accuracy: 0.6648\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.81124\n","Epoch 89/100\n","317/317 [==============================] - 7s 21ms/step - loss: 2.6718 - categorical_accuracy: 0.9900 - val_loss: 5.1837 - val_categorical_accuracy: 0.5694\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.81124\n","Epoch 90/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.6438 - categorical_accuracy: 0.9908 - val_loss: 5.1433 - val_categorical_accuracy: 0.5556\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.81124\n","Epoch 91/100\n","317/317 [==============================] - 7s 22ms/step - loss: 2.6291 - categorical_accuracy: 0.9873 - val_loss: 5.3570 - val_categorical_accuracy: 0.4463\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.81124\n","Epoch 92/100\n","317/317 [==============================] - 7s 21ms/step - loss: 2.5966 - categorical_accuracy: 0.9882 - val_loss: 5.5336 - val_categorical_accuracy: 0.5234\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.81124\n","Epoch 93/100\n","317/317 [==============================] - 7s 23ms/step - loss: 2.5655 - categorical_accuracy: 0.9915 - val_loss: 3.7197 - val_categorical_accuracy: 0.6932\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.81124\n","Epoch 94/100\n","317/317 [==============================] - 6s 19ms/step - loss: 2.5424 - categorical_accuracy: 0.9928 - val_loss: 3.6532 - val_categorical_accuracy: 0.7077\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.81124\n","Epoch 95/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.5081 - categorical_accuracy: 0.9944 - val_loss: 4.4980 - val_categorical_accuracy: 0.5606\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.81124\n","Epoch 96/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.5003 - categorical_accuracy: 0.9897 - val_loss: 5.0511 - val_categorical_accuracy: 0.5701\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.81124\n","Epoch 97/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.4709 - categorical_accuracy: 0.9910 - val_loss: 3.4684 - val_categorical_accuracy: 0.7210\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.81124\n","Epoch 98/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.4421 - categorical_accuracy: 0.9924 - val_loss: 3.4938 - val_categorical_accuracy: 0.7462\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.81124\n","Epoch 99/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.4163 - categorical_accuracy: 0.9923 - val_loss: 6.3792 - val_categorical_accuracy: 0.4817\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.81124\n","Epoch 100/100\n","317/317 [==============================] - 5s 16ms/step - loss: 2.3974 - categorical_accuracy: 0.9920 - val_loss: 3.7090 - val_categorical_accuracy: 0.6957\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.81124\n","50/50 [==============================] - 1s 7ms/step - loss: 5.2444 - categorical_accuracy: 0.8112\n","Test Accuracy =  81.0\n","50/50 [==============================] - 1s 6ms/step\n","Model: \"model_21\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_380 (Conv2D)             (None, 20, 20, 64)   4160        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 20, 20, 64)   256         conv2d_380[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 20, 20, 64)   0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","lambda_161 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_163 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_165 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_167 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_382 (Conv2D)             (None, 20, 20, 8)    584         lambda_161[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_386 (Conv2D)             (None, 20, 20, 8)    584         lambda_163[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_390 (Conv2D)             (None, 20, 20, 8)    584         lambda_165[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_394 (Conv2D)             (None, 20, 20, 8)    584         lambda_167[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_160 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_383 (Conv2D)             (None, 20, 20, 8)    584         conv2d_382[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_162 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_387 (Conv2D)             (None, 20, 20, 8)    584         conv2d_386[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_164 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_391 (Conv2D)             (None, 20, 20, 8)    584         conv2d_390[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_166 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_395 (Conv2D)             (None, 20, 20, 8)    584         conv2d_394[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_381 (Conv2D)             (None, 20, 20, 8)    584         lambda_160[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_384 (Conv2D)             (None, 20, 20, 8)    584         conv2d_383[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_385 (Conv2D)             (None, 20, 20, 8)    584         lambda_162[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_388 (Conv2D)             (None, 20, 20, 8)    584         conv2d_387[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_389 (Conv2D)             (None, 20, 20, 8)    584         lambda_164[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_392 (Conv2D)             (None, 20, 20, 8)    584         conv2d_391[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_393 (Conv2D)             (None, 20, 20, 8)    584         lambda_166[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_396 (Conv2D)             (None, 20, 20, 8)    584         conv2d_395[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 20, 20, 64)   0           conv2d_381[0][0]                 \n","                                                                 conv2d_384[0][0]                 \n","                                                                 conv2d_385[0][0]                 \n","                                                                 conv2d_388[0][0]                 \n","                                                                 conv2d_389[0][0]                 \n","                                                                 conv2d_392[0][0]                 \n","                                                                 conv2d_393[0][0]                 \n","                                                                 conv2d_396[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 20, 20, 64)   256         concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_121 (Activation)     (None, 20, 20, 64)   0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_40 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_121[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_20 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_40[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_20 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_20[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_41 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 20, 20, 64)   256         tf.reshape_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 20, 20, 64)   0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_397 (Conv2D)             (None, 20, 20, 128)  8320        activation_122[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_398 (Conv2D)             (None, 20, 20, 128)  8320        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 20, 20, 128)  512         conv2d_397[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 20, 20, 128)  512         conv2d_398[0][0]                 \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 20, 20, 128)  0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 20, 20, 128)  0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 20, 20, 128)  0           activation_123[0][0]             \n","                                                                 activation_124[0][0]             \n","__________________________________________________________________________________________________\n","activation_125 (Activation)     (None, 20, 20, 128)  0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_399 (Conv2D)             (None, 20, 20, 128)  16512       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 20, 20, 128)  512         conv2d_399[0][0]                 \n","__________________________________________________________________________________________________\n","activation_126 (Activation)     (None, 20, 20, 128)  0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","lambda_169 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_171 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_173 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_175 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_401 (Conv2D)             (None, 20, 20, 16)   2320        lambda_169[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_405 (Conv2D)             (None, 20, 20, 16)   2320        lambda_171[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_409 (Conv2D)             (None, 20, 20, 16)   2320        lambda_173[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_413 (Conv2D)             (None, 20, 20, 16)   2320        lambda_175[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_168 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_402 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_401[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_170 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_406 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_405[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_172 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_410 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_409[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_174 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_414 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_413[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_400 (Conv2D)             (None, 20, 20, 16)   2320        lambda_168[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_403 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_402[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_404 (Conv2D)             (None, 20, 20, 16)   2320        lambda_170[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_407 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_406[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_408 (Conv2D)             (None, 20, 20, 16)   2320        lambda_172[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_411 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_410[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_412 (Conv2D)             (None, 20, 20, 16)   2320        lambda_174[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_415 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_414[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 20, 20, 128)  0           conv2d_400[0][0]                 \n","                                                                 conv2d_403[0][0]                 \n","                                                                 conv2d_404[0][0]                 \n","                                                                 conv2d_407[0][0]                 \n","                                                                 conv2d_408[0][0]                 \n","                                                                 conv2d_411[0][0]                 \n","                                                                 conv2d_412[0][0]                 \n","                                                                 conv2d_415[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 20, 20, 128)  512         concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_127 (Activation)     (None, 20, 20, 128)  0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_42 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_127[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_21 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_42[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_21 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_21[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_43 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 20, 20, 128)  512         tf.reshape_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_128 (Activation)     (None, 20, 20, 128)  0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_416 (Conv2D)             (None, 20, 20, 256)  33024       activation_128[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_417 (Conv2D)             (None, 20, 20, 256)  33024       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 20, 20, 256)  1024        conv2d_416[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 20, 20, 256)  1024        conv2d_417[0][0]                 \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 20, 20, 256)  0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 20, 20, 256)  0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 20, 20, 256)  0           activation_129[0][0]             \n","                                                                 activation_130[0][0]             \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 20, 20, 256)  0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_10 (Gl (None, 256)          0           activation_131[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 90 percent samples from each class in training set \n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples is 7906.\n","\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in training set is 7112.\n","Samples per class in training set: [1231  470  290  657  320  753 2001  414  976]\n","\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Total number of samples in test set is 794.\n","Samples per class in test set: [137  53  33  73  36  84 223  46 109]\n","\n","X_train => (7112, 20, 20, 64)\n","X_test  => (794, 20, 20, 64)\n","y_train => (7112, 9)\n","y_test  => (794, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model_22\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_12 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_418 (Conv2D)             (None, 20, 20, 64)   4160        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 20, 20, 64)   256         conv2d_418[0][0]                 \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 20, 20, 64)   0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","lambda_177 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_179 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_181 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_183 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_420 (Conv2D)             (None, 20, 20, 8)    584         lambda_177[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_424 (Conv2D)             (None, 20, 20, 8)    584         lambda_179[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_428 (Conv2D)             (None, 20, 20, 8)    584         lambda_181[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_432 (Conv2D)             (None, 20, 20, 8)    584         lambda_183[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_176 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_421 (Conv2D)             (None, 20, 20, 8)    584         conv2d_420[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_178 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_425 (Conv2D)             (None, 20, 20, 8)    584         conv2d_424[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_180 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_429 (Conv2D)             (None, 20, 20, 8)    584         conv2d_428[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_182 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_433 (Conv2D)             (None, 20, 20, 8)    584         conv2d_432[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_419 (Conv2D)             (None, 20, 20, 8)    584         lambda_176[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_422 (Conv2D)             (None, 20, 20, 8)    584         conv2d_421[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_423 (Conv2D)             (None, 20, 20, 8)    584         lambda_178[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_426 (Conv2D)             (None, 20, 20, 8)    584         conv2d_425[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_427 (Conv2D)             (None, 20, 20, 8)    584         lambda_180[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_430 (Conv2D)             (None, 20, 20, 8)    584         conv2d_429[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_431 (Conv2D)             (None, 20, 20, 8)    584         lambda_182[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_434 (Conv2D)             (None, 20, 20, 8)    584         conv2d_433[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 20, 20, 64)   0           conv2d_419[0][0]                 \n","                                                                 conv2d_422[0][0]                 \n","                                                                 conv2d_423[0][0]                 \n","                                                                 conv2d_426[0][0]                 \n","                                                                 conv2d_427[0][0]                 \n","                                                                 conv2d_430[0][0]                 \n","                                                                 conv2d_431[0][0]                 \n","                                                                 conv2d_434[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 20, 20, 64)   256         concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 20, 20, 64)   0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_44 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_133[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_22 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_44[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_22 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_22[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_45 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 20, 20, 64)   256         tf.reshape_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 20, 20, 64)   0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_435 (Conv2D)             (None, 20, 20, 128)  8320        activation_134[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_436 (Conv2D)             (None, 20, 20, 128)  8320        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 20, 20, 128)  512         conv2d_435[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 20, 20, 128)  512         conv2d_436[0][0]                 \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 20, 20, 128)  0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 20, 20, 128)  0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 20, 20, 128)  0           activation_135[0][0]             \n","                                                                 activation_136[0][0]             \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 20, 20, 128)  0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_437 (Conv2D)             (None, 20, 20, 128)  16512       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 20, 20, 128)  512         conv2d_437[0][0]                 \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 20, 20, 128)  0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","lambda_185 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_187 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_189 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_191 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_439 (Conv2D)             (None, 20, 20, 16)   2320        lambda_185[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_443 (Conv2D)             (None, 20, 20, 16)   2320        lambda_187[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_447 (Conv2D)             (None, 20, 20, 16)   2320        lambda_189[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_451 (Conv2D)             (None, 20, 20, 16)   2320        lambda_191[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_184 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_440 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_439[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_186 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_444 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_443[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_188 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_448 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_447[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_190 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_452 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_451[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_438 (Conv2D)             (None, 20, 20, 16)   2320        lambda_184[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_441 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_440[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_442 (Conv2D)             (None, 20, 20, 16)   2320        lambda_186[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_445 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_444[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_446 (Conv2D)             (None, 20, 20, 16)   2320        lambda_188[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_449 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_448[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_450 (Conv2D)             (None, 20, 20, 16)   2320        lambda_190[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_453 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_452[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 20, 20, 128)  0           conv2d_438[0][0]                 \n","                                                                 conv2d_441[0][0]                 \n","                                                                 conv2d_442[0][0]                 \n","                                                                 conv2d_445[0][0]                 \n","                                                                 conv2d_446[0][0]                 \n","                                                                 conv2d_449[0][0]                 \n","                                                                 conv2d_450[0][0]                 \n","                                                                 conv2d_453[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 20, 20, 128)  512         concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 20, 20, 128)  0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_46 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_139[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_23 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_46[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_23 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_23[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_47 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 20, 20, 128)  512         tf.reshape_47[0][0]              \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 20, 20, 128)  0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_454 (Conv2D)             (None, 20, 20, 256)  33024       activation_140[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_455 (Conv2D)             (None, 20, 20, 256)  33024       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 20, 20, 256)  1024        conv2d_454[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 20, 20, 256)  1024        conv2d_455[0][0]                 \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 20, 20, 256)  0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 20, 20, 256)  0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 20, 20, 256)  0           activation_141[0][0]             \n","                                                                 activation_142[0][0]             \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 20, 20, 256)  0           add_23[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_11 (Gl (None, 256)          0           activation_143[0][0]             \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d_11[0][0]\n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","356/356 [==============================] - 9s 18ms/step - loss: 9.0551 - categorical_accuracy: 0.3029 - val_loss: 8.4632 - val_categorical_accuracy: 0.4282\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.42821, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","356/356 [==============================] - 6s 16ms/step - loss: 8.3177 - categorical_accuracy: 0.5001 - val_loss: 8.0066 - val_categorical_accuracy: 0.6977\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.42821 to 0.69773, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","356/356 [==============================] - 6s 16ms/step - loss: 8.0376 - categorical_accuracy: 0.5863 - val_loss: 7.7592 - val_categorical_accuracy: 0.7204\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.69773 to 0.72040, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","356/356 [==============================] - 6s 16ms/step - loss: 7.8045 - categorical_accuracy: 0.6481 - val_loss: 7.6052 - val_categorical_accuracy: 0.6889\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.72040\n","Epoch 5/100\n","356/356 [==============================] - 6s 16ms/step - loss: 7.6362 - categorical_accuracy: 0.6663 - val_loss: 7.4287 - val_categorical_accuracy: 0.7443\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.72040 to 0.74433, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","356/356 [==============================] - 6s 16ms/step - loss: 7.4291 - categorical_accuracy: 0.7177 - val_loss: 7.2773 - val_categorical_accuracy: 0.7620\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.74433 to 0.76196, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","356/356 [==============================] - 6s 16ms/step - loss: 7.2483 - categorical_accuracy: 0.7476 - val_loss: 7.1764 - val_categorical_accuracy: 0.7594\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.76196\n","Epoch 8/100\n","356/356 [==============================] - 6s 16ms/step - loss: 7.0998 - categorical_accuracy: 0.7698 - val_loss: 7.1070 - val_categorical_accuracy: 0.6965\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.76196\n","Epoch 9/100\n","356/356 [==============================] - 5s 15ms/step - loss: 6.9554 - categorical_accuracy: 0.7964 - val_loss: 6.9850 - val_categorical_accuracy: 0.7204\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.76196\n","Epoch 10/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.8080 - categorical_accuracy: 0.8194 - val_loss: 6.8551 - val_categorical_accuracy: 0.7343\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.76196\n","Epoch 11/100\n","356/356 [==============================] - 5s 15ms/step - loss: 6.6721 - categorical_accuracy: 0.8374 - val_loss: 6.8157 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.76196\n","Epoch 12/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.5383 - categorical_accuracy: 0.8535 - val_loss: 6.8232 - val_categorical_accuracy: 0.6297\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.76196\n","Epoch 13/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.4226 - categorical_accuracy: 0.8741 - val_loss: 6.6433 - val_categorical_accuracy: 0.7078\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.76196\n","Epoch 14/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.3302 - categorical_accuracy: 0.8719 - val_loss: 6.5648 - val_categorical_accuracy: 0.6864\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.76196\n","Epoch 15/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.2208 - categorical_accuracy: 0.8783 - val_loss: 6.5297 - val_categorical_accuracy: 0.6335\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.76196\n","Epoch 16/100\n","356/356 [==============================] - 6s 16ms/step - loss: 6.1100 - categorical_accuracy: 0.8975 - val_loss: 6.6556 - val_categorical_accuracy: 0.6045\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.76196\n","Epoch 17/100\n","356/356 [==============================] - 6s 17ms/step - loss: 6.0086 - categorical_accuracy: 0.9029 - val_loss: 6.3145 - val_categorical_accuracy: 0.6990\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.76196\n","Epoch 18/100\n","356/356 [==============================] - 6s 17ms/step - loss: 5.9127 - categorical_accuracy: 0.9036 - val_loss: 6.2789 - val_categorical_accuracy: 0.6889\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.76196\n","Epoch 19/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.8222 - categorical_accuracy: 0.9132 - val_loss: 6.1730 - val_categorical_accuracy: 0.7544\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.76196\n","Epoch 20/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.6966 - categorical_accuracy: 0.9270 - val_loss: 6.2427 - val_categorical_accuracy: 0.6713\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.76196\n","Epoch 21/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.6253 - categorical_accuracy: 0.9294 - val_loss: 6.1305 - val_categorical_accuracy: 0.7242\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.76196\n","Epoch 22/100\n","356/356 [==============================] - 6s 17ms/step - loss: 5.5324 - categorical_accuracy: 0.9338 - val_loss: 6.1376 - val_categorical_accuracy: 0.6537\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.76196\n","Epoch 23/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.4487 - categorical_accuracy: 0.9358 - val_loss: 5.9461 - val_categorical_accuracy: 0.7657\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.76196 to 0.76574, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 24/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.3663 - categorical_accuracy: 0.9400 - val_loss: 5.9851 - val_categorical_accuracy: 0.7028\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.76574\n","Epoch 25/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.2982 - categorical_accuracy: 0.9370 - val_loss: 5.9794 - val_categorical_accuracy: 0.7078\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.76574\n","Epoch 26/100\n","356/356 [==============================] - 6s 17ms/step - loss: 5.2033 - categorical_accuracy: 0.9500 - val_loss: 6.1052 - val_categorical_accuracy: 0.6474\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.76574\n","Epoch 27/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.1195 - categorical_accuracy: 0.9532 - val_loss: 5.7578 - val_categorical_accuracy: 0.7368\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.76574\n","Epoch 28/100\n","356/356 [==============================] - 6s 16ms/step - loss: 5.0499 - categorical_accuracy: 0.9566 - val_loss: 5.7332 - val_categorical_accuracy: 0.6940\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.76574\n","Epoch 29/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.9792 - categorical_accuracy: 0.9572 - val_loss: 5.8165 - val_categorical_accuracy: 0.6826\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.76574\n","Epoch 30/100\n","356/356 [==============================] - 6s 15ms/step - loss: 4.9216 - categorical_accuracy: 0.9556 - val_loss: 6.1322 - val_categorical_accuracy: 0.6033\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.76574\n","Epoch 31/100\n","356/356 [==============================] - 6s 17ms/step - loss: 4.8349 - categorical_accuracy: 0.9667 - val_loss: 5.8576 - val_categorical_accuracy: 0.6272\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.76574\n","Epoch 32/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.7632 - categorical_accuracy: 0.9681 - val_loss: 5.8968 - val_categorical_accuracy: 0.6826\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.76574\n","Epoch 33/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.7026 - categorical_accuracy: 0.9681 - val_loss: 5.8996 - val_categorical_accuracy: 0.5781\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.76574\n","Epoch 34/100\n","356/356 [==============================] - 5s 15ms/step - loss: 4.6460 - categorical_accuracy: 0.9670 - val_loss: 5.1829 - val_categorical_accuracy: 0.7242\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.76574\n","Epoch 35/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.5851 - categorical_accuracy: 0.9696 - val_loss: 5.5152 - val_categorical_accuracy: 0.5642\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.76574\n","Epoch 36/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.5233 - categorical_accuracy: 0.9680 - val_loss: 5.1521 - val_categorical_accuracy: 0.7242\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.76574\n","Epoch 37/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.4681 - categorical_accuracy: 0.9676 - val_loss: 5.3110 - val_categorical_accuracy: 0.6234\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.76574\n","Epoch 38/100\n","356/356 [==============================] - 5s 15ms/step - loss: 4.4075 - categorical_accuracy: 0.9691 - val_loss: 5.1284 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.76574\n","Epoch 39/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.3436 - categorical_accuracy: 0.9749 - val_loss: 5.5212 - val_categorical_accuracy: 0.6096\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.76574\n","Epoch 40/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.2992 - categorical_accuracy: 0.9678 - val_loss: 5.2131 - val_categorical_accuracy: 0.6801\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.76574\n","Epoch 41/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.2277 - categorical_accuracy: 0.9776 - val_loss: 4.8426 - val_categorical_accuracy: 0.7380\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.76574\n","Epoch 42/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.1792 - categorical_accuracy: 0.9717 - val_loss: 5.2638 - val_categorical_accuracy: 0.6725\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.76574\n","Epoch 43/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.1224 - categorical_accuracy: 0.9771 - val_loss: 5.5464 - val_categorical_accuracy: 0.5919\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.76574\n","Epoch 44/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.0701 - categorical_accuracy: 0.9776 - val_loss: 4.6062 - val_categorical_accuracy: 0.7569\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.76574\n","Epoch 45/100\n","356/356 [==============================] - 6s 16ms/step - loss: 4.0146 - categorical_accuracy: 0.9808 - val_loss: 4.4853 - val_categorical_accuracy: 0.8010\n","\n","Epoch 00045: val_categorical_accuracy improved from 0.76574 to 0.80101, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//full_models/indian_pines_as_source_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 46/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.9709 - categorical_accuracy: 0.9785 - val_loss: 4.7307 - val_categorical_accuracy: 0.7632\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.80101\n","Epoch 47/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.9205 - categorical_accuracy: 0.9798 - val_loss: 7.0979 - val_categorical_accuracy: 0.5617\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.80101\n","Epoch 48/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.8696 - categorical_accuracy: 0.9801 - val_loss: 4.8229 - val_categorical_accuracy: 0.7267\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.80101\n","Epoch 49/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.8197 - categorical_accuracy: 0.9784 - val_loss: 5.0596 - val_categorical_accuracy: 0.6625\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.80101\n","Epoch 50/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.7688 - categorical_accuracy: 0.9810 - val_loss: 4.5569 - val_categorical_accuracy: 0.6725\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.80101\n","Epoch 51/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.7313 - categorical_accuracy: 0.9804 - val_loss: 4.4579 - val_categorical_accuracy: 0.7242\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.80101\n","Epoch 52/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.6763 - categorical_accuracy: 0.9837 - val_loss: 5.4906 - val_categorical_accuracy: 0.5529\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.80101\n","Epoch 53/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.6402 - categorical_accuracy: 0.9826 - val_loss: 4.7246 - val_categorical_accuracy: 0.6826\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.80101\n","Epoch 54/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.5988 - categorical_accuracy: 0.9825 - val_loss: 8.1681 - val_categorical_accuracy: 0.5516\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.80101\n","Epoch 55/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.5450 - categorical_accuracy: 0.9858 - val_loss: 5.8189 - val_categorical_accuracy: 0.4786\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.80101\n","Epoch 56/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.5136 - categorical_accuracy: 0.9789 - val_loss: 4.3800 - val_categorical_accuracy: 0.7141\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.80101\n","Epoch 57/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.4643 - categorical_accuracy: 0.9852 - val_loss: 5.5194 - val_categorical_accuracy: 0.5000\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.80101\n","Epoch 58/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.4286 - categorical_accuracy: 0.9820 - val_loss: 4.8100 - val_categorical_accuracy: 0.5441\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.80101\n","Epoch 59/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.3800 - categorical_accuracy: 0.9838 - val_loss: 7.7717 - val_categorical_accuracy: 0.5491\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.80101\n","Epoch 60/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.3423 - categorical_accuracy: 0.9857 - val_loss: 6.5836 - val_categorical_accuracy: 0.5277\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.80101\n","Epoch 61/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.2956 - categorical_accuracy: 0.9877 - val_loss: 6.3612 - val_categorical_accuracy: 0.4924\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.80101\n","Epoch 62/100\n","356/356 [==============================] - 6s 17ms/step - loss: 3.2601 - categorical_accuracy: 0.9869 - val_loss: 4.4176 - val_categorical_accuracy: 0.6700\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.80101\n","Epoch 63/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.2220 - categorical_accuracy: 0.9863 - val_loss: 5.0634 - val_categorical_accuracy: 0.5718\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.80101\n","Epoch 64/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.1976 - categorical_accuracy: 0.9822 - val_loss: 7.9539 - val_categorical_accuracy: 0.4219\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.80101\n","Epoch 65/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.1434 - categorical_accuracy: 0.9876 - val_loss: 4.2375 - val_categorical_accuracy: 0.5806\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.80101\n","Epoch 66/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.1094 - categorical_accuracy: 0.9892 - val_loss: 4.6725 - val_categorical_accuracy: 0.6071\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.80101\n","Epoch 67/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.0742 - categorical_accuracy: 0.9895 - val_loss: 7.8206 - val_categorical_accuracy: 0.4496\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.80101\n","Epoch 68/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.0387 - categorical_accuracy: 0.9884 - val_loss: 3.9413 - val_categorical_accuracy: 0.6650\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.80101\n","Epoch 69/100\n","356/356 [==============================] - 6s 16ms/step - loss: 3.0086 - categorical_accuracy: 0.9877 - val_loss: 5.7843 - val_categorical_accuracy: 0.6121\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.80101\n","Epoch 70/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.9662 - categorical_accuracy: 0.9913 - val_loss: 4.1260 - val_categorical_accuracy: 0.6448\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.80101\n","Epoch 71/100\n","356/356 [==============================] - 6s 17ms/step - loss: 2.9284 - categorical_accuracy: 0.9910 - val_loss: 5.1026 - val_categorical_accuracy: 0.5768\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.80101\n","Epoch 72/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.9030 - categorical_accuracy: 0.9874 - val_loss: 6.8161 - val_categorical_accuracy: 0.5164\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.80101\n","Epoch 73/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.8679 - categorical_accuracy: 0.9903 - val_loss: 3.8014 - val_categorical_accuracy: 0.6990\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.80101\n","Epoch 74/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.8303 - categorical_accuracy: 0.9915 - val_loss: 4.0747 - val_categorical_accuracy: 0.6864\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.80101\n","Epoch 75/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.7995 - categorical_accuracy: 0.9926 - val_loss: 4.1738 - val_categorical_accuracy: 0.7053\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.80101\n","Epoch 76/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.7713 - categorical_accuracy: 0.9917 - val_loss: 3.6727 - val_categorical_accuracy: 0.7594\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.80101\n","Epoch 77/100\n","356/356 [==============================] - 5s 15ms/step - loss: 2.7401 - categorical_accuracy: 0.9915 - val_loss: 3.8750 - val_categorical_accuracy: 0.7141\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.80101\n","Epoch 78/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.7121 - categorical_accuracy: 0.9897 - val_loss: 3.4992 - val_categorical_accuracy: 0.7544\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.80101\n","Epoch 79/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.6740 - categorical_accuracy: 0.9937 - val_loss: 5.6552 - val_categorical_accuracy: 0.3678\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.80101\n","Epoch 80/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.6481 - categorical_accuracy: 0.9904 - val_loss: 3.8479 - val_categorical_accuracy: 0.6889\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.80101\n","Epoch 81/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.6217 - categorical_accuracy: 0.9902 - val_loss: 3.7193 - val_categorical_accuracy: 0.7393\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.80101\n","Epoch 82/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.5946 - categorical_accuracy: 0.9896 - val_loss: 3.8855 - val_categorical_accuracy: 0.6952\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.80101\n","Epoch 83/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.5591 - categorical_accuracy: 0.9926 - val_loss: 4.7725 - val_categorical_accuracy: 0.5554\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.80101\n","Epoch 84/100\n","356/356 [==============================] - 5s 15ms/step - loss: 2.5327 - categorical_accuracy: 0.9925 - val_loss: 3.8860 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.80101\n","Epoch 85/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.5069 - categorical_accuracy: 0.9920 - val_loss: 4.7091 - val_categorical_accuracy: 0.5101\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.80101\n","Epoch 86/100\n","356/356 [==============================] - 6s 17ms/step - loss: 2.4778 - categorical_accuracy: 0.9929 - val_loss: 4.2346 - val_categorical_accuracy: 0.5869\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.80101\n","Epoch 87/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.4503 - categorical_accuracy: 0.9927 - val_loss: 4.9938 - val_categorical_accuracy: 0.5554\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.80101\n","Epoch 88/100\n","356/356 [==============================] - 5s 15ms/step - loss: 2.4221 - categorical_accuracy: 0.9948 - val_loss: 7.8040 - val_categorical_accuracy: 0.5554\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.80101\n","Epoch 89/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.3951 - categorical_accuracy: 0.9944 - val_loss: 4.9509 - val_categorical_accuracy: 0.5239\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.80101\n","Epoch 90/100\n","356/356 [==============================] - 5s 15ms/step - loss: 2.3770 - categorical_accuracy: 0.9916 - val_loss: 3.8001 - val_categorical_accuracy: 0.7078\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.80101\n","Epoch 91/100\n","356/356 [==============================] - 6s 17ms/step - loss: 2.3444 - categorical_accuracy: 0.9940 - val_loss: 4.1387 - val_categorical_accuracy: 0.5617\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.80101\n","Epoch 92/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.3207 - categorical_accuracy: 0.9932 - val_loss: 3.1978 - val_categorical_accuracy: 0.7834\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.80101\n","Epoch 93/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.2947 - categorical_accuracy: 0.9929 - val_loss: 3.2443 - val_categorical_accuracy: 0.7229\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.80101\n","Epoch 94/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.2696 - categorical_accuracy: 0.9947 - val_loss: 4.0843 - val_categorical_accuracy: 0.6247\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.80101\n","Epoch 95/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.2477 - categorical_accuracy: 0.9957 - val_loss: 5.3034 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.80101\n","Epoch 96/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.2288 - categorical_accuracy: 0.9905 - val_loss: 5.1005 - val_categorical_accuracy: 0.5088\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.80101\n","Epoch 97/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.2022 - categorical_accuracy: 0.9919 - val_loss: 3.0950 - val_categorical_accuracy: 0.7204\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.80101\n","Epoch 98/100\n","356/356 [==============================] - 5s 15ms/step - loss: 2.1758 - categorical_accuracy: 0.9929 - val_loss: 4.1999 - val_categorical_accuracy: 0.6171\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.80101\n","Epoch 99/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.1519 - categorical_accuracy: 0.9965 - val_loss: 5.4322 - val_categorical_accuracy: 0.5340\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.80101\n","Epoch 100/100\n","356/356 [==============================] - 6s 16ms/step - loss: 2.1312 - categorical_accuracy: 0.9938 - val_loss: 3.7364 - val_categorical_accuracy: 0.6851\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.80101\n","25/25 [==============================] - 1s 7ms/step - loss: 4.4853 - categorical_accuracy: 0.8010\n","Test Accuracy =  80.0\n","25/25 [==============================] - 1s 6ms/step\n","Model: \"model_23\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_12 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_418 (Conv2D)             (None, 20, 20, 64)   4160        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 20, 20, 64)   256         conv2d_418[0][0]                 \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 20, 20, 64)   0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","lambda_177 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_179 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_181 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_183 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_420 (Conv2D)             (None, 20, 20, 8)    584         lambda_177[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_424 (Conv2D)             (None, 20, 20, 8)    584         lambda_179[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_428 (Conv2D)             (None, 20, 20, 8)    584         lambda_181[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_432 (Conv2D)             (None, 20, 20, 8)    584         lambda_183[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_176 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_421 (Conv2D)             (None, 20, 20, 8)    584         conv2d_420[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_178 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_425 (Conv2D)             (None, 20, 20, 8)    584         conv2d_424[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_180 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_429 (Conv2D)             (None, 20, 20, 8)    584         conv2d_428[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_182 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_433 (Conv2D)             (None, 20, 20, 8)    584         conv2d_432[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_419 (Conv2D)             (None, 20, 20, 8)    584         lambda_176[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_422 (Conv2D)             (None, 20, 20, 8)    584         conv2d_421[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_423 (Conv2D)             (None, 20, 20, 8)    584         lambda_178[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_426 (Conv2D)             (None, 20, 20, 8)    584         conv2d_425[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_427 (Conv2D)             (None, 20, 20, 8)    584         lambda_180[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_430 (Conv2D)             (None, 20, 20, 8)    584         conv2d_429[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_431 (Conv2D)             (None, 20, 20, 8)    584         lambda_182[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_434 (Conv2D)             (None, 20, 20, 8)    584         conv2d_433[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 20, 20, 64)   0           conv2d_419[0][0]                 \n","                                                                 conv2d_422[0][0]                 \n","                                                                 conv2d_423[0][0]                 \n","                                                                 conv2d_426[0][0]                 \n","                                                                 conv2d_427[0][0]                 \n","                                                                 conv2d_430[0][0]                 \n","                                                                 conv2d_431[0][0]                 \n","                                                                 conv2d_434[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 20, 20, 64)   256         concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 20, 20, 64)   0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_44 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_133[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_22 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_44[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_22 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_22[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_45 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 20, 20, 64)   256         tf.reshape_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 20, 20, 64)   0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_435 (Conv2D)             (None, 20, 20, 128)  8320        activation_134[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_436 (Conv2D)             (None, 20, 20, 128)  8320        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 20, 20, 128)  512         conv2d_435[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 20, 20, 128)  512         conv2d_436[0][0]                 \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 20, 20, 128)  0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 20, 20, 128)  0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 20, 20, 128)  0           activation_135[0][0]             \n","                                                                 activation_136[0][0]             \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 20, 20, 128)  0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_437 (Conv2D)             (None, 20, 20, 128)  16512       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 20, 20, 128)  512         conv2d_437[0][0]                 \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 20, 20, 128)  0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","lambda_185 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_187 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_189 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_191 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_439 (Conv2D)             (None, 20, 20, 16)   2320        lambda_185[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_443 (Conv2D)             (None, 20, 20, 16)   2320        lambda_187[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_447 (Conv2D)             (None, 20, 20, 16)   2320        lambda_189[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_451 (Conv2D)             (None, 20, 20, 16)   2320        lambda_191[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_184 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_440 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_439[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_186 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_444 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_443[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_188 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_448 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_447[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_190 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_452 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_451[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_438 (Conv2D)             (None, 20, 20, 16)   2320        lambda_184[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_441 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_440[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_442 (Conv2D)             (None, 20, 20, 16)   2320        lambda_186[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_445 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_444[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_446 (Conv2D)             (None, 20, 20, 16)   2320        lambda_188[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_449 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_448[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_450 (Conv2D)             (None, 20, 20, 16)   2320        lambda_190[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_453 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_452[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 20, 20, 128)  0           conv2d_438[0][0]                 \n","                                                                 conv2d_441[0][0]                 \n","                                                                 conv2d_442[0][0]                 \n","                                                                 conv2d_445[0][0]                 \n","                                                                 conv2d_446[0][0]                 \n","                                                                 conv2d_449[0][0]                 \n","                                                                 conv2d_450[0][0]                 \n","                                                                 conv2d_453[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 20, 20, 128)  512         concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 20, 20, 128)  0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_46 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_139[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_23 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_46[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_23 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_23[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_47 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 20, 20, 128)  512         tf.reshape_47[0][0]              \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 20, 20, 128)  0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_454 (Conv2D)             (None, 20, 20, 256)  33024       activation_140[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_455 (Conv2D)             (None, 20, 20, 256)  33024       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 20, 20, 256)  1024        conv2d_454[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 20, 20, 256)  1024        conv2d_455[0][0]                 \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 20, 20, 256)  0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 20, 20, 256)  0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 20, 20, 256)  0           activation_141[0][0]             \n","                                                                 activation_142[0][0]             \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 20, 20, 256)  0           add_23[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_11 (Gl (None, 256)          0           activation_143[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"id":"dCxOwh-vpTVi","executionInfo":{"status":"ok","timestamp":1608672320363,"user_tz":480,"elapsed":1185,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"989e5897-d737-462b-c2b1-a70bb05be914"},"source":["pretrain_results"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Overlap_ratio</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Training_Test_Split</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.8</td>\n","      <td>477</td>\n","      <td>323</td>\n","      <td>60</td>\n","      <td>65.94</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.8</td>\n","      <td>555</td>\n","      <td>245</td>\n","      <td>70</td>\n","      <td>68.57</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.8</td>\n","      <td>636</td>\n","      <td>164</td>\n","      <td>80</td>\n","      <td>75.61</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8</td>\n","      <td>715</td>\n","      <td>85</td>\n","      <td>90</td>\n","      <td>70.59</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.9</td>\n","      <td>2348</td>\n","      <td>1570</td>\n","      <td>60</td>\n","      <td>77.83</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9</td>\n","      <td>2740</td>\n","      <td>1178</td>\n","      <td>70</td>\n","      <td>75.98</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.9</td>\n","      <td>3132</td>\n","      <td>786</td>\n","      <td>80</td>\n","      <td>79.13</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.9</td>\n","      <td>3523</td>\n","      <td>395</td>\n","      <td>90</td>\n","      <td>84.56</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>4740</td>\n","      <td>3166</td>\n","      <td>60</td>\n","      <td>77.51</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.0</td>\n","      <td>5530</td>\n","      <td>2376</td>\n","      <td>70</td>\n","      <td>71.93</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.0</td>\n","      <td>6322</td>\n","      <td>1584</td>\n","      <td>80</td>\n","      <td>81.12</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.0</td>\n","      <td>7112</td>\n","      <td>794</td>\n","      <td>90</td>\n","      <td>80.10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Overlap_ratio  Training Samples  ...  Training_Test_Split  Test_Accuracies\n","0             0.8               477  ...                   60            65.94\n","1             0.8               555  ...                   70            68.57\n","2             0.8               636  ...                   80            75.61\n","3             0.8               715  ...                   90            70.59\n","4             0.9              2348  ...                   60            77.83\n","5             0.9              2740  ...                   70            75.98\n","6             0.9              3132  ...                   80            79.13\n","7             0.9              3523  ...                   90            84.56\n","8             1.0              4740  ...                   60            77.51\n","9             1.0              5530  ...                   70            71.93\n","10            1.0              6322  ...                   80            81.12\n","11            1.0              7112  ...                   90            80.10\n","\n","[12 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"RkxgCjIejh0l"},"source":["# Fine tune on botswana"]},{"cell_type":"code","metadata":{"id":"SJ1kSkHtCuHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608672734045,"user_tz":480,"elapsed":402089,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"5490f143-1d6d-43b9-99f6-87c983269ca7"},"source":["transfer_results, confusion_matrixes = transfer_learning(percentages = [60,70,80,90],\n","                                                        source_dataset = 'indian_pines',\n","                                                        target_dataset = 'botswana',\n","                                                        data = data_target,\n","                                                        ground_truth = ground_truth_target,\n","                                                        classes = classes_target,\n","                                                        overlap_ratios = [0.8,0.9,1],\n","                                                        channels = 64,\n","                                                        cube_size = 20,\n","                                                        learning_rate = 0.0001,\n","                                                        epochs = 100,\n","                                                        batch_size = 20)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","__________________________________________________________________________________________________\n","Samples per class: [136, 52, 125, 110, 132, 128, 125, 97, 145, 120, 131, 68, 110, 50]\n","Total number of samples is 1529.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 914.\n","Samples per class in training set: [81 31 75 66 79 76 75 58 87 72 78 40 66 30]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 615.\n","Samples per class in test set: [55 21 50 44 53 52 50 39 58 48 53 28 44 20]\n","\n","X_train_transfer => (914, 256)\n","X_test_transfer  => (615, 256)\n","y_train => (914, 14)\n","y_test  => (615, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_17 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","46/46 [==============================] - 1s 9ms/step - loss: 4.6744 - categorical_accuracy: 0.1661 - val_loss: 1.9879 - val_categorical_accuracy: 0.5008\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.50081, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","46/46 [==============================] - 0s 5ms/step - loss: 1.6418 - categorical_accuracy: 0.5049 - val_loss: 1.7306 - val_categorical_accuracy: 0.5740\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.50081 to 0.57398, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","46/46 [==============================] - 0s 5ms/step - loss: 1.4423 - categorical_accuracy: 0.5274 - val_loss: 1.5384 - val_categorical_accuracy: 0.5707\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.57398\n","Epoch 4/100\n","46/46 [==============================] - 0s 5ms/step - loss: 1.2000 - categorical_accuracy: 0.6184 - val_loss: 1.4527 - val_categorical_accuracy: 0.5789\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.57398 to 0.57886, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","46/46 [==============================] - 0s 5ms/step - loss: 1.1286 - categorical_accuracy: 0.6908 - val_loss: 1.4082 - val_categorical_accuracy: 0.6179\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.57886 to 0.61789, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","46/46 [==============================] - 0s 5ms/step - loss: 1.0630 - categorical_accuracy: 0.6658 - val_loss: 1.3851 - val_categorical_accuracy: 0.6439\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.61789 to 0.64390, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","46/46 [==============================] - 0s 6ms/step - loss: 1.0488 - categorical_accuracy: 0.7219 - val_loss: 1.2764 - val_categorical_accuracy: 0.6276\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.64390\n","Epoch 8/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.9751 - categorical_accuracy: 0.7174 - val_loss: 1.1920 - val_categorical_accuracy: 0.6797\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.64390 to 0.67967, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 9/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.9366 - categorical_accuracy: 0.7138 - val_loss: 1.1477 - val_categorical_accuracy: 0.6407\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.67967\n","Epoch 10/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.8669 - categorical_accuracy: 0.7443 - val_loss: 1.1636 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.67967\n","Epoch 11/100\n","46/46 [==============================] - 0s 6ms/step - loss: 0.8412 - categorical_accuracy: 0.7492 - val_loss: 1.0562 - val_categorical_accuracy: 0.7203\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.67967 to 0.72033, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 12/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.8100 - categorical_accuracy: 0.7723 - val_loss: 1.2525 - val_categorical_accuracy: 0.6911\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.72033\n","Epoch 13/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.8108 - categorical_accuracy: 0.7578 - val_loss: 1.0326 - val_categorical_accuracy: 0.7122\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.72033\n","Epoch 14/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.7012 - categorical_accuracy: 0.8276 - val_loss: 1.0149 - val_categorical_accuracy: 0.7187\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.72033\n","Epoch 15/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.6892 - categorical_accuracy: 0.8283 - val_loss: 1.0184 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.72033\n","Epoch 16/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.6942 - categorical_accuracy: 0.8211 - val_loss: 0.9905 - val_categorical_accuracy: 0.7496\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.72033 to 0.74959, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 17/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.6747 - categorical_accuracy: 0.8217 - val_loss: 0.9192 - val_categorical_accuracy: 0.7528\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.74959 to 0.75285, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.6235 - categorical_accuracy: 0.8440 - val_loss: 0.9887 - val_categorical_accuracy: 0.7089\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.75285\n","Epoch 19/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.6176 - categorical_accuracy: 0.8345 - val_loss: 0.9723 - val_categorical_accuracy: 0.7642\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.75285 to 0.76423, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 20/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5771 - categorical_accuracy: 0.8488 - val_loss: 0.9619 - val_categorical_accuracy: 0.7463\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.76423\n","Epoch 21/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5490 - categorical_accuracy: 0.8921 - val_loss: 0.9514 - val_categorical_accuracy: 0.7789\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.76423 to 0.77886, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 22/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.6030 - categorical_accuracy: 0.8572 - val_loss: 0.8792 - val_categorical_accuracy: 0.7951\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.77886 to 0.79512, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 23/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5209 - categorical_accuracy: 0.8789 - val_loss: 0.8927 - val_categorical_accuracy: 0.7724\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.79512\n","Epoch 24/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5264 - categorical_accuracy: 0.8855 - val_loss: 0.9241 - val_categorical_accuracy: 0.7252\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.79512\n","Epoch 25/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5055 - categorical_accuracy: 0.8930 - val_loss: 0.8709 - val_categorical_accuracy: 0.7870\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.79512\n","Epoch 26/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.5084 - categorical_accuracy: 0.8968 - val_loss: 0.8993 - val_categorical_accuracy: 0.7561\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.79512\n","Epoch 27/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4715 - categorical_accuracy: 0.8915 - val_loss: 0.8982 - val_categorical_accuracy: 0.7837\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.79512\n","Epoch 28/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4807 - categorical_accuracy: 0.9068 - val_loss: 0.8921 - val_categorical_accuracy: 0.7496\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.79512\n","Epoch 29/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4458 - categorical_accuracy: 0.9281 - val_loss: 0.9436 - val_categorical_accuracy: 0.7073\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.79512\n","Epoch 30/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4458 - categorical_accuracy: 0.9262 - val_loss: 0.8134 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00030: val_categorical_accuracy improved from 0.79512 to 0.81626, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 31/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4229 - categorical_accuracy: 0.9288 - val_loss: 0.8632 - val_categorical_accuracy: 0.7691\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.81626\n","Epoch 32/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.4236 - categorical_accuracy: 0.9271 - val_loss: 0.8171 - val_categorical_accuracy: 0.7919\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.81626\n","Epoch 33/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.4282 - categorical_accuracy: 0.9118 - val_loss: 0.7732 - val_categorical_accuracy: 0.8098\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.81626\n","Epoch 34/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.4081 - categorical_accuracy: 0.9479 - val_loss: 0.8589 - val_categorical_accuracy: 0.7610\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.81626\n","Epoch 35/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.4393 - categorical_accuracy: 0.9072 - val_loss: 0.8529 - val_categorical_accuracy: 0.7415\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.81626\n","Epoch 36/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3947 - categorical_accuracy: 0.9301 - val_loss: 0.7430 - val_categorical_accuracy: 0.8374\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.81626 to 0.83740, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 37/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3875 - categorical_accuracy: 0.9366 - val_loss: 0.7818 - val_categorical_accuracy: 0.8049\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.83740\n","Epoch 38/100\n","46/46 [==============================] - 0s 7ms/step - loss: 0.3664 - categorical_accuracy: 0.9342 - val_loss: 0.7669 - val_categorical_accuracy: 0.7919\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.83740\n","Epoch 39/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3692 - categorical_accuracy: 0.9349 - val_loss: 0.7676 - val_categorical_accuracy: 0.8146\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.83740\n","Epoch 40/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3385 - categorical_accuracy: 0.9511 - val_loss: 0.7770 - val_categorical_accuracy: 0.8065\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.83740\n","Epoch 41/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3386 - categorical_accuracy: 0.9330 - val_loss: 0.8121 - val_categorical_accuracy: 0.7821\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.83740\n","Epoch 42/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3427 - categorical_accuracy: 0.9519 - val_loss: 0.8060 - val_categorical_accuracy: 0.7951\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.83740\n","Epoch 43/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3193 - categorical_accuracy: 0.9487 - val_loss: 0.7368 - val_categorical_accuracy: 0.8341\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.83740\n","Epoch 44/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3434 - categorical_accuracy: 0.9327 - val_loss: 0.7481 - val_categorical_accuracy: 0.8146\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.83740\n","Epoch 45/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3019 - categorical_accuracy: 0.9680 - val_loss: 0.8188 - val_categorical_accuracy: 0.7707\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.83740\n","Epoch 46/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3120 - categorical_accuracy: 0.9593 - val_loss: 0.7776 - val_categorical_accuracy: 0.8016\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.83740\n","Epoch 47/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2973 - categorical_accuracy: 0.9412 - val_loss: 0.7324 - val_categorical_accuracy: 0.8211\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.83740\n","Epoch 48/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2995 - categorical_accuracy: 0.9658 - val_loss: 0.7459 - val_categorical_accuracy: 0.7789\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.83740\n","Epoch 49/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3353 - categorical_accuracy: 0.9414 - val_loss: 0.7351 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.83740\n","Epoch 50/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.3034 - categorical_accuracy: 0.9527 - val_loss: 0.7231 - val_categorical_accuracy: 0.8146\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.83740\n","Epoch 51/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2983 - categorical_accuracy: 0.9652 - val_loss: 0.7164 - val_categorical_accuracy: 0.8407\n","\n","Epoch 00051: val_categorical_accuracy improved from 0.83740 to 0.84065, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 52/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2926 - categorical_accuracy: 0.9673 - val_loss: 0.7347 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.84065\n","Epoch 53/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2848 - categorical_accuracy: 0.9630 - val_loss: 0.7303 - val_categorical_accuracy: 0.8130\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.84065\n","Epoch 54/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2770 - categorical_accuracy: 0.9621 - val_loss: 0.7909 - val_categorical_accuracy: 0.7756\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.84065\n","Epoch 55/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.2836 - categorical_accuracy: 0.9717 - val_loss: 0.7405 - val_categorical_accuracy: 0.8065\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.84065\n","Epoch 56/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2621 - categorical_accuracy: 0.9575 - val_loss: 0.7031 - val_categorical_accuracy: 0.8325\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.84065\n","Epoch 57/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2533 - categorical_accuracy: 0.9727 - val_loss: 0.7386 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.84065\n","Epoch 58/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2707 - categorical_accuracy: 0.9536 - val_loss: 0.7866 - val_categorical_accuracy: 0.8146\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.84065\n","Epoch 59/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2638 - categorical_accuracy: 0.9522 - val_loss: 0.7662 - val_categorical_accuracy: 0.8130\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.84065\n","Epoch 60/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2554 - categorical_accuracy: 0.9661 - val_loss: 0.7358 - val_categorical_accuracy: 0.8081\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.84065\n","Epoch 61/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.2432 - categorical_accuracy: 0.9781 - val_loss: 0.7001 - val_categorical_accuracy: 0.8325\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.84065\n","Epoch 62/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2350 - categorical_accuracy: 0.9725 - val_loss: 0.7517 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.84065\n","Epoch 63/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2675 - categorical_accuracy: 0.9619 - val_loss: 0.7006 - val_categorical_accuracy: 0.8260\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.84065\n","Epoch 64/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.2333 - categorical_accuracy: 0.9742 - val_loss: 0.7054 - val_categorical_accuracy: 0.8407\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.84065\n","Epoch 65/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2269 - categorical_accuracy: 0.9729 - val_loss: 0.7338 - val_categorical_accuracy: 0.8130\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.84065\n","Epoch 66/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.2126 - categorical_accuracy: 0.9811 - val_loss: 0.7237 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.84065\n","Epoch 67/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2566 - categorical_accuracy: 0.9530 - val_loss: 0.6894 - val_categorical_accuracy: 0.8325\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.84065\n","Epoch 68/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2100 - categorical_accuracy: 0.9805 - val_loss: 0.7360 - val_categorical_accuracy: 0.8098\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.84065\n","Epoch 69/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2260 - categorical_accuracy: 0.9737 - val_loss: 0.7311 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.84065\n","Epoch 70/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2149 - categorical_accuracy: 0.9773 - val_loss: 0.7301 - val_categorical_accuracy: 0.8244\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.84065\n","Epoch 71/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2099 - categorical_accuracy: 0.9754 - val_loss: 0.7093 - val_categorical_accuracy: 0.8618\n","\n","Epoch 00071: val_categorical_accuracy improved from 0.84065 to 0.86179, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 72/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2091 - categorical_accuracy: 0.9851 - val_loss: 0.7095 - val_categorical_accuracy: 0.8179\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.86179\n","Epoch 73/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2215 - categorical_accuracy: 0.9746 - val_loss: 0.7295 - val_categorical_accuracy: 0.8163\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.86179\n","Epoch 74/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2151 - categorical_accuracy: 0.9714 - val_loss: 0.7181 - val_categorical_accuracy: 0.8130\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.86179\n","Epoch 75/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2108 - categorical_accuracy: 0.9689 - val_loss: 0.6634 - val_categorical_accuracy: 0.8276\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.86179\n","Epoch 76/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2103 - categorical_accuracy: 0.9802 - val_loss: 0.7525 - val_categorical_accuracy: 0.8455\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.86179\n","Epoch 77/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1959 - categorical_accuracy: 0.9753 - val_loss: 0.6831 - val_categorical_accuracy: 0.8520\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.86179\n","Epoch 78/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1999 - categorical_accuracy: 0.9652 - val_loss: 0.7223 - val_categorical_accuracy: 0.8211\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.86179\n","Epoch 79/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2052 - categorical_accuracy: 0.9766 - val_loss: 0.6949 - val_categorical_accuracy: 0.8309\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.86179\n","Epoch 80/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.2134 - categorical_accuracy: 0.9763 - val_loss: 0.6537 - val_categorical_accuracy: 0.8553\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.86179\n","Epoch 81/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1944 - categorical_accuracy: 0.9728 - val_loss: 0.7216 - val_categorical_accuracy: 0.8260\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.86179\n","Epoch 82/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1834 - categorical_accuracy: 0.9820 - val_loss: 0.7675 - val_categorical_accuracy: 0.8309\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.86179\n","Epoch 83/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1948 - categorical_accuracy: 0.9776 - val_loss: 0.6763 - val_categorical_accuracy: 0.8423\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.86179\n","Epoch 84/100\n","46/46 [==============================] - 0s 7ms/step - loss: 0.1826 - categorical_accuracy: 0.9861 - val_loss: 0.6852 - val_categorical_accuracy: 0.8520\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.86179\n","Epoch 85/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1980 - categorical_accuracy: 0.9755 - val_loss: 0.6489 - val_categorical_accuracy: 0.8423\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.86179\n","Epoch 86/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1765 - categorical_accuracy: 0.9822 - val_loss: 0.7142 - val_categorical_accuracy: 0.8309\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.86179\n","Epoch 87/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.1777 - categorical_accuracy: 0.9754 - val_loss: 0.7160 - val_categorical_accuracy: 0.8341\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.86179\n","Epoch 88/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1624 - categorical_accuracy: 0.9853 - val_loss: 0.7076 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.86179\n","Epoch 89/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1547 - categorical_accuracy: 0.9911 - val_loss: 0.7060 - val_categorical_accuracy: 0.8374\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.86179\n","Epoch 90/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.1680 - categorical_accuracy: 0.9874 - val_loss: 0.6805 - val_categorical_accuracy: 0.8407\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.86179\n","Epoch 91/100\n","46/46 [==============================] - 0s 4ms/step - loss: 0.1724 - categorical_accuracy: 0.9754 - val_loss: 0.6822 - val_categorical_accuracy: 0.8374\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.86179\n","Epoch 92/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1680 - categorical_accuracy: 0.9837 - val_loss: 0.7062 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.86179\n","Epoch 93/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1666 - categorical_accuracy: 0.9841 - val_loss: 0.6984 - val_categorical_accuracy: 0.8211\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.86179\n","Epoch 94/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1636 - categorical_accuracy: 0.9837 - val_loss: 0.6618 - val_categorical_accuracy: 0.8537\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.86179\n","Epoch 95/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1615 - categorical_accuracy: 0.9798 - val_loss: 0.7235 - val_categorical_accuracy: 0.8244\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.86179\n","Epoch 96/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1517 - categorical_accuracy: 0.9930 - val_loss: 0.7252 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.86179\n","Epoch 97/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1665 - categorical_accuracy: 0.9785 - val_loss: 0.6919 - val_categorical_accuracy: 0.8260\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.86179\n","Epoch 98/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1608 - categorical_accuracy: 0.9817 - val_loss: 0.6690 - val_categorical_accuracy: 0.8520\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.86179\n","Epoch 99/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1536 - categorical_accuracy: 0.9888 - val_loss: 0.7541 - val_categorical_accuracy: 0.8049\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.86179\n","Epoch 100/100\n","46/46 [==============================] - 0s 5ms/step - loss: 0.1687 - categorical_accuracy: 0.9800 - val_loss: 0.6925 - val_categorical_accuracy: 0.8520\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.86179\n","20/20 [==============================] - 0s 4ms/step - loss: 0.7093 - categorical_accuracy: 0.8618\n","Test accuracy on target dataset = 0.8617886304855347\n","20/20 [==============================] - 0s 1ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 0.9 and 70 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_190 (Conv2D)             (None, 20, 20, 64)   4160        input_6[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 20, 20, 64)   256         conv2d_190[0][0]                 \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 20, 20, 64)   0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","lambda_81 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","lambda_83 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","lambda_85 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","lambda_87 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_192 (Conv2D)             (None, 20, 20, 8)    584         lambda_81[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_196 (Conv2D)             (None, 20, 20, 8)    584         lambda_83[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_200 (Conv2D)             (None, 20, 20, 8)    584         lambda_85[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_204 (Conv2D)             (None, 20, 20, 8)    584         lambda_87[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_80 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_193 (Conv2D)             (None, 20, 20, 8)    584         conv2d_192[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_82 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_197 (Conv2D)             (None, 20, 20, 8)    584         conv2d_196[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_84 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_201 (Conv2D)             (None, 20, 20, 8)    584         conv2d_200[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_86 (Lambda)              (None, 20, 20, 8)    0           activation_60[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_205 (Conv2D)             (None, 20, 20, 8)    584         conv2d_204[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_191 (Conv2D)             (None, 20, 20, 8)    584         lambda_80[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_194 (Conv2D)             (None, 20, 20, 8)    584         conv2d_193[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_195 (Conv2D)             (None, 20, 20, 8)    584         lambda_82[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_198 (Conv2D)             (None, 20, 20, 8)    584         conv2d_197[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_199 (Conv2D)             (None, 20, 20, 8)    584         lambda_84[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_202 (Conv2D)             (None, 20, 20, 8)    584         conv2d_201[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_203 (Conv2D)             (None, 20, 20, 8)    584         lambda_86[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_206 (Conv2D)             (None, 20, 20, 8)    584         conv2d_205[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 20, 20, 64)   0           conv2d_191[0][0]                 \n","                                                                 conv2d_194[0][0]                 \n","                                                                 conv2d_195[0][0]                 \n","                                                                 conv2d_198[0][0]                 \n","                                                                 conv2d_199[0][0]                 \n","                                                                 conv2d_202[0][0]                 \n","                                                                 conv2d_203[0][0]                 \n","                                                                 conv2d_206[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 20, 20, 64)   256         concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 20, 20, 64)   0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_20 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_61[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_10 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_20[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_10 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_10[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_21 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 20, 20, 64)   256         tf.reshape_21[0][0]              \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 20, 20, 64)   0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_207 (Conv2D)             (None, 20, 20, 128)  8320        activation_62[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_208 (Conv2D)             (None, 20, 20, 128)  8320        input_6[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 20, 20, 128)  512         conv2d_207[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 20, 20, 128)  512         conv2d_208[0][0]                 \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 20, 20, 128)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 20, 20, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 20, 20, 128)  0           activation_63[0][0]              \n","                                                                 activation_64[0][0]              \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 20, 20, 128)  0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_209 (Conv2D)             (None, 20, 20, 128)  16512       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 20, 20, 128)  512         conv2d_209[0][0]                 \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 20, 20, 128)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","lambda_89 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","lambda_91 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","lambda_93 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","lambda_95 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_211 (Conv2D)             (None, 20, 20, 16)   2320        lambda_89[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_215 (Conv2D)             (None, 20, 20, 16)   2320        lambda_91[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_219 (Conv2D)             (None, 20, 20, 16)   2320        lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_223 (Conv2D)             (None, 20, 20, 16)   2320        lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_88 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_212 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_211[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_90 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_216 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_215[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_92 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_220 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_219[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_94 (Lambda)              (None, 20, 20, 16)   0           activation_66[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_224 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_223[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_210 (Conv2D)             (None, 20, 20, 16)   2320        lambda_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_213 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_212[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_214 (Conv2D)             (None, 20, 20, 16)   2320        lambda_90[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_217 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_216[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_218 (Conv2D)             (None, 20, 20, 16)   2320        lambda_92[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_221 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_220[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_222 (Conv2D)             (None, 20, 20, 16)   2320        lambda_94[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_225 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_224[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 20, 20, 128)  0           conv2d_210[0][0]                 \n","                                                                 conv2d_213[0][0]                 \n","                                                                 conv2d_214[0][0]                 \n","                                                                 conv2d_217[0][0]                 \n","                                                                 conv2d_218[0][0]                 \n","                                                                 conv2d_221[0][0]                 \n","                                                                 conv2d_222[0][0]                 \n","                                                                 conv2d_225[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 20, 20, 128)  512         concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 20, 20, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_22 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_67[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_11 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_22[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_11 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_11[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_23 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 20, 20, 128)  512         tf.reshape_23[0][0]              \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 20, 20, 128)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_226 (Conv2D)             (None, 20, 20, 256)  33024       activation_68[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_227 (Conv2D)             (None, 20, 20, 256)  33024       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 20, 20, 256)  1024        conv2d_226[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 20, 20, 256)  1024        conv2d_227[0][0]                 \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 20, 20, 256)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 20, 20, 256)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 20, 20, 256)  0           activation_69[0][0]              \n","                                                                 activation_70[0][0]              \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 20, 20, 256)  0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_5 (Glo (None, 256)          0           activation_71[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [136, 52, 125, 110, 132, 128, 125, 97, 145, 120, 131, 68, 110, 50]\n","Total number of samples is 1529.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 1065.\n","Samples per class in training set: [ 95  36  87  77  92  89  87  67 101  84  91  47  77  35]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 464.\n","Samples per class in test set: [41 16 38 33 40 39 38 30 44 36 40 21 33 15]\n","\n","X_train_transfer => (1065, 256)\n","X_test_transfer  => (464, 256)\n","y_train => (1065, 14)\n","y_test  => (464, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_18 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","54/54 [==============================] - 1s 7ms/step - loss: 6.5822 - categorical_accuracy: 0.1138 - val_loss: 2.3507 - val_categorical_accuracy: 0.2759\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.27586, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","54/54 [==============================] - 0s 4ms/step - loss: 2.0022 - categorical_accuracy: 0.3535 - val_loss: 1.9264 - val_categorical_accuracy: 0.3685\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.27586 to 0.36853, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","54/54 [==============================] - 0s 5ms/step - loss: 1.6839 - categorical_accuracy: 0.4611 - val_loss: 1.8218 - val_categorical_accuracy: 0.4224\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.36853 to 0.42241, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.5466 - categorical_accuracy: 0.5030 - val_loss: 1.6610 - val_categorical_accuracy: 0.3879\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.42241\n","Epoch 5/100\n","54/54 [==============================] - 0s 5ms/step - loss: 1.4161 - categorical_accuracy: 0.5687 - val_loss: 1.5304 - val_categorical_accuracy: 0.5237\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.42241 to 0.52371, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","54/54 [==============================] - 0s 5ms/step - loss: 1.2914 - categorical_accuracy: 0.6042 - val_loss: 1.4393 - val_categorical_accuracy: 0.4849\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.52371\n","Epoch 7/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.2760 - categorical_accuracy: 0.6269 - val_loss: 1.4207 - val_categorical_accuracy: 0.6379\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.52371 to 0.63793, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.2023 - categorical_accuracy: 0.6561 - val_loss: 1.3746 - val_categorical_accuracy: 0.6056\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.63793\n","Epoch 9/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.1692 - categorical_accuracy: 0.6514 - val_loss: 1.3195 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.63793\n","Epoch 10/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.1634 - categorical_accuracy: 0.6603 - val_loss: 1.3250 - val_categorical_accuracy: 0.6164\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.63793\n","Epoch 11/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.0892 - categorical_accuracy: 0.6748 - val_loss: 1.2709 - val_categorical_accuracy: 0.5690\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.63793\n","Epoch 12/100\n","54/54 [==============================] - 0s 4ms/step - loss: 1.0267 - categorical_accuracy: 0.7062 - val_loss: 1.2432 - val_categorical_accuracy: 0.7306\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.63793 to 0.73060, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 13/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.9721 - categorical_accuracy: 0.7351 - val_loss: 1.2016 - val_categorical_accuracy: 0.6983\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.73060\n","Epoch 14/100\n","54/54 [==============================] - 0s 8ms/step - loss: 0.9519 - categorical_accuracy: 0.7433 - val_loss: 1.1650 - val_categorical_accuracy: 0.7134\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.73060\n","Epoch 15/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.9426 - categorical_accuracy: 0.7768 - val_loss: 1.1281 - val_categorical_accuracy: 0.7392\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.73060 to 0.73922, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.8708 - categorical_accuracy: 0.7689 - val_loss: 1.2079 - val_categorical_accuracy: 0.6315\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.73922\n","Epoch 17/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.8624 - categorical_accuracy: 0.7674 - val_loss: 1.1865 - val_categorical_accuracy: 0.6466\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.73922\n","Epoch 18/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.8907 - categorical_accuracy: 0.7249 - val_loss: 1.1209 - val_categorical_accuracy: 0.6746\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.73922\n","Epoch 19/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.8487 - categorical_accuracy: 0.7933 - val_loss: 1.0838 - val_categorical_accuracy: 0.6487\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.73922\n","Epoch 20/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.8206 - categorical_accuracy: 0.7885 - val_loss: 1.0580 - val_categorical_accuracy: 0.7198\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.73922\n","Epoch 21/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.7832 - categorical_accuracy: 0.8168 - val_loss: 1.0855 - val_categorical_accuracy: 0.6767\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.73922\n","Epoch 22/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.8072 - categorical_accuracy: 0.8009 - val_loss: 1.0580 - val_categorical_accuracy: 0.7091\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.73922\n","Epoch 23/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.7634 - categorical_accuracy: 0.8109 - val_loss: 1.0273 - val_categorical_accuracy: 0.7608\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.73922 to 0.76078, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 24/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.7752 - categorical_accuracy: 0.8095 - val_loss: 1.0398 - val_categorical_accuracy: 0.6897\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.76078\n","Epoch 25/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.7488 - categorical_accuracy: 0.8319 - val_loss: 1.0532 - val_categorical_accuracy: 0.6875\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.76078\n","Epoch 26/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.7090 - categorical_accuracy: 0.8363 - val_loss: 1.0442 - val_categorical_accuracy: 0.7522\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.76078\n","Epoch 27/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.7477 - categorical_accuracy: 0.8213 - val_loss: 1.0055 - val_categorical_accuracy: 0.7565\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.76078\n","Epoch 28/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.6935 - categorical_accuracy: 0.8193 - val_loss: 0.9787 - val_categorical_accuracy: 0.7241\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.76078\n","Epoch 29/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6495 - categorical_accuracy: 0.8509 - val_loss: 0.9430 - val_categorical_accuracy: 0.7909\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.76078 to 0.79095, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 30/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6388 - categorical_accuracy: 0.8648 - val_loss: 1.0380 - val_categorical_accuracy: 0.6875\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.79095\n","Epoch 31/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6165 - categorical_accuracy: 0.8445 - val_loss: 1.0134 - val_categorical_accuracy: 0.7091\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.79095\n","Epoch 32/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6476 - categorical_accuracy: 0.8619 - val_loss: 0.9507 - val_categorical_accuracy: 0.7198\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.79095\n","Epoch 33/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6004 - categorical_accuracy: 0.8518 - val_loss: 0.9317 - val_categorical_accuracy: 0.7737\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.79095\n","Epoch 34/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.6466 - categorical_accuracy: 0.8677 - val_loss: 0.9686 - val_categorical_accuracy: 0.7263\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.79095\n","Epoch 35/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5844 - categorical_accuracy: 0.8869 - val_loss: 0.9076 - val_categorical_accuracy: 0.8060\n","\n","Epoch 00035: val_categorical_accuracy improved from 0.79095 to 0.80603, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 36/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5980 - categorical_accuracy: 0.8598 - val_loss: 0.8985 - val_categorical_accuracy: 0.7737\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.80603\n","Epoch 37/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5789 - categorical_accuracy: 0.8697 - val_loss: 0.9240 - val_categorical_accuracy: 0.7823\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.80603\n","Epoch 38/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5954 - categorical_accuracy: 0.8967 - val_loss: 0.9108 - val_categorical_accuracy: 0.7759\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.80603\n","Epoch 39/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5891 - categorical_accuracy: 0.8839 - val_loss: 0.8877 - val_categorical_accuracy: 0.7802\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.80603\n","Epoch 40/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5490 - categorical_accuracy: 0.8824 - val_loss: 0.8816 - val_categorical_accuracy: 0.8039\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.80603\n","Epoch 41/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5250 - categorical_accuracy: 0.8936 - val_loss: 0.9034 - val_categorical_accuracy: 0.7586\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.80603\n","Epoch 42/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5245 - categorical_accuracy: 0.8970 - val_loss: 0.8688 - val_categorical_accuracy: 0.7780\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.80603\n","Epoch 43/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5313 - categorical_accuracy: 0.8921 - val_loss: 0.9174 - val_categorical_accuracy: 0.7866\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.80603\n","Epoch 44/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5435 - categorical_accuracy: 0.8957 - val_loss: 0.8761 - val_categorical_accuracy: 0.7716\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.80603\n","Epoch 45/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5184 - categorical_accuracy: 0.8881 - val_loss: 0.8550 - val_categorical_accuracy: 0.8017\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.80603\n","Epoch 46/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5155 - categorical_accuracy: 0.9059 - val_loss: 0.8652 - val_categorical_accuracy: 0.8103\n","\n","Epoch 00046: val_categorical_accuracy improved from 0.80603 to 0.81034, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 47/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.5022 - categorical_accuracy: 0.8941 - val_loss: 0.9459 - val_categorical_accuracy: 0.7500\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.81034\n","Epoch 48/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5042 - categorical_accuracy: 0.9107 - val_loss: 0.8878 - val_categorical_accuracy: 0.7478\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.81034\n","Epoch 49/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4636 - categorical_accuracy: 0.9167 - val_loss: 0.8490 - val_categorical_accuracy: 0.8060\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.81034\n","Epoch 50/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.5017 - categorical_accuracy: 0.8921 - val_loss: 0.9039 - val_categorical_accuracy: 0.7866\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.81034\n","Epoch 51/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4536 - categorical_accuracy: 0.9155 - val_loss: 0.8575 - val_categorical_accuracy: 0.7651\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.81034\n","Epoch 52/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4791 - categorical_accuracy: 0.8921 - val_loss: 0.8908 - val_categorical_accuracy: 0.7478\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.81034\n","Epoch 53/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4329 - categorical_accuracy: 0.9219 - val_loss: 0.8252 - val_categorical_accuracy: 0.7909\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.81034\n","Epoch 54/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4465 - categorical_accuracy: 0.9137 - val_loss: 0.8468 - val_categorical_accuracy: 0.8147\n","\n","Epoch 00054: val_categorical_accuracy improved from 0.81034 to 0.81466, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 55/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4493 - categorical_accuracy: 0.9096 - val_loss: 0.8916 - val_categorical_accuracy: 0.7349\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.81466\n","Epoch 56/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4380 - categorical_accuracy: 0.9165 - val_loss: 0.8972 - val_categorical_accuracy: 0.8125\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.81466\n","Epoch 57/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4383 - categorical_accuracy: 0.9171 - val_loss: 0.8454 - val_categorical_accuracy: 0.7565\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.81466\n","Epoch 58/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4340 - categorical_accuracy: 0.9073 - val_loss: 0.8726 - val_categorical_accuracy: 0.7866\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.81466\n","Epoch 59/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4259 - categorical_accuracy: 0.9359 - val_loss: 0.8423 - val_categorical_accuracy: 0.8362\n","\n","Epoch 00059: val_categorical_accuracy improved from 0.81466 to 0.83621, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 60/100\n","54/54 [==============================] - 0s 7ms/step - loss: 0.4104 - categorical_accuracy: 0.9352 - val_loss: 0.8394 - val_categorical_accuracy: 0.7802\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.83621\n","Epoch 61/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.4037 - categorical_accuracy: 0.9193 - val_loss: 0.8611 - val_categorical_accuracy: 0.7565\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.83621\n","Epoch 62/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3972 - categorical_accuracy: 0.9256 - val_loss: 0.8193 - val_categorical_accuracy: 0.7608\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.83621\n","Epoch 63/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3883 - categorical_accuracy: 0.9402 - val_loss: 0.8710 - val_categorical_accuracy: 0.7565\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.83621\n","Epoch 64/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4006 - categorical_accuracy: 0.9351 - val_loss: 0.8301 - val_categorical_accuracy: 0.7672\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.83621\n","Epoch 65/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4261 - categorical_accuracy: 0.9042 - val_loss: 0.8260 - val_categorical_accuracy: 0.8448\n","\n","Epoch 00065: val_categorical_accuracy improved from 0.83621 to 0.84483, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 66/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.4007 - categorical_accuracy: 0.9206 - val_loss: 0.8343 - val_categorical_accuracy: 0.8190\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.84483\n","Epoch 67/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3751 - categorical_accuracy: 0.9330 - val_loss: 0.8070 - val_categorical_accuracy: 0.8578\n","\n","Epoch 00067: val_categorical_accuracy improved from 0.84483 to 0.85776, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 68/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3593 - categorical_accuracy: 0.9440 - val_loss: 0.8068 - val_categorical_accuracy: 0.8534\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.85776\n","Epoch 69/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3942 - categorical_accuracy: 0.9222 - val_loss: 0.7945 - val_categorical_accuracy: 0.7823\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.85776\n","Epoch 70/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3669 - categorical_accuracy: 0.9395 - val_loss: 0.8022 - val_categorical_accuracy: 0.7888\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.85776\n","Epoch 71/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3693 - categorical_accuracy: 0.9269 - val_loss: 0.8050 - val_categorical_accuracy: 0.7672\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.85776\n","Epoch 72/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3714 - categorical_accuracy: 0.9325 - val_loss: 0.8111 - val_categorical_accuracy: 0.8362\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.85776\n","Epoch 73/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3387 - categorical_accuracy: 0.9379 - val_loss: 0.7800 - val_categorical_accuracy: 0.8599\n","\n","Epoch 00073: val_categorical_accuracy improved from 0.85776 to 0.85991, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 74/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3512 - categorical_accuracy: 0.9344 - val_loss: 0.7591 - val_categorical_accuracy: 0.8470\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.85991\n","Epoch 75/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3490 - categorical_accuracy: 0.9505 - val_loss: 0.8614 - val_categorical_accuracy: 0.7802\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.85991\n","Epoch 76/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3458 - categorical_accuracy: 0.9464 - val_loss: 0.8176 - val_categorical_accuracy: 0.8060\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.85991\n","Epoch 77/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3421 - categorical_accuracy: 0.9478 - val_loss: 0.7902 - val_categorical_accuracy: 0.8254\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.85991\n","Epoch 78/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3287 - categorical_accuracy: 0.9488 - val_loss: 0.8023 - val_categorical_accuracy: 0.7737\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.85991\n","Epoch 79/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3502 - categorical_accuracy: 0.9448 - val_loss: 0.7949 - val_categorical_accuracy: 0.8362\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.85991\n","Epoch 80/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3325 - categorical_accuracy: 0.9469 - val_loss: 0.7851 - val_categorical_accuracy: 0.8211\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.85991\n","Epoch 81/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3295 - categorical_accuracy: 0.9511 - val_loss: 0.7776 - val_categorical_accuracy: 0.8578\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.85991\n","Epoch 82/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3173 - categorical_accuracy: 0.9561 - val_loss: 0.7782 - val_categorical_accuracy: 0.8125\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.85991\n","Epoch 83/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3144 - categorical_accuracy: 0.9548 - val_loss: 0.8038 - val_categorical_accuracy: 0.8341\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.85991\n","Epoch 84/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3290 - categorical_accuracy: 0.9478 - val_loss: 0.7617 - val_categorical_accuracy: 0.8836\n","\n","Epoch 00084: val_categorical_accuracy improved from 0.85991 to 0.88362, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 85/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3352 - categorical_accuracy: 0.9350 - val_loss: 0.8019 - val_categorical_accuracy: 0.8405\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.88362\n","Epoch 86/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3357 - categorical_accuracy: 0.9264 - val_loss: 0.7684 - val_categorical_accuracy: 0.8125\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.88362\n","Epoch 87/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3277 - categorical_accuracy: 0.9394 - val_loss: 0.8414 - val_categorical_accuracy: 0.7522\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.88362\n","Epoch 88/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3112 - categorical_accuracy: 0.9576 - val_loss: 0.7927 - val_categorical_accuracy: 0.7651\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.88362\n","Epoch 89/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3057 - categorical_accuracy: 0.9404 - val_loss: 0.7816 - val_categorical_accuracy: 0.8599\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.88362\n","Epoch 90/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.3046 - categorical_accuracy: 0.9568 - val_loss: 0.7583 - val_categorical_accuracy: 0.8599\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.88362\n","Epoch 91/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.2892 - categorical_accuracy: 0.9563 - val_loss: 0.8015 - val_categorical_accuracy: 0.7780\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.88362\n","Epoch 92/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.2964 - categorical_accuracy: 0.9510 - val_loss: 0.8102 - val_categorical_accuracy: 0.7608\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.88362\n","Epoch 93/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.2879 - categorical_accuracy: 0.9600 - val_loss: 0.7602 - val_categorical_accuracy: 0.8728\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.88362\n","Epoch 94/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.2888 - categorical_accuracy: 0.9632 - val_loss: 0.7692 - val_categorical_accuracy: 0.8578\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.88362\n","Epoch 95/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.3011 - categorical_accuracy: 0.9613 - val_loss: 0.7947 - val_categorical_accuracy: 0.7759\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.88362\n","Epoch 96/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.2813 - categorical_accuracy: 0.9641 - val_loss: 0.7885 - val_categorical_accuracy: 0.8190\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.88362\n","Epoch 97/100\n","54/54 [==============================] - 0s 5ms/step - loss: 0.2864 - categorical_accuracy: 0.9591 - val_loss: 0.7582 - val_categorical_accuracy: 0.8621\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.88362\n","Epoch 98/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.2729 - categorical_accuracy: 0.9685 - val_loss: 0.7948 - val_categorical_accuracy: 0.7909\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.88362\n","Epoch 99/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.2735 - categorical_accuracy: 0.9584 - val_loss: 0.7945 - val_categorical_accuracy: 0.7953\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.88362\n","Epoch 100/100\n","54/54 [==============================] - 0s 4ms/step - loss: 0.2712 - categorical_accuracy: 0.9552 - val_loss: 0.7605 - val_categorical_accuracy: 0.8513\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.88362\n","15/15 [==============================] - 0s 2ms/step - loss: 0.7617 - categorical_accuracy: 0.8836\n","Test accuracy on target dataset = 0.8836206793785095\n","15/15 [==============================] - 0s 2ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 0.9 and 80 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_13\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_228 (Conv2D)             (None, 20, 20, 64)   4160        input_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 20, 20, 64)   256         conv2d_228[0][0]                 \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 20, 20, 64)   0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","lambda_97 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_99 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_101 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","lambda_103 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_230 (Conv2D)             (None, 20, 20, 8)    584         lambda_97[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_234 (Conv2D)             (None, 20, 20, 8)    584         lambda_99[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_238 (Conv2D)             (None, 20, 20, 8)    584         lambda_101[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_242 (Conv2D)             (None, 20, 20, 8)    584         lambda_103[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_96 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_231 (Conv2D)             (None, 20, 20, 8)    584         conv2d_230[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_98 (Lambda)              (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_235 (Conv2D)             (None, 20, 20, 8)    584         conv2d_234[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_100 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_239 (Conv2D)             (None, 20, 20, 8)    584         conv2d_238[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_102 (Lambda)             (None, 20, 20, 8)    0           activation_72[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_243 (Conv2D)             (None, 20, 20, 8)    584         conv2d_242[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_229 (Conv2D)             (None, 20, 20, 8)    584         lambda_96[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_232 (Conv2D)             (None, 20, 20, 8)    584         conv2d_231[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_233 (Conv2D)             (None, 20, 20, 8)    584         lambda_98[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_236 (Conv2D)             (None, 20, 20, 8)    584         conv2d_235[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_237 (Conv2D)             (None, 20, 20, 8)    584         lambda_100[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_240 (Conv2D)             (None, 20, 20, 8)    584         conv2d_239[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_241 (Conv2D)             (None, 20, 20, 8)    584         lambda_102[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_244 (Conv2D)             (None, 20, 20, 8)    584         conv2d_243[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 20, 20, 64)   0           conv2d_229[0][0]                 \n","                                                                 conv2d_232[0][0]                 \n","                                                                 conv2d_233[0][0]                 \n","                                                                 conv2d_236[0][0]                 \n","                                                                 conv2d_237[0][0]                 \n","                                                                 conv2d_240[0][0]                 \n","                                                                 conv2d_241[0][0]                 \n","                                                                 conv2d_244[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 20, 20, 64)   256         concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 20, 20, 64)   0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_24 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_73[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_12 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_24[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_12 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_12[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_25 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 20, 20, 64)   256         tf.reshape_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 20, 20, 64)   0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_245 (Conv2D)             (None, 20, 20, 128)  8320        activation_74[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_246 (Conv2D)             (None, 20, 20, 128)  8320        input_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 20, 20, 128)  512         conv2d_245[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 20, 20, 128)  512         conv2d_246[0][0]                 \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 20, 20, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 20, 20, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 20, 20, 128)  0           activation_75[0][0]              \n","                                                                 activation_76[0][0]              \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 20, 20, 128)  0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_247 (Conv2D)             (None, 20, 20, 128)  16512       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 20, 20, 128)  512         conv2d_247[0][0]                 \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 20, 20, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","lambda_105 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_107 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_109 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","lambda_111 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_249 (Conv2D)             (None, 20, 20, 16)   2320        lambda_105[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_253 (Conv2D)             (None, 20, 20, 16)   2320        lambda_107[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_257 (Conv2D)             (None, 20, 20, 16)   2320        lambda_109[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_261 (Conv2D)             (None, 20, 20, 16)   2320        lambda_111[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_104 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_250 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_249[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_106 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_254 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_253[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_108 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_258 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_257[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_110 (Lambda)             (None, 20, 20, 16)   0           activation_78[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_262 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_261[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_248 (Conv2D)             (None, 20, 20, 16)   2320        lambda_104[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_251 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_250[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_252 (Conv2D)             (None, 20, 20, 16)   2320        lambda_106[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_255 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_254[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_256 (Conv2D)             (None, 20, 20, 16)   2320        lambda_108[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_259 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_258[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_260 (Conv2D)             (None, 20, 20, 16)   2320        lambda_110[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_263 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_262[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 20, 20, 128)  0           conv2d_248[0][0]                 \n","                                                                 conv2d_251[0][0]                 \n","                                                                 conv2d_252[0][0]                 \n","                                                                 conv2d_255[0][0]                 \n","                                                                 conv2d_256[0][0]                 \n","                                                                 conv2d_259[0][0]                 \n","                                                                 conv2d_260[0][0]                 \n","                                                                 conv2d_263[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 20, 20, 128)  512         concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 20, 20, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_26 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_79[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_13 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_26[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_13 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_13[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_27 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 20, 20, 128)  512         tf.reshape_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 20, 20, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_264 (Conv2D)             (None, 20, 20, 256)  33024       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_265 (Conv2D)             (None, 20, 20, 256)  33024       activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 20, 20, 256)  1024        conv2d_264[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 20, 20, 256)  1024        conv2d_265[0][0]                 \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 20, 20, 256)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 20, 20, 256)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 20, 20, 256)  0           activation_81[0][0]              \n","                                                                 activation_82[0][0]              \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 20, 20, 256)  0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_6 (Glo (None, 256)          0           activation_83[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [136, 52, 125, 110, 132, 128, 125, 97, 145, 120, 131, 68, 110, 50]\n","Total number of samples is 1529.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 1219.\n","Samples per class in training set: [108  41 100  88 105 102 100  77 116  96 104  54  88  40]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 310.\n","Samples per class in test set: [28 11 25 22 27 26 25 20 29 24 27 14 22 10]\n","\n","X_train_transfer => (1219, 256)\n","X_test_transfer  => (310, 256)\n","y_train => (1219, 14)\n","y_test  => (310, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_19 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","61/61 [==============================] - 1s 6ms/step - loss: 3.9956 - categorical_accuracy: 0.2045 - val_loss: 1.9979 - val_categorical_accuracy: 0.3387\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.33871, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.8389 - categorical_accuracy: 0.3944 - val_loss: 1.7477 - val_categorical_accuracy: 0.4839\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.33871 to 0.48387, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.5706 - categorical_accuracy: 0.4707 - val_loss: 1.4953 - val_categorical_accuracy: 0.4935\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.48387 to 0.49355, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.3819 - categorical_accuracy: 0.5689 - val_loss: 1.4465 - val_categorical_accuracy: 0.5839\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.49355 to 0.58387, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.2748 - categorical_accuracy: 0.6003 - val_loss: 1.3630 - val_categorical_accuracy: 0.6000\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.58387 to 0.60000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.1785 - categorical_accuracy: 0.6132 - val_loss: 1.2954 - val_categorical_accuracy: 0.6065\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.60000 to 0.60645, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.1464 - categorical_accuracy: 0.6306 - val_loss: 1.2573 - val_categorical_accuracy: 0.7097\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.60645 to 0.70968, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.0625 - categorical_accuracy: 0.7084 - val_loss: 1.1414 - val_categorical_accuracy: 0.7516\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.70968 to 0.75161, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 9/100\n","61/61 [==============================] - 0s 4ms/step - loss: 1.0331 - categorical_accuracy: 0.7001 - val_loss: 1.2387 - val_categorical_accuracy: 0.5355\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.75161\n","Epoch 10/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.9702 - categorical_accuracy: 0.7267 - val_loss: 1.1243 - val_categorical_accuracy: 0.6774\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.75161\n","Epoch 11/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.9672 - categorical_accuracy: 0.7380 - val_loss: 1.0804 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.75161\n","Epoch 12/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.8902 - categorical_accuracy: 0.7584 - val_loss: 1.0387 - val_categorical_accuracy: 0.7871\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.75161 to 0.78710, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 13/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.8106 - categorical_accuracy: 0.8195 - val_loss: 1.0125 - val_categorical_accuracy: 0.6806\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.78710\n","Epoch 14/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.8119 - categorical_accuracy: 0.7926 - val_loss: 0.9806 - val_categorical_accuracy: 0.7452\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.78710\n","Epoch 15/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.7942 - categorical_accuracy: 0.8095 - val_loss: 0.9772 - val_categorical_accuracy: 0.7355\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.78710\n","Epoch 16/100\n","61/61 [==============================] - 0s 5ms/step - loss: 0.7607 - categorical_accuracy: 0.8377 - val_loss: 0.8917 - val_categorical_accuracy: 0.8129\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.78710 to 0.81290, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 17/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.7188 - categorical_accuracy: 0.8213 - val_loss: 0.8882 - val_categorical_accuracy: 0.8032\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.81290\n","Epoch 18/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.7152 - categorical_accuracy: 0.8234 - val_loss: 0.8844 - val_categorical_accuracy: 0.8258\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.81290 to 0.82581, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6945 - categorical_accuracy: 0.8354 - val_loss: 0.9115 - val_categorical_accuracy: 0.8323\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.82581 to 0.83226, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 20/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6659 - categorical_accuracy: 0.8542 - val_loss: 0.8481 - val_categorical_accuracy: 0.8323\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.83226\n","Epoch 21/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6767 - categorical_accuracy: 0.8316 - val_loss: 0.8949 - val_categorical_accuracy: 0.8000\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.83226\n","Epoch 22/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6537 - categorical_accuracy: 0.8463 - val_loss: 0.8185 - val_categorical_accuracy: 0.8452\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.83226 to 0.84516, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 23/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6145 - categorical_accuracy: 0.8686 - val_loss: 0.8318 - val_categorical_accuracy: 0.7839\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.84516\n","Epoch 24/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5831 - categorical_accuracy: 0.8834 - val_loss: 0.8333 - val_categorical_accuracy: 0.8194\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.84516\n","Epoch 25/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5975 - categorical_accuracy: 0.8730 - val_loss: 0.7996 - val_categorical_accuracy: 0.8452\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.84516\n","Epoch 26/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5864 - categorical_accuracy: 0.8594 - val_loss: 0.7826 - val_categorical_accuracy: 0.8581\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.84516 to 0.85806, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 27/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5576 - categorical_accuracy: 0.8657 - val_loss: 0.8003 - val_categorical_accuracy: 0.8419\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.85806\n","Epoch 28/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5425 - categorical_accuracy: 0.8792 - val_loss: 0.7792 - val_categorical_accuracy: 0.8065\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.85806\n","Epoch 29/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5296 - categorical_accuracy: 0.8957 - val_loss: 0.7830 - val_categorical_accuracy: 0.7742\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.85806\n","Epoch 30/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5223 - categorical_accuracy: 0.9001 - val_loss: 0.7773 - val_categorical_accuracy: 0.8226\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.85806\n","Epoch 31/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5149 - categorical_accuracy: 0.8963 - val_loss: 0.7509 - val_categorical_accuracy: 0.8774\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.85806 to 0.87742, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 32/100\n","61/61 [==============================] - 0s 6ms/step - loss: 0.4974 - categorical_accuracy: 0.8978 - val_loss: 0.8075 - val_categorical_accuracy: 0.8194\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.87742\n","Epoch 33/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.5091 - categorical_accuracy: 0.8968 - val_loss: 0.7360 - val_categorical_accuracy: 0.9097\n","\n","Epoch 00033: val_categorical_accuracy improved from 0.87742 to 0.90968, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 34/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4889 - categorical_accuracy: 0.9001 - val_loss: 0.7234 - val_categorical_accuracy: 0.8677\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.90968\n","Epoch 35/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4716 - categorical_accuracy: 0.9016 - val_loss: 0.7045 - val_categorical_accuracy: 0.8839\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.90968\n","Epoch 36/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4417 - categorical_accuracy: 0.9222 - val_loss: 0.7350 - val_categorical_accuracy: 0.8710\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.90968\n","Epoch 37/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4526 - categorical_accuracy: 0.9161 - val_loss: 0.7119 - val_categorical_accuracy: 0.9032\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.90968\n","Epoch 38/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4513 - categorical_accuracy: 0.9296 - val_loss: 0.7191 - val_categorical_accuracy: 0.8516\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.90968\n","Epoch 39/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4146 - categorical_accuracy: 0.9337 - val_loss: 0.6807 - val_categorical_accuracy: 0.9097\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.90968\n","Epoch 40/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4251 - categorical_accuracy: 0.9280 - val_loss: 0.7545 - val_categorical_accuracy: 0.8806\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.90968\n","Epoch 41/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4253 - categorical_accuracy: 0.9326 - val_loss: 0.6860 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.90968\n","Epoch 42/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3798 - categorical_accuracy: 0.9475 - val_loss: 0.7088 - val_categorical_accuracy: 0.8548\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.90968\n","Epoch 43/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.4216 - categorical_accuracy: 0.9207 - val_loss: 0.7084 - val_categorical_accuracy: 0.8484\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.90968\n","Epoch 44/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3923 - categorical_accuracy: 0.9286 - val_loss: 0.7489 - val_categorical_accuracy: 0.8355\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.90968\n","Epoch 45/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3886 - categorical_accuracy: 0.9282 - val_loss: 0.6809 - val_categorical_accuracy: 0.8613\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.90968\n","Epoch 46/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3860 - categorical_accuracy: 0.9373 - val_loss: 0.7273 - val_categorical_accuracy: 0.8710\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.90968\n","Epoch 47/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3739 - categorical_accuracy: 0.9304 - val_loss: 0.6691 - val_categorical_accuracy: 0.9129\n","\n","Epoch 00047: val_categorical_accuracy improved from 0.90968 to 0.91290, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 48/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3545 - categorical_accuracy: 0.9462 - val_loss: 0.6802 - val_categorical_accuracy: 0.9355\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.91290 to 0.93548, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 49/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3445 - categorical_accuracy: 0.9490 - val_loss: 0.7814 - val_categorical_accuracy: 0.8258\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.93548\n","Epoch 50/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3637 - categorical_accuracy: 0.9426 - val_loss: 0.6650 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.93548\n","Epoch 51/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3458 - categorical_accuracy: 0.9487 - val_loss: 0.7216 - val_categorical_accuracy: 0.8581\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.93548\n","Epoch 52/100\n","61/61 [==============================] - 0s 3ms/step - loss: 0.3574 - categorical_accuracy: 0.9360 - val_loss: 0.6967 - val_categorical_accuracy: 0.8548\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.93548\n","Epoch 53/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3533 - categorical_accuracy: 0.9443 - val_loss: 0.6620 - val_categorical_accuracy: 0.9129\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.93548\n","Epoch 54/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3281 - categorical_accuracy: 0.9479 - val_loss: 0.6558 - val_categorical_accuracy: 0.8710\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.93548\n","Epoch 55/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3280 - categorical_accuracy: 0.9449 - val_loss: 0.6969 - val_categorical_accuracy: 0.8645\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.93548\n","Epoch 56/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3220 - categorical_accuracy: 0.9539 - val_loss: 0.6588 - val_categorical_accuracy: 0.8742\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.93548\n","Epoch 57/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3052 - categorical_accuracy: 0.9660 - val_loss: 0.6426 - val_categorical_accuracy: 0.9452\n","\n","Epoch 00057: val_categorical_accuracy improved from 0.93548 to 0.94516, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 58/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3265 - categorical_accuracy: 0.9334 - val_loss: 0.6793 - val_categorical_accuracy: 0.9000\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.94516\n","Epoch 59/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3068 - categorical_accuracy: 0.9576 - val_loss: 0.6615 - val_categorical_accuracy: 0.8613\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.94516\n","Epoch 60/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2966 - categorical_accuracy: 0.9618 - val_loss: 0.6648 - val_categorical_accuracy: 0.8903\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.94516\n","Epoch 61/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.3035 - categorical_accuracy: 0.9403 - val_loss: 0.6350 - val_categorical_accuracy: 0.9226\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.94516\n","Epoch 62/100\n","61/61 [==============================] - 0s 5ms/step - loss: 0.2927 - categorical_accuracy: 0.9619 - val_loss: 0.6560 - val_categorical_accuracy: 0.9032\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.94516\n","Epoch 63/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2935 - categorical_accuracy: 0.9543 - val_loss: 0.6517 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.94516\n","Epoch 64/100\n","61/61 [==============================] - 0s 5ms/step - loss: 0.2785 - categorical_accuracy: 0.9581 - val_loss: 0.6178 - val_categorical_accuracy: 0.9129\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.94516\n","Epoch 65/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2787 - categorical_accuracy: 0.9424 - val_loss: 0.6048 - val_categorical_accuracy: 0.9290\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.94516\n","Epoch 66/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2773 - categorical_accuracy: 0.9543 - val_loss: 0.6603 - val_categorical_accuracy: 0.9032\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.94516\n","Epoch 67/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2711 - categorical_accuracy: 0.9647 - val_loss: 0.6562 - val_categorical_accuracy: 0.9129\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.94516\n","Epoch 68/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2569 - categorical_accuracy: 0.9621 - val_loss: 0.6254 - val_categorical_accuracy: 0.9258\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.94516\n","Epoch 69/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2625 - categorical_accuracy: 0.9690 - val_loss: 0.6393 - val_categorical_accuracy: 0.9161\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.94516\n","Epoch 70/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2695 - categorical_accuracy: 0.9599 - val_loss: 0.6407 - val_categorical_accuracy: 0.9516\n","\n","Epoch 00070: val_categorical_accuracy improved from 0.94516 to 0.95161, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 71/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2699 - categorical_accuracy: 0.9641 - val_loss: 0.6239 - val_categorical_accuracy: 0.9161\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.95161\n","Epoch 72/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2563 - categorical_accuracy: 0.9711 - val_loss: 0.6300 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.95161\n","Epoch 73/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2578 - categorical_accuracy: 0.9609 - val_loss: 0.6284 - val_categorical_accuracy: 0.9484\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.95161\n","Epoch 74/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2460 - categorical_accuracy: 0.9694 - val_loss: 0.6781 - val_categorical_accuracy: 0.8581\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.95161\n","Epoch 75/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2602 - categorical_accuracy: 0.9616 - val_loss: 0.6314 - val_categorical_accuracy: 0.9161\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.95161\n","Epoch 76/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2417 - categorical_accuracy: 0.9728 - val_loss: 0.6234 - val_categorical_accuracy: 0.9000\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.95161\n","Epoch 77/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2493 - categorical_accuracy: 0.9621 - val_loss: 0.6168 - val_categorical_accuracy: 0.9290\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.95161\n","Epoch 78/100\n","61/61 [==============================] - 0s 6ms/step - loss: 0.2491 - categorical_accuracy: 0.9684 - val_loss: 0.6751 - val_categorical_accuracy: 0.8839\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.95161\n","Epoch 79/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2489 - categorical_accuracy: 0.9668 - val_loss: 0.6230 - val_categorical_accuracy: 0.8903\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.95161\n","Epoch 80/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2320 - categorical_accuracy: 0.9678 - val_loss: 0.6762 - val_categorical_accuracy: 0.8645\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.95161\n","Epoch 81/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2470 - categorical_accuracy: 0.9651 - val_loss: 0.6012 - val_categorical_accuracy: 0.9355\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.95161\n","Epoch 82/100\n","61/61 [==============================] - 0s 5ms/step - loss: 0.2275 - categorical_accuracy: 0.9809 - val_loss: 0.5996 - val_categorical_accuracy: 0.9355\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.95161\n","Epoch 83/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2147 - categorical_accuracy: 0.9776 - val_loss: 0.6307 - val_categorical_accuracy: 0.9097\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.95161\n","Epoch 84/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2150 - categorical_accuracy: 0.9724 - val_loss: 0.6314 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.95161\n","Epoch 85/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2263 - categorical_accuracy: 0.9690 - val_loss: 0.5903 - val_categorical_accuracy: 0.9355\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.95161\n","Epoch 86/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2319 - categorical_accuracy: 0.9675 - val_loss: 0.6301 - val_categorical_accuracy: 0.9387\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.95161\n","Epoch 87/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2260 - categorical_accuracy: 0.9617 - val_loss: 0.6305 - val_categorical_accuracy: 0.9290\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.95161\n","Epoch 88/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.1974 - categorical_accuracy: 0.9867 - val_loss: 0.6026 - val_categorical_accuracy: 0.9355\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.95161\n","Epoch 89/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2193 - categorical_accuracy: 0.9707 - val_loss: 0.6161 - val_categorical_accuracy: 0.9323\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.95161\n","Epoch 90/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2078 - categorical_accuracy: 0.9759 - val_loss: 0.6302 - val_categorical_accuracy: 0.9516\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.95161\n","Epoch 91/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2075 - categorical_accuracy: 0.9767 - val_loss: 0.6164 - val_categorical_accuracy: 0.9323\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.95161\n","Epoch 92/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2121 - categorical_accuracy: 0.9812 - val_loss: 0.6025 - val_categorical_accuracy: 0.9387\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.95161\n","Epoch 93/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.1921 - categorical_accuracy: 0.9821 - val_loss: 0.6511 - val_categorical_accuracy: 0.9258\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.95161\n","Epoch 94/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2039 - categorical_accuracy: 0.9768 - val_loss: 0.6589 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.95161\n","Epoch 95/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2006 - categorical_accuracy: 0.9729 - val_loss: 0.6281 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.95161\n","Epoch 96/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2080 - categorical_accuracy: 0.9711 - val_loss: 0.5997 - val_categorical_accuracy: 0.9323\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.95161\n","Epoch 97/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.1998 - categorical_accuracy: 0.9726 - val_loss: 0.6151 - val_categorical_accuracy: 0.9323\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.95161\n","Epoch 98/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2073 - categorical_accuracy: 0.9712 - val_loss: 0.6532 - val_categorical_accuracy: 0.8968\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.95161\n","Epoch 99/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.2095 - categorical_accuracy: 0.9751 - val_loss: 0.6100 - val_categorical_accuracy: 0.9290\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.95161\n","Epoch 100/100\n","61/61 [==============================] - 0s 4ms/step - loss: 0.1996 - categorical_accuracy: 0.9671 - val_loss: 0.6363 - val_categorical_accuracy: 0.8839\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.95161\n","10/10 [==============================] - 0s 3ms/step - loss: 0.6407 - categorical_accuracy: 0.9516\n","Test accuracy on target dataset = 0.9516128897666931\n","10/10 [==============================] - 0s 2ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 0.9 and 90 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_15\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_266 (Conv2D)             (None, 20, 20, 64)   4160        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 20, 20, 64)   256         conv2d_266[0][0]                 \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 20, 20, 64)   0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","lambda_113 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_115 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_117 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","lambda_119 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_268 (Conv2D)             (None, 20, 20, 8)    584         lambda_113[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_272 (Conv2D)             (None, 20, 20, 8)    584         lambda_115[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_276 (Conv2D)             (None, 20, 20, 8)    584         lambda_117[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_280 (Conv2D)             (None, 20, 20, 8)    584         lambda_119[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_112 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_269 (Conv2D)             (None, 20, 20, 8)    584         conv2d_268[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_114 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_273 (Conv2D)             (None, 20, 20, 8)    584         conv2d_272[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_116 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_277 (Conv2D)             (None, 20, 20, 8)    584         conv2d_276[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_118 (Lambda)             (None, 20, 20, 8)    0           activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_281 (Conv2D)             (None, 20, 20, 8)    584         conv2d_280[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_267 (Conv2D)             (None, 20, 20, 8)    584         lambda_112[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_270 (Conv2D)             (None, 20, 20, 8)    584         conv2d_269[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_271 (Conv2D)             (None, 20, 20, 8)    584         lambda_114[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_274 (Conv2D)             (None, 20, 20, 8)    584         conv2d_273[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_275 (Conv2D)             (None, 20, 20, 8)    584         lambda_116[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_278 (Conv2D)             (None, 20, 20, 8)    584         conv2d_277[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_279 (Conv2D)             (None, 20, 20, 8)    584         lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_282 (Conv2D)             (None, 20, 20, 8)    584         conv2d_281[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 20, 20, 64)   0           conv2d_267[0][0]                 \n","                                                                 conv2d_270[0][0]                 \n","                                                                 conv2d_271[0][0]                 \n","                                                                 conv2d_274[0][0]                 \n","                                                                 conv2d_275[0][0]                 \n","                                                                 conv2d_278[0][0]                 \n","                                                                 conv2d_279[0][0]                 \n","                                                                 conv2d_282[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 20, 20, 64)   256         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 20, 20, 64)   0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_28 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_85[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_14 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_28[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_14 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_14[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_29 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 20, 20, 64)   256         tf.reshape_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 20, 20, 64)   0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_283 (Conv2D)             (None, 20, 20, 128)  8320        activation_86[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_284 (Conv2D)             (None, 20, 20, 128)  8320        input_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 20, 20, 128)  512         conv2d_283[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 20, 20, 128)  512         conv2d_284[0][0]                 \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 20, 20, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 20, 20, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 20, 20, 128)  0           activation_87[0][0]              \n","                                                                 activation_88[0][0]              \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 20, 20, 128)  0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_285 (Conv2D)             (None, 20, 20, 128)  16512       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 20, 20, 128)  512         conv2d_285[0][0]                 \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 20, 20, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","lambda_121 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_123 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_125 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","lambda_127 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_287 (Conv2D)             (None, 20, 20, 16)   2320        lambda_121[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_291 (Conv2D)             (None, 20, 20, 16)   2320        lambda_123[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_295 (Conv2D)             (None, 20, 20, 16)   2320        lambda_125[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_299 (Conv2D)             (None, 20, 20, 16)   2320        lambda_127[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_120 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_288 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_287[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_122 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_292 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_291[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_124 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_296 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_295[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_126 (Lambda)             (None, 20, 20, 16)   0           activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_300 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_299[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_286 (Conv2D)             (None, 20, 20, 16)   2320        lambda_120[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_289 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_288[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_290 (Conv2D)             (None, 20, 20, 16)   2320        lambda_122[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_293 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_292[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_294 (Conv2D)             (None, 20, 20, 16)   2320        lambda_124[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_297 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_296[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_298 (Conv2D)             (None, 20, 20, 16)   2320        lambda_126[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_301 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_300[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 20, 20, 128)  0           conv2d_286[0][0]                 \n","                                                                 conv2d_289[0][0]                 \n","                                                                 conv2d_290[0][0]                 \n","                                                                 conv2d_293[0][0]                 \n","                                                                 conv2d_294[0][0]                 \n","                                                                 conv2d_297[0][0]                 \n","                                                                 conv2d_298[0][0]                 \n","                                                                 conv2d_301[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 20, 20, 128)  512         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 20, 20, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_30 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_91[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_15 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_30[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_15 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_15[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_31 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 20, 20, 128)  512         tf.reshape_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 20, 20, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_302 (Conv2D)             (None, 20, 20, 256)  33024       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_303 (Conv2D)             (None, 20, 20, 256)  33024       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 20, 20, 256)  1024        conv2d_302[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 20, 20, 256)  1024        conv2d_303[0][0]                 \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 20, 20, 256)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 20, 20, 256)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 20, 20, 256)  0           activation_93[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 20, 20, 256)  0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_7 (Glo (None, 256)          0           activation_95[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [136, 52, 125, 110, 132, 128, 125, 97, 145, 120, 131, 68, 110, 50]\n","Total number of samples is 1529.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 1371.\n","Samples per class in training set: [122  46 112  99 118 115 112  87 130 108 117  61  99  45]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 158.\n","Samples per class in test set: [14  6 13 11 14 13 13 10 15 12 14  7 11  5]\n","\n","X_train_transfer => (1371, 256)\n","X_test_transfer  => (158, 256)\n","y_train => (1371, 14)\n","y_test  => (158, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_20 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","69/69 [==============================] - 1s 6ms/step - loss: 5.7326 - categorical_accuracy: 0.1241 - val_loss: 2.4586 - val_categorical_accuracy: 0.2468\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.24684, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","69/69 [==============================] - 0s 4ms/step - loss: 1.8685 - categorical_accuracy: 0.3777 - val_loss: 1.7975 - val_categorical_accuracy: 0.3671\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.24684 to 0.36709, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","69/69 [==============================] - 0s 4ms/step - loss: 1.5121 - categorical_accuracy: 0.4793 - val_loss: 1.8237 - val_categorical_accuracy: 0.2405\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.36709\n","Epoch 4/100\n","69/69 [==============================] - 0s 4ms/step - loss: 1.3814 - categorical_accuracy: 0.5319 - val_loss: 1.4373 - val_categorical_accuracy: 0.6392\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.36709 to 0.63924, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","69/69 [==============================] - 0s 4ms/step - loss: 1.1901 - categorical_accuracy: 0.6003 - val_loss: 1.4185 - val_categorical_accuracy: 0.4177\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.63924\n","Epoch 6/100\n","69/69 [==============================] - 0s 4ms/step - loss: 1.1195 - categorical_accuracy: 0.6537 - val_loss: 1.2359 - val_categorical_accuracy: 0.6013\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.63924\n","Epoch 7/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.9813 - categorical_accuracy: 0.7004 - val_loss: 1.2374 - val_categorical_accuracy: 0.6646\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.63924 to 0.66456, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","69/69 [==============================] - 0s 6ms/step - loss: 0.9393 - categorical_accuracy: 0.7201 - val_loss: 1.1651 - val_categorical_accuracy: 0.5696\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.66456\n","Epoch 9/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.8915 - categorical_accuracy: 0.7480 - val_loss: 1.0334 - val_categorical_accuracy: 0.8165\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.66456 to 0.81646, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 10/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.7887 - categorical_accuracy: 0.7930 - val_loss: 1.0377 - val_categorical_accuracy: 0.7468\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.81646\n","Epoch 11/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.7618 - categorical_accuracy: 0.8014 - val_loss: 1.1259 - val_categorical_accuracy: 0.6013\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.81646\n","Epoch 12/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.7273 - categorical_accuracy: 0.7953 - val_loss: 0.9980 - val_categorical_accuracy: 0.7532\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.81646\n","Epoch 13/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.6833 - categorical_accuracy: 0.8343 - val_loss: 1.1125 - val_categorical_accuracy: 0.5886\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.81646\n","Epoch 14/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.6182 - categorical_accuracy: 0.8494 - val_loss: 0.9365 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.81646\n","Epoch 15/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.5905 - categorical_accuracy: 0.8669 - val_loss: 0.8435 - val_categorical_accuracy: 0.8734\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.81646 to 0.87342, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.5674 - categorical_accuracy: 0.8781 - val_loss: 0.9865 - val_categorical_accuracy: 0.6392\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.87342\n","Epoch 17/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.5371 - categorical_accuracy: 0.8837 - val_loss: 0.7752 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.87342 to 0.89873, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.5427 - categorical_accuracy: 0.8994 - val_loss: 0.7992 - val_categorical_accuracy: 0.8354\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.89873\n","Epoch 19/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.5061 - categorical_accuracy: 0.8884 - val_loss: 0.7620 - val_categorical_accuracy: 0.8481\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.89873\n","Epoch 20/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.4896 - categorical_accuracy: 0.9075 - val_loss: 0.8207 - val_categorical_accuracy: 0.7468\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.89873\n","Epoch 21/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.4463 - categorical_accuracy: 0.9193 - val_loss: 0.7336 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.89873\n","Epoch 22/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.4758 - categorical_accuracy: 0.9092 - val_loss: 0.7643 - val_categorical_accuracy: 0.7785\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.89873\n","Epoch 23/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.4469 - categorical_accuracy: 0.9163 - val_loss: 0.6965 - val_categorical_accuracy: 0.8924\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.89873\n","Epoch 24/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.4104 - categorical_accuracy: 0.9213 - val_loss: 0.8008 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.89873\n","Epoch 25/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.4124 - categorical_accuracy: 0.9117 - val_loss: 0.6965 - val_categorical_accuracy: 0.8608\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.89873\n","Epoch 26/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3993 - categorical_accuracy: 0.9224 - val_loss: 0.6825 - val_categorical_accuracy: 0.8734\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.89873\n","Epoch 27/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3867 - categorical_accuracy: 0.9202 - val_loss: 0.7497 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.89873\n","Epoch 28/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3906 - categorical_accuracy: 0.9205 - val_loss: 0.7226 - val_categorical_accuracy: 0.8418\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.89873\n","Epoch 29/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3507 - categorical_accuracy: 0.9490 - val_loss: 0.8214 - val_categorical_accuracy: 0.7975\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.89873\n","Epoch 30/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3635 - categorical_accuracy: 0.9316 - val_loss: 0.6857 - val_categorical_accuracy: 0.8734\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.89873\n","Epoch 31/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3582 - categorical_accuracy: 0.9322 - val_loss: 0.7572 - val_categorical_accuracy: 0.8165\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.89873\n","Epoch 32/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.3357 - categorical_accuracy: 0.9350 - val_loss: 0.6660 - val_categorical_accuracy: 0.7722\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.89873\n","Epoch 33/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.3134 - categorical_accuracy: 0.9486 - val_loss: 0.6238 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.89873\n","Epoch 34/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.3190 - categorical_accuracy: 0.9402 - val_loss: 0.6617 - val_categorical_accuracy: 0.8671\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.89873\n","Epoch 35/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.3078 - categorical_accuracy: 0.9477 - val_loss: 0.6191 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00035: val_categorical_accuracy improved from 0.89873 to 0.92405, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 36/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2880 - categorical_accuracy: 0.9603 - val_loss: 0.6150 - val_categorical_accuracy: 0.8924\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.92405\n","Epoch 37/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2989 - categorical_accuracy: 0.9441 - val_loss: 0.6428 - val_categorical_accuracy: 0.8165\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.92405\n","Epoch 38/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2735 - categorical_accuracy: 0.9670 - val_loss: 0.5591 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.92405\n","Epoch 39/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2678 - categorical_accuracy: 0.9631 - val_loss: 0.5539 - val_categorical_accuracy: 0.8797\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.92405\n","Epoch 40/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2721 - categorical_accuracy: 0.9468 - val_loss: 0.5028 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.92405\n","Epoch 41/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2632 - categorical_accuracy: 0.9663 - val_loss: 0.5409 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00041: val_categorical_accuracy improved from 0.92405 to 0.93038, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 42/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2696 - categorical_accuracy: 0.9611 - val_loss: 0.5359 - val_categorical_accuracy: 0.9114\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.93038\n","Epoch 43/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2561 - categorical_accuracy: 0.9565 - val_loss: 0.5371 - val_categorical_accuracy: 0.8608\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.93038\n","Epoch 44/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2575 - categorical_accuracy: 0.9540 - val_loss: 0.5483 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.93038\n","Epoch 45/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2389 - categorical_accuracy: 0.9653 - val_loss: 0.5439 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.93038\n","Epoch 46/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2425 - categorical_accuracy: 0.9598 - val_loss: 0.5122 - val_categorical_accuracy: 0.8797\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.93038\n","Epoch 47/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2313 - categorical_accuracy: 0.9731 - val_loss: 0.5724 - val_categorical_accuracy: 0.9177\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.93038\n","Epoch 48/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2321 - categorical_accuracy: 0.9721 - val_loss: 0.5207 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.93038\n","Epoch 49/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2316 - categorical_accuracy: 0.9712 - val_loss: 0.4665 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.93038\n","Epoch 50/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2150 - categorical_accuracy: 0.9745 - val_loss: 0.4415 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.93038\n","Epoch 51/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2382 - categorical_accuracy: 0.9627 - val_loss: 0.4839 - val_categorical_accuracy: 0.8797\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.93038\n","Epoch 52/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2048 - categorical_accuracy: 0.9741 - val_loss: 0.5689 - val_categorical_accuracy: 0.8544\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.93038\n","Epoch 53/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2115 - categorical_accuracy: 0.9761 - val_loss: 0.4546 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.93038\n","Epoch 54/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.2157 - categorical_accuracy: 0.9677 - val_loss: 0.4766 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.93038\n","Epoch 55/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1911 - categorical_accuracy: 0.9806 - val_loss: 0.4316 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.93038\n","Epoch 56/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2169 - categorical_accuracy: 0.9681 - val_loss: 0.4728 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.93038\n","Epoch 57/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1831 - categorical_accuracy: 0.9713 - val_loss: 0.4510 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.93038\n","Epoch 58/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1973 - categorical_accuracy: 0.9814 - val_loss: 0.5874 - val_categorical_accuracy: 0.8608\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.93038\n","Epoch 59/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.2014 - categorical_accuracy: 0.9694 - val_loss: 0.4367 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.93038\n","Epoch 60/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1845 - categorical_accuracy: 0.9809 - val_loss: 0.5990 - val_categorical_accuracy: 0.8038\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.93038\n","Epoch 61/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1973 - categorical_accuracy: 0.9680 - val_loss: 0.4614 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.93038\n","Epoch 62/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1800 - categorical_accuracy: 0.9761 - val_loss: 0.4194 - val_categorical_accuracy: 0.9430\n","\n","Epoch 00062: val_categorical_accuracy improved from 0.93038 to 0.94304, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 63/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1775 - categorical_accuracy: 0.9759 - val_loss: 0.3626 - val_categorical_accuracy: 0.9367\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.94304\n","Epoch 64/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1736 - categorical_accuracy: 0.9771 - val_loss: 0.4314 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.94304\n","Epoch 65/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.1779 - categorical_accuracy: 0.9776 - val_loss: 0.4414 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.94304\n","Epoch 66/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1634 - categorical_accuracy: 0.9889 - val_loss: 0.4214 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.94304\n","Epoch 67/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1845 - categorical_accuracy: 0.9812 - val_loss: 0.4269 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.94304\n","Epoch 68/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1690 - categorical_accuracy: 0.9827 - val_loss: 0.4407 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.94304\n","Epoch 69/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1628 - categorical_accuracy: 0.9836 - val_loss: 0.4262 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.94304\n","Epoch 70/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1528 - categorical_accuracy: 0.9834 - val_loss: 0.4278 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.94304\n","Epoch 71/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1647 - categorical_accuracy: 0.9791 - val_loss: 0.4441 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.94304\n","Epoch 72/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1689 - categorical_accuracy: 0.9824 - val_loss: 0.3704 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.94304\n","Epoch 73/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1576 - categorical_accuracy: 0.9821 - val_loss: 0.4117 - val_categorical_accuracy: 0.9114\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.94304\n","Epoch 74/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1510 - categorical_accuracy: 0.9852 - val_loss: 0.3344 - val_categorical_accuracy: 0.9367\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.94304\n","Epoch 75/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1533 - categorical_accuracy: 0.9826 - val_loss: 0.3689 - val_categorical_accuracy: 0.9494\n","\n","Epoch 00075: val_categorical_accuracy improved from 0.94304 to 0.94937, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 76/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1536 - categorical_accuracy: 0.9835 - val_loss: 0.4374 - val_categorical_accuracy: 0.9051\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.94937\n","Epoch 77/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1412 - categorical_accuracy: 0.9887 - val_loss: 0.3662 - val_categorical_accuracy: 0.8987\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.94937\n","Epoch 78/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1534 - categorical_accuracy: 0.9821 - val_loss: 0.3148 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.94937\n","Epoch 79/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1429 - categorical_accuracy: 0.9835 - val_loss: 0.3908 - val_categorical_accuracy: 0.8797\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.94937\n","Epoch 80/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.1539 - categorical_accuracy: 0.9834 - val_loss: 0.3482 - val_categorical_accuracy: 0.9430\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.94937\n","Epoch 81/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1514 - categorical_accuracy: 0.9707 - val_loss: 0.4055 - val_categorical_accuracy: 0.9177\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.94937\n","Epoch 82/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1368 - categorical_accuracy: 0.9892 - val_loss: 0.3183 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.94937\n","Epoch 83/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1337 - categorical_accuracy: 0.9878 - val_loss: 0.4462 - val_categorical_accuracy: 0.8861\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.94937\n","Epoch 84/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1503 - categorical_accuracy: 0.9786 - val_loss: 0.3984 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.94937\n","Epoch 85/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1391 - categorical_accuracy: 0.9872 - val_loss: 0.3176 - val_categorical_accuracy: 0.9557\n","\n","Epoch 00085: val_categorical_accuracy improved from 0.94937 to 0.95570, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_0.9_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 86/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1294 - categorical_accuracy: 0.9858 - val_loss: 0.4127 - val_categorical_accuracy: 0.9367\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.95570\n","Epoch 87/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1365 - categorical_accuracy: 0.9879 - val_loss: 0.3522 - val_categorical_accuracy: 0.9430\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.95570\n","Epoch 88/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1147 - categorical_accuracy: 0.9890 - val_loss: 0.2976 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.95570\n","Epoch 89/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1354 - categorical_accuracy: 0.9902 - val_loss: 0.2879 - val_categorical_accuracy: 0.9430\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.95570\n","Epoch 90/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1400 - categorical_accuracy: 0.9770 - val_loss: 0.3504 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.95570\n","Epoch 91/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1191 - categorical_accuracy: 0.9895 - val_loss: 0.3242 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.95570\n","Epoch 92/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1217 - categorical_accuracy: 0.9897 - val_loss: 0.3448 - val_categorical_accuracy: 0.8924\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.95570\n","Epoch 93/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1208 - categorical_accuracy: 0.9892 - val_loss: 0.4015 - val_categorical_accuracy: 0.8734\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.95570\n","Epoch 94/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1383 - categorical_accuracy: 0.9822 - val_loss: 0.2989 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.95570\n","Epoch 95/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1243 - categorical_accuracy: 0.9887 - val_loss: 0.3405 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.95570\n","Epoch 96/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1137 - categorical_accuracy: 0.9905 - val_loss: 0.3044 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.95570\n","Epoch 97/100\n","69/69 [==============================] - 0s 3ms/step - loss: 0.1196 - categorical_accuracy: 0.9857 - val_loss: 0.3324 - val_categorical_accuracy: 0.9177\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.95570\n","Epoch 98/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1211 - categorical_accuracy: 0.9857 - val_loss: 0.3641 - val_categorical_accuracy: 0.9177\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.95570\n","Epoch 99/100\n","69/69 [==============================] - 0s 4ms/step - loss: 0.1206 - categorical_accuracy: 0.9865 - val_loss: 0.3289 - val_categorical_accuracy: 0.9494\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.95570\n","Epoch 100/100\n","69/69 [==============================] - 0s 5ms/step - loss: 0.1035 - categorical_accuracy: 0.9942 - val_loss: 0.2864 - val_categorical_accuracy: 0.9304\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.95570\n","5/5 [==============================] - 0s 5ms/step - loss: 0.3176 - categorical_accuracy: 0.9557\n","Test accuracy on target dataset = 0.9556962251663208\n","5/5 [==============================] - 0s 2ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 60 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_17\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_304 (Conv2D)             (None, 20, 20, 64)   4160        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 20, 20, 64)   256         conv2d_304[0][0]                 \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 20, 20, 64)   0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","lambda_129 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_131 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_133 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","lambda_135 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_306 (Conv2D)             (None, 20, 20, 8)    584         lambda_129[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_310 (Conv2D)             (None, 20, 20, 8)    584         lambda_131[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_314 (Conv2D)             (None, 20, 20, 8)    584         lambda_133[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_318 (Conv2D)             (None, 20, 20, 8)    584         lambda_135[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_128 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_307 (Conv2D)             (None, 20, 20, 8)    584         conv2d_306[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_130 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_311 (Conv2D)             (None, 20, 20, 8)    584         conv2d_310[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_132 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_315 (Conv2D)             (None, 20, 20, 8)    584         conv2d_314[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_134 (Lambda)             (None, 20, 20, 8)    0           activation_96[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_319 (Conv2D)             (None, 20, 20, 8)    584         conv2d_318[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_305 (Conv2D)             (None, 20, 20, 8)    584         lambda_128[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_308 (Conv2D)             (None, 20, 20, 8)    584         conv2d_307[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_309 (Conv2D)             (None, 20, 20, 8)    584         lambda_130[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_312 (Conv2D)             (None, 20, 20, 8)    584         conv2d_311[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_313 (Conv2D)             (None, 20, 20, 8)    584         lambda_132[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_316 (Conv2D)             (None, 20, 20, 8)    584         conv2d_315[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_317 (Conv2D)             (None, 20, 20, 8)    584         lambda_134[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_320 (Conv2D)             (None, 20, 20, 8)    584         conv2d_319[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 20, 20, 64)   0           conv2d_305[0][0]                 \n","                                                                 conv2d_308[0][0]                 \n","                                                                 conv2d_309[0][0]                 \n","                                                                 conv2d_312[0][0]                 \n","                                                                 conv2d_313[0][0]                 \n","                                                                 conv2d_316[0][0]                 \n","                                                                 conv2d_317[0][0]                 \n","                                                                 conv2d_320[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 20, 20, 64)   256         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 20, 20, 64)   0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_32 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_97[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_16 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_32[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_16 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_16[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_33 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 20, 20, 64)   256         tf.reshape_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 20, 20, 64)   0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_321 (Conv2D)             (None, 20, 20, 128)  8320        activation_98[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_322 (Conv2D)             (None, 20, 20, 128)  8320        input_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 20, 20, 128)  512         conv2d_321[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 20, 20, 128)  512         conv2d_322[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 20, 20, 128)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 20, 20, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 20, 20, 128)  0           activation_99[0][0]              \n","                                                                 activation_100[0][0]             \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 20, 20, 128)  0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_323 (Conv2D)             (None, 20, 20, 128)  16512       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 20, 20, 128)  512         conv2d_323[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 20, 20, 128)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","lambda_137 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_139 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_141 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","lambda_143 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_325 (Conv2D)             (None, 20, 20, 16)   2320        lambda_137[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_329 (Conv2D)             (None, 20, 20, 16)   2320        lambda_139[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_333 (Conv2D)             (None, 20, 20, 16)   2320        lambda_141[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_337 (Conv2D)             (None, 20, 20, 16)   2320        lambda_143[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_136 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_326 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_325[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_138 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_330 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_329[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_140 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_334 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_333[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_142 (Lambda)             (None, 20, 20, 16)   0           activation_102[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_338 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_337[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_324 (Conv2D)             (None, 20, 20, 16)   2320        lambda_136[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_327 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_326[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_328 (Conv2D)             (None, 20, 20, 16)   2320        lambda_138[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_331 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_330[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_332 (Conv2D)             (None, 20, 20, 16)   2320        lambda_140[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_335 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_334[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_336 (Conv2D)             (None, 20, 20, 16)   2320        lambda_142[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_339 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_338[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 20, 20, 128)  0           conv2d_324[0][0]                 \n","                                                                 conv2d_327[0][0]                 \n","                                                                 conv2d_328[0][0]                 \n","                                                                 conv2d_331[0][0]                 \n","                                                                 conv2d_332[0][0]                 \n","                                                                 conv2d_335[0][0]                 \n","                                                                 conv2d_336[0][0]                 \n","                                                                 conv2d_339[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 20, 20, 128)  512         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 20, 20, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_34 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_103[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_17 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_34[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_17 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_17[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_35 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 20, 20, 128)  512         tf.reshape_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 20, 20, 128)  0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_340 (Conv2D)             (None, 20, 20, 256)  33024       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_341 (Conv2D)             (None, 20, 20, 256)  33024       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 20, 20, 256)  1024        conv2d_340[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 20, 20, 256)  1024        conv2d_341[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 20, 20, 256)  0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 20, 20, 256)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 20, 20, 256)  0           activation_105[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 20, 20, 256)  0           add_17[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_8 (Glo (None, 256)          0           activation_107[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples is 3144.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 1880.\n","Samples per class in training set: [162  60 150 129 161 161 155 121 188 148 165  79 144  57]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 1264.\n","Samples per class in test set: [108  41 101  86 108 108 104  82 126 100 111  54  97  38]\n","\n","X_train_transfer => (1880, 256)\n","X_test_transfer  => (1264, 256)\n","y_train => (1880, 14)\n","y_test  => (1264, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_21 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","94/94 [==============================] - 1s 6ms/step - loss: 3.1595 - categorical_accuracy: 0.2419 - val_loss: 1.6968 - val_categorical_accuracy: 0.4794\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.47943, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","94/94 [==============================] - 0s 4ms/step - loss: 1.4075 - categorical_accuracy: 0.6207 - val_loss: 1.5129 - val_categorical_accuracy: 0.5744\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.47943 to 0.57437, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","94/94 [==============================] - 0s 4ms/step - loss: 1.1556 - categorical_accuracy: 0.7091 - val_loss: 1.3822 - val_categorical_accuracy: 0.5902\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.57437 to 0.59019, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.9952 - categorical_accuracy: 0.7793 - val_loss: 1.2782 - val_categorical_accuracy: 0.5601\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.59019\n","Epoch 5/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.9077 - categorical_accuracy: 0.8033 - val_loss: 1.1826 - val_categorical_accuracy: 0.7413\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.59019 to 0.74130, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.8333 - categorical_accuracy: 0.8310 - val_loss: 1.1419 - val_categorical_accuracy: 0.7745\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.74130 to 0.77453, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.7632 - categorical_accuracy: 0.8601 - val_loss: 1.0647 - val_categorical_accuracy: 0.7674\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.77453\n","Epoch 8/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.6950 - categorical_accuracy: 0.8582 - val_loss: 1.0503 - val_categorical_accuracy: 0.8046\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.77453 to 0.80459, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 9/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.6712 - categorical_accuracy: 0.8788 - val_loss: 1.0221 - val_categorical_accuracy: 0.7310\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.80459\n","Epoch 10/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.6157 - categorical_accuracy: 0.8928 - val_loss: 1.0058 - val_categorical_accuracy: 0.7927\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.80459\n","Epoch 11/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5813 - categorical_accuracy: 0.8801 - val_loss: 0.9393 - val_categorical_accuracy: 0.8006\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.80459\n","Epoch 12/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5691 - categorical_accuracy: 0.8798 - val_loss: 0.9343 - val_categorical_accuracy: 0.8133\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.80459 to 0.81329, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 13/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5288 - categorical_accuracy: 0.8846 - val_loss: 0.9353 - val_categorical_accuracy: 0.8070\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.81329\n","Epoch 14/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.5105 - categorical_accuracy: 0.8929 - val_loss: 0.9333 - val_categorical_accuracy: 0.8093\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.81329\n","Epoch 15/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.4610 - categorical_accuracy: 0.9211 - val_loss: 0.8570 - val_categorical_accuracy: 0.8220\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.81329 to 0.82199, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.4695 - categorical_accuracy: 0.9171 - val_loss: 0.8704 - val_categorical_accuracy: 0.8093\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.82199\n","Epoch 17/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.4265 - categorical_accuracy: 0.9262 - val_loss: 0.8541 - val_categorical_accuracy: 0.8062\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.82199\n","Epoch 18/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.4194 - categorical_accuracy: 0.9313 - val_loss: 0.8272 - val_categorical_accuracy: 0.8038\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.82199\n","Epoch 19/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.4120 - categorical_accuracy: 0.9181 - val_loss: 0.8410 - val_categorical_accuracy: 0.7872\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.82199\n","Epoch 20/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3764 - categorical_accuracy: 0.9308 - val_loss: 0.8393 - val_categorical_accuracy: 0.7935\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.82199\n","Epoch 21/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.3912 - categorical_accuracy: 0.9361 - val_loss: 0.7889 - val_categorical_accuracy: 0.8093\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.82199\n","Epoch 22/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.3751 - categorical_accuracy: 0.9287 - val_loss: 0.7995 - val_categorical_accuracy: 0.8299\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.82199 to 0.82991, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 23/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3620 - categorical_accuracy: 0.9398 - val_loss: 0.7735 - val_categorical_accuracy: 0.7943\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.82991\n","Epoch 24/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3506 - categorical_accuracy: 0.9436 - val_loss: 0.7882 - val_categorical_accuracy: 0.8133\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.82991\n","Epoch 25/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3372 - categorical_accuracy: 0.9406 - val_loss: 0.7723 - val_categorical_accuracy: 0.8339\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.82991 to 0.83386, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 26/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3109 - categorical_accuracy: 0.9542 - val_loss: 0.7608 - val_categorical_accuracy: 0.8117\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.83386\n","Epoch 27/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3211 - categorical_accuracy: 0.9518 - val_loss: 0.7354 - val_categorical_accuracy: 0.8038\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.83386\n","Epoch 28/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3104 - categorical_accuracy: 0.9457 - val_loss: 0.7624 - val_categorical_accuracy: 0.8022\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.83386\n","Epoch 29/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2985 - categorical_accuracy: 0.9452 - val_loss: 0.7127 - val_categorical_accuracy: 0.8378\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.83386 to 0.83782, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 30/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2838 - categorical_accuracy: 0.9517 - val_loss: 0.7324 - val_categorical_accuracy: 0.8054\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.83782\n","Epoch 31/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.3052 - categorical_accuracy: 0.9467 - val_loss: 0.7151 - val_categorical_accuracy: 0.8528\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.83782 to 0.85285, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 32/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2699 - categorical_accuracy: 0.9599 - val_loss: 0.7194 - val_categorical_accuracy: 0.8228\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.85285\n","Epoch 33/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2670 - categorical_accuracy: 0.9587 - val_loss: 0.7310 - val_categorical_accuracy: 0.8576\n","\n","Epoch 00033: val_categorical_accuracy improved from 0.85285 to 0.85759, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 34/100\n","94/94 [==============================] - 1s 7ms/step - loss: 0.2597 - categorical_accuracy: 0.9636 - val_loss: 0.7025 - val_categorical_accuracy: 0.8307\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.85759\n","Epoch 35/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2606 - categorical_accuracy: 0.9548 - val_loss: 0.6890 - val_categorical_accuracy: 0.8252\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.85759\n","Epoch 36/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.2632 - categorical_accuracy: 0.9605 - val_loss: 0.6796 - val_categorical_accuracy: 0.8283\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.85759\n","Epoch 37/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2507 - categorical_accuracy: 0.9594 - val_loss: 0.6894 - val_categorical_accuracy: 0.8307\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.85759\n","Epoch 38/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2489 - categorical_accuracy: 0.9618 - val_loss: 0.6899 - val_categorical_accuracy: 0.8473\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.85759\n","Epoch 39/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2289 - categorical_accuracy: 0.9710 - val_loss: 0.6680 - val_categorical_accuracy: 0.8426\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.85759\n","Epoch 40/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2270 - categorical_accuracy: 0.9687 - val_loss: 0.7121 - val_categorical_accuracy: 0.8331\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.85759\n","Epoch 41/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2292 - categorical_accuracy: 0.9676 - val_loss: 0.6829 - val_categorical_accuracy: 0.8449\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.85759\n","Epoch 42/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2341 - categorical_accuracy: 0.9633 - val_loss: 0.6738 - val_categorical_accuracy: 0.8347\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.85759\n","Epoch 43/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2194 - categorical_accuracy: 0.9726 - val_loss: 0.6957 - val_categorical_accuracy: 0.8204\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.85759\n","Epoch 44/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2156 - categorical_accuracy: 0.9707 - val_loss: 0.6559 - val_categorical_accuracy: 0.8339\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.85759\n","Epoch 45/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2169 - categorical_accuracy: 0.9686 - val_loss: 0.6767 - val_categorical_accuracy: 0.8212\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.85759\n","Epoch 46/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2073 - categorical_accuracy: 0.9675 - val_loss: 0.6634 - val_categorical_accuracy: 0.8449\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.85759\n","Epoch 47/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2010 - categorical_accuracy: 0.9739 - val_loss: 0.6685 - val_categorical_accuracy: 0.8402\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.85759\n","Epoch 48/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1837 - categorical_accuracy: 0.9715 - val_loss: 0.6776 - val_categorical_accuracy: 0.8426\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.85759\n","Epoch 49/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1944 - categorical_accuracy: 0.9793 - val_loss: 0.6557 - val_categorical_accuracy: 0.8418\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.85759\n","Epoch 50/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.2062 - categorical_accuracy: 0.9691 - val_loss: 0.6433 - val_categorical_accuracy: 0.8608\n","\n","Epoch 00050: val_categorical_accuracy improved from 0.85759 to 0.86076, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 51/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1782 - categorical_accuracy: 0.9767 - val_loss: 0.6409 - val_categorical_accuracy: 0.8449\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.86076\n","Epoch 52/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1813 - categorical_accuracy: 0.9788 - val_loss: 0.6319 - val_categorical_accuracy: 0.8426\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.86076\n","Epoch 53/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1829 - categorical_accuracy: 0.9741 - val_loss: 0.6605 - val_categorical_accuracy: 0.8323\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.86076\n","Epoch 54/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1850 - categorical_accuracy: 0.9778 - val_loss: 0.6471 - val_categorical_accuracy: 0.8710\n","\n","Epoch 00054: val_categorical_accuracy improved from 0.86076 to 0.87104, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 55/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1776 - categorical_accuracy: 0.9727 - val_loss: 0.6498 - val_categorical_accuracy: 0.8616\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.87104\n","Epoch 56/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1719 - categorical_accuracy: 0.9723 - val_loss: 0.6287 - val_categorical_accuracy: 0.8449\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.87104\n","Epoch 57/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1681 - categorical_accuracy: 0.9828 - val_loss: 0.6465 - val_categorical_accuracy: 0.8434\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.87104\n","Epoch 58/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1796 - categorical_accuracy: 0.9757 - val_loss: 0.6180 - val_categorical_accuracy: 0.8679\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.87104\n","Epoch 59/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1821 - categorical_accuracy: 0.9732 - val_loss: 0.6263 - val_categorical_accuracy: 0.8568\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.87104\n","Epoch 60/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1602 - categorical_accuracy: 0.9833 - val_loss: 0.6385 - val_categorical_accuracy: 0.8750\n","\n","Epoch 00060: val_categorical_accuracy improved from 0.87104 to 0.87500, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_60_samples_from_each_class_in_training_set.h5\n","Epoch 61/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1616 - categorical_accuracy: 0.9794 - val_loss: 0.6492 - val_categorical_accuracy: 0.8457\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.87500\n","Epoch 62/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1763 - categorical_accuracy: 0.9774 - val_loss: 0.6309 - val_categorical_accuracy: 0.8362\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.87500\n","Epoch 63/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1548 - categorical_accuracy: 0.9800 - val_loss: 0.6203 - val_categorical_accuracy: 0.8639\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.87500\n","Epoch 64/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1691 - categorical_accuracy: 0.9790 - val_loss: 0.6169 - val_categorical_accuracy: 0.8726\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.87500\n","Epoch 65/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1649 - categorical_accuracy: 0.9761 - val_loss: 0.6327 - val_categorical_accuracy: 0.8528\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.87500\n","Epoch 66/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1623 - categorical_accuracy: 0.9786 - val_loss: 0.6375 - val_categorical_accuracy: 0.8347\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.87500\n","Epoch 67/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1554 - categorical_accuracy: 0.9814 - val_loss: 0.6047 - val_categorical_accuracy: 0.8584\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.87500\n","Epoch 68/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1449 - categorical_accuracy: 0.9824 - val_loss: 0.6076 - val_categorical_accuracy: 0.8750\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.87500\n","Epoch 69/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1406 - categorical_accuracy: 0.9799 - val_loss: 0.6229 - val_categorical_accuracy: 0.8473\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.87500\n","Epoch 70/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1462 - categorical_accuracy: 0.9843 - val_loss: 0.6304 - val_categorical_accuracy: 0.8513\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.87500\n","Epoch 71/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1430 - categorical_accuracy: 0.9878 - val_loss: 0.6160 - val_categorical_accuracy: 0.8544\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.87500\n","Epoch 72/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1355 - categorical_accuracy: 0.9892 - val_loss: 0.6157 - val_categorical_accuracy: 0.8521\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.87500\n","Epoch 73/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1373 - categorical_accuracy: 0.9850 - val_loss: 0.6209 - val_categorical_accuracy: 0.8521\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.87500\n","Epoch 74/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1384 - categorical_accuracy: 0.9842 - val_loss: 0.6338 - val_categorical_accuracy: 0.8307\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.87500\n","Epoch 75/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1403 - categorical_accuracy: 0.9796 - val_loss: 0.6252 - val_categorical_accuracy: 0.8354\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.87500\n","Epoch 76/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1364 - categorical_accuracy: 0.9851 - val_loss: 0.6343 - val_categorical_accuracy: 0.8481\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.87500\n","Epoch 77/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1386 - categorical_accuracy: 0.9828 - val_loss: 0.6094 - val_categorical_accuracy: 0.8465\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.87500\n","Epoch 78/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1335 - categorical_accuracy: 0.9825 - val_loss: 0.6182 - val_categorical_accuracy: 0.8465\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.87500\n","Epoch 79/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1349 - categorical_accuracy: 0.9842 - val_loss: 0.6201 - val_categorical_accuracy: 0.8623\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.87500\n","Epoch 80/100\n","94/94 [==============================] - 1s 5ms/step - loss: 0.1295 - categorical_accuracy: 0.9848 - val_loss: 0.6157 - val_categorical_accuracy: 0.8473\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.87500\n","Epoch 81/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1214 - categorical_accuracy: 0.9888 - val_loss: 0.6184 - val_categorical_accuracy: 0.8616\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.87500\n","Epoch 82/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1306 - categorical_accuracy: 0.9866 - val_loss: 0.6078 - val_categorical_accuracy: 0.8489\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.87500\n","Epoch 83/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1308 - categorical_accuracy: 0.9771 - val_loss: 0.6169 - val_categorical_accuracy: 0.8616\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.87500\n","Epoch 84/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1293 - categorical_accuracy: 0.9857 - val_loss: 0.6049 - val_categorical_accuracy: 0.8497\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.87500\n","Epoch 85/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1273 - categorical_accuracy: 0.9871 - val_loss: 0.6092 - val_categorical_accuracy: 0.8481\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.87500\n","Epoch 86/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1248 - categorical_accuracy: 0.9857 - val_loss: 0.6066 - val_categorical_accuracy: 0.8434\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.87500\n","Epoch 87/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1136 - categorical_accuracy: 0.9915 - val_loss: 0.5935 - val_categorical_accuracy: 0.8623\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.87500\n","Epoch 88/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1188 - categorical_accuracy: 0.9842 - val_loss: 0.6090 - val_categorical_accuracy: 0.8521\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.87500\n","Epoch 89/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1194 - categorical_accuracy: 0.9877 - val_loss: 0.5989 - val_categorical_accuracy: 0.8497\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.87500\n","Epoch 90/100\n","94/94 [==============================] - 0s 5ms/step - loss: 0.1131 - categorical_accuracy: 0.9891 - val_loss: 0.5992 - val_categorical_accuracy: 0.8513\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.87500\n","Epoch 91/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1087 - categorical_accuracy: 0.9892 - val_loss: 0.5914 - val_categorical_accuracy: 0.8536\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.87500\n","Epoch 92/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1162 - categorical_accuracy: 0.9844 - val_loss: 0.6120 - val_categorical_accuracy: 0.8449\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.87500\n","Epoch 93/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1135 - categorical_accuracy: 0.9903 - val_loss: 0.6306 - val_categorical_accuracy: 0.8267\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.87500\n","Epoch 94/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1095 - categorical_accuracy: 0.9897 - val_loss: 0.6156 - val_categorical_accuracy: 0.8513\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.87500\n","Epoch 95/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1265 - categorical_accuracy: 0.9793 - val_loss: 0.6179 - val_categorical_accuracy: 0.8394\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.87500\n","Epoch 96/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1111 - categorical_accuracy: 0.9875 - val_loss: 0.6096 - val_categorical_accuracy: 0.8544\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.87500\n","Epoch 97/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1034 - categorical_accuracy: 0.9887 - val_loss: 0.6098 - val_categorical_accuracy: 0.8481\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.87500\n","Epoch 98/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1110 - categorical_accuracy: 0.9867 - val_loss: 0.5967 - val_categorical_accuracy: 0.8608\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.87500\n","Epoch 99/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1092 - categorical_accuracy: 0.9884 - val_loss: 0.6053 - val_categorical_accuracy: 0.8528\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.87500\n","Epoch 100/100\n","94/94 [==============================] - 0s 4ms/step - loss: 0.1085 - categorical_accuracy: 0.9893 - val_loss: 0.5958 - val_categorical_accuracy: 0.8489\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.87500\n","40/40 [==============================] - 0s 3ms/step - loss: 0.6385 - categorical_accuracy: 0.8750\n","Test accuracy on target dataset = 0.875\n","40/40 [==============================] - 0s 1ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 70 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_19\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_342 (Conv2D)             (None, 20, 20, 64)   4160        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 20, 20, 64)   256         conv2d_342[0][0]                 \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 20, 20, 64)   0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","lambda_145 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_147 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_149 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","lambda_151 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_344 (Conv2D)             (None, 20, 20, 8)    584         lambda_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_348 (Conv2D)             (None, 20, 20, 8)    584         lambda_147[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_352 (Conv2D)             (None, 20, 20, 8)    584         lambda_149[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_356 (Conv2D)             (None, 20, 20, 8)    584         lambda_151[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_144 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_345 (Conv2D)             (None, 20, 20, 8)    584         conv2d_344[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_146 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_349 (Conv2D)             (None, 20, 20, 8)    584         conv2d_348[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_148 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_353 (Conv2D)             (None, 20, 20, 8)    584         conv2d_352[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_150 (Lambda)             (None, 20, 20, 8)    0           activation_108[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_357 (Conv2D)             (None, 20, 20, 8)    584         conv2d_356[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_343 (Conv2D)             (None, 20, 20, 8)    584         lambda_144[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_346 (Conv2D)             (None, 20, 20, 8)    584         conv2d_345[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_347 (Conv2D)             (None, 20, 20, 8)    584         lambda_146[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_350 (Conv2D)             (None, 20, 20, 8)    584         conv2d_349[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_351 (Conv2D)             (None, 20, 20, 8)    584         lambda_148[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_354 (Conv2D)             (None, 20, 20, 8)    584         conv2d_353[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_355 (Conv2D)             (None, 20, 20, 8)    584         lambda_150[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_358 (Conv2D)             (None, 20, 20, 8)    584         conv2d_357[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 20, 20, 64)   0           conv2d_343[0][0]                 \n","                                                                 conv2d_346[0][0]                 \n","                                                                 conv2d_347[0][0]                 \n","                                                                 conv2d_350[0][0]                 \n","                                                                 conv2d_351[0][0]                 \n","                                                                 conv2d_354[0][0]                 \n","                                                                 conv2d_355[0][0]                 \n","                                                                 conv2d_358[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 20, 20, 64)   256         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 20, 20, 64)   0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_36 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_109[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_18 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_36[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_18 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_18[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_37 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 20, 20, 64)   256         tf.reshape_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 20, 20, 64)   0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_359 (Conv2D)             (None, 20, 20, 128)  8320        activation_110[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_360 (Conv2D)             (None, 20, 20, 128)  8320        input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 20, 20, 128)  512         conv2d_359[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 20, 20, 128)  512         conv2d_360[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 20, 20, 128)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 20, 20, 128)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 20, 20, 128)  0           activation_111[0][0]             \n","                                                                 activation_112[0][0]             \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 20, 20, 128)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_361 (Conv2D)             (None, 20, 20, 128)  16512       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 20, 20, 128)  512         conv2d_361[0][0]                 \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 20, 20, 128)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","lambda_153 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_155 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_157 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","lambda_159 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_363 (Conv2D)             (None, 20, 20, 16)   2320        lambda_153[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_367 (Conv2D)             (None, 20, 20, 16)   2320        lambda_155[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_371 (Conv2D)             (None, 20, 20, 16)   2320        lambda_157[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_375 (Conv2D)             (None, 20, 20, 16)   2320        lambda_159[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_152 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_364 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_363[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_154 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_368 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_367[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_156 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_372 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_371[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_158 (Lambda)             (None, 20, 20, 16)   0           activation_114[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_376 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_375[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_362 (Conv2D)             (None, 20, 20, 16)   2320        lambda_152[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_365 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_364[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_366 (Conv2D)             (None, 20, 20, 16)   2320        lambda_154[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_369 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_368[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_370 (Conv2D)             (None, 20, 20, 16)   2320        lambda_156[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_373 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_372[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_374 (Conv2D)             (None, 20, 20, 16)   2320        lambda_158[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_377 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_376[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 20, 20, 128)  0           conv2d_362[0][0]                 \n","                                                                 conv2d_365[0][0]                 \n","                                                                 conv2d_366[0][0]                 \n","                                                                 conv2d_369[0][0]                 \n","                                                                 conv2d_370[0][0]                 \n","                                                                 conv2d_373[0][0]                 \n","                                                                 conv2d_374[0][0]                 \n","                                                                 conv2d_377[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 20, 20, 128)  512         concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 20, 20, 128)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_38 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_115[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_19 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_38[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_19 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_19[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_39 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 20, 20, 128)  512         tf.reshape_39[0][0]              \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 20, 20, 128)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_378 (Conv2D)             (None, 20, 20, 256)  33024       activation_116[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_379 (Conv2D)             (None, 20, 20, 256)  33024       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 20, 20, 256)  1024        conv2d_378[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 20, 20, 256)  1024        conv2d_379[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 20, 20, 256)  0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 20, 20, 256)  0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 20, 20, 256)  0           activation_117[0][0]             \n","                                                                 activation_118[0][0]             \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 20, 20, 256)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_9 (Glo (None, 256)          0           activation_119[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples is 3144.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 2195.\n","Samples per class in training set: [189  70 175 150 188 188 181 142 219 173 193  93 168  66]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 949.\n","Samples per class in test set: [81 31 76 65 81 81 78 61 95 75 83 40 73 29]\n","\n","X_train_transfer => (2195, 256)\n","X_test_transfer  => (949, 256)\n","y_train => (2195, 14)\n","y_test  => (949, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_22 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","110/110 [==============================] - 1s 5ms/step - loss: 3.2707 - categorical_accuracy: 0.1689 - val_loss: 1.9272 - val_categorical_accuracy: 0.4847\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.48472, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.8537 - categorical_accuracy: 0.4538 - val_loss: 1.6996 - val_categorical_accuracy: 0.5869\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.48472 to 0.58693, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.6016 - categorical_accuracy: 0.5544 - val_loss: 1.5756 - val_categorical_accuracy: 0.5248\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.58693\n","Epoch 4/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.4545 - categorical_accuracy: 0.5885 - val_loss: 1.4773 - val_categorical_accuracy: 0.6228\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.58693 to 0.62276, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.3475 - categorical_accuracy: 0.6457 - val_loss: 1.3786 - val_categorical_accuracy: 0.7439\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.62276 to 0.74394, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.2688 - categorical_accuracy: 0.6885 - val_loss: 1.2787 - val_categorical_accuracy: 0.7513\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.74394 to 0.75132, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.2189 - categorical_accuracy: 0.7031 - val_loss: 1.2644 - val_categorical_accuracy: 0.6322\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.75132\n","Epoch 8/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.1357 - categorical_accuracy: 0.7349 - val_loss: 1.1858 - val_categorical_accuracy: 0.7819\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.75132 to 0.78188, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 9/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.0703 - categorical_accuracy: 0.7552 - val_loss: 1.1525 - val_categorical_accuracy: 0.7745\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.78188\n","Epoch 10/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.0367 - categorical_accuracy: 0.7668 - val_loss: 1.1445 - val_categorical_accuracy: 0.7935\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.78188 to 0.79347, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 11/100\n","110/110 [==============================] - 0s 4ms/step - loss: 1.0059 - categorical_accuracy: 0.7913 - val_loss: 1.0955 - val_categorical_accuracy: 0.7977\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.79347 to 0.79768, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 12/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.9183 - categorical_accuracy: 0.8066 - val_loss: 1.0768 - val_categorical_accuracy: 0.7239\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.79768\n","Epoch 13/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.8983 - categorical_accuracy: 0.8340 - val_loss: 1.0159 - val_categorical_accuracy: 0.8946\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.79768 to 0.89463, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 14/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.8668 - categorical_accuracy: 0.8232 - val_loss: 1.0115 - val_categorical_accuracy: 0.8377\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.89463\n","Epoch 15/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.8331 - categorical_accuracy: 0.8404 - val_loss: 1.0016 - val_categorical_accuracy: 0.8641\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.89463\n","Epoch 16/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.7990 - categorical_accuracy: 0.8594 - val_loss: 0.9848 - val_categorical_accuracy: 0.8261\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.89463\n","Epoch 17/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.7620 - categorical_accuracy: 0.8440 - val_loss: 0.9416 - val_categorical_accuracy: 0.8957\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.89463 to 0.89568, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.7592 - categorical_accuracy: 0.8423 - val_loss: 0.8978 - val_categorical_accuracy: 0.9146\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.89568 to 0.91465, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","110/110 [==============================] - 1s 6ms/step - loss: 0.7125 - categorical_accuracy: 0.8896 - val_loss: 0.9057 - val_categorical_accuracy: 0.8535\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.91465\n","Epoch 20/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.6847 - categorical_accuracy: 0.9050 - val_loss: 0.8651 - val_categorical_accuracy: 0.8894\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.91465\n","Epoch 21/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.6437 - categorical_accuracy: 0.8930 - val_loss: 0.8760 - val_categorical_accuracy: 0.9336\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.91465 to 0.93361, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 22/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.6449 - categorical_accuracy: 0.9127 - val_loss: 0.8806 - val_categorical_accuracy: 0.8704\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.93361\n","Epoch 23/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.6270 - categorical_accuracy: 0.9081 - val_loss: 0.8483 - val_categorical_accuracy: 0.8799\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.93361\n","Epoch 24/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.6207 - categorical_accuracy: 0.9016 - val_loss: 0.8129 - val_categorical_accuracy: 0.9020\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.93361\n","Epoch 25/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5984 - categorical_accuracy: 0.9090 - val_loss: 0.8155 - val_categorical_accuracy: 0.8978\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.93361\n","Epoch 26/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5846 - categorical_accuracy: 0.9226 - val_loss: 0.8259 - val_categorical_accuracy: 0.8883\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.93361\n","Epoch 27/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5795 - categorical_accuracy: 0.9164 - val_loss: 0.8116 - val_categorical_accuracy: 0.8915\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.93361\n","Epoch 28/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5466 - categorical_accuracy: 0.9293 - val_loss: 0.7789 - val_categorical_accuracy: 0.9009\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.93361\n","Epoch 29/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5440 - categorical_accuracy: 0.9221 - val_loss: 0.7792 - val_categorical_accuracy: 0.9115\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.93361\n","Epoch 30/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5124 - categorical_accuracy: 0.9226 - val_loss: 0.7838 - val_categorical_accuracy: 0.8999\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.93361\n","Epoch 31/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.5152 - categorical_accuracy: 0.9310 - val_loss: 0.7530 - val_categorical_accuracy: 0.9262\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.93361\n","Epoch 32/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4859 - categorical_accuracy: 0.9370 - val_loss: 0.7333 - val_categorical_accuracy: 0.9357\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.93361 to 0.93572, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 33/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.4818 - categorical_accuracy: 0.9446 - val_loss: 0.7398 - val_categorical_accuracy: 0.8946\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.93572\n","Epoch 34/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.4574 - categorical_accuracy: 0.9402 - val_loss: 0.7442 - val_categorical_accuracy: 0.9168\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.93572\n","Epoch 35/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.4619 - categorical_accuracy: 0.9492 - val_loss: 0.7245 - val_categorical_accuracy: 0.9210\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.93572\n","Epoch 36/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4244 - categorical_accuracy: 0.9510 - val_loss: 0.7407 - val_categorical_accuracy: 0.9009\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.93572\n","Epoch 37/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4404 - categorical_accuracy: 0.9523 - val_loss: 0.7185 - val_categorical_accuracy: 0.9210\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.93572\n","Epoch 38/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4292 - categorical_accuracy: 0.9478 - val_loss: 0.6985 - val_categorical_accuracy: 0.9189\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.93572\n","Epoch 39/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4154 - categorical_accuracy: 0.9508 - val_loss: 0.7078 - val_categorical_accuracy: 0.9378\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.93572 to 0.93783, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 40/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4110 - categorical_accuracy: 0.9548 - val_loss: 0.7164 - val_categorical_accuracy: 0.9104\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.93783\n","Epoch 41/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.4034 - categorical_accuracy: 0.9568 - val_loss: 0.7132 - val_categorical_accuracy: 0.9157\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.93783\n","Epoch 42/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3923 - categorical_accuracy: 0.9495 - val_loss: 0.7010 - val_categorical_accuracy: 0.9136\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.93783\n","Epoch 43/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3755 - categorical_accuracy: 0.9587 - val_loss: 0.7126 - val_categorical_accuracy: 0.8957\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.93783\n","Epoch 44/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3824 - categorical_accuracy: 0.9528 - val_loss: 0.6660 - val_categorical_accuracy: 0.9399\n","\n","Epoch 00044: val_categorical_accuracy improved from 0.93783 to 0.93994, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_70_samples_from_each_class_in_training_set.h5\n","Epoch 45/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3774 - categorical_accuracy: 0.9491 - val_loss: 0.6759 - val_categorical_accuracy: 0.9252\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.93994\n","Epoch 46/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3590 - categorical_accuracy: 0.9583 - val_loss: 0.6661 - val_categorical_accuracy: 0.9136\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.93994\n","Epoch 47/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3599 - categorical_accuracy: 0.9659 - val_loss: 0.6713 - val_categorical_accuracy: 0.9357\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.93994\n","Epoch 48/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3515 - categorical_accuracy: 0.9662 - val_loss: 0.6473 - val_categorical_accuracy: 0.9125\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.93994\n","Epoch 49/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3456 - categorical_accuracy: 0.9623 - val_loss: 0.6706 - val_categorical_accuracy: 0.9262\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.93994\n","Epoch 50/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3482 - categorical_accuracy: 0.9579 - val_loss: 0.6586 - val_categorical_accuracy: 0.9062\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.93994\n","Epoch 51/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.3392 - categorical_accuracy: 0.9625 - val_loss: 0.6524 - val_categorical_accuracy: 0.9052\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.93994\n","Epoch 52/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3224 - categorical_accuracy: 0.9634 - val_loss: 0.6417 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.93994\n","Epoch 53/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3185 - categorical_accuracy: 0.9701 - val_loss: 0.6362 - val_categorical_accuracy: 0.9136\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.93994\n","Epoch 54/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3095 - categorical_accuracy: 0.9656 - val_loss: 0.6351 - val_categorical_accuracy: 0.9399\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.93994\n","Epoch 55/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3019 - categorical_accuracy: 0.9643 - val_loss: 0.6598 - val_categorical_accuracy: 0.8946\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.93994\n","Epoch 56/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.3084 - categorical_accuracy: 0.9638 - val_loss: 0.6418 - val_categorical_accuracy: 0.9136\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.93994\n","Epoch 57/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2867 - categorical_accuracy: 0.9721 - val_loss: 0.6165 - val_categorical_accuracy: 0.9357\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.93994\n","Epoch 58/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2942 - categorical_accuracy: 0.9768 - val_loss: 0.6361 - val_categorical_accuracy: 0.9231\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.93994\n","Epoch 59/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2981 - categorical_accuracy: 0.9658 - val_loss: 0.6424 - val_categorical_accuracy: 0.9104\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.93994\n","Epoch 60/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2809 - categorical_accuracy: 0.9739 - val_loss: 0.6156 - val_categorical_accuracy: 0.9347\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.93994\n","Epoch 61/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2827 - categorical_accuracy: 0.9735 - val_loss: 0.6477 - val_categorical_accuracy: 0.8799\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.93994\n","Epoch 62/100\n","110/110 [==============================] - 0s 5ms/step - loss: 0.2667 - categorical_accuracy: 0.9768 - val_loss: 0.6243 - val_categorical_accuracy: 0.9326\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.93994\n","Epoch 63/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2732 - categorical_accuracy: 0.9656 - val_loss: 0.6354 - val_categorical_accuracy: 0.8946\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.93994\n","Epoch 64/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2682 - categorical_accuracy: 0.9727 - val_loss: 0.6000 - val_categorical_accuracy: 0.9262\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.93994\n","Epoch 65/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2501 - categorical_accuracy: 0.9765 - val_loss: 0.6091 - val_categorical_accuracy: 0.9157\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.93994\n","Epoch 66/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2559 - categorical_accuracy: 0.9773 - val_loss: 0.6025 - val_categorical_accuracy: 0.9241\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.93994\n","Epoch 67/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2697 - categorical_accuracy: 0.9733 - val_loss: 0.6104 - val_categorical_accuracy: 0.9273\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.93994\n","Epoch 68/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2465 - categorical_accuracy: 0.9786 - val_loss: 0.6065 - val_categorical_accuracy: 0.9231\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.93994\n","Epoch 69/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2508 - categorical_accuracy: 0.9741 - val_loss: 0.6116 - val_categorical_accuracy: 0.9073\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.93994\n","Epoch 70/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2467 - categorical_accuracy: 0.9759 - val_loss: 0.6068 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.93994\n","Epoch 71/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2367 - categorical_accuracy: 0.9832 - val_loss: 0.5860 - val_categorical_accuracy: 0.9231\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.93994\n","Epoch 72/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2352 - categorical_accuracy: 0.9753 - val_loss: 0.5927 - val_categorical_accuracy: 0.9347\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.93994\n","Epoch 73/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.2316 - categorical_accuracy: 0.9798 - val_loss: 0.5910 - val_categorical_accuracy: 0.9315\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.93994\n","Epoch 74/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2215 - categorical_accuracy: 0.9791 - val_loss: 0.6032 - val_categorical_accuracy: 0.9368\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.93994\n","Epoch 75/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2419 - categorical_accuracy: 0.9801 - val_loss: 0.5909 - val_categorical_accuracy: 0.9336\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.93994\n","Epoch 76/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2194 - categorical_accuracy: 0.9781 - val_loss: 0.5830 - val_categorical_accuracy: 0.9347\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.93994\n","Epoch 77/100\n","110/110 [==============================] - 1s 6ms/step - loss: 0.2176 - categorical_accuracy: 0.9832 - val_loss: 0.5911 - val_categorical_accuracy: 0.9178\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.93994\n","Epoch 78/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2174 - categorical_accuracy: 0.9763 - val_loss: 0.5853 - val_categorical_accuracy: 0.9294\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.93994\n","Epoch 79/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2266 - categorical_accuracy: 0.9751 - val_loss: 0.5770 - val_categorical_accuracy: 0.9231\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.93994\n","Epoch 80/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2049 - categorical_accuracy: 0.9811 - val_loss: 0.6047 - val_categorical_accuracy: 0.9168\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.93994\n","Epoch 81/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2042 - categorical_accuracy: 0.9850 - val_loss: 0.6153 - val_categorical_accuracy: 0.9041\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.93994\n","Epoch 82/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2161 - categorical_accuracy: 0.9766 - val_loss: 0.5852 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.93994\n","Epoch 83/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2052 - categorical_accuracy: 0.9786 - val_loss: 0.5796 - val_categorical_accuracy: 0.9294\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.93994\n","Epoch 84/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1998 - categorical_accuracy: 0.9793 - val_loss: 0.5994 - val_categorical_accuracy: 0.9210\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.93994\n","Epoch 85/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2026 - categorical_accuracy: 0.9849 - val_loss: 0.5871 - val_categorical_accuracy: 0.9326\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.93994\n","Epoch 86/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.2010 - categorical_accuracy: 0.9813 - val_loss: 0.5782 - val_categorical_accuracy: 0.9273\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.93994\n","Epoch 87/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1992 - categorical_accuracy: 0.9852 - val_loss: 0.5915 - val_categorical_accuracy: 0.9252\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.93994\n","Epoch 88/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1877 - categorical_accuracy: 0.9847 - val_loss: 0.5891 - val_categorical_accuracy: 0.9210\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.93994\n","Epoch 89/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1920 - categorical_accuracy: 0.9870 - val_loss: 0.5750 - val_categorical_accuracy: 0.9315\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.93994\n","Epoch 90/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1968 - categorical_accuracy: 0.9804 - val_loss: 0.5797 - val_categorical_accuracy: 0.9326\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.93994\n","Epoch 91/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.1956 - categorical_accuracy: 0.9821 - val_loss: 0.5810 - val_categorical_accuracy: 0.9357\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.93994\n","Epoch 92/100\n","110/110 [==============================] - 1s 5ms/step - loss: 0.1851 - categorical_accuracy: 0.9885 - val_loss: 0.5916 - val_categorical_accuracy: 0.9252\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.93994\n","Epoch 93/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1785 - categorical_accuracy: 0.9856 - val_loss: 0.5729 - val_categorical_accuracy: 0.9189\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.93994\n","Epoch 94/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1777 - categorical_accuracy: 0.9851 - val_loss: 0.5842 - val_categorical_accuracy: 0.9252\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.93994\n","Epoch 95/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1778 - categorical_accuracy: 0.9860 - val_loss: 0.5766 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.93994\n","Epoch 96/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1807 - categorical_accuracy: 0.9784 - val_loss: 0.6032 - val_categorical_accuracy: 0.9125\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.93994\n","Epoch 97/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1811 - categorical_accuracy: 0.9833 - val_loss: 0.5711 - val_categorical_accuracy: 0.9231\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.93994\n","Epoch 98/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1809 - categorical_accuracy: 0.9859 - val_loss: 0.5761 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.93994\n","Epoch 99/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1700 - categorical_accuracy: 0.9877 - val_loss: 0.5738 - val_categorical_accuracy: 0.9168\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.93994\n","Epoch 100/100\n","110/110 [==============================] - 0s 4ms/step - loss: 0.1737 - categorical_accuracy: 0.9843 - val_loss: 0.5846 - val_categorical_accuracy: 0.9083\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.93994\n","30/30 [==============================] - 0s 3ms/step - loss: 0.6660 - categorical_accuracy: 0.9399\n","Test accuracy on target dataset = 0.9399367570877075\n","30/30 [==============================] - 0s 1ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 80 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_21\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_380 (Conv2D)             (None, 20, 20, 64)   4160        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 20, 20, 64)   256         conv2d_380[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 20, 20, 64)   0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","lambda_161 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_163 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_165 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","lambda_167 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_382 (Conv2D)             (None, 20, 20, 8)    584         lambda_161[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_386 (Conv2D)             (None, 20, 20, 8)    584         lambda_163[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_390 (Conv2D)             (None, 20, 20, 8)    584         lambda_165[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_394 (Conv2D)             (None, 20, 20, 8)    584         lambda_167[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_160 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_383 (Conv2D)             (None, 20, 20, 8)    584         conv2d_382[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_162 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_387 (Conv2D)             (None, 20, 20, 8)    584         conv2d_386[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_164 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_391 (Conv2D)             (None, 20, 20, 8)    584         conv2d_390[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_166 (Lambda)             (None, 20, 20, 8)    0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_395 (Conv2D)             (None, 20, 20, 8)    584         conv2d_394[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_381 (Conv2D)             (None, 20, 20, 8)    584         lambda_160[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_384 (Conv2D)             (None, 20, 20, 8)    584         conv2d_383[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_385 (Conv2D)             (None, 20, 20, 8)    584         lambda_162[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_388 (Conv2D)             (None, 20, 20, 8)    584         conv2d_387[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_389 (Conv2D)             (None, 20, 20, 8)    584         lambda_164[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_392 (Conv2D)             (None, 20, 20, 8)    584         conv2d_391[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_393 (Conv2D)             (None, 20, 20, 8)    584         lambda_166[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_396 (Conv2D)             (None, 20, 20, 8)    584         conv2d_395[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 20, 20, 64)   0           conv2d_381[0][0]                 \n","                                                                 conv2d_384[0][0]                 \n","                                                                 conv2d_385[0][0]                 \n","                                                                 conv2d_388[0][0]                 \n","                                                                 conv2d_389[0][0]                 \n","                                                                 conv2d_392[0][0]                 \n","                                                                 conv2d_393[0][0]                 \n","                                                                 conv2d_396[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 20, 20, 64)   256         concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_121 (Activation)     (None, 20, 20, 64)   0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_40 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_121[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_20 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_40[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_20 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_20[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_41 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 20, 20, 64)   256         tf.reshape_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 20, 20, 64)   0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_397 (Conv2D)             (None, 20, 20, 128)  8320        activation_122[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_398 (Conv2D)             (None, 20, 20, 128)  8320        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 20, 20, 128)  512         conv2d_397[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 20, 20, 128)  512         conv2d_398[0][0]                 \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 20, 20, 128)  0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 20, 20, 128)  0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 20, 20, 128)  0           activation_123[0][0]             \n","                                                                 activation_124[0][0]             \n","__________________________________________________________________________________________________\n","activation_125 (Activation)     (None, 20, 20, 128)  0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_399 (Conv2D)             (None, 20, 20, 128)  16512       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 20, 20, 128)  512         conv2d_399[0][0]                 \n","__________________________________________________________________________________________________\n","activation_126 (Activation)     (None, 20, 20, 128)  0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","lambda_169 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_171 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_173 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","lambda_175 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_401 (Conv2D)             (None, 20, 20, 16)   2320        lambda_169[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_405 (Conv2D)             (None, 20, 20, 16)   2320        lambda_171[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_409 (Conv2D)             (None, 20, 20, 16)   2320        lambda_173[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_413 (Conv2D)             (None, 20, 20, 16)   2320        lambda_175[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_168 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_402 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_401[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_170 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_406 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_405[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_172 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_410 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_409[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_174 (Lambda)             (None, 20, 20, 16)   0           activation_126[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_414 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_413[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_400 (Conv2D)             (None, 20, 20, 16)   2320        lambda_168[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_403 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_402[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_404 (Conv2D)             (None, 20, 20, 16)   2320        lambda_170[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_407 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_406[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_408 (Conv2D)             (None, 20, 20, 16)   2320        lambda_172[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_411 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_410[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_412 (Conv2D)             (None, 20, 20, 16)   2320        lambda_174[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_415 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_414[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 20, 20, 128)  0           conv2d_400[0][0]                 \n","                                                                 conv2d_403[0][0]                 \n","                                                                 conv2d_404[0][0]                 \n","                                                                 conv2d_407[0][0]                 \n","                                                                 conv2d_408[0][0]                 \n","                                                                 conv2d_411[0][0]                 \n","                                                                 conv2d_412[0][0]                 \n","                                                                 conv2d_415[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 20, 20, 128)  512         concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_127 (Activation)     (None, 20, 20, 128)  0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_42 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_127[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_21 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_42[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_21 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_21[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_43 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 20, 20, 128)  512         tf.reshape_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_128 (Activation)     (None, 20, 20, 128)  0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_416 (Conv2D)             (None, 20, 20, 256)  33024       activation_128[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_417 (Conv2D)             (None, 20, 20, 256)  33024       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 20, 20, 256)  1024        conv2d_416[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 20, 20, 256)  1024        conv2d_417[0][0]                 \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 20, 20, 256)  0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 20, 20, 256)  0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 20, 20, 256)  0           activation_129[0][0]             \n","                                                                 activation_130[0][0]             \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 20, 20, 256)  0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_10 (Gl (None, 256)          0           activation_131[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples is 3144.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 2510.\n","Samples per class in training set: [216  80 200 172 215 215 207 162 251 198 220 106 192  76]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 634.\n","Samples per class in test set: [54 21 51 43 54 54 52 41 63 50 56 27 49 19]\n","\n","X_train_transfer => (2510, 256)\n","X_test_transfer  => (634, 256)\n","y_train => (2510, 14)\n","y_test  => (634, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_23 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","126/126 [==============================] - 1s 5ms/step - loss: 3.4533 - categorical_accuracy: 0.2566 - val_loss: 1.4577 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.69085, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","126/126 [==============================] - 0s 4ms/step - loss: 1.3498 - categorical_accuracy: 0.6386 - val_loss: 1.2662 - val_categorical_accuracy: 0.7823\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.69085 to 0.78233, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","126/126 [==============================] - 1s 4ms/step - loss: 1.0909 - categorical_accuracy: 0.7269 - val_loss: 1.2003 - val_categorical_accuracy: 0.6215\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.78233\n","Epoch 4/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.9416 - categorical_accuracy: 0.7673 - val_loss: 1.0719 - val_categorical_accuracy: 0.7603\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.78233\n","Epoch 5/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.8074 - categorical_accuracy: 0.8250 - val_loss: 1.0124 - val_categorical_accuracy: 0.7823\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.78233\n","Epoch 6/100\n","126/126 [==============================] - 1s 5ms/step - loss: 0.7203 - categorical_accuracy: 0.8583 - val_loss: 1.0063 - val_categorical_accuracy: 0.7808\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.78233\n","Epoch 7/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.6847 - categorical_accuracy: 0.8623 - val_loss: 0.9687 - val_categorical_accuracy: 0.7886\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.78233 to 0.78864, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 8/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.6372 - categorical_accuracy: 0.8658 - val_loss: 0.9497 - val_categorical_accuracy: 0.7666\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.78864\n","Epoch 9/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.5869 - categorical_accuracy: 0.8829 - val_loss: 0.8789 - val_categorical_accuracy: 0.8675\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.78864 to 0.86751, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 10/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.5289 - categorical_accuracy: 0.9103 - val_loss: 0.9199 - val_categorical_accuracy: 0.8423\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.86751\n","Epoch 11/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.5049 - categorical_accuracy: 0.9040 - val_loss: 0.9044 - val_categorical_accuracy: 0.8013\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.86751\n","Epoch 12/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.4610 - categorical_accuracy: 0.9217 - val_loss: 0.8685 - val_categorical_accuracy: 0.8470\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.86751\n","Epoch 13/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.4390 - categorical_accuracy: 0.9298 - val_loss: 0.8691 - val_categorical_accuracy: 0.8470\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.86751\n","Epoch 14/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.4262 - categorical_accuracy: 0.9276 - val_loss: 0.8514 - val_categorical_accuracy: 0.8517\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.86751\n","Epoch 15/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3919 - categorical_accuracy: 0.9436 - val_loss: 0.8390 - val_categorical_accuracy: 0.8817\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.86751 to 0.88170, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3818 - categorical_accuracy: 0.9387 - val_loss: 0.8429 - val_categorical_accuracy: 0.8849\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.88170 to 0.88486, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 17/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3499 - categorical_accuracy: 0.9502 - val_loss: 0.8340 - val_categorical_accuracy: 0.8738\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.88486\n","Epoch 18/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3452 - categorical_accuracy: 0.9452 - val_loss: 0.8398 - val_categorical_accuracy: 0.8754\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.88486\n","Epoch 19/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3334 - categorical_accuracy: 0.9545 - val_loss: 0.8506 - val_categorical_accuracy: 0.8644\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.88486\n","Epoch 20/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3009 - categorical_accuracy: 0.9605 - val_loss: 0.8197 - val_categorical_accuracy: 0.8785\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.88486\n","Epoch 21/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.3004 - categorical_accuracy: 0.9612 - val_loss: 0.8091 - val_categorical_accuracy: 0.9180\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.88486 to 0.91798, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 22/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2905 - categorical_accuracy: 0.9535 - val_loss: 0.8252 - val_categorical_accuracy: 0.8880\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.91798\n","Epoch 23/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.2844 - categorical_accuracy: 0.9513 - val_loss: 0.7982 - val_categorical_accuracy: 0.9069\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.91798\n","Epoch 24/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2717 - categorical_accuracy: 0.9589 - val_loss: 0.8842 - val_categorical_accuracy: 0.8754\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.91798\n","Epoch 25/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2730 - categorical_accuracy: 0.9535 - val_loss: 0.8371 - val_categorical_accuracy: 0.8502\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.91798\n","Epoch 26/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.2513 - categorical_accuracy: 0.9627 - val_loss: 0.8390 - val_categorical_accuracy: 0.9196\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.91798 to 0.91956, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 27/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2528 - categorical_accuracy: 0.9647 - val_loss: 0.8288 - val_categorical_accuracy: 0.9243\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.91956 to 0.92429, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 28/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.2403 - categorical_accuracy: 0.9626 - val_loss: 0.8364 - val_categorical_accuracy: 0.8596\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.92429\n","Epoch 29/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2366 - categorical_accuracy: 0.9635 - val_loss: 0.8025 - val_categorical_accuracy: 0.8880\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.92429\n","Epoch 30/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2382 - categorical_accuracy: 0.9632 - val_loss: 0.7951 - val_categorical_accuracy: 0.8975\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.92429\n","Epoch 31/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.2100 - categorical_accuracy: 0.9723 - val_loss: 0.8087 - val_categorical_accuracy: 0.9022\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.92429\n","Epoch 32/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2234 - categorical_accuracy: 0.9672 - val_loss: 0.7953 - val_categorical_accuracy: 0.9069\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.92429\n","Epoch 33/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2222 - categorical_accuracy: 0.9695 - val_loss: 0.8260 - val_categorical_accuracy: 0.8722\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.92429\n","Epoch 34/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.2028 - categorical_accuracy: 0.9721 - val_loss: 0.8307 - val_categorical_accuracy: 0.8959\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.92429\n","Epoch 35/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.2108 - categorical_accuracy: 0.9691 - val_loss: 0.7901 - val_categorical_accuracy: 0.9180\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.92429\n","Epoch 36/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1880 - categorical_accuracy: 0.9763 - val_loss: 0.7917 - val_categorical_accuracy: 0.9148\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.92429\n","Epoch 37/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1864 - categorical_accuracy: 0.9734 - val_loss: 0.8140 - val_categorical_accuracy: 0.9227\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.92429\n","Epoch 38/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1809 - categorical_accuracy: 0.9748 - val_loss: 0.8255 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.92429\n","Epoch 39/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1845 - categorical_accuracy: 0.9756 - val_loss: 0.8091 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.92429\n","Epoch 40/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1828 - categorical_accuracy: 0.9750 - val_loss: 0.8010 - val_categorical_accuracy: 0.8691\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.92429\n","Epoch 41/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1769 - categorical_accuracy: 0.9787 - val_loss: 0.7971 - val_categorical_accuracy: 0.9132\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.92429\n","Epoch 42/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1737 - categorical_accuracy: 0.9688 - val_loss: 0.8147 - val_categorical_accuracy: 0.9022\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.92429\n","Epoch 43/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1773 - categorical_accuracy: 0.9712 - val_loss: 0.8319 - val_categorical_accuracy: 0.9022\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.92429\n","Epoch 44/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1592 - categorical_accuracy: 0.9770 - val_loss: 0.8629 - val_categorical_accuracy: 0.8991\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.92429\n","Epoch 45/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1656 - categorical_accuracy: 0.9757 - val_loss: 0.7965 - val_categorical_accuracy: 0.9227\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.92429\n","Epoch 46/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1657 - categorical_accuracy: 0.9781 - val_loss: 0.8342 - val_categorical_accuracy: 0.9385\n","\n","Epoch 00046: val_categorical_accuracy improved from 0.92429 to 0.93849, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_80_samples_from_each_class_in_training_set.h5\n","Epoch 47/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1517 - categorical_accuracy: 0.9740 - val_loss: 0.8067 - val_categorical_accuracy: 0.9290\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.93849\n","Epoch 48/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1583 - categorical_accuracy: 0.9775 - val_loss: 0.8209 - val_categorical_accuracy: 0.9227\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.93849\n","Epoch 49/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1434 - categorical_accuracy: 0.9826 - val_loss: 0.8290 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.93849\n","Epoch 50/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1435 - categorical_accuracy: 0.9825 - val_loss: 0.8093 - val_categorical_accuracy: 0.9101\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.93849\n","Epoch 51/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1560 - categorical_accuracy: 0.9762 - val_loss: 0.8652 - val_categorical_accuracy: 0.9038\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.93849\n","Epoch 52/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1669 - categorical_accuracy: 0.9707 - val_loss: 0.8264 - val_categorical_accuracy: 0.9180\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.93849\n","Epoch 53/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1352 - categorical_accuracy: 0.9798 - val_loss: 0.8220 - val_categorical_accuracy: 0.9101\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.93849\n","Epoch 54/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1356 - categorical_accuracy: 0.9799 - val_loss: 0.8272 - val_categorical_accuracy: 0.9054\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.93849\n","Epoch 55/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1419 - categorical_accuracy: 0.9756 - val_loss: 0.8336 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.93849\n","Epoch 56/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1363 - categorical_accuracy: 0.9806 - val_loss: 0.8166 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.93849\n","Epoch 57/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1649 - categorical_accuracy: 0.9721 - val_loss: 0.8406 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.93849\n","Epoch 58/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1355 - categorical_accuracy: 0.9799 - val_loss: 0.8482 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.93849\n","Epoch 59/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1301 - categorical_accuracy: 0.9823 - val_loss: 0.8283 - val_categorical_accuracy: 0.9196\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.93849\n","Epoch 60/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1277 - categorical_accuracy: 0.9843 - val_loss: 0.8492 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.93849\n","Epoch 61/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1346 - categorical_accuracy: 0.9763 - val_loss: 0.8236 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.93849\n","Epoch 62/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1143 - categorical_accuracy: 0.9858 - val_loss: 0.8192 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.93849\n","Epoch 63/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1261 - categorical_accuracy: 0.9807 - val_loss: 0.8241 - val_categorical_accuracy: 0.9054\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.93849\n","Epoch 64/100\n","126/126 [==============================] - 1s 5ms/step - loss: 0.1232 - categorical_accuracy: 0.9821 - val_loss: 0.8211 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.93849\n","Epoch 65/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.1226 - categorical_accuracy: 0.9825 - val_loss: 0.8550 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.93849\n","Epoch 66/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1129 - categorical_accuracy: 0.9864 - val_loss: 0.8379 - val_categorical_accuracy: 0.8943\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.93849\n","Epoch 67/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1175 - categorical_accuracy: 0.9835 - val_loss: 0.8692 - val_categorical_accuracy: 0.9148\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.93849\n","Epoch 68/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1248 - categorical_accuracy: 0.9806 - val_loss: 0.8467 - val_categorical_accuracy: 0.8975\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.93849\n","Epoch 69/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1185 - categorical_accuracy: 0.9904 - val_loss: 0.8221 - val_categorical_accuracy: 0.9227\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.93849\n","Epoch 70/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1148 - categorical_accuracy: 0.9843 - val_loss: 0.8454 - val_categorical_accuracy: 0.9148\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.93849\n","Epoch 71/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1203 - categorical_accuracy: 0.9821 - val_loss: 0.8296 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.93849\n","Epoch 72/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1169 - categorical_accuracy: 0.9813 - val_loss: 0.8731 - val_categorical_accuracy: 0.9006\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.93849\n","Epoch 73/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1229 - categorical_accuracy: 0.9792 - val_loss: 0.8233 - val_categorical_accuracy: 0.9148\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.93849\n","Epoch 74/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1096 - categorical_accuracy: 0.9842 - val_loss: 0.8462 - val_categorical_accuracy: 0.9101\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.93849\n","Epoch 75/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1197 - categorical_accuracy: 0.9835 - val_loss: 0.8408 - val_categorical_accuracy: 0.9148\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.93849\n","Epoch 76/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0996 - categorical_accuracy: 0.9857 - val_loss: 0.8282 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.93849\n","Epoch 77/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1031 - categorical_accuracy: 0.9851 - val_loss: 0.8632 - val_categorical_accuracy: 0.8943\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.93849\n","Epoch 78/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1090 - categorical_accuracy: 0.9814 - val_loss: 0.8662 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.93849\n","Epoch 79/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1056 - categorical_accuracy: 0.9848 - val_loss: 0.8202 - val_categorical_accuracy: 0.9338\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.93849\n","Epoch 80/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1059 - categorical_accuracy: 0.9831 - val_loss: 0.8595 - val_categorical_accuracy: 0.9006\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.93849\n","Epoch 81/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1024 - categorical_accuracy: 0.9829 - val_loss: 0.8303 - val_categorical_accuracy: 0.9085\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.93849\n","Epoch 82/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0950 - categorical_accuracy: 0.9869 - val_loss: 0.8514 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.93849\n","Epoch 83/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1009 - categorical_accuracy: 0.9842 - val_loss: 0.8363 - val_categorical_accuracy: 0.9259\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.93849\n","Epoch 84/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1027 - categorical_accuracy: 0.9841 - val_loss: 0.8264 - val_categorical_accuracy: 0.9274\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.93849\n","Epoch 85/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0956 - categorical_accuracy: 0.9840 - val_loss: 0.8579 - val_categorical_accuracy: 0.9069\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.93849\n","Epoch 86/100\n","126/126 [==============================] - 1s 4ms/step - loss: 0.1005 - categorical_accuracy: 0.9831 - val_loss: 0.8975 - val_categorical_accuracy: 0.9117\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.93849\n","Epoch 87/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0974 - categorical_accuracy: 0.9837 - val_loss: 0.8338 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.93849\n","Epoch 88/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0992 - categorical_accuracy: 0.9865 - val_loss: 0.8481 - val_categorical_accuracy: 0.9085\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.93849\n","Epoch 89/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.1010 - categorical_accuracy: 0.9858 - val_loss: 0.8400 - val_categorical_accuracy: 0.9054\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.93849\n","Epoch 90/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.0897 - categorical_accuracy: 0.9874 - val_loss: 0.8515 - val_categorical_accuracy: 0.9132\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.93849\n","Epoch 91/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0948 - categorical_accuracy: 0.9851 - val_loss: 0.8478 - val_categorical_accuracy: 0.9274\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.93849\n","Epoch 92/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0856 - categorical_accuracy: 0.9896 - val_loss: 0.8361 - val_categorical_accuracy: 0.9211\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.93849\n","Epoch 93/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0965 - categorical_accuracy: 0.9852 - val_loss: 0.8873 - val_categorical_accuracy: 0.9132\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.93849\n","Epoch 94/100\n","126/126 [==============================] - 0s 3ms/step - loss: 0.0955 - categorical_accuracy: 0.9810 - val_loss: 0.8605 - val_categorical_accuracy: 0.9274\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.93849\n","Epoch 95/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0887 - categorical_accuracy: 0.9894 - val_loss: 0.8718 - val_categorical_accuracy: 0.9069\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.93849\n","Epoch 96/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0921 - categorical_accuracy: 0.9853 - val_loss: 0.8494 - val_categorical_accuracy: 0.9132\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.93849\n","Epoch 97/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0855 - categorical_accuracy: 0.9917 - val_loss: 0.8943 - val_categorical_accuracy: 0.9274\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.93849\n","Epoch 98/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0930 - categorical_accuracy: 0.9822 - val_loss: 0.8599 - val_categorical_accuracy: 0.9196\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.93849\n","Epoch 99/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0947 - categorical_accuracy: 0.9856 - val_loss: 0.8669 - val_categorical_accuracy: 0.9164\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.93849\n","Epoch 100/100\n","126/126 [==============================] - 0s 4ms/step - loss: 0.0862 - categorical_accuracy: 0.9876 - val_loss: 0.8807 - val_categorical_accuracy: 0.9101\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.93849\n","20/20 [==============================] - 0s 3ms/step - loss: 0.8342 - categorical_accuracy: 0.9385\n","Test accuracy on target dataset = 0.9384858012199402\n","20/20 [==============================] - 0s 1ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with overlap ratio 1.0 and 90 percent samples from each class in training set \n","==============================================================================================================\n","\n","Model: \"model_23\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_12 (InputLayer)           [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d_418 (Conv2D)             (None, 20, 20, 64)   4160        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 20, 20, 64)   256         conv2d_418[0][0]                 \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 20, 20, 64)   0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","lambda_177 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_179 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_181 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","lambda_183 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_420 (Conv2D)             (None, 20, 20, 8)    584         lambda_177[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_424 (Conv2D)             (None, 20, 20, 8)    584         lambda_179[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_428 (Conv2D)             (None, 20, 20, 8)    584         lambda_181[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_432 (Conv2D)             (None, 20, 20, 8)    584         lambda_183[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_176 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_421 (Conv2D)             (None, 20, 20, 8)    584         conv2d_420[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_178 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_425 (Conv2D)             (None, 20, 20, 8)    584         conv2d_424[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_180 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_429 (Conv2D)             (None, 20, 20, 8)    584         conv2d_428[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_182 (Lambda)             (None, 20, 20, 8)    0           activation_132[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_433 (Conv2D)             (None, 20, 20, 8)    584         conv2d_432[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_419 (Conv2D)             (None, 20, 20, 8)    584         lambda_176[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_422 (Conv2D)             (None, 20, 20, 8)    584         conv2d_421[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_423 (Conv2D)             (None, 20, 20, 8)    584         lambda_178[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_426 (Conv2D)             (None, 20, 20, 8)    584         conv2d_425[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_427 (Conv2D)             (None, 20, 20, 8)    584         lambda_180[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_430 (Conv2D)             (None, 20, 20, 8)    584         conv2d_429[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_431 (Conv2D)             (None, 20, 20, 8)    584         lambda_182[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_434 (Conv2D)             (None, 20, 20, 8)    584         conv2d_433[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 20, 20, 64)   0           conv2d_419[0][0]                 \n","                                                                 conv2d_422[0][0]                 \n","                                                                 conv2d_423[0][0]                 \n","                                                                 conv2d_426[0][0]                 \n","                                                                 conv2d_427[0][0]                 \n","                                                                 conv2d_430[0][0]                 \n","                                                                 conv2d_431[0][0]                 \n","                                                                 conv2d_434[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 20, 20, 64)   256         concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 20, 20, 64)   0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_44 (TFOpLambda)      (None, 20, 20, 8, 8) 0           activation_133[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_22 (TFOp (None, 20, 20, 8, 8) 0           tf.reshape_44[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_22 (TFOpLambda)      (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose_22[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_45 (TFOpLambda)      (None, 20, 20, 64)   0           tf.reverse_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 20, 20, 64)   256         tf.reshape_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 20, 20, 64)   0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_435 (Conv2D)             (None, 20, 20, 128)  8320        activation_134[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_436 (Conv2D)             (None, 20, 20, 128)  8320        input_12[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 20, 20, 128)  512         conv2d_435[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 20, 20, 128)  512         conv2d_436[0][0]                 \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 20, 20, 128)  0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 20, 20, 128)  0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 20, 20, 128)  0           activation_135[0][0]             \n","                                                                 activation_136[0][0]             \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 20, 20, 128)  0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_437 (Conv2D)             (None, 20, 20, 128)  16512       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 20, 20, 128)  512         conv2d_437[0][0]                 \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 20, 20, 128)  0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","lambda_185 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_187 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_189 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","lambda_191 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_439 (Conv2D)             (None, 20, 20, 16)   2320        lambda_185[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_443 (Conv2D)             (None, 20, 20, 16)   2320        lambda_187[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_447 (Conv2D)             (None, 20, 20, 16)   2320        lambda_189[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_451 (Conv2D)             (None, 20, 20, 16)   2320        lambda_191[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_184 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_440 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_439[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_186 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_444 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_443[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_188 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_448 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_447[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_190 (Lambda)             (None, 20, 20, 16)   0           activation_138[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_452 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_451[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_438 (Conv2D)             (None, 20, 20, 16)   2320        lambda_184[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_441 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_440[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_442 (Conv2D)             (None, 20, 20, 16)   2320        lambda_186[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_445 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_444[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_446 (Conv2D)             (None, 20, 20, 16)   2320        lambda_188[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_449 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_448[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_450 (Conv2D)             (None, 20, 20, 16)   2320        lambda_190[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_453 (Conv2D)             (None, 20, 20, 16)   2320        conv2d_452[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 20, 20, 128)  0           conv2d_438[0][0]                 \n","                                                                 conv2d_441[0][0]                 \n","                                                                 conv2d_442[0][0]                 \n","                                                                 conv2d_445[0][0]                 \n","                                                                 conv2d_446[0][0]                 \n","                                                                 conv2d_449[0][0]                 \n","                                                                 conv2d_450[0][0]                 \n","                                                                 conv2d_453[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 20, 20, 128)  512         concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 20, 20, 128)  0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","tf.reshape_46 (TFOpLambda)      (None, 20, 20, 8, 16 0           activation_139[0][0]             \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_23 (TFOp (None, 20, 20, 16, 8 0           tf.reshape_46[0][0]              \n","__________________________________________________________________________________________________\n","tf.reverse_23 (TFOpLambda)      (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_23[0][0]  \n","__________________________________________________________________________________________________\n","tf.reshape_47 (TFOpLambda)      (None, 20, 20, 128)  0           tf.reverse_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 20, 20, 128)  512         tf.reshape_47[0][0]              \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 20, 20, 128)  0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_454 (Conv2D)             (None, 20, 20, 256)  33024       activation_140[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_455 (Conv2D)             (None, 20, 20, 256)  33024       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 20, 20, 256)  1024        conv2d_454[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 20, 20, 256)  1024        conv2d_455[0][0]                 \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 20, 20, 256)  0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 20, 20, 256)  0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 20, 20, 256)  0           activation_141[0][0]             \n","                                                                 activation_142[0][0]             \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 20, 20, 256)  0           add_23[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_11 (Gl (None, 256)          0           activation_143[0][0]             \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples is 3144.\n","\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in training set is 2823.\n","Samples per class in training set: [243  90 225 193 242 242 233 182 282 223 248 119 216  85]\n","\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Total number of samples in test set is 321.\n","Samples per class in test set: [27 11 26 22 27 27 26 21 32 25 28 14 25 10]\n","\n","X_train_transfer => (2823, 256)\n","X_test_transfer  => (321, 256)\n","y_train => (2823, 14)\n","y_test  => (321, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_24 (InputLayer)        [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","142/142 [==============================] - 1s 4ms/step - loss: 2.8201 - categorical_accuracy: 0.2464 - val_loss: 1.4633 - val_categorical_accuracy: 0.5047\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.50467, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","142/142 [==============================] - 1s 4ms/step - loss: 1.2929 - categorical_accuracy: 0.6115 - val_loss: 1.2343 - val_categorical_accuracy: 0.6916\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.50467 to 0.69159, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","142/142 [==============================] - 1s 4ms/step - loss: 1.0855 - categorical_accuracy: 0.6987 - val_loss: 1.1487 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.69159\n","Epoch 4/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.9802 - categorical_accuracy: 0.7245 - val_loss: 0.9826 - val_categorical_accuracy: 0.8193\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.69159 to 0.81931, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.8709 - categorical_accuracy: 0.7806 - val_loss: 0.9286 - val_categorical_accuracy: 0.8785\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.81931 to 0.87850, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.8357 - categorical_accuracy: 0.7864 - val_loss: 0.8792 - val_categorical_accuracy: 0.7352\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.87850\n","Epoch 7/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.7845 - categorical_accuracy: 0.7901 - val_loss: 0.8576 - val_categorical_accuracy: 0.8255\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.87850\n","Epoch 8/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.7327 - categorical_accuracy: 0.8120 - val_loss: 0.7869 - val_categorical_accuracy: 0.7975\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.87850\n","Epoch 9/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.6995 - categorical_accuracy: 0.8193 - val_loss: 0.7513 - val_categorical_accuracy: 0.8318\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.87850\n","Epoch 10/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.6411 - categorical_accuracy: 0.8495 - val_loss: 0.7093 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.87850 to 0.92835, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 11/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.5994 - categorical_accuracy: 0.8774 - val_loss: 0.6669 - val_categorical_accuracy: 0.8910\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.92835\n","Epoch 12/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.5858 - categorical_accuracy: 0.8631 - val_loss: 0.6663 - val_categorical_accuracy: 0.8660\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.92835\n","Epoch 13/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.5497 - categorical_accuracy: 0.8837 - val_loss: 0.6192 - val_categorical_accuracy: 0.8816\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.92835\n","Epoch 14/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.5261 - categorical_accuracy: 0.8857 - val_loss: 0.6372 - val_categorical_accuracy: 0.9221\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.92835\n","Epoch 15/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.5016 - categorical_accuracy: 0.8892 - val_loss: 0.5517 - val_categorical_accuracy: 0.9065\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.92835\n","Epoch 16/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.4835 - categorical_accuracy: 0.9131 - val_loss: 0.5763 - val_categorical_accuracy: 0.9003\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.92835\n","Epoch 17/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.4627 - categorical_accuracy: 0.9108 - val_loss: 0.5480 - val_categorical_accuracy: 0.9408\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.92835 to 0.94081, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.4472 - categorical_accuracy: 0.9045 - val_loss: 0.5150 - val_categorical_accuracy: 0.8785\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.94081\n","Epoch 19/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.4319 - categorical_accuracy: 0.9179 - val_loss: 0.4829 - val_categorical_accuracy: 0.9533\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.94081 to 0.95327, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 20/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.4246 - categorical_accuracy: 0.9186 - val_loss: 0.4720 - val_categorical_accuracy: 0.9346\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.95327\n","Epoch 21/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.4006 - categorical_accuracy: 0.9213 - val_loss: 0.4745 - val_categorical_accuracy: 0.9252\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.95327\n","Epoch 22/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3706 - categorical_accuracy: 0.9348 - val_loss: 0.4883 - val_categorical_accuracy: 0.9315\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.95327\n","Epoch 23/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.3699 - categorical_accuracy: 0.9318 - val_loss: 0.4535 - val_categorical_accuracy: 0.9377\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.95327\n","Epoch 24/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3586 - categorical_accuracy: 0.9403 - val_loss: 0.4185 - val_categorical_accuracy: 0.9159\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.95327\n","Epoch 25/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3616 - categorical_accuracy: 0.9347 - val_loss: 0.4370 - val_categorical_accuracy: 0.9377\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.95327\n","Epoch 26/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3285 - categorical_accuracy: 0.9353 - val_loss: 0.3947 - val_categorical_accuracy: 0.9346\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.95327\n","Epoch 27/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3504 - categorical_accuracy: 0.9248 - val_loss: 0.4154 - val_categorical_accuracy: 0.9128\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.95327\n","Epoch 28/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.3348 - categorical_accuracy: 0.9390 - val_loss: 0.4360 - val_categorical_accuracy: 0.9533\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.95327\n","Epoch 29/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.3200 - categorical_accuracy: 0.9427 - val_loss: 0.3968 - val_categorical_accuracy: 0.9377\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.95327\n","Epoch 30/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3133 - categorical_accuracy: 0.9471 - val_loss: 0.3835 - val_categorical_accuracy: 0.9346\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.95327\n","Epoch 31/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.3175 - categorical_accuracy: 0.9391 - val_loss: 0.3809 - val_categorical_accuracy: 0.9439\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.95327\n","Epoch 32/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2998 - categorical_accuracy: 0.9515 - val_loss: 0.3647 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.95327\n","Epoch 33/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2978 - categorical_accuracy: 0.9413 - val_loss: 0.3790 - val_categorical_accuracy: 0.9159\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.95327\n","Epoch 34/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2756 - categorical_accuracy: 0.9551 - val_loss: 0.3411 - val_categorical_accuracy: 0.9502\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.95327\n","Epoch 35/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2721 - categorical_accuracy: 0.9559 - val_loss: 0.3290 - val_categorical_accuracy: 0.9564\n","\n","Epoch 00035: val_categorical_accuracy improved from 0.95327 to 0.95639, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 36/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2621 - categorical_accuracy: 0.9524 - val_loss: 0.3209 - val_categorical_accuracy: 0.9564\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.95639\n","Epoch 37/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2584 - categorical_accuracy: 0.9559 - val_loss: 0.3297 - val_categorical_accuracy: 0.9346\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.95639\n","Epoch 38/100\n","142/142 [==============================] - 1s 3ms/step - loss: 0.2481 - categorical_accuracy: 0.9652 - val_loss: 0.3123 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.95639\n","Epoch 39/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2588 - categorical_accuracy: 0.9557 - val_loss: 0.3179 - val_categorical_accuracy: 0.9502\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.95639\n","Epoch 40/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2559 - categorical_accuracy: 0.9559 - val_loss: 0.2970 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00040: val_categorical_accuracy improved from 0.95639 to 0.96573, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 41/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2438 - categorical_accuracy: 0.9507 - val_loss: 0.2954 - val_categorical_accuracy: 0.9595\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.96573\n","Epoch 42/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2179 - categorical_accuracy: 0.9617 - val_loss: 0.3040 - val_categorical_accuracy: 0.9470\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.96573\n","Epoch 43/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2271 - categorical_accuracy: 0.9690 - val_loss: 0.2881 - val_categorical_accuracy: 0.9439\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.96573\n","Epoch 44/100\n","142/142 [==============================] - 0s 4ms/step - loss: 0.2362 - categorical_accuracy: 0.9570 - val_loss: 0.2927 - val_categorical_accuracy: 0.9315\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.96573\n","Epoch 45/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2236 - categorical_accuracy: 0.9581 - val_loss: 0.3115 - val_categorical_accuracy: 0.9470\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.96573\n","Epoch 46/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2183 - categorical_accuracy: 0.9678 - val_loss: 0.2701 - val_categorical_accuracy: 0.9439\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.96573\n","Epoch 47/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2134 - categorical_accuracy: 0.9678 - val_loss: 0.2851 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00047: val_categorical_accuracy improved from 0.96573 to 0.96885, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 48/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.2145 - categorical_accuracy: 0.9643 - val_loss: 0.2791 - val_categorical_accuracy: 0.9408\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.96885\n","Epoch 49/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2077 - categorical_accuracy: 0.9682 - val_loss: 0.2643 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.96885\n","Epoch 50/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1954 - categorical_accuracy: 0.9684 - val_loss: 0.2791 - val_categorical_accuracy: 0.9283\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.96885\n","Epoch 51/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1964 - categorical_accuracy: 0.9704 - val_loss: 0.2900 - val_categorical_accuracy: 0.9159\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.96885\n","Epoch 52/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1954 - categorical_accuracy: 0.9743 - val_loss: 0.3317 - val_categorical_accuracy: 0.8879\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.96885\n","Epoch 53/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.2069 - categorical_accuracy: 0.9576 - val_loss: 0.2682 - val_categorical_accuracy: 0.9346\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.96885\n","Epoch 54/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1922 - categorical_accuracy: 0.9703 - val_loss: 0.2547 - val_categorical_accuracy: 0.9595\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.96885\n","Epoch 55/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1873 - categorical_accuracy: 0.9737 - val_loss: 0.2489 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.96885\n","Epoch 56/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1887 - categorical_accuracy: 0.9728 - val_loss: 0.2739 - val_categorical_accuracy: 0.9190\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.96885\n","Epoch 57/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1826 - categorical_accuracy: 0.9768 - val_loss: 0.2342 - val_categorical_accuracy: 0.9751\n","\n","Epoch 00057: val_categorical_accuracy improved from 0.96885 to 0.97508, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 58/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1930 - categorical_accuracy: 0.9640 - val_loss: 0.2431 - val_categorical_accuracy: 0.9377\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.97508\n","Epoch 59/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1864 - categorical_accuracy: 0.9694 - val_loss: 0.2628 - val_categorical_accuracy: 0.9533\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.97508\n","Epoch 60/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1694 - categorical_accuracy: 0.9727 - val_loss: 0.2228 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.97508\n","Epoch 61/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1940 - categorical_accuracy: 0.9611 - val_loss: 0.2251 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.97508\n","Epoch 62/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1767 - categorical_accuracy: 0.9696 - val_loss: 0.2279 - val_categorical_accuracy: 0.9502\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.97508\n","Epoch 63/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1717 - categorical_accuracy: 0.9735 - val_loss: 0.2469 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.97508\n","Epoch 64/100\n","142/142 [==============================] - 1s 3ms/step - loss: 0.1625 - categorical_accuracy: 0.9774 - val_loss: 0.2330 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.97508\n","Epoch 65/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1542 - categorical_accuracy: 0.9821 - val_loss: 0.2109 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.97508\n","Epoch 66/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1773 - categorical_accuracy: 0.9705 - val_loss: 0.2468 - val_categorical_accuracy: 0.9502\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.97508\n","Epoch 67/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1483 - categorical_accuracy: 0.9817 - val_loss: 0.2056 - val_categorical_accuracy: 0.9782\n","\n","Epoch 00067: val_categorical_accuracy improved from 0.97508 to 0.97819, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 68/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1526 - categorical_accuracy: 0.9744 - val_loss: 0.2151 - val_categorical_accuracy: 0.9875\n","\n","Epoch 00068: val_categorical_accuracy improved from 0.97819 to 0.98754, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_overlap_ratio_1.0_and_90_samples_from_each_class_in_training_set.h5\n","Epoch 69/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1506 - categorical_accuracy: 0.9750 - val_loss: 0.2253 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.98754\n","Epoch 70/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1491 - categorical_accuracy: 0.9804 - val_loss: 0.2079 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.98754\n","Epoch 71/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1511 - categorical_accuracy: 0.9775 - val_loss: 0.2317 - val_categorical_accuracy: 0.9470\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.98754\n","Epoch 72/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1604 - categorical_accuracy: 0.9709 - val_loss: 0.2116 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.98754\n","Epoch 73/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1463 - categorical_accuracy: 0.9769 - val_loss: 0.2095 - val_categorical_accuracy: 0.9782\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.98754\n","Epoch 74/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1534 - categorical_accuracy: 0.9802 - val_loss: 0.2072 - val_categorical_accuracy: 0.9720\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.98754\n","Epoch 75/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1476 - categorical_accuracy: 0.9729 - val_loss: 0.2053 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.98754\n","Epoch 76/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1426 - categorical_accuracy: 0.9764 - val_loss: 0.2205 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.98754\n","Epoch 77/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1418 - categorical_accuracy: 0.9765 - val_loss: 0.2075 - val_categorical_accuracy: 0.9813\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.98754\n","Epoch 78/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1470 - categorical_accuracy: 0.9760 - val_loss: 0.2001 - val_categorical_accuracy: 0.9595\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.98754\n","Epoch 79/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1544 - categorical_accuracy: 0.9716 - val_loss: 0.2159 - val_categorical_accuracy: 0.9564\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.98754\n","Epoch 80/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1449 - categorical_accuracy: 0.9766 - val_loss: 0.1956 - val_categorical_accuracy: 0.9533\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.98754\n","Epoch 81/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1380 - categorical_accuracy: 0.9806 - val_loss: 0.1895 - val_categorical_accuracy: 0.9751\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.98754\n","Epoch 82/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1282 - categorical_accuracy: 0.9820 - val_loss: 0.1891 - val_categorical_accuracy: 0.9844\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.98754\n","Epoch 83/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1369 - categorical_accuracy: 0.9755 - val_loss: 0.1772 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.98754\n","Epoch 84/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1350 - categorical_accuracy: 0.9789 - val_loss: 0.1761 - val_categorical_accuracy: 0.9751\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.98754\n","Epoch 85/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1319 - categorical_accuracy: 0.9792 - val_loss: 0.2029 - val_categorical_accuracy: 0.9751\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.98754\n","Epoch 86/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1330 - categorical_accuracy: 0.9770 - val_loss: 0.1722 - val_categorical_accuracy: 0.9720\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.98754\n","Epoch 87/100\n","142/142 [==============================] - 0s 4ms/step - loss: 0.1206 - categorical_accuracy: 0.9864 - val_loss: 0.1811 - val_categorical_accuracy: 0.9751\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.98754\n","Epoch 88/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1276 - categorical_accuracy: 0.9822 - val_loss: 0.1835 - val_categorical_accuracy: 0.9720\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.98754\n","Epoch 89/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1307 - categorical_accuracy: 0.9747 - val_loss: 0.1995 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.98754\n","Epoch 90/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1244 - categorical_accuracy: 0.9831 - val_loss: 0.1681 - val_categorical_accuracy: 0.9782\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.98754\n","Epoch 91/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1212 - categorical_accuracy: 0.9803 - val_loss: 0.1811 - val_categorical_accuracy: 0.9657\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.98754\n","Epoch 92/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1259 - categorical_accuracy: 0.9799 - val_loss: 0.1857 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.98754\n","Epoch 93/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1170 - categorical_accuracy: 0.9833 - val_loss: 0.1763 - val_categorical_accuracy: 0.9720\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.98754\n","Epoch 94/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1186 - categorical_accuracy: 0.9816 - val_loss: 0.2133 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.98754\n","Epoch 95/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1291 - categorical_accuracy: 0.9818 - val_loss: 0.1658 - val_categorical_accuracy: 0.9626\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.98754\n","Epoch 96/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1252 - categorical_accuracy: 0.9771 - val_loss: 0.2000 - val_categorical_accuracy: 0.9782\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.98754\n","Epoch 97/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1236 - categorical_accuracy: 0.9811 - val_loss: 0.1704 - val_categorical_accuracy: 0.9875\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.98754\n","Epoch 98/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1149 - categorical_accuracy: 0.9805 - val_loss: 0.1653 - val_categorical_accuracy: 0.9813\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.98754\n","Epoch 99/100\n","142/142 [==============================] - 1s 4ms/step - loss: 0.1167 - categorical_accuracy: 0.9844 - val_loss: 0.1754 - val_categorical_accuracy: 0.9813\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.98754\n","Epoch 100/100\n","142/142 [==============================] - 0s 3ms/step - loss: 0.1099 - categorical_accuracy: 0.9863 - val_loss: 0.1621 - val_categorical_accuracy: 0.9688\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.98754\n","11/11 [==============================] - 0s 3ms/step - loss: 0.2151 - categorical_accuracy: 0.9875\n","Test accuracy on target dataset = 0.9875389337539673\n","11/11 [==============================] - 0s 3ms/step\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"id":"R_WJcBsGjtRA","executionInfo":{"status":"ok","timestamp":1608672883442,"user_tz":480,"elapsed":1084,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"f0583ec1-a8cb-4a48-df27-52d593e4811a"},"source":["transfer_results"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Overlap_ratio</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Training_Test_Split</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.8</td>\n","      <td>251</td>\n","      <td>175</td>\n","      <td>60</td>\n","      <td>74.86</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.8</td>\n","      <td>293</td>\n","      <td>133</td>\n","      <td>70</td>\n","      <td>87.22</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.8</td>\n","      <td>337</td>\n","      <td>89</td>\n","      <td>80</td>\n","      <td>92.13</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8</td>\n","      <td>378</td>\n","      <td>48</td>\n","      <td>90</td>\n","      <td>95.83</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.9</td>\n","      <td>914</td>\n","      <td>615</td>\n","      <td>60</td>\n","      <td>86.18</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9</td>\n","      <td>1065</td>\n","      <td>464</td>\n","      <td>70</td>\n","      <td>88.36</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.9</td>\n","      <td>1219</td>\n","      <td>310</td>\n","      <td>80</td>\n","      <td>95.16</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.9</td>\n","      <td>1371</td>\n","      <td>158</td>\n","      <td>90</td>\n","      <td>95.57</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>1880</td>\n","      <td>1264</td>\n","      <td>60</td>\n","      <td>87.50</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.0</td>\n","      <td>2195</td>\n","      <td>949</td>\n","      <td>70</td>\n","      <td>93.99</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.0</td>\n","      <td>2510</td>\n","      <td>634</td>\n","      <td>80</td>\n","      <td>93.85</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.0</td>\n","      <td>2823</td>\n","      <td>321</td>\n","      <td>90</td>\n","      <td>98.75</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Overlap_ratio  Training Samples  ...  Training_Test_Split  Test_Accuracies\n","0             0.8               251  ...                   60            74.86\n","1             0.8               293  ...                   70            87.22\n","2             0.8               337  ...                   80            92.13\n","3             0.8               378  ...                   90            95.83\n","4             0.9               914  ...                   60            86.18\n","5             0.9              1065  ...                   70            88.36\n","6             0.9              1219  ...                   80            95.16\n","7             0.9              1371  ...                   90            95.57\n","8             1.0              1880  ...                   60            87.50\n","9             1.0              2195  ...                   70            93.99\n","10            1.0              2510  ...                   80            93.85\n","11            1.0              2823  ...                   90            98.75\n","\n","[12 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhikZcccng2K","executionInfo":{"status":"ok","timestamp":1608672909850,"user_tz":480,"elapsed":1043,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"ca5cf115-26f0-44b7-cdef-f3a477279dd5"},"source":["for cm in confusion_matrixes:\n","  print(cm)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["                1  2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              13  0   0   0   0  ...   0   0   0   0                     92.86\n","1               0  5   0   0   1  ...   0   0   0   0                     83.33\n","2               0  0   7   0   0  ...   0   0   0   0                      50.0\n","3               0  0   0  11   0  ...   0   0   0   0                     91.67\n","4               3  0   0   2  17  ...   0   0   0   0                     70.83\n","5               0  0   0   0   0  ...   0   0   0   0                       0.0\n","6               3  0   0   0   0  ...   0   0   0   0                     76.92\n","7               0  0   0   0   0  ...   0   1   0   0                      90.0\n","8               0  0   0   0   0  ...   0   0   0   0                     100.0\n","9               0  0   0   0   0  ...   0   0   0   0                     100.0\n","10              0  0   0   0   0  ...  10   0   0   0                     76.92\n","11              0  0   0   0   0  ...   0   8   0   0                     100.0\n","12              0  0   0   0   0  ...   0   3   9   0                      75.0\n","13              0  0   0   0   3  ...   0   0   0   5                      62.5\n","Total Samples  14  6  14  12  24  ...  13   8  12   8                         -\n","\n","[15 rows x 15 columns]\n","                1  2   3  4   5  ...  11  12  13  14  classfication_accuracies\n","0              11  0   0  0   0  ...   0   0   0   0                     100.0\n","1               0  4   0  0   1  ...   0   0   0   0                      80.0\n","2               0  0   8  0   0  ...   0   0   0   0                      80.0\n","3               0  0   0  7   0  ...   0   0   0   0                     77.78\n","4               3  0   0  0  15  ...   0   0   0   0                     83.33\n","5               0  0   0  0   0  ...   0   0   0   0                     100.0\n","6               0  0   0  0   0  ...   0   0   0   0                     100.0\n","7               0  0   0  0   0  ...   0   0   0   0                     100.0\n","8               0  0   0  0   0  ...   0   0   0   0                     83.33\n","9               0  0   0  0   0  ...   0   0   0   0                     100.0\n","10              0  0   0  0   0  ...   9   0   0   0                      90.0\n","11              0  0   0  0   0  ...   0   6   0   0                     100.0\n","12              0  0   0  0   0  ...   0   3   6   0                     66.67\n","13              0  0   0  0   3  ...   0   0   0   3                      50.0\n","Total Samples  11  5  10  9  18  ...  10   6   9   6                         -\n","\n","[15 rows x 15 columns]\n","               1  2  3  4   5  6  ...  10  11  12  13  14  classfication_accuracies\n","0              7  0  0  0   0  0  ...   0   0   0   0   0                     100.0\n","1              0  3  0  0   0  0  ...   0   0   0   0   0                     100.0\n","2              0  0  7  0   0  0  ...   0   0   0   0   0                     100.0\n","3              0  0  0  4   0  0  ...   0   0   0   0   0                     66.67\n","4              0  0  0  0  10  1  ...   0   0   0   0   0                     83.33\n","5              0  0  0  0   0  7  ...   0   0   0   0   0                     100.0\n","6              0  0  0  0   0  0  ...   0   0   0   0   0                     100.0\n","7              0  0  0  0   0  0  ...   0   0   0   0   0                     100.0\n","8              0  0  0  0   0  0  ...   0   0   0   0   0                     100.0\n","9              0  0  0  0   0  0  ...   6   0   0   0   0                     100.0\n","10             0  0  0  0   0  0  ...   0   7   0   0   0                     100.0\n","11             0  0  0  0   0  0  ...   0   0   4   0   0                     100.0\n","12             0  0  0  0   0  0  ...   0   0   0   6   0                     100.0\n","13             0  0  0  0   3  0  ...   0   0   0   0   1                      25.0\n","Total Samples  7  3  7  6  12  7  ...   6   7   4   6   4                         -\n","\n","[15 rows x 15 columns]\n","               1  2  3  4  5  6  ...  10  11  12  13  14  classfication_accuracies\n","0              4  0  0  0  0  0  ...   0   0   0   0   0                     100.0\n","1              0  2  0  0  0  0  ...   0   0   0   0   0                     100.0\n","2              0  0  4  0  0  0  ...   0   0   0   0   0                     100.0\n","3              0  0  0  3  0  0  ...   0   0   0   0   0                     100.0\n","4              0  0  0  0  6  0  ...   0   0   0   0   0                     100.0\n","5              0  0  0  0  0  4  ...   0   0   0   0   0                     100.0\n","6              0  0  0  0  0  0  ...   0   0   0   0   0                     100.0\n","7              0  0  0  0  0  0  ...   0   0   0   0   0                     100.0\n","8              0  0  0  0  0  0  ...   0   0   0   0   0                     100.0\n","9              0  0  0  0  0  0  ...   3   0   0   0   0                     100.0\n","10             0  0  0  0  0  0  ...   0   4   0   0   0                     100.0\n","11             0  0  0  0  0  0  ...   0   0   2   0   0                     100.0\n","12             0  0  0  0  0  0  ...   0   0   0   3   0                     100.0\n","13             0  0  0  0  2  0  ...   0   0   0   0   0                       0.0\n","Total Samples  4  2  4  3  6  4  ...   3   4   2   3   2                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              55   0   0   0   0  ...   0   0   0   0                     100.0\n","1               0  21   0   0   0  ...   0   0   0   0                     100.0\n","2               0   0  49   0   0  ...   0   0   0   0                      98.0\n","3               0   0   0  35   2  ...   0   0   0   0                     79.55\n","4               6   0   0   3  34  ...   0   0   0   0                     64.15\n","5               0   0   0   0   1  ...   0   0   0   0                     61.54\n","6               0   0   0   0   0  ...   0   0   0   0                     100.0\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   0   0   3   0  ...   0   0   0   0                     75.86\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   0   0   0  ...  52   0   0   0                     98.11\n","11              0   0   0   0   0  ...   0  28   0   0                     100.0\n","12              0   0   0   0   0  ...   0   5  31   0                     70.45\n","13              0   0   0   0   5  ...   0   0   0  12                      60.0\n","Total Samples  55  21  50  44  53  ...  53  28  44  20                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              41   0   0   0   0  ...   0   0   0   0                     100.0\n","1               0  15   0   0   0  ...   0   0   0   0                     93.75\n","2               0   0  38   0   0  ...   0   0   0   0                     100.0\n","3               0   0   0  33   0  ...   0   0   0   0                     100.0\n","4               8   0   0   0  29  ...   0   0   0   0                      72.5\n","5               0   0   0   0   0  ...   0   0   0   0                     100.0\n","6               1   0   0   0   0  ...   0   0   0   0                     97.37\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   4   0   0   0  ...   0   0   0   0                     61.36\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   1   0   0  ...  37   0   0   0                      92.5\n","11              0   0   0   0   0  ...   0  21   0   0                     100.0\n","12              0   0   0   0   0  ...   0  13  20   0                     60.61\n","13              0   2   0   0   6  ...   0   0   0   7                     46.67\n","Total Samples  41  16  38  33  40  ...  40  21  33  15                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              28   0   0   0   0  ...   0   0   0   0                     100.0\n","1               0  11   0   0   0  ...   0   0   0   0                     100.0\n","2               0   0  25   0   0  ...   0   0   0   0                     100.0\n","3               0   0   0  22   0  ...   0   0   0   0                     100.0\n","4               0   0   0   0  27  ...   0   0   0   0                     100.0\n","5               0   0   0   0   0  ...   0   0   0   0                     100.0\n","6               0   0   0   0   0  ...   0   0   0   0                     100.0\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   0   0   0   0  ...   0   0   0   0                     100.0\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   0   0   0  ...  27   0   0   0                     100.0\n","11              0   0   0   0   0  ...   0  14   0   0                     100.0\n","12              0   0   0   0   0  ...   0   7  15   0                     68.18\n","13              0   0   0   0   8  ...   0   0   0   2                      20.0\n","Total Samples  28  11  25  22  27  ...  27  14  22  10                         -\n","\n","[15 rows x 15 columns]\n","                1  2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              14  0   0   0   0  ...   0   0   0   0                     100.0\n","1               0  6   0   0   0  ...   0   0   0   0                     100.0\n","2               0  0  13   0   0  ...   0   0   0   0                     100.0\n","3               0  0   0  11   0  ...   0   0   0   0                     100.0\n","4               0  0   0   0  14  ...   0   0   0   0                     100.0\n","5               0  0   0   0   0  ...   0   0   0   0                     100.0\n","6               1  0   0   0   0  ...   0   0   0   0                     92.31\n","7               0  0   0   0   0  ...   0   0   0   0                     100.0\n","8               0  0   0   0   0  ...   0   0   0   0                     100.0\n","9               0  0   0   0   0  ...   0   0   0   0                     100.0\n","10              0  0   0   0   0  ...  14   0   0   0                     100.0\n","11              0  0   0   0   0  ...   0   7   0   0                     100.0\n","12              0  0   0   0   0  ...   0   0  10   0                     90.91\n","13              0  0   0   0   5  ...   0   0   0   0                       0.0\n","Total Samples  14  6  13  11  14  ...  14   7  11   5                         -\n","\n","[15 rows x 15 columns]\n","                 1   2    3   4    5  ...   11  12  13  14  classfication_accuracies\n","0              104   0    0   0    4  ...    0   0   0   0                      96.3\n","1                0  41    0   0    0  ...    0   0   0   0                     100.0\n","2                0   0  101   0    0  ...    0   0   0   0                     100.0\n","3                0   0    1  67    0  ...    0   0   2   0                     77.91\n","4               13   0    0   6   75  ...    0   0   0   0                     69.44\n","5                0   0    0   4    0  ...    0   0   1   0                     57.41\n","6               13   0    0   0    0  ...    0   0   0   0                      87.5\n","7                0   0    0   0    0  ...    0   0   0   0                     100.0\n","8                0   1    0   0    0  ...    0   0   0   0                     99.21\n","9                0   0    0   0    0  ...    0   0   0   0                     100.0\n","10               0   0    0   0    0  ...  110   0   0   0                      99.1\n","11               0   0    0   0    0  ...    0  54   0   0                     100.0\n","12               0   0    0   0    0  ...    0  25  72   0                     74.23\n","13               0   0    0   0    6  ...    0   0   0  22                     57.89\n","Total Samples  108  41  101  86  108  ...  111  54  97  38                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              78   0   1   0   2  ...   0   0   0   0                      96.3\n","1               0  31   0   0   0  ...   0   0   0   0                     100.0\n","2               0   0  76   0   0  ...   0   0   0   0                     100.0\n","3               0   0   0  65   0  ...   0   0   0   0                     100.0\n","4              14   0   0   0  60  ...   0   0   0   0                     74.07\n","5               0   0   0   0   0  ...   0   0   0   0                     100.0\n","6               0   0   0   0   0  ...   0   0   0   0                     100.0\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   0   0   0   0  ...   0   0   0   0                     100.0\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   1   0   0  ...  78   0   0   0                     93.98\n","11              0   0   0   0   0  ...   0  40   0   0                     100.0\n","12              0   0   0   0   0  ...   0  12  61   0                     83.56\n","13              0   0   0   0  16  ...   0   0   0  13                     44.83\n","Total Samples  81  31  76  65  81  ...  83  40  73  29                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              51   0   0   0   3  ...   0   0   0   0                     94.44\n","1               0  21   0   0   0  ...   0   0   0   0                     100.0\n","2               0   0  50   0   0  ...   0   0   0   0                     98.04\n","3               0   0   2  37   0  ...   0   0   0   0                     86.05\n","4               0   0   0   0  50  ...   0   0   0   0                     92.59\n","5               0   0   0   0   0  ...   0   0   0   0                     100.0\n","6               0   0   0   0   0  ...   0   0   0   0                     100.0\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   2   0   0   0  ...   0   0   0   0                     96.83\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   0   0   0  ...  56   0   0   0                     100.0\n","11              0   0   0   0   0  ...   0  27   0   0                     100.0\n","12              0   0   0   0   0  ...   0   7  42   0                     85.71\n","13              0   0   0   0  16  ...   0   0   0   3                     15.79\n","Total Samples  54  21  51  43  54  ...  56  27  49  19                         -\n","\n","[15 rows x 15 columns]\n","                1   2   3   4   5  ...  11  12  13  14  classfication_accuracies\n","0              26   0   0   0   1  ...   0   0   0   0                      96.3\n","1               0  11   0   0   0  ...   0   0   0   0                     100.0\n","2               0   0  26   0   0  ...   0   0   0   0                     100.0\n","3               0   0   0  22   0  ...   0   0   0   0                     100.0\n","4               0   0   0   0  27  ...   0   0   0   0                     100.0\n","5               0   0   0   0   0  ...   0   0   0   0                     100.0\n","6               0   0   0   0   0  ...   0   0   0   0                     100.0\n","7               0   0   0   0   0  ...   0   0   0   0                     100.0\n","8               0   0   0   0   0  ...   0   0   0   0                     100.0\n","9               0   0   0   0   0  ...   0   0   0   0                     100.0\n","10              0   0   0   0   0  ...  28   0   0   0                     100.0\n","11              0   0   0   0   0  ...   0  14   0   0                     100.0\n","12              0   0   0   0   0  ...   0   0  25   0                     100.0\n","13              0   1   0   0   2  ...   0   0   0   7                      70.0\n","Total Samples  27  11  26  22  27  ...  28  14  25  10                         -\n","\n","[15 rows x 15 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_BFKA0crn0Gp"},"source":[""],"execution_count":null,"outputs":[]}]}