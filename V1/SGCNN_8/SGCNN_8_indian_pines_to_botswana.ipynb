{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SGCNN_8_indian_pines_to_botswana.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_nG8NlV-lz-"},"source":["## Set up google colab environment"]},{"cell_type":"code","metadata":{"id":"9bq_kqWQtg0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615786114337,"user_tz":420,"elapsed":22533,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"06c589c4-0c34-458c-9e0a-fac555f238d1"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK95udG-qHAy","executionInfo":{"status":"ok","timestamp":1615786143292,"user_tz":420,"elapsed":356,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification/V1/SGCNN_8')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn-wRAH4t3WY","executionInfo":{"status":"ok","timestamp":1615786146915,"user_tz":420,"elapsed":2879,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["from sample_extraction_V1_SGCNN_8 import *\n","import scipy.io as sio"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky2Qzuw_qDdS"},"source":["## Load Indian Pines Dataset - Source"]},{"cell_type":"code","metadata":{"id":"svwF-yzh-l0N","executionInfo":{"status":"ok","timestamp":1615786153078,"user_tz":420,"elapsed":2183,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uIndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_corrected.mat')\n","gt_IndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_gt.mat')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLGpYj4P-l0N","executionInfo":{"status":"ok","timestamp":1615786154309,"user_tz":420,"elapsed":414,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_source = uIndianPines['indian_pines_corrected']\n","ground_truth_source = gt_IndianPines['indian_pines_gt']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHQe_Xhwza79","executionInfo":{"status":"ok","timestamp":1615786156028,"user_tz":420,"elapsed":371,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"e69534dd-0528-469d-9b48-5dc2c549c3dd"},"source":["data_source.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145, 200)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAjjOxj3qDdb","executionInfo":{"status":"ok","timestamp":1615786156900,"user_tz":420,"elapsed":335,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"5ea0c51b-a9e2-40ac-e354-37d11d3433cb"},"source":["ground_truth_source.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"wmLGB_VlWx6m"},"source":["# Load target dataset"]},{"cell_type":"code","metadata":{"id":"qu6T10joWpmQ","executionInfo":{"status":"ok","timestamp":1615786160630,"user_tz":420,"elapsed":2503,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uBotswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana.mat')\n","gt_Botswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana_gt.mat')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"09gPGGX8W2Us","executionInfo":{"status":"ok","timestamp":1615786161636,"user_tz":420,"elapsed":365,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_target = uBotswana['Botswana']\n","ground_truth_target = gt_Botswana['Botswana_gt']"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qG_LxbHeXBVQ","executionInfo":{"status":"ok","timestamp":1615786163858,"user_tz":420,"elapsed":540,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"a28a369a-64cd-4ac2-d2ad-81560847efe1"},"source":["data_target.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256, 145)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYillUc_XDKC","executionInfo":{"status":"ok","timestamp":1615786164424,"user_tz":420,"elapsed":245,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"4b381b10-cdb4-45d5-a6ad-21330e7ecfb8"},"source":["ground_truth_target.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"5WxjgWNGqDdc"},"source":["## Distrubution of samples for each class in Source"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"yFA7eqA7qDdd","executionInfo":{"status":"ok","timestamp":1615786167120,"user_tz":420,"elapsed":350,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"aa975880-5106-4cf0-e0e1-ed5d70fce98f"},"source":["class_distribution_source = pd.DataFrame(np.unique(ground_truth_source, return_counts = True))\n","class_distribution_source = class_distribution_source.transpose()\n","class_distribution_source.columns = ['class','samples']\n","class_distribution_source"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>830</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>483</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>730</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>478</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>972</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2455</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>1265</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>386</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0    10776\n","1       1       46\n","2       2     1428\n","3       3      830\n","4       4      237\n","5       5      483\n","6       6      730\n","7       7       28\n","8       8      478\n","9       9       20\n","10     10      972\n","11     11     2455\n","12     12      593\n","13     13      205\n","14     14     1265\n","15     15      386\n","16     16       93"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"7zTsq-yPqDdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615786170888,"user_tz":420,"elapsed":392,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"f934934d-f1de-45d0-df26-d678cbcb2b41"},"source":["classes_source , counts_source = np.unique(ground_truth_source, return_counts = True)\n","classes_source = classes_source[[2,3,5,6,8,10,11,12,14]] ## Dropping classes with small number of samples\n","classes_source"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2,  3,  5,  6,  8, 10, 11, 12, 14], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"lwQmdin9Xmeg"},"source":["# Class distribution of samples in Target"]},{"cell_type":"code","metadata":{"id":"8EjIMOQHXU3h","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"ok","timestamp":1615786181083,"user_tz":420,"elapsed":417,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"00ba0b27-ce6e-43c9-d433-0f1e9759e7c4"},"source":["class_distribution_target = pd.DataFrame(np.unique(ground_truth_target, return_counts = True))\n","class_distribution_target = class_distribution_target.transpose()\n","class_distribution_target.columns = ['class','samples']\n","class_distribution_target"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>374608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>270</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>215</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>259</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>203</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>314</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>248</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>305</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>268</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0   374608\n","1       1      270\n","2       2      101\n","3       3      251\n","4       4      215\n","5       5      269\n","6       6      269\n","7       7      259\n","8       8      203\n","9       9      314\n","10     10      248\n","11     11      305\n","12     12      181\n","13     13      268\n","14     14       95"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"CgE2FPXbXtt9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615786184253,"user_tz":420,"elapsed":381,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"ae16821c-5b84-4bfb-a148-1f4f7781d432"},"source":["classes_target , counts_target = np.unique(ground_truth_target, return_counts = True)\n","classes_target = classes_target[1:] ## Dropping classes with small number of samples\n","classes_target"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n","      dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"l_PESscnqDde"},"source":["## Source : Indian Pines\n","\n","## Train model for samples extracted with different overlap ratios and a percent of  samples picked from each class to be present in the training set. \n","\n","## Model except the final fully connected layer is saved for transfer learning."]},{"cell_type":"code","metadata":{"id":"7vc1sJwRqDdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615786245532,"user_tz":420,"elapsed":55152,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"4a64f630-074d-4bb3-d3b7-0660a8dca375"},"source":["pretrain_source_models(training_set_size = [200],\n","                      classes = classes_source,\n","                      cube_size = 20,\n","                      overlap_ratio = 1,\n","                      data = data_source,\n","                      ground_truth = ground_truth_source,\n","                      batch_size = 20,\n","                      channels = 64,\n","                      epochs = 50,\n","                      Verbosity = 1,\n","                      accuracies = [],\n","                      learning_rate = 0.0001,\n","                      source_dataset = 'indian_pines')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["\n","=============================================================================================================\n","Model training starts for data with 200 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 1800.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [200 200 200 200 200 200 200 200 200]\n","\n","Total number of samples in test set 6106.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1168  323  123  530  156  637 2024  260  885]\n","\n","X_train => (1800, 20, 20, 64)\n","X_test  => (6106, 20, 20, 64)\n","y_train => (1800, 9)\n","y_test  => (6106, 9)\n","\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          33024       global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 104,201\n","Trainable params: 103,305\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","90/90 [==============================] - 17s 8ms/step - loss: 4.6240 - categorical_accuracy: 0.1624\n","\n","Epoch 00001: categorical_accuracy improved from -inf to 0.18667, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 2/50\n","90/90 [==============================] - 1s 8ms/step - loss: 4.3151 - categorical_accuracy: 0.3098\n","\n","Epoch 00002: categorical_accuracy improved from 0.18667 to 0.36389, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 3/50\n","90/90 [==============================] - 1s 9ms/step - loss: 4.1629 - categorical_accuracy: 0.5287\n","\n","Epoch 00003: categorical_accuracy improved from 0.36389 to 0.55389, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 4/50\n","90/90 [==============================] - 1s 8ms/step - loss: 4.0515 - categorical_accuracy: 0.6185\n","\n","Epoch 00004: categorical_accuracy improved from 0.55389 to 0.64778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 5/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.9361 - categorical_accuracy: 0.6853\n","\n","Epoch 00005: categorical_accuracy improved from 0.64778 to 0.71333, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 6/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.8129 - categorical_accuracy: 0.7580\n","\n","Epoch 00006: categorical_accuracy improved from 0.71333 to 0.74167, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 7/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.7401 - categorical_accuracy: 0.7719\n","\n","Epoch 00007: categorical_accuracy improved from 0.74167 to 0.76722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 8/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.6263 - categorical_accuracy: 0.8185\n","\n","Epoch 00008: categorical_accuracy improved from 0.76722 to 0.80500, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 9/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5591 - categorical_accuracy: 0.8059\n","\n","Epoch 00009: categorical_accuracy did not improve from 0.80500\n","Epoch 10/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5092 - categorical_accuracy: 0.8148\n","\n","Epoch 00010: categorical_accuracy improved from 0.80500 to 0.81722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 11/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.4411 - categorical_accuracy: 0.8230\n","\n","Epoch 00011: categorical_accuracy improved from 0.81722 to 0.81889, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 12/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.3636 - categorical_accuracy: 0.8463\n","\n","Epoch 00012: categorical_accuracy improved from 0.81889 to 0.83778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 13/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.3277 - categorical_accuracy: 0.8238\n","\n","Epoch 00013: categorical_accuracy improved from 0.83778 to 0.84000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 14/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.2621 - categorical_accuracy: 0.8459\n","\n","Epoch 00014: categorical_accuracy improved from 0.84000 to 0.85278, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 15/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.2295 - categorical_accuracy: 0.8649\n","\n","Epoch 00015: categorical_accuracy improved from 0.85278 to 0.87056, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 16/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.1466 - categorical_accuracy: 0.8654\n","\n","Epoch 00016: categorical_accuracy did not improve from 0.87056\n","Epoch 17/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.1169 - categorical_accuracy: 0.8765\n","\n","Epoch 00017: categorical_accuracy improved from 0.87056 to 0.87611, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 18/50\n","90/90 [==============================] - 1s 9ms/step - loss: 3.0548 - categorical_accuracy: 0.8795\n","\n","Epoch 00018: categorical_accuracy improved from 0.87611 to 0.87667, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 19/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.9905 - categorical_accuracy: 0.8846\n","\n","Epoch 00019: categorical_accuracy improved from 0.87667 to 0.88167, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 20/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.9635 - categorical_accuracy: 0.8903\n","\n","Epoch 00020: categorical_accuracy improved from 0.88167 to 0.89333, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 21/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.9156 - categorical_accuracy: 0.8976\n","\n","Epoch 00021: categorical_accuracy improved from 0.89333 to 0.89611, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 22/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.8821 - categorical_accuracy: 0.8924\n","\n","Epoch 00022: categorical_accuracy did not improve from 0.89611\n","Epoch 23/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.8386 - categorical_accuracy: 0.9125\n","\n","Epoch 00023: categorical_accuracy improved from 0.89611 to 0.90556, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 24/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.8085 - categorical_accuracy: 0.9115\n","\n","Epoch 00024: categorical_accuracy improved from 0.90556 to 0.91278, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 25/50\n","90/90 [==============================] - 1s 9ms/step - loss: 2.7661 - categorical_accuracy: 0.9128\n","\n","Epoch 00025: categorical_accuracy did not improve from 0.91278\n","Epoch 26/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.7359 - categorical_accuracy: 0.9189\n","\n","Epoch 00026: categorical_accuracy improved from 0.91278 to 0.92278, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 27/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.7118 - categorical_accuracy: 0.9166\n","\n","Epoch 00027: categorical_accuracy improved from 0.92278 to 0.92556, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 28/50\n","90/90 [==============================] - 1s 9ms/step - loss: 2.6621 - categorical_accuracy: 0.9281\n","\n","Epoch 00028: categorical_accuracy did not improve from 0.92556\n","Epoch 29/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.6430 - categorical_accuracy: 0.9323\n","\n","Epoch 00029: categorical_accuracy improved from 0.92556 to 0.93222, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 30/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.6082 - categorical_accuracy: 0.9357\n","\n","Epoch 00030: categorical_accuracy did not improve from 0.93222\n","Epoch 31/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.5964 - categorical_accuracy: 0.9231\n","\n","Epoch 00031: categorical_accuracy did not improve from 0.93222\n","Epoch 32/50\n","90/90 [==============================] - 1s 8ms/step - loss: 2.5727 - categorical_accuracy: 0.9301\n","\n","Epoch 00032: categorical_accuracy did not improve from 0.93222\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RkxgCjIejh0l"},"source":["# Fine tune on botswana"]},{"cell_type":"code","metadata":{"id":"SJ1kSkHtCuHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615786798734,"user_tz":420,"elapsed":256746,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"2e1ffc70-eed3-4a8c-9036-85e30fe76172"},"source":["transfer_results, confusion_matrixes = transfer_learning(source_dataset = 'indian_pines',\n","                                        target_dataset = 'botswana',\n","                                        data = data_target,\n","                                        ground_truth = ground_truth_target,\n","                                        training_samples_from_each_class = [15,30,45,60,75],\n","                                        source_training_size = [200],\n","                                        classes = classes_target,\n","                                        overlap_ratio = 1,\n","                                        channels = 64,\n","                                        cube_size = 20,\n","                                        learning_rate = 0.0001,\n","                                        epochs = 150,\n","                                        batch_size = 20,\n","                                        test_accuracies = [],\n","                                        )"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\n","================================================================================================================================\n","Model training starts for data with 15 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 210.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [15 15 15 15 15 15 15 15 15 15 15 15 15 15]\n","\n","Total number of samples in test set 2934.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [255  86 236 200 254 254 244 188 299 233 261 118 226  80]\n","\n","X_train_transfer => (210, 128)\n","X_test_transfer  => (2934, 128)\n","y_train => (210, 14)\n","y_test  => (2934, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","11/11 [==============================] - 1s 57ms/step - loss: 3.8985 - categorical_accuracy: 0.0862 - val_loss: 3.0781 - val_categorical_accuracy: 0.0791\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.07907, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.9501 - categorical_accuracy: 0.0633 - val_loss: 2.7106 - val_categorical_accuracy: 0.0699\n","\n","Epoch 00002: val_categorical_accuracy did not improve from 0.07907\n","Epoch 3/150\n","11/11 [==============================] - 0s 26ms/step - loss: 2.6926 - categorical_accuracy: 0.0121 - val_loss: 2.5964 - val_categorical_accuracy: 0.0361\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.07907\n","Epoch 4/150\n","11/11 [==============================] - 0s 28ms/step - loss: 2.5741 - categorical_accuracy: 0.0424 - val_loss: 2.5284 - val_categorical_accuracy: 0.1162\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.07907 to 0.11622, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","11/11 [==============================] - 0s 26ms/step - loss: 2.5168 - categorical_accuracy: 0.1631 - val_loss: 2.4699 - val_categorical_accuracy: 0.1670\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.11622 to 0.16701, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","11/11 [==============================] - 0s 26ms/step - loss: 2.4554 - categorical_accuracy: 0.2529 - val_loss: 2.4230 - val_categorical_accuracy: 0.2134\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.16701 to 0.21336, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","11/11 [==============================] - 0s 30ms/step - loss: 2.3585 - categorical_accuracy: 0.2702 - val_loss: 2.3881 - val_categorical_accuracy: 0.2485\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.21336 to 0.24847, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.3768 - categorical_accuracy: 0.2697 - val_loss: 2.3573 - val_categorical_accuracy: 0.2205\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.24847\n","Epoch 9/150\n","11/11 [==============================] - 0s 28ms/step - loss: 2.2982 - categorical_accuracy: 0.2811 - val_loss: 2.3294 - val_categorical_accuracy: 0.2372\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.24847\n","Epoch 10/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.2266 - categorical_accuracy: 0.3326 - val_loss: 2.3009 - val_categorical_accuracy: 0.2832\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.24847 to 0.28323, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.2189 - categorical_accuracy: 0.3395 - val_loss: 2.2810 - val_categorical_accuracy: 0.2744\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.28323\n","Epoch 12/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.1575 - categorical_accuracy: 0.3554 - val_loss: 2.2575 - val_categorical_accuracy: 0.2887\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.28323 to 0.28868, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.1810 - categorical_accuracy: 0.3358 - val_loss: 2.2382 - val_categorical_accuracy: 0.3153\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.28868 to 0.31527, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","11/11 [==============================] - 0s 30ms/step - loss: 2.1213 - categorical_accuracy: 0.3920 - val_loss: 2.2076 - val_categorical_accuracy: 0.3701\n","\n","Epoch 00014: val_categorical_accuracy improved from 0.31527 to 0.37014, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 15/150\n","11/11 [==============================] - 0s 28ms/step - loss: 2.0765 - categorical_accuracy: 0.4145 - val_loss: 2.1859 - val_categorical_accuracy: 0.3647\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.37014\n","Epoch 16/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.0167 - categorical_accuracy: 0.4347 - val_loss: 2.1682 - val_categorical_accuracy: 0.3701\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.37014\n","Epoch 17/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.0497 - categorical_accuracy: 0.4519 - val_loss: 2.1531 - val_categorical_accuracy: 0.3712\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.37014 to 0.37117, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 18/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.0271 - categorical_accuracy: 0.4252 - val_loss: 2.1338 - val_categorical_accuracy: 0.3732\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.37117 to 0.37321, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 19/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.0299 - categorical_accuracy: 0.4886 - val_loss: 2.1138 - val_categorical_accuracy: 0.3913\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.37321 to 0.39127, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 20/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.9831 - categorical_accuracy: 0.5098 - val_loss: 2.0969 - val_categorical_accuracy: 0.3838\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.39127\n","Epoch 21/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.9450 - categorical_accuracy: 0.3878 - val_loss: 2.0815 - val_categorical_accuracy: 0.4001\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.39127 to 0.40014, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.9497 - categorical_accuracy: 0.4760 - val_loss: 2.0663 - val_categorical_accuracy: 0.3681\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.40014\n","Epoch 23/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.8465 - categorical_accuracy: 0.5501 - val_loss: 2.0509 - val_categorical_accuracy: 0.4012\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.40014 to 0.40116, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 24/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.8786 - categorical_accuracy: 0.4977 - val_loss: 2.0430 - val_categorical_accuracy: 0.3732\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.40116\n","Epoch 25/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.9457 - categorical_accuracy: 0.4058 - val_loss: 2.0307 - val_categorical_accuracy: 0.3967\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.40116\n","Epoch 26/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.8516 - categorical_accuracy: 0.5670 - val_loss: 2.0121 - val_categorical_accuracy: 0.4431\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.40116 to 0.44308, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 27/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.8120 - categorical_accuracy: 0.6595 - val_loss: 2.0010 - val_categorical_accuracy: 0.4533\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.44308 to 0.45331, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.7918 - categorical_accuracy: 0.6588 - val_loss: 1.9956 - val_categorical_accuracy: 0.4158\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.45331\n","Epoch 29/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.8084 - categorical_accuracy: 0.5213 - val_loss: 1.9917 - val_categorical_accuracy: 0.3937\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.45331\n","Epoch 30/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.7789 - categorical_accuracy: 0.5183 - val_loss: 1.9710 - val_categorical_accuracy: 0.4438\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.45331\n","Epoch 31/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.8174 - categorical_accuracy: 0.6018 - val_loss: 1.9525 - val_categorical_accuracy: 0.4867\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.45331 to 0.48671, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 32/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.7457 - categorical_accuracy: 0.6691 - val_loss: 1.9440 - val_categorical_accuracy: 0.4922\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.48671 to 0.49216, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 33/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.7909 - categorical_accuracy: 0.6644 - val_loss: 1.9489 - val_categorical_accuracy: 0.4298\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.49216\n","Epoch 34/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.7665 - categorical_accuracy: 0.5224 - val_loss: 1.9366 - val_categorical_accuracy: 0.4601\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.49216\n","Epoch 35/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.7491 - categorical_accuracy: 0.6196 - val_loss: 1.9219 - val_categorical_accuracy: 0.4441\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.49216\n","Epoch 36/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.6519 - categorical_accuracy: 0.6927 - val_loss: 1.9145 - val_categorical_accuracy: 0.4680\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.49216\n","Epoch 37/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.7255 - categorical_accuracy: 0.6745 - val_loss: 1.9093 - val_categorical_accuracy: 0.4530\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.49216\n","Epoch 38/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.6652 - categorical_accuracy: 0.6606 - val_loss: 1.8976 - val_categorical_accuracy: 0.4898\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.49216\n","Epoch 39/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.6455 - categorical_accuracy: 0.6885 - val_loss: 1.8802 - val_categorical_accuracy: 0.5095\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.49216 to 0.50954, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 40/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.6910 - categorical_accuracy: 0.6435 - val_loss: 1.8778 - val_categorical_accuracy: 0.4853\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.50954\n","Epoch 41/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.6890 - categorical_accuracy: 0.5931 - val_loss: 1.8762 - val_categorical_accuracy: 0.4455\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.50954\n","Epoch 42/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.6603 - categorical_accuracy: 0.6049 - val_loss: 1.8674 - val_categorical_accuracy: 0.5153\n","\n","Epoch 00042: val_categorical_accuracy improved from 0.50954 to 0.51534, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 43/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.6216 - categorical_accuracy: 0.7018 - val_loss: 1.8525 - val_categorical_accuracy: 0.5402\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.51534 to 0.54022, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.5853 - categorical_accuracy: 0.7146 - val_loss: 1.8530 - val_categorical_accuracy: 0.4918\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.54022\n","Epoch 45/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.6079 - categorical_accuracy: 0.6712 - val_loss: 1.8433 - val_categorical_accuracy: 0.5078\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.54022\n","Epoch 46/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5837 - categorical_accuracy: 0.7457 - val_loss: 1.8359 - val_categorical_accuracy: 0.5184\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.54022\n","Epoch 47/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5578 - categorical_accuracy: 0.7510 - val_loss: 1.8306 - val_categorical_accuracy: 0.4714\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.54022\n","Epoch 48/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5214 - categorical_accuracy: 0.7874 - val_loss: 1.8185 - val_categorical_accuracy: 0.5262\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.54022\n","Epoch 49/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.5657 - categorical_accuracy: 0.8543 - val_loss: 1.8096 - val_categorical_accuracy: 0.5266\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.54022\n","Epoch 50/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.5827 - categorical_accuracy: 0.8062 - val_loss: 1.8080 - val_categorical_accuracy: 0.4608\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.54022\n","Epoch 51/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5755 - categorical_accuracy: 0.6479 - val_loss: 1.8046 - val_categorical_accuracy: 0.4796\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.54022\n","Epoch 52/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5842 - categorical_accuracy: 0.6616 - val_loss: 1.8000 - val_categorical_accuracy: 0.5020\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.54022\n","Epoch 53/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5886 - categorical_accuracy: 0.7626 - val_loss: 1.7854 - val_categorical_accuracy: 0.5487\n","\n","Epoch 00053: val_categorical_accuracy improved from 0.54022 to 0.54874, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 54/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.5766 - categorical_accuracy: 0.7800 - val_loss: 1.7807 - val_categorical_accuracy: 0.5181\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.54874\n","Epoch 55/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.5361 - categorical_accuracy: 0.7573 - val_loss: 1.7784 - val_categorical_accuracy: 0.5055\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.54874\n","Epoch 56/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.5674 - categorical_accuracy: 0.7944 - val_loss: 1.7709 - val_categorical_accuracy: 0.5750\n","\n","Epoch 00056: val_categorical_accuracy improved from 0.54874 to 0.57498, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 57/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5703 - categorical_accuracy: 0.7995 - val_loss: 1.7658 - val_categorical_accuracy: 0.5617\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.57498\n","Epoch 58/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.4798 - categorical_accuracy: 0.8280 - val_loss: 1.7589 - val_categorical_accuracy: 0.5453\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.57498\n","Epoch 59/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4566 - categorical_accuracy: 0.8089 - val_loss: 1.7478 - val_categorical_accuracy: 0.5624\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.57498\n","Epoch 60/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.4938 - categorical_accuracy: 0.7814 - val_loss: 1.7413 - val_categorical_accuracy: 0.5651\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.57498\n","Epoch 61/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.4423 - categorical_accuracy: 0.7837 - val_loss: 1.7442 - val_categorical_accuracy: 0.5177\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.57498\n","Epoch 62/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.4862 - categorical_accuracy: 0.7766 - val_loss: 1.7358 - val_categorical_accuracy: 0.5262\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.57498\n","Epoch 63/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5159 - categorical_accuracy: 0.8190 - val_loss: 1.7306 - val_categorical_accuracy: 0.5668\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.57498\n","Epoch 64/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4987 - categorical_accuracy: 0.8493 - val_loss: 1.7274 - val_categorical_accuracy: 0.5907\n","\n","Epoch 00064: val_categorical_accuracy improved from 0.57498 to 0.59066, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 65/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.4641 - categorical_accuracy: 0.8126 - val_loss: 1.7270 - val_categorical_accuracy: 0.5368\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.59066\n","Epoch 66/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.5199 - categorical_accuracy: 0.7087 - val_loss: 1.7198 - val_categorical_accuracy: 0.5378\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.59066\n","Epoch 67/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4073 - categorical_accuracy: 0.7796 - val_loss: 1.7160 - val_categorical_accuracy: 0.5354\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.59066\n","Epoch 68/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4579 - categorical_accuracy: 0.7745 - val_loss: 1.6988 - val_categorical_accuracy: 0.5590\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.59066\n","Epoch 69/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.4475 - categorical_accuracy: 0.8888 - val_loss: 1.6890 - val_categorical_accuracy: 0.6033\n","\n","Epoch 00069: val_categorical_accuracy improved from 0.59066 to 0.60327, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 70/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4141 - categorical_accuracy: 0.8519 - val_loss: 1.6910 - val_categorical_accuracy: 0.5985\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.60327\n","Epoch 71/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3644 - categorical_accuracy: 0.8496 - val_loss: 1.6928 - val_categorical_accuracy: 0.5603\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.60327\n","Epoch 72/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3745 - categorical_accuracy: 0.8684 - val_loss: 1.6836 - val_categorical_accuracy: 0.5658\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.60327\n","Epoch 73/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.4056 - categorical_accuracy: 0.7888 - val_loss: 1.6885 - val_categorical_accuracy: 0.4928\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.60327\n","Epoch 74/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.4599 - categorical_accuracy: 0.7447 - val_loss: 1.6766 - val_categorical_accuracy: 0.5781\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.60327\n","Epoch 75/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.4396 - categorical_accuracy: 0.8271 - val_loss: 1.6750 - val_categorical_accuracy: 0.5675\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.60327\n","Epoch 76/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3843 - categorical_accuracy: 0.8492 - val_loss: 1.6757 - val_categorical_accuracy: 0.5348\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.60327\n","Epoch 77/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3882 - categorical_accuracy: 0.8591 - val_loss: 1.6632 - val_categorical_accuracy: 0.5804\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.60327\n","Epoch 78/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3816 - categorical_accuracy: 0.8575 - val_loss: 1.6522 - val_categorical_accuracy: 0.6217\n","\n","Epoch 00078: val_categorical_accuracy improved from 0.60327 to 0.62168, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 79/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.4445 - categorical_accuracy: 0.8422 - val_loss: 1.6515 - val_categorical_accuracy: 0.5746\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.62168\n","Epoch 80/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3607 - categorical_accuracy: 0.8428 - val_loss: 1.6533 - val_categorical_accuracy: 0.5784\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.62168\n","Epoch 81/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4053 - categorical_accuracy: 0.8551 - val_loss: 1.6472 - val_categorical_accuracy: 0.5873\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.62168\n","Epoch 82/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3908 - categorical_accuracy: 0.8578 - val_loss: 1.6403 - val_categorical_accuracy: 0.6247\n","\n","Epoch 00082: val_categorical_accuracy improved from 0.62168 to 0.62474, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 83/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.3823 - categorical_accuracy: 0.8909 - val_loss: 1.6399 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.62474\n","Epoch 84/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.3403 - categorical_accuracy: 0.8690 - val_loss: 1.6427 - val_categorical_accuracy: 0.5702\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.62474\n","Epoch 85/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3284 - categorical_accuracy: 0.8156 - val_loss: 1.6312 - val_categorical_accuracy: 0.5988\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.62474\n","Epoch 86/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3172 - categorical_accuracy: 0.8568 - val_loss: 1.6260 - val_categorical_accuracy: 0.5978\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.62474\n","Epoch 87/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3300 - categorical_accuracy: 0.8653 - val_loss: 1.6321 - val_categorical_accuracy: 0.5733\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.62474\n","Epoch 88/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3565 - categorical_accuracy: 0.7821 - val_loss: 1.6280 - val_categorical_accuracy: 0.5930\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.62474\n","Epoch 89/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2910 - categorical_accuracy: 0.8816 - val_loss: 1.6269 - val_categorical_accuracy: 0.5828\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.62474\n","Epoch 90/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3271 - categorical_accuracy: 0.8703 - val_loss: 1.6215 - val_categorical_accuracy: 0.5798\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.62474\n","Epoch 91/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3562 - categorical_accuracy: 0.8336 - val_loss: 1.6179 - val_categorical_accuracy: 0.5477\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.62474\n","Epoch 92/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3171 - categorical_accuracy: 0.7770 - val_loss: 1.6177 - val_categorical_accuracy: 0.5508\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.62474\n","Epoch 93/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2704 - categorical_accuracy: 0.7981 - val_loss: 1.6044 - val_categorical_accuracy: 0.5855\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.62474\n","Epoch 94/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2321 - categorical_accuracy: 0.8875 - val_loss: 1.6001 - val_categorical_accuracy: 0.6043\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.62474\n","Epoch 95/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3326 - categorical_accuracy: 0.8631 - val_loss: 1.6004 - val_categorical_accuracy: 0.5753\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.62474\n","Epoch 96/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2511 - categorical_accuracy: 0.8613 - val_loss: 1.5933 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.62474\n","Epoch 97/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2635 - categorical_accuracy: 0.9052 - val_loss: 1.5883 - val_categorical_accuracy: 0.6172\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.62474\n","Epoch 98/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2636 - categorical_accuracy: 0.8999 - val_loss: 1.5864 - val_categorical_accuracy: 0.6084\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.62474\n","Epoch 99/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2281 - categorical_accuracy: 0.8800 - val_loss: 1.5825 - val_categorical_accuracy: 0.6125\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.62474\n","Epoch 100/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.2047 - categorical_accuracy: 0.8863 - val_loss: 1.5828 - val_categorical_accuracy: 0.5961\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.62474\n","Epoch 101/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2793 - categorical_accuracy: 0.8627 - val_loss: 1.5772 - val_categorical_accuracy: 0.6469\n","\n","Epoch 00101: val_categorical_accuracy improved from 0.62474 to 0.64690, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 102/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2376 - categorical_accuracy: 0.9227 - val_loss: 1.5784 - val_categorical_accuracy: 0.6097\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.64690\n","Epoch 103/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2415 - categorical_accuracy: 0.8925 - val_loss: 1.5675 - val_categorical_accuracy: 0.6264\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.64690\n","Epoch 104/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2003 - categorical_accuracy: 0.9138 - val_loss: 1.5731 - val_categorical_accuracy: 0.6135\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.64690\n","Epoch 105/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2286 - categorical_accuracy: 0.8987 - val_loss: 1.5666 - val_categorical_accuracy: 0.6101\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.64690\n","Epoch 106/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1323 - categorical_accuracy: 0.8858 - val_loss: 1.5732 - val_categorical_accuracy: 0.5866\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.64690\n","Epoch 107/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.2269 - categorical_accuracy: 0.8226 - val_loss: 1.5656 - val_categorical_accuracy: 0.6213\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.64690\n","Epoch 108/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.2209 - categorical_accuracy: 0.9111 - val_loss: 1.5602 - val_categorical_accuracy: 0.6203\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.64690\n","Epoch 109/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.1654 - categorical_accuracy: 0.8740 - val_loss: 1.5545 - val_categorical_accuracy: 0.6040\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.64690\n","Epoch 110/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2440 - categorical_accuracy: 0.9012 - val_loss: 1.5515 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.64690\n","Epoch 111/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2282 - categorical_accuracy: 0.9135 - val_loss: 1.5534 - val_categorical_accuracy: 0.6135\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.64690\n","Epoch 112/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2507 - categorical_accuracy: 0.8680 - val_loss: 1.5500 - val_categorical_accuracy: 0.6111\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.64690\n","Epoch 113/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2133 - categorical_accuracy: 0.9241 - val_loss: 1.5446 - val_categorical_accuracy: 0.6503\n","\n","Epoch 00113: val_categorical_accuracy improved from 0.64690 to 0.65031, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 114/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1398 - categorical_accuracy: 0.9390 - val_loss: 1.5461 - val_categorical_accuracy: 0.6097\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.65031\n","Epoch 115/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1531 - categorical_accuracy: 0.8961 - val_loss: 1.5473 - val_categorical_accuracy: 0.6033\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.65031\n","Epoch 116/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.2176 - categorical_accuracy: 0.8902 - val_loss: 1.5403 - val_categorical_accuracy: 0.6138\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.65031\n","Epoch 117/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1178 - categorical_accuracy: 0.9035 - val_loss: 1.5354 - val_categorical_accuracy: 0.6115\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.65031\n","Epoch 118/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1765 - categorical_accuracy: 0.9043 - val_loss: 1.5368 - val_categorical_accuracy: 0.6057\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.65031\n","Epoch 119/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1951 - categorical_accuracy: 0.8897 - val_loss: 1.5422 - val_categorical_accuracy: 0.6005\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.65031\n","Epoch 120/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0668 - categorical_accuracy: 0.8900 - val_loss: 1.5303 - val_categorical_accuracy: 0.6421\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.65031\n","Epoch 121/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1419 - categorical_accuracy: 0.9524 - val_loss: 1.5254 - val_categorical_accuracy: 0.6544\n","\n","Epoch 00121: val_categorical_accuracy improved from 0.65031 to 0.65440, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 122/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1725 - categorical_accuracy: 0.9679 - val_loss: 1.5265 - val_categorical_accuracy: 0.6558\n","\n","Epoch 00122: val_categorical_accuracy improved from 0.65440 to 0.65576, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 123/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.1424 - categorical_accuracy: 0.9615 - val_loss: 1.5265 - val_categorical_accuracy: 0.6578\n","\n","Epoch 00123: val_categorical_accuracy improved from 0.65576 to 0.65781, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 124/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.1158 - categorical_accuracy: 0.9495 - val_loss: 1.5184 - val_categorical_accuracy: 0.6220\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.65781\n","Epoch 125/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1007 - categorical_accuracy: 0.8817 - val_loss: 1.5211 - val_categorical_accuracy: 0.5988\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.65781\n","Epoch 126/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1121 - categorical_accuracy: 0.8966 - val_loss: 1.5142 - val_categorical_accuracy: 0.6166\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.65781\n","Epoch 127/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0534 - categorical_accuracy: 0.9195 - val_loss: 1.5109 - val_categorical_accuracy: 0.6408\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.65781\n","Epoch 128/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.1453 - categorical_accuracy: 0.9183 - val_loss: 1.5122 - val_categorical_accuracy: 0.6172\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.65781\n","Epoch 129/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1527 - categorical_accuracy: 0.8935 - val_loss: 1.5116 - val_categorical_accuracy: 0.6578\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.65781\n","Epoch 130/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0483 - categorical_accuracy: 0.9348 - val_loss: 1.5098 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.65781\n","Epoch 131/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0664 - categorical_accuracy: 0.9537 - val_loss: 1.5100 - val_categorical_accuracy: 0.6534\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.65781\n","Epoch 132/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1210 - categorical_accuracy: 0.9217 - val_loss: 1.5102 - val_categorical_accuracy: 0.6132\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.65781\n","Epoch 133/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1238 - categorical_accuracy: 0.8657 - val_loss: 1.5023 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.65781\n","Epoch 134/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1304 - categorical_accuracy: 0.8798 - val_loss: 1.5051 - val_categorical_accuracy: 0.6036\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.65781\n","Epoch 135/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1432 - categorical_accuracy: 0.8787 - val_loss: 1.5002 - val_categorical_accuracy: 0.6176\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.65781\n","Epoch 136/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.0856 - categorical_accuracy: 0.9547 - val_loss: 1.4881 - val_categorical_accuracy: 0.6660\n","\n","Epoch 00136: val_categorical_accuracy improved from 0.65781 to 0.66598, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 137/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1116 - categorical_accuracy: 0.9554 - val_loss: 1.4954 - val_categorical_accuracy: 0.6438\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.66598\n","Epoch 138/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0688 - categorical_accuracy: 0.9270 - val_loss: 1.4895 - val_categorical_accuracy: 0.6401\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.66598\n","Epoch 139/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0787 - categorical_accuracy: 0.9358 - val_loss: 1.4887 - val_categorical_accuracy: 0.6186\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.66598\n","Epoch 140/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.0702 - categorical_accuracy: 0.9185 - val_loss: 1.4906 - val_categorical_accuracy: 0.6544\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.66598\n","Epoch 141/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0964 - categorical_accuracy: 0.9111 - val_loss: 1.4880 - val_categorical_accuracy: 0.6558\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.66598\n","Epoch 142/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0121 - categorical_accuracy: 0.9867 - val_loss: 1.4791 - val_categorical_accuracy: 0.6684\n","\n","Epoch 00142: val_categorical_accuracy improved from 0.66598 to 0.66837, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 143/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0905 - categorical_accuracy: 0.9508 - val_loss: 1.4801 - val_categorical_accuracy: 0.6534\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.66837\n","Epoch 144/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0812 - categorical_accuracy: 0.9416 - val_loss: 1.4767 - val_categorical_accuracy: 0.6503\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.66837\n","Epoch 145/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0503 - categorical_accuracy: 0.9659 - val_loss: 1.4774 - val_categorical_accuracy: 0.6534\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.66837\n","Epoch 146/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0648 - categorical_accuracy: 0.9539 - val_loss: 1.4787 - val_categorical_accuracy: 0.6254\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.66837\n","Epoch 147/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0615 - categorical_accuracy: 0.9392 - val_loss: 1.4743 - val_categorical_accuracy: 0.6435\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.66837\n","Epoch 148/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0808 - categorical_accuracy: 0.9236 - val_loss: 1.4785 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.66837\n","Epoch 149/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0882 - categorical_accuracy: 0.8881 - val_loss: 1.4742 - val_categorical_accuracy: 0.6067\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.66837\n","Epoch 150/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1055 - categorical_accuracy: 0.8886 - val_loss: 1.4768 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.66837\n","92/92 [==============================] - 0s 2ms/step - loss: 1.4791 - categorical_accuracy: 0.6684\n","92/92 [==============================] - 0s 973us/step\n","\n","================================================================================================================================\n","Model training starts for data with 30 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 420.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n","\n","Total number of samples in test set 2724.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [240  71 221 185 239 239 229 173 284 218 246 103 211  65]\n","\n","X_train_transfer => (420, 128)\n","X_test_transfer  => (2724, 128)\n","y_train => (420, 14)\n","y_test  => (2724, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","21/21 [==============================] - 1s 20ms/step - loss: 3.6284 - categorical_accuracy: 0.0975 - val_loss: 2.7178 - val_categorical_accuracy: 0.0745\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.07452, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","21/21 [==============================] - 0s 13ms/step - loss: 2.7163 - categorical_accuracy: 0.0367 - val_loss: 2.5424 - val_categorical_accuracy: 0.1101\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.07452 to 0.11013, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","21/21 [==============================] - 0s 13ms/step - loss: 2.5101 - categorical_accuracy: 0.1191 - val_loss: 2.4472 - val_categorical_accuracy: 0.1780\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.11013 to 0.17805, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.4072 - categorical_accuracy: 0.2204 - val_loss: 2.3773 - val_categorical_accuracy: 0.1990\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.17805 to 0.19897, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.2890 - categorical_accuracy: 0.2916 - val_loss: 2.3289 - val_categorical_accuracy: 0.2662\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.19897 to 0.26615, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.2266 - categorical_accuracy: 0.3206 - val_loss: 2.2772 - val_categorical_accuracy: 0.3021\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.26615 to 0.30213, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.1457 - categorical_accuracy: 0.3954 - val_loss: 2.2278 - val_categorical_accuracy: 0.3576\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.30213 to 0.35756, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.0567 - categorical_accuracy: 0.4813 - val_loss: 2.1916 - val_categorical_accuracy: 0.3715\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.35756 to 0.37151, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.0311 - categorical_accuracy: 0.4267 - val_loss: 2.1574 - val_categorical_accuracy: 0.3682\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.37151\n","Epoch 10/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.9826 - categorical_accuracy: 0.4236 - val_loss: 2.1330 - val_categorical_accuracy: 0.3432\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.37151\n","Epoch 11/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.9627 - categorical_accuracy: 0.4559 - val_loss: 2.0911 - val_categorical_accuracy: 0.4023\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.37151 to 0.40235, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 12/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.9595 - categorical_accuracy: 0.4667 - val_loss: 2.0645 - val_categorical_accuracy: 0.3818\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.40235\n","Epoch 13/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.9004 - categorical_accuracy: 0.5669 - val_loss: 2.0487 - val_categorical_accuracy: 0.3818\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.40235\n","Epoch 14/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.8838 - categorical_accuracy: 0.5349 - val_loss: 2.0204 - val_categorical_accuracy: 0.4295\n","\n","Epoch 00014: val_categorical_accuracy improved from 0.40235 to 0.42952, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 15/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.8155 - categorical_accuracy: 0.6205 - val_loss: 1.9944 - val_categorical_accuracy: 0.4391\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.42952 to 0.43906, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.7617 - categorical_accuracy: 0.6390 - val_loss: 1.9750 - val_categorical_accuracy: 0.4126\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.43906\n","Epoch 17/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.7856 - categorical_accuracy: 0.6234 - val_loss: 1.9607 - val_categorical_accuracy: 0.4090\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.43906\n","Epoch 18/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.7868 - categorical_accuracy: 0.6208 - val_loss: 1.9422 - val_categorical_accuracy: 0.4879\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.43906 to 0.48789, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 19/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.7115 - categorical_accuracy: 0.6320 - val_loss: 1.9176 - val_categorical_accuracy: 0.5121\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.48789 to 0.51211, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 20/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.7127 - categorical_accuracy: 0.6520 - val_loss: 1.9128 - val_categorical_accuracy: 0.4534\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.51211\n","Epoch 21/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.6790 - categorical_accuracy: 0.6213 - val_loss: 1.8888 - val_categorical_accuracy: 0.4736\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.51211\n","Epoch 22/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.6576 - categorical_accuracy: 0.7653 - val_loss: 1.8788 - val_categorical_accuracy: 0.5040\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.51211\n","Epoch 23/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.6477 - categorical_accuracy: 0.6499 - val_loss: 1.8611 - val_categorical_accuracy: 0.4618\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.51211\n","Epoch 24/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.6379 - categorical_accuracy: 0.6683 - val_loss: 1.8525 - val_categorical_accuracy: 0.4952\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.51211\n","Epoch 25/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.6390 - categorical_accuracy: 0.6313 - val_loss: 1.8364 - val_categorical_accuracy: 0.5151\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.51211 to 0.51505, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.6114 - categorical_accuracy: 0.7167 - val_loss: 1.8195 - val_categorical_accuracy: 0.5195\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.51505 to 0.51946, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 27/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.5523 - categorical_accuracy: 0.7516 - val_loss: 1.8030 - val_categorical_accuracy: 0.5202\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.51946 to 0.52019, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5642 - categorical_accuracy: 0.7518 - val_loss: 1.7941 - val_categorical_accuracy: 0.5180\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.52019\n","Epoch 29/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.5537 - categorical_accuracy: 0.7354 - val_loss: 1.7785 - val_categorical_accuracy: 0.5661\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.52019 to 0.56608, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 30/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4914 - categorical_accuracy: 0.7560 - val_loss: 1.7727 - val_categorical_accuracy: 0.5066\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.56608\n","Epoch 31/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5287 - categorical_accuracy: 0.8123 - val_loss: 1.7506 - val_categorical_accuracy: 0.5786\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.56608 to 0.57856, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 32/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4530 - categorical_accuracy: 0.8392 - val_loss: 1.7476 - val_categorical_accuracy: 0.5407\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.57856\n","Epoch 33/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4308 - categorical_accuracy: 0.7328 - val_loss: 1.7350 - val_categorical_accuracy: 0.5543\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.57856\n","Epoch 34/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4549 - categorical_accuracy: 0.7436 - val_loss: 1.7188 - val_categorical_accuracy: 0.6248\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.57856 to 0.62482, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3960 - categorical_accuracy: 0.8830 - val_loss: 1.7200 - val_categorical_accuracy: 0.5455\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.62482\n","Epoch 36/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4238 - categorical_accuracy: 0.8344 - val_loss: 1.7099 - val_categorical_accuracy: 0.5628\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.62482\n","Epoch 37/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4286 - categorical_accuracy: 0.7972 - val_loss: 1.7055 - val_categorical_accuracy: 0.4967\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.62482\n","Epoch 38/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4155 - categorical_accuracy: 0.8080 - val_loss: 1.6840 - val_categorical_accuracy: 0.6156\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.62482\n","Epoch 39/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4139 - categorical_accuracy: 0.8271 - val_loss: 1.6850 - val_categorical_accuracy: 0.5661\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.62482\n","Epoch 40/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.3563 - categorical_accuracy: 0.8903 - val_loss: 1.6774 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.62482\n","Epoch 41/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3583 - categorical_accuracy: 0.8849 - val_loss: 1.6649 - val_categorical_accuracy: 0.5826\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.62482\n","Epoch 42/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3896 - categorical_accuracy: 0.8723 - val_loss: 1.6605 - val_categorical_accuracy: 0.5991\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.62482\n","Epoch 43/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.3496 - categorical_accuracy: 0.8886 - val_loss: 1.6599 - val_categorical_accuracy: 0.5558\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.62482\n","Epoch 44/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3480 - categorical_accuracy: 0.8806 - val_loss: 1.6437 - val_categorical_accuracy: 0.6076\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.62482\n","Epoch 45/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3249 - categorical_accuracy: 0.8984 - val_loss: 1.6442 - val_categorical_accuracy: 0.5620\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.62482\n","Epoch 46/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3638 - categorical_accuracy: 0.8508 - val_loss: 1.6302 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.62482\n","Epoch 47/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3130 - categorical_accuracy: 0.9242 - val_loss: 1.6247 - val_categorical_accuracy: 0.6032\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.62482\n","Epoch 48/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.2992 - categorical_accuracy: 0.9079 - val_loss: 1.6187 - val_categorical_accuracy: 0.5760\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.62482\n","Epoch 49/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2677 - categorical_accuracy: 0.8749 - val_loss: 1.6098 - val_categorical_accuracy: 0.6006\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.62482\n","Epoch 50/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2695 - categorical_accuracy: 0.9143 - val_loss: 1.6101 - val_categorical_accuracy: 0.5859\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.62482\n","Epoch 51/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.2775 - categorical_accuracy: 0.9395 - val_loss: 1.5992 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.62482\n","Epoch 52/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2466 - categorical_accuracy: 0.9388 - val_loss: 1.5886 - val_categorical_accuracy: 0.6013\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.62482\n","Epoch 53/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2673 - categorical_accuracy: 0.9254 - val_loss: 1.5888 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.62482\n","Epoch 54/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2393 - categorical_accuracy: 0.8351 - val_loss: 1.5846 - val_categorical_accuracy: 0.5903\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.62482\n","Epoch 55/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2471 - categorical_accuracy: 0.9165 - val_loss: 1.5726 - val_categorical_accuracy: 0.6373\n","\n","Epoch 00055: val_categorical_accuracy improved from 0.62482 to 0.63730, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 56/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1990 - categorical_accuracy: 0.9283 - val_loss: 1.5725 - val_categorical_accuracy: 0.5675\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.63730\n","Epoch 57/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2108 - categorical_accuracy: 0.9248 - val_loss: 1.5593 - val_categorical_accuracy: 0.6314\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.63730\n","Epoch 58/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.2459 - categorical_accuracy: 0.9068 - val_loss: 1.5672 - val_categorical_accuracy: 0.5833\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.63730\n","Epoch 59/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2338 - categorical_accuracy: 0.9202 - val_loss: 1.5568 - val_categorical_accuracy: 0.5903\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.63730\n","Epoch 60/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.1710 - categorical_accuracy: 0.8951 - val_loss: 1.5505 - val_categorical_accuracy: 0.6002\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.63730\n","Epoch 61/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1693 - categorical_accuracy: 0.9401 - val_loss: 1.5470 - val_categorical_accuracy: 0.6101\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.63730\n","Epoch 62/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1157 - categorical_accuracy: 0.9403 - val_loss: 1.5456 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.63730\n","Epoch 63/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1586 - categorical_accuracy: 0.9426 - val_loss: 1.5424 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.63730\n","Epoch 64/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1935 - categorical_accuracy: 0.9054 - val_loss: 1.5348 - val_categorical_accuracy: 0.6318\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.63730\n","Epoch 65/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1265 - categorical_accuracy: 0.9126 - val_loss: 1.5241 - val_categorical_accuracy: 0.6149\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.63730\n","Epoch 66/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1444 - categorical_accuracy: 0.9107 - val_loss: 1.5247 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.63730\n","Epoch 67/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.1163 - categorical_accuracy: 0.9251 - val_loss: 1.5200 - val_categorical_accuracy: 0.6215\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.63730\n","Epoch 68/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.1644 - categorical_accuracy: 0.9748 - val_loss: 1.5203 - val_categorical_accuracy: 0.6189\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.63730\n","Epoch 69/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1290 - categorical_accuracy: 0.9384 - val_loss: 1.5095 - val_categorical_accuracy: 0.6366\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.63730\n","Epoch 70/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.1221 - categorical_accuracy: 0.9110 - val_loss: 1.5131 - val_categorical_accuracy: 0.5826\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.63730\n","Epoch 71/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.1034 - categorical_accuracy: 0.9279 - val_loss: 1.5046 - val_categorical_accuracy: 0.6138\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.63730\n","Epoch 72/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0841 - categorical_accuracy: 0.9341 - val_loss: 1.5052 - val_categorical_accuracy: 0.5995\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.63730\n","Epoch 73/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1174 - categorical_accuracy: 0.9395 - val_loss: 1.5022 - val_categorical_accuracy: 0.5778\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.63730\n","Epoch 74/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0748 - categorical_accuracy: 0.9199 - val_loss: 1.4933 - val_categorical_accuracy: 0.6333\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.63730\n","Epoch 75/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0447 - categorical_accuracy: 0.9100 - val_loss: 1.4874 - val_categorical_accuracy: 0.5999\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.63730\n","Epoch 76/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0516 - categorical_accuracy: 0.9468 - val_loss: 1.4798 - val_categorical_accuracy: 0.6553\n","\n","Epoch 00076: val_categorical_accuracy improved from 0.63730 to 0.65529, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 77/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0861 - categorical_accuracy: 0.9608 - val_loss: 1.4903 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.65529\n","Epoch 78/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0453 - categorical_accuracy: 0.9027 - val_loss: 1.4805 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.65529\n","Epoch 79/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0239 - categorical_accuracy: 0.9457 - val_loss: 1.4686 - val_categorical_accuracy: 0.6553\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.65529\n","Epoch 80/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0567 - categorical_accuracy: 0.9766 - val_loss: 1.4772 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.65529\n","Epoch 81/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0315 - categorical_accuracy: 0.9204 - val_loss: 1.4682 - val_categorical_accuracy: 0.6208\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.65529\n","Epoch 82/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0102 - categorical_accuracy: 0.9442 - val_loss: 1.4612 - val_categorical_accuracy: 0.6604\n","\n","Epoch 00082: val_categorical_accuracy improved from 0.65529 to 0.66043, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 83/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0205 - categorical_accuracy: 0.9751 - val_loss: 1.4607 - val_categorical_accuracy: 0.6490\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.66043\n","Epoch 84/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0597 - categorical_accuracy: 0.9323 - val_loss: 1.4651 - val_categorical_accuracy: 0.6215\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.66043\n","Epoch 85/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0182 - categorical_accuracy: 0.9239 - val_loss: 1.4622 - val_categorical_accuracy: 0.6252\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.66043\n","Epoch 86/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0298 - categorical_accuracy: 0.9616 - val_loss: 1.4501 - val_categorical_accuracy: 0.6483\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.66043\n","Epoch 87/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0192 - categorical_accuracy: 0.9596 - val_loss: 1.4546 - val_categorical_accuracy: 0.6329\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.66043\n","Epoch 88/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0113 - categorical_accuracy: 0.9575 - val_loss: 1.4451 - val_categorical_accuracy: 0.6457\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.66043\n","Epoch 89/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9634 - categorical_accuracy: 0.9761 - val_loss: 1.4396 - val_categorical_accuracy: 0.6659\n","\n","Epoch 00089: val_categorical_accuracy improved from 0.66043 to 0.66593, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 90/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9515 - categorical_accuracy: 0.9836 - val_loss: 1.4376 - val_categorical_accuracy: 0.6516\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.66593\n","Epoch 91/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0267 - categorical_accuracy: 0.9540 - val_loss: 1.4416 - val_categorical_accuracy: 0.6281\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.66593\n","Epoch 92/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9890 - categorical_accuracy: 0.9661 - val_loss: 1.4352 - val_categorical_accuracy: 0.6446\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.66593\n","Epoch 93/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.9986 - categorical_accuracy: 0.9376 - val_loss: 1.4315 - val_categorical_accuracy: 0.6490\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.66593\n","Epoch 94/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9565 - categorical_accuracy: 0.9554 - val_loss: 1.4246 - val_categorical_accuracy: 0.6468\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.66593\n","Epoch 95/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9898 - categorical_accuracy: 0.9861 - val_loss: 1.4207 - val_categorical_accuracy: 0.6630\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.66593\n","Epoch 96/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9410 - categorical_accuracy: 0.9519 - val_loss: 1.4236 - val_categorical_accuracy: 0.6501\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.66593\n","Epoch 97/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9682 - categorical_accuracy: 0.9488 - val_loss: 1.4135 - val_categorical_accuracy: 0.6362\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.66593\n","Epoch 98/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.9685 - categorical_accuracy: 0.9778 - val_loss: 1.4148 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00098: val_categorical_accuracy improved from 0.66593 to 0.67878, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 99/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9796 - categorical_accuracy: 0.9676 - val_loss: 1.4112 - val_categorical_accuracy: 0.6670\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.67878\n","Epoch 100/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9385 - categorical_accuracy: 0.9750 - val_loss: 1.4123 - val_categorical_accuracy: 0.6597\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.67878\n","Epoch 101/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9554 - categorical_accuracy: 0.9854 - val_loss: 1.4061 - val_categorical_accuracy: 0.6410\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.67878\n","Epoch 102/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9527 - categorical_accuracy: 0.9678 - val_loss: 1.4070 - val_categorical_accuracy: 0.6590\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.67878\n","Epoch 103/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9003 - categorical_accuracy: 0.9657 - val_loss: 1.4019 - val_categorical_accuracy: 0.6659\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.67878\n","Epoch 104/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9376 - categorical_accuracy: 0.9636 - val_loss: 1.3997 - val_categorical_accuracy: 0.6557\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.67878\n","Epoch 105/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8859 - categorical_accuracy: 0.9604 - val_loss: 1.3969 - val_categorical_accuracy: 0.6766\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.67878\n","Epoch 106/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9166 - categorical_accuracy: 0.9848 - val_loss: 1.3944 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.67878\n","Epoch 107/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8994 - categorical_accuracy: 0.9887 - val_loss: 1.3910 - val_categorical_accuracy: 0.6729\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.67878\n","Epoch 108/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.9164 - categorical_accuracy: 0.9589 - val_loss: 1.3914 - val_categorical_accuracy: 0.6586\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.67878\n","Epoch 109/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8805 - categorical_accuracy: 0.9679 - val_loss: 1.3884 - val_categorical_accuracy: 0.6535\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.67878\n","Epoch 110/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8958 - categorical_accuracy: 0.9571 - val_loss: 1.3824 - val_categorical_accuracy: 0.6645\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.67878\n","Epoch 111/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9139 - categorical_accuracy: 0.9687 - val_loss: 1.3800 - val_categorical_accuracy: 0.6791\n","\n","Epoch 00111: val_categorical_accuracy improved from 0.67878 to 0.67915, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 112/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8365 - categorical_accuracy: 0.9802 - val_loss: 1.3762 - val_categorical_accuracy: 0.6806\n","\n","Epoch 00112: val_categorical_accuracy improved from 0.67915 to 0.68062, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 113/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9252 - categorical_accuracy: 0.9771 - val_loss: 1.3784 - val_categorical_accuracy: 0.6718\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.68062\n","Epoch 114/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9017 - categorical_accuracy: 0.9718 - val_loss: 1.3768 - val_categorical_accuracy: 0.6340\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.68062\n","Epoch 115/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8724 - categorical_accuracy: 0.9714 - val_loss: 1.3749 - val_categorical_accuracy: 0.6711\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.68062\n","Epoch 116/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8656 - categorical_accuracy: 0.9663 - val_loss: 1.3706 - val_categorical_accuracy: 0.6949\n","\n","Epoch 00116: val_categorical_accuracy improved from 0.68062 to 0.69493, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 117/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8158 - categorical_accuracy: 0.9793 - val_loss: 1.3686 - val_categorical_accuracy: 0.6722\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.69493\n","Epoch 118/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8627 - categorical_accuracy: 0.9883 - val_loss: 1.3682 - val_categorical_accuracy: 0.6744\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.69493\n","Epoch 119/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8566 - categorical_accuracy: 0.9588 - val_loss: 1.3680 - val_categorical_accuracy: 0.6689\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.69493\n","Epoch 120/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8549 - categorical_accuracy: 0.9936 - val_loss: 1.3566 - val_categorical_accuracy: 0.7008\n","\n","Epoch 00120: val_categorical_accuracy improved from 0.69493 to 0.70081, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 121/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8223 - categorical_accuracy: 0.9767 - val_loss: 1.3566 - val_categorical_accuracy: 0.6832\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.70081\n","Epoch 122/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8740 - categorical_accuracy: 0.9799 - val_loss: 1.3624 - val_categorical_accuracy: 0.6725\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.70081\n","Epoch 123/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8291 - categorical_accuracy: 0.9849 - val_loss: 1.3518 - val_categorical_accuracy: 0.6836\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.70081\n","Epoch 124/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8354 - categorical_accuracy: 0.9838 - val_loss: 1.3564 - val_categorical_accuracy: 0.6714\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.70081\n","Epoch 125/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8454 - categorical_accuracy: 0.9829 - val_loss: 1.3537 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.70081\n","Epoch 126/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8127 - categorical_accuracy: 0.9601 - val_loss: 1.3498 - val_categorical_accuracy: 0.6817\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.70081\n","Epoch 127/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8349 - categorical_accuracy: 0.9912 - val_loss: 1.3502 - val_categorical_accuracy: 0.6670\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.70081\n","Epoch 128/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8114 - categorical_accuracy: 0.9723 - val_loss: 1.3428 - val_categorical_accuracy: 0.6898\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.70081\n","Epoch 129/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8126 - categorical_accuracy: 0.9903 - val_loss: 1.3445 - val_categorical_accuracy: 0.6825\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.70081\n","Epoch 130/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8053 - categorical_accuracy: 0.9902 - val_loss: 1.3421 - val_categorical_accuracy: 0.6751\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.70081\n","Epoch 131/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8030 - categorical_accuracy: 0.9682 - val_loss: 1.3411 - val_categorical_accuracy: 0.6769\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.70081\n","Epoch 132/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7999 - categorical_accuracy: 0.9922 - val_loss: 1.3353 - val_categorical_accuracy: 0.6938\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.70081\n","Epoch 133/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7903 - categorical_accuracy: 0.9909 - val_loss: 1.3414 - val_categorical_accuracy: 0.6780\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.70081\n","Epoch 134/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7981 - categorical_accuracy: 0.9828 - val_loss: 1.3337 - val_categorical_accuracy: 0.6880\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.70081\n","Epoch 135/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7811 - categorical_accuracy: 0.9833 - val_loss: 1.3294 - val_categorical_accuracy: 0.6869\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.70081\n","Epoch 136/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7670 - categorical_accuracy: 0.9813 - val_loss: 1.3301 - val_categorical_accuracy: 0.6773\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.70081\n","Epoch 137/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7871 - categorical_accuracy: 0.9983 - val_loss: 1.3258 - val_categorical_accuracy: 0.6920\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.70081\n","Epoch 138/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7662 - categorical_accuracy: 0.9977 - val_loss: 1.3198 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.70081\n","Epoch 139/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7599 - categorical_accuracy: 0.9863 - val_loss: 1.3319 - val_categorical_accuracy: 0.6791\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.70081\n","Epoch 140/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7909 - categorical_accuracy: 0.9672 - val_loss: 1.3252 - val_categorical_accuracy: 0.6832\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.70081\n","Epoch 141/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7739 - categorical_accuracy: 0.9832 - val_loss: 1.3213 - val_categorical_accuracy: 0.6997\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.70081\n","Epoch 142/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7821 - categorical_accuracy: 0.9964 - val_loss: 1.3171 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.70081\n","Epoch 143/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7857 - categorical_accuracy: 0.9676 - val_loss: 1.3120 - val_categorical_accuracy: 0.7004\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.70081\n","Epoch 144/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7456 - categorical_accuracy: 0.9880 - val_loss: 1.3188 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.70081\n","Epoch 145/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7586 - categorical_accuracy: 0.9935 - val_loss: 1.3094 - val_categorical_accuracy: 0.6971\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.70081\n","Epoch 146/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7282 - categorical_accuracy: 0.9851 - val_loss: 1.3201 - val_categorical_accuracy: 0.6722\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.70081\n","Epoch 147/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7234 - categorical_accuracy: 0.9834 - val_loss: 1.3117 - val_categorical_accuracy: 0.7067\n","\n","Epoch 00147: val_categorical_accuracy improved from 0.70081 to 0.70668, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 148/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7666 - categorical_accuracy: 0.9879 - val_loss: 1.3152 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.70668\n","Epoch 149/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7323 - categorical_accuracy: 0.9709 - val_loss: 1.3091 - val_categorical_accuracy: 0.6814\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.70668\n","Epoch 150/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7228 - categorical_accuracy: 0.9793 - val_loss: 1.3050 - val_categorical_accuracy: 0.6931\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.70668\n","86/86 [==============================] - 0s 2ms/step - loss: 1.3117 - categorical_accuracy: 0.7067\n","86/86 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 45 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 630.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [45 45 45 45 45 45 45 45 45 45 45 45 45 45]\n","\n","Total number of samples in test set 2514.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [225  56 206 170 224 224 214 158 269 203 231  88 196  50]\n","\n","X_train_transfer => (630, 128)\n","X_test_transfer  => (2514, 128)\n","y_train => (630, 14)\n","y_test  => (2514, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","32/32 [==============================] - 1s 14ms/step - loss: 3.4717 - categorical_accuracy: 0.0793 - val_loss: 2.6066 - val_categorical_accuracy: 0.0426\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.04256, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.5325 - categorical_accuracy: 0.0714 - val_loss: 2.4507 - val_categorical_accuracy: 0.1691\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.04256 to 0.16905, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.3861 - categorical_accuracy: 0.2224 - val_loss: 2.3540 - val_categorical_accuracy: 0.2673\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.16905 to 0.26730, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.2449 - categorical_accuracy: 0.3299 - val_loss: 2.2886 - val_categorical_accuracy: 0.2928\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.26730 to 0.29276, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","32/32 [==============================] - 0s 9ms/step - loss: 2.1918 - categorical_accuracy: 0.2715 - val_loss: 2.2198 - val_categorical_accuracy: 0.3091\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.29276 to 0.30907, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.0880 - categorical_accuracy: 0.3161 - val_loss: 2.1607 - val_categorical_accuracy: 0.3592\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.30907 to 0.35919, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.0258 - categorical_accuracy: 0.4342 - val_loss: 2.1316 - val_categorical_accuracy: 0.3134\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.35919\n","Epoch 8/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.9339 - categorical_accuracy: 0.3632 - val_loss: 2.0697 - val_categorical_accuracy: 0.3791\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.35919 to 0.37908, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.8901 - categorical_accuracy: 0.4827 - val_loss: 2.0307 - val_categorical_accuracy: 0.4264\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.37908 to 0.42641, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 10/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.8357 - categorical_accuracy: 0.6198 - val_loss: 1.9998 - val_categorical_accuracy: 0.4443\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.42641 to 0.44431, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.8063 - categorical_accuracy: 0.7031 - val_loss: 1.9759 - val_categorical_accuracy: 0.3974\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.44431\n","Epoch 12/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.7624 - categorical_accuracy: 0.5979 - val_loss: 1.9496 - val_categorical_accuracy: 0.4360\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.44431\n","Epoch 13/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.7396 - categorical_accuracy: 0.6183 - val_loss: 1.9141 - val_categorical_accuracy: 0.5040\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.44431 to 0.50398, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.7016 - categorical_accuracy: 0.7302 - val_loss: 1.9112 - val_categorical_accuracy: 0.3890\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.50398\n","Epoch 15/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.6844 - categorical_accuracy: 0.5064 - val_loss: 1.8674 - val_categorical_accuracy: 0.4710\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.50398\n","Epoch 16/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.6540 - categorical_accuracy: 0.6707 - val_loss: 1.8549 - val_categorical_accuracy: 0.5159\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.50398 to 0.51591, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 17/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.6371 - categorical_accuracy: 0.6297 - val_loss: 1.8239 - val_categorical_accuracy: 0.5561\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.51591 to 0.55609, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 18/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.5923 - categorical_accuracy: 0.7731 - val_loss: 1.8105 - val_categorical_accuracy: 0.5203\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.55609\n","Epoch 19/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.5000 - categorical_accuracy: 0.7102 - val_loss: 1.7814 - val_categorical_accuracy: 0.5402\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.55609\n","Epoch 20/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.5189 - categorical_accuracy: 0.7760 - val_loss: 1.7666 - val_categorical_accuracy: 0.5442\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.55609\n","Epoch 21/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.5098 - categorical_accuracy: 0.7331 - val_loss: 1.7573 - val_categorical_accuracy: 0.5605\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.55609 to 0.56046, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.4496 - categorical_accuracy: 0.8214 - val_loss: 1.7510 - val_categorical_accuracy: 0.5652\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.56046 to 0.56523, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 23/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.4425 - categorical_accuracy: 0.7557 - val_loss: 1.7192 - val_categorical_accuracy: 0.5780\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.56523 to 0.57796, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 24/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.4465 - categorical_accuracy: 0.7372 - val_loss: 1.7233 - val_categorical_accuracy: 0.5752\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.57796\n","Epoch 25/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.4250 - categorical_accuracy: 0.7785 - val_loss: 1.7152 - val_categorical_accuracy: 0.5358\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.57796\n","Epoch 26/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.4034 - categorical_accuracy: 0.8087 - val_loss: 1.6899 - val_categorical_accuracy: 0.5529\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.57796\n","Epoch 27/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.3622 - categorical_accuracy: 0.8783 - val_loss: 1.6794 - val_categorical_accuracy: 0.5613\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.57796\n","Epoch 28/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3318 - categorical_accuracy: 0.8316 - val_loss: 1.6685 - val_categorical_accuracy: 0.5652\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.57796\n","Epoch 29/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3743 - categorical_accuracy: 0.8589 - val_loss: 1.6589 - val_categorical_accuracy: 0.5438\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.57796\n","Epoch 30/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3382 - categorical_accuracy: 0.8717 - val_loss: 1.6542 - val_categorical_accuracy: 0.5668\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.57796\n","Epoch 31/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3139 - categorical_accuracy: 0.7919 - val_loss: 1.6436 - val_categorical_accuracy: 0.5573\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.57796\n","Epoch 32/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.2501 - categorical_accuracy: 0.8521 - val_loss: 1.6176 - val_categorical_accuracy: 0.5704\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.57796\n","Epoch 33/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2814 - categorical_accuracy: 0.9202 - val_loss: 1.6251 - val_categorical_accuracy: 0.5609\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.57796\n","Epoch 34/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2684 - categorical_accuracy: 0.8735 - val_loss: 1.6143 - val_categorical_accuracy: 0.5656\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.57796\n","Epoch 35/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2779 - categorical_accuracy: 0.8772 - val_loss: 1.6058 - val_categorical_accuracy: 0.5577\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.57796\n","Epoch 36/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2132 - categorical_accuracy: 0.8941 - val_loss: 1.5938 - val_categorical_accuracy: 0.5716\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.57796\n","Epoch 37/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2211 - categorical_accuracy: 0.8150 - val_loss: 1.5808 - val_categorical_accuracy: 0.5668\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.57796\n","Epoch 38/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.2255 - categorical_accuracy: 0.9068 - val_loss: 1.5781 - val_categorical_accuracy: 0.5660\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.57796\n","Epoch 39/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2225 - categorical_accuracy: 0.8713 - val_loss: 1.5731 - val_categorical_accuracy: 0.5863\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.57796 to 0.58632, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 40/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.1845 - categorical_accuracy: 0.8907 - val_loss: 1.5664 - val_categorical_accuracy: 0.5939\n","\n","Epoch 00040: val_categorical_accuracy improved from 0.58632 to 0.59387, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 41/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2077 - categorical_accuracy: 0.9155 - val_loss: 1.5624 - val_categorical_accuracy: 0.5975\n","\n","Epoch 00041: val_categorical_accuracy improved from 0.59387 to 0.59745, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 42/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2003 - categorical_accuracy: 0.9480 - val_loss: 1.5564 - val_categorical_accuracy: 0.5788\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.59745\n","Epoch 43/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1396 - categorical_accuracy: 0.8863 - val_loss: 1.5396 - val_categorical_accuracy: 0.6130\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.59745 to 0.61297, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0951 - categorical_accuracy: 0.9361 - val_loss: 1.5272 - val_categorical_accuracy: 0.5982\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.61297\n","Epoch 45/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1217 - categorical_accuracy: 0.9144 - val_loss: 1.5300 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.61297\n","Epoch 46/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1248 - categorical_accuracy: 0.9327 - val_loss: 1.5203 - val_categorical_accuracy: 0.6122\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.61297\n","Epoch 47/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0774 - categorical_accuracy: 0.8873 - val_loss: 1.5037 - val_categorical_accuracy: 0.6305\n","\n","Epoch 00047: val_categorical_accuracy improved from 0.61297 to 0.63047, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 48/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0872 - categorical_accuracy: 0.9779 - val_loss: 1.5064 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.63047\n","Epoch 49/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0763 - categorical_accuracy: 0.9284 - val_loss: 1.5050 - val_categorical_accuracy: 0.6253\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.63047\n","Epoch 50/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1142 - categorical_accuracy: 0.8993 - val_loss: 1.4945 - val_categorical_accuracy: 0.6368\n","\n","Epoch 00050: val_categorical_accuracy improved from 0.63047 to 0.63683, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 51/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1033 - categorical_accuracy: 0.9288 - val_loss: 1.4790 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.63683\n","Epoch 52/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0300 - categorical_accuracy: 0.9253 - val_loss: 1.4849 - val_categorical_accuracy: 0.6321\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.63683\n","Epoch 53/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0851 - categorical_accuracy: 0.9476 - val_loss: 1.4761 - val_categorical_accuracy: 0.6265\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.63683\n","Epoch 54/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0333 - categorical_accuracy: 0.9597 - val_loss: 1.4848 - val_categorical_accuracy: 0.6066\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.63683\n","Epoch 55/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0143 - categorical_accuracy: 0.9322 - val_loss: 1.4540 - val_categorical_accuracy: 0.6448\n","\n","Epoch 00055: val_categorical_accuracy improved from 0.63683 to 0.64479, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 56/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0295 - categorical_accuracy: 0.9758 - val_loss: 1.4716 - val_categorical_accuracy: 0.6058\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.64479\n","Epoch 57/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0327 - categorical_accuracy: 0.9578 - val_loss: 1.4590 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.64479\n","Epoch 58/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.0086 - categorical_accuracy: 0.9320 - val_loss: 1.4581 - val_categorical_accuracy: 0.6484\n","\n","Epoch 00058: val_categorical_accuracy improved from 0.64479 to 0.64837, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 59/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9907 - categorical_accuracy: 0.9681 - val_loss: 1.4518 - val_categorical_accuracy: 0.6404\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.64837\n","Epoch 60/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0051 - categorical_accuracy: 0.9594 - val_loss: 1.4505 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.64837\n","Epoch 61/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.9257 - categorical_accuracy: 0.9474 - val_loss: 1.4448 - val_categorical_accuracy: 0.6368\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.64837\n","Epoch 62/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9861 - categorical_accuracy: 0.9400 - val_loss: 1.4384 - val_categorical_accuracy: 0.6205\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.64837\n","Epoch 63/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9141 - categorical_accuracy: 0.9372 - val_loss: 1.4294 - val_categorical_accuracy: 0.6412\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.64837\n","Epoch 64/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9572 - categorical_accuracy: 0.9727 - val_loss: 1.4256 - val_categorical_accuracy: 0.6340\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.64837\n","Epoch 65/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.9707 - categorical_accuracy: 0.9493 - val_loss: 1.4189 - val_categorical_accuracy: 0.6444\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.64837\n","Epoch 66/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9398 - categorical_accuracy: 0.9638 - val_loss: 1.4336 - val_categorical_accuracy: 0.6348\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.64837\n","Epoch 67/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.9580 - categorical_accuracy: 0.9517 - val_loss: 1.4245 - val_categorical_accuracy: 0.6134\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.64837\n","Epoch 68/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9353 - categorical_accuracy: 0.9749 - val_loss: 1.4063 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.64837\n","Epoch 69/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9105 - categorical_accuracy: 0.9592 - val_loss: 1.4130 - val_categorical_accuracy: 0.6333\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.64837\n","Epoch 70/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8885 - categorical_accuracy: 0.9825 - val_loss: 1.4089 - val_categorical_accuracy: 0.6313\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.64837\n","Epoch 71/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9174 - categorical_accuracy: 0.9685 - val_loss: 1.4085 - val_categorical_accuracy: 0.6269\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.64837\n","Epoch 72/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8571 - categorical_accuracy: 0.9498 - val_loss: 1.3955 - val_categorical_accuracy: 0.6627\n","\n","Epoch 00072: val_categorical_accuracy improved from 0.64837 to 0.66269, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 73/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9182 - categorical_accuracy: 0.9801 - val_loss: 1.3991 - val_categorical_accuracy: 0.6508\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.66269\n","Epoch 74/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8804 - categorical_accuracy: 0.9687 - val_loss: 1.3860 - val_categorical_accuracy: 0.6651\n","\n","Epoch 00074: val_categorical_accuracy improved from 0.66269 to 0.66508, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 75/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8734 - categorical_accuracy: 0.9648 - val_loss: 1.3893 - val_categorical_accuracy: 0.6368\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.66508\n","Epoch 76/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9101 - categorical_accuracy: 0.9760 - val_loss: 1.3768 - val_categorical_accuracy: 0.6539\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.66508\n","Epoch 77/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8875 - categorical_accuracy: 0.9606 - val_loss: 1.3844 - val_categorical_accuracy: 0.6512\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.66508\n","Epoch 78/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8321 - categorical_accuracy: 0.9745 - val_loss: 1.3766 - val_categorical_accuracy: 0.6750\n","\n","Epoch 00078: val_categorical_accuracy improved from 0.66508 to 0.67502, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 79/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8955 - categorical_accuracy: 0.9658 - val_loss: 1.3897 - val_categorical_accuracy: 0.6265\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.67502\n","Epoch 80/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8195 - categorical_accuracy: 0.9830 - val_loss: 1.3788 - val_categorical_accuracy: 0.6384\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.67502\n","Epoch 81/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8277 - categorical_accuracy: 0.9612 - val_loss: 1.3650 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.67502\n","Epoch 82/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8158 - categorical_accuracy: 0.9683 - val_loss: 1.3616 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00082: val_categorical_accuracy improved from 0.67502 to 0.68536, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 83/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8659 - categorical_accuracy: 0.9761 - val_loss: 1.3556 - val_categorical_accuracy: 0.6635\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.68536\n","Epoch 84/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8232 - categorical_accuracy: 0.9573 - val_loss: 1.3571 - val_categorical_accuracy: 0.6706\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.68536\n","Epoch 85/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8132 - categorical_accuracy: 0.9683 - val_loss: 1.3511 - val_categorical_accuracy: 0.6508\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.68536\n","Epoch 86/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8029 - categorical_accuracy: 0.9724 - val_loss: 1.3549 - val_categorical_accuracy: 0.6611\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.68536\n","Epoch 87/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8011 - categorical_accuracy: 0.9835 - val_loss: 1.3565 - val_categorical_accuracy: 0.6571\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.68536\n","Epoch 88/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8212 - categorical_accuracy: 0.9798 - val_loss: 1.3435 - val_categorical_accuracy: 0.6714\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.68536\n","Epoch 89/150\n","32/32 [==============================] - 0s 14ms/step - loss: 0.8043 - categorical_accuracy: 0.9862 - val_loss: 1.3436 - val_categorical_accuracy: 0.6484\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.68536\n","Epoch 90/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7876 - categorical_accuracy: 0.9647 - val_loss: 1.3330 - val_categorical_accuracy: 0.6563\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.68536\n","Epoch 91/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7853 - categorical_accuracy: 0.9921 - val_loss: 1.3370 - val_categorical_accuracy: 0.6702\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.68536\n","Epoch 92/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7684 - categorical_accuracy: 0.9871 - val_loss: 1.3333 - val_categorical_accuracy: 0.6655\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.68536\n","Epoch 93/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7905 - categorical_accuracy: 0.9926 - val_loss: 1.3331 - val_categorical_accuracy: 0.6635\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.68536\n","Epoch 94/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7706 - categorical_accuracy: 0.9776 - val_loss: 1.3231 - val_categorical_accuracy: 0.6539\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.68536\n","Epoch 95/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7440 - categorical_accuracy: 0.9575 - val_loss: 1.3290 - val_categorical_accuracy: 0.6738\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.68536\n","Epoch 96/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7629 - categorical_accuracy: 0.9781 - val_loss: 1.3188 - val_categorical_accuracy: 0.6643\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.68536\n","Epoch 97/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7889 - categorical_accuracy: 0.9730 - val_loss: 1.3279 - val_categorical_accuracy: 0.6663\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.68536\n","Epoch 98/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7467 - categorical_accuracy: 0.9855 - val_loss: 1.3241 - val_categorical_accuracy: 0.6691\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.68536\n","Epoch 99/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7434 - categorical_accuracy: 0.9695 - val_loss: 1.3147 - val_categorical_accuracy: 0.6786\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.68536\n","Epoch 100/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7374 - categorical_accuracy: 0.9852 - val_loss: 1.3233 - val_categorical_accuracy: 0.6663\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.68536\n","Epoch 101/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7107 - categorical_accuracy: 0.9811 - val_loss: 1.3189 - val_categorical_accuracy: 0.6718\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.68536\n","Epoch 102/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7350 - categorical_accuracy: 0.9847 - val_loss: 1.3028 - val_categorical_accuracy: 0.7152\n","\n","Epoch 00102: val_categorical_accuracy improved from 0.68536 to 0.71519, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 103/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7041 - categorical_accuracy: 0.9831 - val_loss: 1.3056 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.71519\n","Epoch 104/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7141 - categorical_accuracy: 0.9872 - val_loss: 1.3070 - val_categorical_accuracy: 0.6571\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.71519\n","Epoch 105/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7266 - categorical_accuracy: 0.9855 - val_loss: 1.3137 - val_categorical_accuracy: 0.6388\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.71519\n","Epoch 106/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7220 - categorical_accuracy: 0.9858 - val_loss: 1.3085 - val_categorical_accuracy: 0.6567\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.71519\n","Epoch 107/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7199 - categorical_accuracy: 0.9759 - val_loss: 1.3025 - val_categorical_accuracy: 0.6599\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.71519\n","Epoch 108/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7151 - categorical_accuracy: 0.9697 - val_loss: 1.2970 - val_categorical_accuracy: 0.6969\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.71519\n","Epoch 109/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6847 - categorical_accuracy: 0.9934 - val_loss: 1.2972 - val_categorical_accuracy: 0.6687\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.71519\n","Epoch 110/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6947 - categorical_accuracy: 0.9881 - val_loss: 1.2878 - val_categorical_accuracy: 0.6687\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.71519\n","Epoch 111/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6834 - categorical_accuracy: 0.9770 - val_loss: 1.2887 - val_categorical_accuracy: 0.6679\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.71519\n","Epoch 112/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6797 - categorical_accuracy: 0.9868 - val_loss: 1.2851 - val_categorical_accuracy: 0.7188\n","\n","Epoch 00112: val_categorical_accuracy improved from 0.71519 to 0.71877, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 113/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6762 - categorical_accuracy: 0.9872 - val_loss: 1.2893 - val_categorical_accuracy: 0.6683\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.71877\n","Epoch 114/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6709 - categorical_accuracy: 0.9921 - val_loss: 1.2792 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.71877\n","Epoch 115/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6707 - categorical_accuracy: 0.9916 - val_loss: 1.2812 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.71877\n","Epoch 116/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6808 - categorical_accuracy: 0.9921 - val_loss: 1.2787 - val_categorical_accuracy: 0.6858\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.71877\n","Epoch 117/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6518 - categorical_accuracy: 0.9874 - val_loss: 1.2728 - val_categorical_accuracy: 0.6881\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.71877\n","Epoch 118/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6489 - categorical_accuracy: 0.9832 - val_loss: 1.2739 - val_categorical_accuracy: 0.6997\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.71877\n","Epoch 119/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6645 - categorical_accuracy: 0.9739 - val_loss: 1.2677 - val_categorical_accuracy: 0.6941\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.71877\n","Epoch 120/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6515 - categorical_accuracy: 0.9818 - val_loss: 1.2689 - val_categorical_accuracy: 0.7009\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.71877\n","Epoch 121/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6381 - categorical_accuracy: 0.9969 - val_loss: 1.2633 - val_categorical_accuracy: 0.6893\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.71877\n","Epoch 122/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6663 - categorical_accuracy: 0.9778 - val_loss: 1.2612 - val_categorical_accuracy: 0.7108\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.71877\n","Epoch 123/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6332 - categorical_accuracy: 0.9838 - val_loss: 1.2683 - val_categorical_accuracy: 0.6814\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.71877\n","Epoch 124/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6362 - categorical_accuracy: 0.9782 - val_loss: 1.2609 - val_categorical_accuracy: 0.7056\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.71877\n","Epoch 125/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6438 - categorical_accuracy: 0.9938 - val_loss: 1.2650 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.71877\n","Epoch 126/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6065 - categorical_accuracy: 0.9911 - val_loss: 1.2589 - val_categorical_accuracy: 0.6862\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.71877\n","Epoch 127/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6265 - categorical_accuracy: 0.9780 - val_loss: 1.2517 - val_categorical_accuracy: 0.7192\n","\n","Epoch 00127: val_categorical_accuracy improved from 0.71877 to 0.71917, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 128/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6109 - categorical_accuracy: 0.9747 - val_loss: 1.2606 - val_categorical_accuracy: 0.6834\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.71917\n","Epoch 129/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6073 - categorical_accuracy: 0.9801 - val_loss: 1.2549 - val_categorical_accuracy: 0.6965\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.71917\n","Epoch 130/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6276 - categorical_accuracy: 0.9782 - val_loss: 1.2512 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.71917\n","Epoch 131/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.6134 - categorical_accuracy: 0.9912 - val_loss: 1.2492 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.71917\n","Epoch 132/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6007 - categorical_accuracy: 0.9942 - val_loss: 1.2497 - val_categorical_accuracy: 0.6798\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.71917\n","Epoch 133/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5795 - categorical_accuracy: 0.9865 - val_loss: 1.2537 - val_categorical_accuracy: 0.6782\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.71917\n","Epoch 134/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5994 - categorical_accuracy: 0.9918 - val_loss: 1.2396 - val_categorical_accuracy: 0.7132\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.71917\n","Epoch 135/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5750 - categorical_accuracy: 0.9941 - val_loss: 1.2511 - val_categorical_accuracy: 0.6802\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.71917\n","Epoch 136/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6094 - categorical_accuracy: 0.9776 - val_loss: 1.2378 - val_categorical_accuracy: 0.7172\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.71917\n","Epoch 137/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6060 - categorical_accuracy: 0.9884 - val_loss: 1.2524 - val_categorical_accuracy: 0.6770\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.71917\n","Epoch 138/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5818 - categorical_accuracy: 0.9805 - val_loss: 1.2327 - val_categorical_accuracy: 0.7160\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.71917\n","Epoch 139/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5712 - categorical_accuracy: 0.9810 - val_loss: 1.2386 - val_categorical_accuracy: 0.6921\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.71917\n","Epoch 140/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5603 - categorical_accuracy: 0.9953 - val_loss: 1.2370 - val_categorical_accuracy: 0.6866\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.71917\n","Epoch 141/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5704 - categorical_accuracy: 0.9948 - val_loss: 1.2382 - val_categorical_accuracy: 0.6913\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.71917\n","Epoch 142/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5705 - categorical_accuracy: 0.9883 - val_loss: 1.2307 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.71917\n","Epoch 143/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5628 - categorical_accuracy: 0.9852 - val_loss: 1.2321 - val_categorical_accuracy: 0.6981\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.71917\n","Epoch 144/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5669 - categorical_accuracy: 0.9899 - val_loss: 1.2363 - val_categorical_accuracy: 0.6889\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.71917\n","Epoch 145/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5683 - categorical_accuracy: 0.9789 - val_loss: 1.2425 - val_categorical_accuracy: 0.6838\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.71917\n","Epoch 146/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5491 - categorical_accuracy: 0.9935 - val_loss: 1.2242 - val_categorical_accuracy: 0.6937\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.71917\n","Epoch 147/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5408 - categorical_accuracy: 0.9962 - val_loss: 1.2200 - val_categorical_accuracy: 0.6993\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.71917\n","Epoch 148/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5446 - categorical_accuracy: 0.9939 - val_loss: 1.2274 - val_categorical_accuracy: 0.6850\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.71917\n","Epoch 149/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5434 - categorical_accuracy: 0.9882 - val_loss: 1.2237 - val_categorical_accuracy: 0.6985\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.71917\n","Epoch 150/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5594 - categorical_accuracy: 0.9938 - val_loss: 1.2249 - val_categorical_accuracy: 0.6969\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.71917\n","79/79 [==============================] - 0s 2ms/step - loss: 1.2517 - categorical_accuracy: 0.7192\n","79/79 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 60 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 840.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [60 60 60 60 60 60 60 60 60 60 60 60 60 60]\n","\n","Total number of samples in test set 2304.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [210  41 191 155 209 209 199 143 254 188 216  73 181  35]\n","\n","X_train_transfer => (840, 128)\n","X_test_transfer  => (2304, 128)\n","y_train => (840, 14)\n","y_test  => (2304, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","42/42 [==============================] - 1s 10ms/step - loss: 3.3792 - categorical_accuracy: 0.0893 - val_loss: 2.5461 - val_categorical_accuracy: 0.0681\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.06814, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","42/42 [==============================] - 0s 8ms/step - loss: 2.4864 - categorical_accuracy: 0.1307 - val_loss: 2.3982 - val_categorical_accuracy: 0.1697\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.06814 to 0.16970, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","42/42 [==============================] - 0s 8ms/step - loss: 2.2883 - categorical_accuracy: 0.2806 - val_loss: 2.2760 - val_categorical_accuracy: 0.2878\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.16970 to 0.28776, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","42/42 [==============================] - 0s 7ms/step - loss: 2.1441 - categorical_accuracy: 0.3863 - val_loss: 2.2235 - val_categorical_accuracy: 0.2682\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.28776\n","Epoch 5/150\n","42/42 [==============================] - 0s 8ms/step - loss: 2.0283 - categorical_accuracy: 0.3803 - val_loss: 2.1454 - val_categorical_accuracy: 0.3411\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.28776 to 0.34115, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","42/42 [==============================] - 0s 9ms/step - loss: 2.0148 - categorical_accuracy: 0.4106 - val_loss: 2.0945 - val_categorical_accuracy: 0.3251\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.34115\n","Epoch 7/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.9393 - categorical_accuracy: 0.4104 - val_loss: 2.0351 - val_categorical_accuracy: 0.4800\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.34115 to 0.48003, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.8569 - categorical_accuracy: 0.5934 - val_loss: 1.9993 - val_categorical_accuracy: 0.3915\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.48003\n","Epoch 9/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.8137 - categorical_accuracy: 0.5320 - val_loss: 1.9713 - val_categorical_accuracy: 0.4106\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.48003\n","Epoch 10/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.7735 - categorical_accuracy: 0.6611 - val_loss: 1.9193 - val_categorical_accuracy: 0.3997\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.48003\n","Epoch 11/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.6898 - categorical_accuracy: 0.5377 - val_loss: 1.8961 - val_categorical_accuracy: 0.4132\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.48003\n","Epoch 12/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.7003 - categorical_accuracy: 0.6457 - val_loss: 1.8684 - val_categorical_accuracy: 0.5078\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.48003 to 0.50781, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.6186 - categorical_accuracy: 0.6199 - val_loss: 1.8362 - val_categorical_accuracy: 0.5556\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.50781 to 0.55556, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.5520 - categorical_accuracy: 0.6431 - val_loss: 1.8111 - val_categorical_accuracy: 0.5191\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.55556\n","Epoch 15/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.5698 - categorical_accuracy: 0.6849 - val_loss: 1.7798 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.55556 to 0.59288, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.4933 - categorical_accuracy: 0.7640 - val_loss: 1.7580 - val_categorical_accuracy: 0.5386\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.59288\n","Epoch 17/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.4966 - categorical_accuracy: 0.7862 - val_loss: 1.7444 - val_categorical_accuracy: 0.4809\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.59288\n","Epoch 18/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.4876 - categorical_accuracy: 0.7356 - val_loss: 1.7226 - val_categorical_accuracy: 0.5395\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.59288\n","Epoch 19/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.4536 - categorical_accuracy: 0.7857 - val_loss: 1.7096 - val_categorical_accuracy: 0.5395\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.59288\n","Epoch 20/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.4284 - categorical_accuracy: 0.8569 - val_loss: 1.7049 - val_categorical_accuracy: 0.4466\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.59288\n","Epoch 21/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.4020 - categorical_accuracy: 0.7393 - val_loss: 1.6602 - val_categorical_accuracy: 0.5395\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.59288\n","Epoch 22/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.3546 - categorical_accuracy: 0.9053 - val_loss: 1.6683 - val_categorical_accuracy: 0.4970\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.59288\n","Epoch 23/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.3493 - categorical_accuracy: 0.7542 - val_loss: 1.6391 - val_categorical_accuracy: 0.5725\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.59288\n","Epoch 24/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2962 - categorical_accuracy: 0.8381 - val_loss: 1.6317 - val_categorical_accuracy: 0.5725\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.59288\n","Epoch 25/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.3369 - categorical_accuracy: 0.8807 - val_loss: 1.6197 - val_categorical_accuracy: 0.5699\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.59288\n","Epoch 26/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.2508 - categorical_accuracy: 0.8112 - val_loss: 1.5903 - val_categorical_accuracy: 0.5816\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.59288\n","Epoch 27/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2600 - categorical_accuracy: 0.8817 - val_loss: 1.6012 - val_categorical_accuracy: 0.5677\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.59288\n","Epoch 28/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.2581 - categorical_accuracy: 0.8124 - val_loss: 1.5799 - val_categorical_accuracy: 0.5564\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.59288\n","Epoch 29/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2480 - categorical_accuracy: 0.9030 - val_loss: 1.5711 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.59288\n","Epoch 30/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1917 - categorical_accuracy: 0.8550 - val_loss: 1.5536 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00030: val_categorical_accuracy improved from 0.59288 to 0.60938, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 31/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1650 - categorical_accuracy: 0.9359 - val_loss: 1.5459 - val_categorical_accuracy: 0.5846\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.60938\n","Epoch 32/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2044 - categorical_accuracy: 0.9066 - val_loss: 1.5519 - val_categorical_accuracy: 0.5443\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.60938\n","Epoch 33/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1474 - categorical_accuracy: 0.8909 - val_loss: 1.5242 - val_categorical_accuracy: 0.5820\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.60938\n","Epoch 34/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1221 - categorical_accuracy: 0.9011 - val_loss: 1.5236 - val_categorical_accuracy: 0.6120\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.60938 to 0.61198, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1181 - categorical_accuracy: 0.9124 - val_loss: 1.5313 - val_categorical_accuracy: 0.5712\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.61198\n","Epoch 36/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1224 - categorical_accuracy: 0.8735 - val_loss: 1.4985 - val_categorical_accuracy: 0.5998\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.61198\n","Epoch 37/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0897 - categorical_accuracy: 0.9263 - val_loss: 1.5232 - val_categorical_accuracy: 0.5404\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.61198\n","Epoch 38/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1045 - categorical_accuracy: 0.9029 - val_loss: 1.5101 - val_categorical_accuracy: 0.5490\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.61198\n","Epoch 39/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1116 - categorical_accuracy: 0.9456 - val_loss: 1.4807 - val_categorical_accuracy: 0.5651\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.61198\n","Epoch 40/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0492 - categorical_accuracy: 0.9471 - val_loss: 1.4805 - val_categorical_accuracy: 0.5859\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.61198\n","Epoch 41/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0511 - categorical_accuracy: 0.9167 - val_loss: 1.4800 - val_categorical_accuracy: 0.5764\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.61198\n","Epoch 42/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0583 - categorical_accuracy: 0.9419 - val_loss: 1.4692 - val_categorical_accuracy: 0.5720\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.61198\n","Epoch 43/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0052 - categorical_accuracy: 0.9636 - val_loss: 1.4706 - val_categorical_accuracy: 0.5773\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.61198\n","Epoch 44/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0452 - categorical_accuracy: 0.9318 - val_loss: 1.4486 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.61198\n","Epoch 45/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0122 - categorical_accuracy: 0.9367 - val_loss: 1.4307 - val_categorical_accuracy: 0.6888\n","\n","Epoch 00045: val_categorical_accuracy improved from 0.61198 to 0.68880, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 46/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0078 - categorical_accuracy: 0.9364 - val_loss: 1.4297 - val_categorical_accuracy: 0.6185\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.68880\n","Epoch 47/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0086 - categorical_accuracy: 0.9258 - val_loss: 1.4410 - val_categorical_accuracy: 0.6007\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.68880\n","Epoch 48/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0169 - categorical_accuracy: 0.9368 - val_loss: 1.4267 - val_categorical_accuracy: 0.6476\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.68880\n","Epoch 49/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0141 - categorical_accuracy: 0.9507 - val_loss: 1.4082 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.68880\n","Epoch 50/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9840 - categorical_accuracy: 0.9644 - val_loss: 1.4307 - val_categorical_accuracy: 0.5634\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.68880\n","Epoch 51/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9594 - categorical_accuracy: 0.9498 - val_loss: 1.4079 - val_categorical_accuracy: 0.5911\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.68880\n","Epoch 52/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9470 - categorical_accuracy: 0.9703 - val_loss: 1.4128 - val_categorical_accuracy: 0.6029\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.68880\n","Epoch 53/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9557 - categorical_accuracy: 0.9542 - val_loss: 1.3981 - val_categorical_accuracy: 0.5990\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.68880\n","Epoch 54/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9002 - categorical_accuracy: 0.9478 - val_loss: 1.3926 - val_categorical_accuracy: 0.6272\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.68880\n","Epoch 55/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8694 - categorical_accuracy: 0.9528 - val_loss: 1.3807 - val_categorical_accuracy: 0.6315\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.68880\n","Epoch 56/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8837 - categorical_accuracy: 0.9600 - val_loss: 1.3673 - val_categorical_accuracy: 0.6701\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.68880\n","Epoch 57/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9247 - categorical_accuracy: 0.9725 - val_loss: 1.3883 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.68880\n","Epoch 58/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9006 - categorical_accuracy: 0.9664 - val_loss: 1.3792 - val_categorical_accuracy: 0.6189\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.68880\n","Epoch 59/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8904 - categorical_accuracy: 0.9732 - val_loss: 1.3719 - val_categorical_accuracy: 0.6419\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.68880\n","Epoch 60/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8974 - categorical_accuracy: 0.9852 - val_loss: 1.3707 - val_categorical_accuracy: 0.6233\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.68880\n","Epoch 61/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8481 - categorical_accuracy: 0.9599 - val_loss: 1.3490 - val_categorical_accuracy: 0.6567\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.68880\n","Epoch 62/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8747 - categorical_accuracy: 0.9829 - val_loss: 1.3638 - val_categorical_accuracy: 0.6050\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.68880\n","Epoch 63/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8570 - categorical_accuracy: 0.9786 - val_loss: 1.3602 - val_categorical_accuracy: 0.6337\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.68880\n","Epoch 64/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8349 - categorical_accuracy: 0.9630 - val_loss: 1.3562 - val_categorical_accuracy: 0.6649\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.68880\n","Epoch 65/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8150 - categorical_accuracy: 0.9480 - val_loss: 1.3364 - val_categorical_accuracy: 0.6710\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.68880\n","Epoch 66/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8139 - categorical_accuracy: 0.9183 - val_loss: 1.3263 - val_categorical_accuracy: 0.6523\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.68880\n","Epoch 67/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8139 - categorical_accuracy: 0.9655 - val_loss: 1.3401 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.68880\n","Epoch 68/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8252 - categorical_accuracy: 0.9803 - val_loss: 1.3536 - val_categorical_accuracy: 0.5621\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.68880\n","Epoch 69/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7829 - categorical_accuracy: 0.9441 - val_loss: 1.3292 - val_categorical_accuracy: 0.6732\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.68880\n","Epoch 70/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7952 - categorical_accuracy: 0.9754 - val_loss: 1.3254 - val_categorical_accuracy: 0.6359\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.68880\n","Epoch 71/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7843 - categorical_accuracy: 0.9758 - val_loss: 1.3042 - val_categorical_accuracy: 0.6901\n","\n","Epoch 00071: val_categorical_accuracy improved from 0.68880 to 0.69010, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 72/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7491 - categorical_accuracy: 0.9730 - val_loss: 1.3105 - val_categorical_accuracy: 0.6363\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.69010\n","Epoch 73/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7711 - categorical_accuracy: 0.9538 - val_loss: 1.3061 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.69010\n","Epoch 74/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7667 - categorical_accuracy: 0.9725 - val_loss: 1.2976 - val_categorical_accuracy: 0.6853\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.69010\n","Epoch 75/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7780 - categorical_accuracy: 0.9846 - val_loss: 1.2999 - val_categorical_accuracy: 0.6502\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.69010\n","Epoch 76/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7314 - categorical_accuracy: 0.9839 - val_loss: 1.2979 - val_categorical_accuracy: 0.6528\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.69010\n","Epoch 77/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7104 - categorical_accuracy: 0.9748 - val_loss: 1.2983 - val_categorical_accuracy: 0.6719\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.69010\n","Epoch 78/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7369 - categorical_accuracy: 0.9860 - val_loss: 1.2883 - val_categorical_accuracy: 0.6654\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.69010\n","Epoch 79/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7229 - categorical_accuracy: 0.9730 - val_loss: 1.2942 - val_categorical_accuracy: 0.6454\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.69010\n","Epoch 80/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7155 - categorical_accuracy: 0.9722 - val_loss: 1.2748 - val_categorical_accuracy: 0.6528\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.69010\n","Epoch 81/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7144 - categorical_accuracy: 0.9764 - val_loss: 1.2806 - val_categorical_accuracy: 0.6758\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.69010\n","Epoch 82/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7088 - categorical_accuracy: 0.9843 - val_loss: 1.2740 - val_categorical_accuracy: 0.6484\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.69010\n","Epoch 83/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6927 - categorical_accuracy: 0.9829 - val_loss: 1.2800 - val_categorical_accuracy: 0.6510\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.69010\n","Epoch 84/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6956 - categorical_accuracy: 0.9844 - val_loss: 1.2613 - val_categorical_accuracy: 0.6675\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.69010\n","Epoch 85/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7031 - categorical_accuracy: 0.9791 - val_loss: 1.2688 - val_categorical_accuracy: 0.6593\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.69010\n","Epoch 86/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6824 - categorical_accuracy: 0.9845 - val_loss: 1.2807 - val_categorical_accuracy: 0.6632\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.69010\n","Epoch 87/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6619 - categorical_accuracy: 0.9871 - val_loss: 1.2634 - val_categorical_accuracy: 0.6658\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.69010\n","Epoch 88/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6810 - categorical_accuracy: 0.9738 - val_loss: 1.2576 - val_categorical_accuracy: 0.6632\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.69010\n","Epoch 89/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6888 - categorical_accuracy: 0.9789 - val_loss: 1.2552 - val_categorical_accuracy: 0.6701\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.69010\n","Epoch 90/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6717 - categorical_accuracy: 0.9850 - val_loss: 1.2562 - val_categorical_accuracy: 0.6536\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.69010\n","Epoch 91/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6500 - categorical_accuracy: 0.9823 - val_loss: 1.2414 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.69010\n","Epoch 92/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.6420 - categorical_accuracy: 0.9881 - val_loss: 1.2279 - val_categorical_accuracy: 0.6801\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.69010\n","Epoch 93/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6235 - categorical_accuracy: 0.9871 - val_loss: 1.2410 - val_categorical_accuracy: 0.6905\n","\n","Epoch 00093: val_categorical_accuracy improved from 0.69010 to 0.69054, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 94/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6510 - categorical_accuracy: 0.9847 - val_loss: 1.2485 - val_categorical_accuracy: 0.6827\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.69054\n","Epoch 95/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6521 - categorical_accuracy: 0.9872 - val_loss: 1.2542 - val_categorical_accuracy: 0.6393\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.69054\n","Epoch 96/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.6231 - categorical_accuracy: 0.9753 - val_loss: 1.2291 - val_categorical_accuracy: 0.6858\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.69054\n","Epoch 97/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6411 - categorical_accuracy: 0.9844 - val_loss: 1.2330 - val_categorical_accuracy: 0.6979\n","\n","Epoch 00097: val_categorical_accuracy improved from 0.69054 to 0.69792, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 98/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6191 - categorical_accuracy: 0.9847 - val_loss: 1.2320 - val_categorical_accuracy: 0.6589\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.69792\n","Epoch 99/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6462 - categorical_accuracy: 0.9804 - val_loss: 1.2387 - val_categorical_accuracy: 0.6740\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.69792\n","Epoch 100/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5952 - categorical_accuracy: 0.9821 - val_loss: 1.2239 - val_categorical_accuracy: 0.6879\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.69792\n","Epoch 101/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5990 - categorical_accuracy: 0.9859 - val_loss: 1.2161 - val_categorical_accuracy: 0.7170\n","\n","Epoch 00101: val_categorical_accuracy improved from 0.69792 to 0.71701, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 102/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5985 - categorical_accuracy: 0.9842 - val_loss: 1.2187 - val_categorical_accuracy: 0.6871\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.71701\n","Epoch 103/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6093 - categorical_accuracy: 0.9810 - val_loss: 1.2237 - val_categorical_accuracy: 0.6749\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.71701\n","Epoch 104/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5829 - categorical_accuracy: 0.9829 - val_loss: 1.2252 - val_categorical_accuracy: 0.6970\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.71701\n","Epoch 105/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5887 - categorical_accuracy: 0.9859 - val_loss: 1.2127 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.71701\n","Epoch 106/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5777 - categorical_accuracy: 0.9867 - val_loss: 1.2083 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.71701\n","Epoch 107/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5762 - categorical_accuracy: 0.9831 - val_loss: 1.1997 - val_categorical_accuracy: 0.6749\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.71701\n","Epoch 108/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5831 - categorical_accuracy: 0.9732 - val_loss: 1.2172 - val_categorical_accuracy: 0.6619\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.71701\n","Epoch 109/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5706 - categorical_accuracy: 0.9868 - val_loss: 1.2050 - val_categorical_accuracy: 0.6710\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.71701\n","Epoch 110/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5762 - categorical_accuracy: 0.9772 - val_loss: 1.2020 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.71701\n","Epoch 111/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5457 - categorical_accuracy: 0.9859 - val_loss: 1.2100 - val_categorical_accuracy: 0.6641\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.71701\n","Epoch 112/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.5596 - categorical_accuracy: 0.9673 - val_loss: 1.2183 - val_categorical_accuracy: 0.6515\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.71701\n","Epoch 113/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5451 - categorical_accuracy: 0.9817 - val_loss: 1.2085 - val_categorical_accuracy: 0.6658\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.71701\n","Epoch 114/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5553 - categorical_accuracy: 0.9839 - val_loss: 1.1956 - val_categorical_accuracy: 0.6723\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.71701\n","Epoch 115/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5353 - categorical_accuracy: 0.9889 - val_loss: 1.2040 - val_categorical_accuracy: 0.6706\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.71701\n","Epoch 116/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5350 - categorical_accuracy: 0.9801 - val_loss: 1.1841 - val_categorical_accuracy: 0.6944\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.71701\n","Epoch 117/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5448 - categorical_accuracy: 0.9903 - val_loss: 1.1917 - val_categorical_accuracy: 0.6727\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.71701\n","Epoch 118/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5329 - categorical_accuracy: 0.9854 - val_loss: 1.1973 - val_categorical_accuracy: 0.6606\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.71701\n","Epoch 119/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5321 - categorical_accuracy: 0.9770 - val_loss: 1.1829 - val_categorical_accuracy: 0.7083\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.71701\n","Epoch 120/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5266 - categorical_accuracy: 0.9879 - val_loss: 1.1917 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.71701\n","Epoch 121/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5351 - categorical_accuracy: 0.9868 - val_loss: 1.1691 - val_categorical_accuracy: 0.6966\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.71701\n","Epoch 122/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5243 - categorical_accuracy: 0.9905 - val_loss: 1.1741 - val_categorical_accuracy: 0.6784\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.71701\n","Epoch 123/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5132 - categorical_accuracy: 0.9882 - val_loss: 1.1787 - val_categorical_accuracy: 0.7005\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.71701\n","Epoch 124/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4955 - categorical_accuracy: 0.9915 - val_loss: 1.1659 - val_categorical_accuracy: 0.6866\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.71701\n","Epoch 125/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4711 - categorical_accuracy: 0.9946 - val_loss: 1.1660 - val_categorical_accuracy: 0.7183\n","\n","Epoch 00125: val_categorical_accuracy improved from 0.71701 to 0.71832, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 126/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5081 - categorical_accuracy: 0.9895 - val_loss: 1.1696 - val_categorical_accuracy: 0.6745\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.71832\n","Epoch 127/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4995 - categorical_accuracy: 0.9858 - val_loss: 1.1713 - val_categorical_accuracy: 0.6723\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.71832\n","Epoch 128/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5010 - categorical_accuracy: 0.9801 - val_loss: 1.1666 - val_categorical_accuracy: 0.7023\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.71832\n","Epoch 129/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4662 - categorical_accuracy: 0.9899 - val_loss: 1.1653 - val_categorical_accuracy: 0.6732\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.71832\n","Epoch 130/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5136 - categorical_accuracy: 0.9717 - val_loss: 1.1639 - val_categorical_accuracy: 0.6832\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.71832\n","Epoch 131/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4996 - categorical_accuracy: 0.9870 - val_loss: 1.1623 - val_categorical_accuracy: 0.6988\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.71832\n","Epoch 132/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4986 - categorical_accuracy: 0.9907 - val_loss: 1.1605 - val_categorical_accuracy: 0.6918\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.71832\n","Epoch 133/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4627 - categorical_accuracy: 0.9911 - val_loss: 1.1556 - val_categorical_accuracy: 0.6849\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.71832\n","Epoch 134/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4779 - categorical_accuracy: 0.9915 - val_loss: 1.1549 - val_categorical_accuracy: 0.6719\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.71832\n","Epoch 135/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4536 - categorical_accuracy: 0.9893 - val_loss: 1.1626 - val_categorical_accuracy: 0.6662\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.71832\n","Epoch 136/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4770 - categorical_accuracy: 0.9865 - val_loss: 1.1472 - val_categorical_accuracy: 0.6901\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.71832\n","Epoch 137/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4681 - categorical_accuracy: 0.9935 - val_loss: 1.1501 - val_categorical_accuracy: 0.6749\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.71832\n","Epoch 138/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4474 - categorical_accuracy: 0.9916 - val_loss: 1.1445 - val_categorical_accuracy: 0.6966\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.71832\n","Epoch 139/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4635 - categorical_accuracy: 0.9903 - val_loss: 1.1612 - val_categorical_accuracy: 0.6623\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.71832\n","Epoch 140/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4813 - categorical_accuracy: 0.9772 - val_loss: 1.1472 - val_categorical_accuracy: 0.6936\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.71832\n","Epoch 141/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4466 - categorical_accuracy: 0.9938 - val_loss: 1.1561 - val_categorical_accuracy: 0.6793\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.71832\n","Epoch 142/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4596 - categorical_accuracy: 0.9862 - val_loss: 1.1393 - val_categorical_accuracy: 0.6944\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.71832\n","Epoch 143/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4438 - categorical_accuracy: 0.9848 - val_loss: 1.1425 - val_categorical_accuracy: 0.6849\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.71832\n","Epoch 144/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4395 - categorical_accuracy: 0.9866 - val_loss: 1.1355 - val_categorical_accuracy: 0.6975\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.71832\n","Epoch 145/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4503 - categorical_accuracy: 0.9908 - val_loss: 1.1416 - val_categorical_accuracy: 0.6797\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.71832\n","Epoch 146/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4285 - categorical_accuracy: 0.9928 - val_loss: 1.1355 - val_categorical_accuracy: 0.7005\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.71832\n","Epoch 147/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4229 - categorical_accuracy: 0.9904 - val_loss: 1.1368 - val_categorical_accuracy: 0.6832\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.71832\n","Epoch 148/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4449 - categorical_accuracy: 0.9845 - val_loss: 1.1331 - val_categorical_accuracy: 0.7148\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.71832\n","Epoch 149/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4288 - categorical_accuracy: 0.9830 - val_loss: 1.1377 - val_categorical_accuracy: 0.6780\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.71832\n","Epoch 150/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4266 - categorical_accuracy: 0.9933 - val_loss: 1.1445 - val_categorical_accuracy: 0.6606\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.71832\n","72/72 [==============================] - 0s 2ms/step - loss: 1.1660 - categorical_accuracy: 0.7183\n","72/72 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 75 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 8)   0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 8, 8)   0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 8, 8)   0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 64)     0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_3[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 1050.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [75 75 75 75 75 75 75 75 75 75 75 75 75 75]\n","\n","Total number of samples in test set 2094.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [195  26 176 140 194 194 184 128 239 173 201  58 166  20]\n","\n","X_train_transfer => (1050, 128)\n","X_test_transfer  => (2094, 128)\n","y_train => (1050, 14)\n","y_test  => (2094, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","53/53 [==============================] - 1s 9ms/step - loss: 3.2922 - categorical_accuracy: 0.0688 - val_loss: 2.5033 - val_categorical_accuracy: 0.1170\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.11700, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","53/53 [==============================] - 0s 7ms/step - loss: 2.4191 - categorical_accuracy: 0.2015 - val_loss: 2.3387 - val_categorical_accuracy: 0.3171\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.11700 to 0.31710, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","53/53 [==============================] - 0s 7ms/step - loss: 2.2260 - categorical_accuracy: 0.2842 - val_loss: 2.2724 - val_categorical_accuracy: 0.2875\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.31710\n","Epoch 4/150\n","53/53 [==============================] - 0s 6ms/step - loss: 2.1232 - categorical_accuracy: 0.3569 - val_loss: 2.1533 - val_categorical_accuracy: 0.3572\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.31710 to 0.35721, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.9972 - categorical_accuracy: 0.4375 - val_loss: 2.0805 - val_categorical_accuracy: 0.4126\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.35721 to 0.41261, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.9227 - categorical_accuracy: 0.4659 - val_loss: 2.0052 - val_categorical_accuracy: 0.5100\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.41261 to 0.51003, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.8227 - categorical_accuracy: 0.5566 - val_loss: 1.9556 - val_categorical_accuracy: 0.4656\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.51003\n","Epoch 8/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.7808 - categorical_accuracy: 0.5357 - val_loss: 1.9057 - val_categorical_accuracy: 0.4823\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.51003\n","Epoch 9/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.7792 - categorical_accuracy: 0.5631 - val_loss: 1.9026 - val_categorical_accuracy: 0.4298\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.51003\n","Epoch 10/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.6774 - categorical_accuracy: 0.6131 - val_loss: 1.8380 - val_categorical_accuracy: 0.5033\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.51003\n","Epoch 11/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.6003 - categorical_accuracy: 0.6221 - val_loss: 1.8194 - val_categorical_accuracy: 0.4446\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.51003\n","Epoch 12/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.5908 - categorical_accuracy: 0.6971 - val_loss: 1.8000 - val_categorical_accuracy: 0.4331\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.51003\n","Epoch 13/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.5451 - categorical_accuracy: 0.6461 - val_loss: 1.7663 - val_categorical_accuracy: 0.4995\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.51003\n","Epoch 14/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.4797 - categorical_accuracy: 0.6909 - val_loss: 1.7270 - val_categorical_accuracy: 0.4632\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.51003\n","Epoch 15/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.4972 - categorical_accuracy: 0.7018 - val_loss: 1.7129 - val_categorical_accuracy: 0.5597\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.51003 to 0.55969, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.4539 - categorical_accuracy: 0.7425 - val_loss: 1.6875 - val_categorical_accuracy: 0.5272\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.55969\n","Epoch 17/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.3988 - categorical_accuracy: 0.7517 - val_loss: 1.6736 - val_categorical_accuracy: 0.5344\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.55969\n","Epoch 18/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.3797 - categorical_accuracy: 0.7927 - val_loss: 1.6346 - val_categorical_accuracy: 0.5931\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.55969 to 0.59312, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 19/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.3917 - categorical_accuracy: 0.8137 - val_loss: 1.6355 - val_categorical_accuracy: 0.5597\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.59312\n","Epoch 20/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.3454 - categorical_accuracy: 0.8067 - val_loss: 1.6408 - val_categorical_accuracy: 0.5062\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.59312\n","Epoch 21/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.3130 - categorical_accuracy: 0.7960 - val_loss: 1.5987 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.59312 to 0.62607, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.2945 - categorical_accuracy: 0.8916 - val_loss: 1.5983 - val_categorical_accuracy: 0.5205\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.62607\n","Epoch 23/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.2881 - categorical_accuracy: 0.7977 - val_loss: 1.5956 - val_categorical_accuracy: 0.5162\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.62607\n","Epoch 24/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.2496 - categorical_accuracy: 0.7989 - val_loss: 1.5581 - val_categorical_accuracy: 0.5898\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.62607\n","Epoch 25/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.2681 - categorical_accuracy: 0.8873 - val_loss: 1.5485 - val_categorical_accuracy: 0.5587\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.62607\n","Epoch 26/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.2050 - categorical_accuracy: 0.8218 - val_loss: 1.5368 - val_categorical_accuracy: 0.5974\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.62607\n","Epoch 27/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.1869 - categorical_accuracy: 0.8776 - val_loss: 1.5086 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.62607\n","Epoch 28/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.1851 - categorical_accuracy: 0.8950 - val_loss: 1.4983 - val_categorical_accuracy: 0.6409\n","\n","Epoch 00028: val_categorical_accuracy improved from 0.62607 to 0.64088, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 29/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.1614 - categorical_accuracy: 0.8935 - val_loss: 1.4834 - val_categorical_accuracy: 0.6103\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.64088\n","Epoch 30/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.1457 - categorical_accuracy: 0.9065 - val_loss: 1.5055 - val_categorical_accuracy: 0.6566\n","\n","Epoch 00030: val_categorical_accuracy improved from 0.64088 to 0.65664, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 31/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.1516 - categorical_accuracy: 0.8904 - val_loss: 1.5009 - val_categorical_accuracy: 0.5931\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.65664\n","Epoch 32/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.1490 - categorical_accuracy: 0.8684 - val_loss: 1.4709 - val_categorical_accuracy: 0.5888\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.65664\n","Epoch 33/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0841 - categorical_accuracy: 0.8874 - val_loss: 1.4516 - val_categorical_accuracy: 0.6409\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.65664\n","Epoch 34/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.0693 - categorical_accuracy: 0.9165 - val_loss: 1.4449 - val_categorical_accuracy: 0.6390\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.65664\n","Epoch 35/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0617 - categorical_accuracy: 0.8939 - val_loss: 1.4395 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.65664\n","Epoch 36/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0553 - categorical_accuracy: 0.9125 - val_loss: 1.4293 - val_categorical_accuracy: 0.6232\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.65664\n","Epoch 37/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.0285 - categorical_accuracy: 0.9023 - val_loss: 1.4343 - val_categorical_accuracy: 0.6156\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.65664\n","Epoch 38/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0159 - categorical_accuracy: 0.9183 - val_loss: 1.4174 - val_categorical_accuracy: 0.6490\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.65664\n","Epoch 39/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.0066 - categorical_accuracy: 0.9419 - val_loss: 1.4311 - val_categorical_accuracy: 0.5821\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.65664\n","Epoch 40/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.9864 - categorical_accuracy: 0.9097 - val_loss: 1.4057 - val_categorical_accuracy: 0.6490\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.65664\n","Epoch 41/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.9900 - categorical_accuracy: 0.9379 - val_loss: 1.3774 - val_categorical_accuracy: 0.6662\n","\n","Epoch 00041: val_categorical_accuracy improved from 0.65664 to 0.66619, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 42/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9623 - categorical_accuracy: 0.9380 - val_loss: 1.3915 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.66619\n","Epoch 43/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9713 - categorical_accuracy: 0.9120 - val_loss: 1.3799 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.66619\n","Epoch 44/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9869 - categorical_accuracy: 0.9042 - val_loss: 1.3908 - val_categorical_accuracy: 0.6557\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.66619\n","Epoch 45/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9305 - categorical_accuracy: 0.9425 - val_loss: 1.3863 - val_categorical_accuracy: 0.6595\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.66619\n","Epoch 46/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9400 - categorical_accuracy: 0.9268 - val_loss: 1.3635 - val_categorical_accuracy: 0.6103\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.66619\n","Epoch 47/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9123 - categorical_accuracy: 0.9382 - val_loss: 1.3539 - val_categorical_accuracy: 0.6619\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.66619\n","Epoch 48/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9395 - categorical_accuracy: 0.9320 - val_loss: 1.3630 - val_categorical_accuracy: 0.6084\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.66619\n","Epoch 49/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8982 - categorical_accuracy: 0.9368 - val_loss: 1.3437 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.66619\n","Epoch 50/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8776 - categorical_accuracy: 0.9390 - val_loss: 1.3246 - val_categorical_accuracy: 0.6619\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.66619\n","Epoch 51/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8642 - categorical_accuracy: 0.9297 - val_loss: 1.3353 - val_categorical_accuracy: 0.6609\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.66619\n","Epoch 52/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8923 - categorical_accuracy: 0.9129 - val_loss: 1.3164 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.66619\n","Epoch 53/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8570 - categorical_accuracy: 0.9481 - val_loss: 1.3208 - val_categorical_accuracy: 0.6648\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.66619\n","Epoch 54/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8534 - categorical_accuracy: 0.9564 - val_loss: 1.3159 - val_categorical_accuracy: 0.6361\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.66619\n","Epoch 55/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8422 - categorical_accuracy: 0.9327 - val_loss: 1.3075 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00055: val_categorical_accuracy improved from 0.66619 to 0.68768, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 56/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.7993 - categorical_accuracy: 0.9538 - val_loss: 1.2917 - val_categorical_accuracy: 0.6691\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.68768\n","Epoch 57/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8285 - categorical_accuracy: 0.9532 - val_loss: 1.2936 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00057: val_categorical_accuracy improved from 0.68768 to 0.69293, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 58/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7785 - categorical_accuracy: 0.9528 - val_loss: 1.3088 - val_categorical_accuracy: 0.6691\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.69293\n","Epoch 59/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8253 - categorical_accuracy: 0.9408 - val_loss: 1.2784 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.69293\n","Epoch 60/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.7912 - categorical_accuracy: 0.9488 - val_loss: 1.2637 - val_categorical_accuracy: 0.6920\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.69293\n","Epoch 61/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7641 - categorical_accuracy: 0.9566 - val_loss: 1.2853 - val_categorical_accuracy: 0.6461\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.69293\n","Epoch 62/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.7864 - categorical_accuracy: 0.9497 - val_loss: 1.2823 - val_categorical_accuracy: 0.6681\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.69293\n","Epoch 63/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7781 - categorical_accuracy: 0.9541 - val_loss: 1.2510 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.69293\n","Epoch 64/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7373 - categorical_accuracy: 0.9606 - val_loss: 1.2589 - val_categorical_accuracy: 0.6676\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.69293\n","Epoch 65/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.7694 - categorical_accuracy: 0.9552 - val_loss: 1.2750 - val_categorical_accuracy: 0.6882\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.69293\n","Epoch 66/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7207 - categorical_accuracy: 0.9480 - val_loss: 1.2495 - val_categorical_accuracy: 0.6862\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.69293\n","Epoch 67/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7512 - categorical_accuracy: 0.9610 - val_loss: 1.2469 - val_categorical_accuracy: 0.6691\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.69293\n","Epoch 68/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7200 - categorical_accuracy: 0.9445 - val_loss: 1.2576 - val_categorical_accuracy: 0.6777\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.69293\n","Epoch 69/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7406 - categorical_accuracy: 0.9571 - val_loss: 1.2549 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.69293\n","Epoch 70/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.7146 - categorical_accuracy: 0.9665 - val_loss: 1.2226 - val_categorical_accuracy: 0.6910\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.69293\n","Epoch 71/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7098 - categorical_accuracy: 0.9706 - val_loss: 1.2455 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00071: val_categorical_accuracy improved from 0.69293 to 0.69532, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 72/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6947 - categorical_accuracy: 0.9613 - val_loss: 1.2302 - val_categorical_accuracy: 0.6824\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.69532\n","Epoch 73/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6702 - categorical_accuracy: 0.9559 - val_loss: 1.2209 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.69532\n","Epoch 74/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6804 - categorical_accuracy: 0.9720 - val_loss: 1.2239 - val_categorical_accuracy: 0.6657\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.69532\n","Epoch 75/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6594 - categorical_accuracy: 0.9627 - val_loss: 1.2022 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.69532\n","Epoch 76/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6762 - categorical_accuracy: 0.9668 - val_loss: 1.2016 - val_categorical_accuracy: 0.6958\n","\n","Epoch 00076: val_categorical_accuracy improved from 0.69532 to 0.69580, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 77/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6523 - categorical_accuracy: 0.9684 - val_loss: 1.2092 - val_categorical_accuracy: 0.6819\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.69580\n","Epoch 78/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6620 - categorical_accuracy: 0.9702 - val_loss: 1.2144 - val_categorical_accuracy: 0.6777\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.69580\n","Epoch 79/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6499 - categorical_accuracy: 0.9688 - val_loss: 1.1881 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.69580\n","Epoch 80/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6279 - categorical_accuracy: 0.9762 - val_loss: 1.2161 - val_categorical_accuracy: 0.6834\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.69580\n","Epoch 81/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6121 - categorical_accuracy: 0.9649 - val_loss: 1.1824 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.69580\n","Epoch 82/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6389 - categorical_accuracy: 0.9646 - val_loss: 1.1727 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00082: val_categorical_accuracy improved from 0.69580 to 0.70153, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 83/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6216 - categorical_accuracy: 0.9763 - val_loss: 1.1699 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00083: val_categorical_accuracy improved from 0.70153 to 0.70248, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 84/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6054 - categorical_accuracy: 0.9661 - val_loss: 1.1860 - val_categorical_accuracy: 0.6710\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.70248\n","Epoch 85/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6240 - categorical_accuracy: 0.9656 - val_loss: 1.1785 - val_categorical_accuracy: 0.6867\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.70248\n","Epoch 86/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5919 - categorical_accuracy: 0.9738 - val_loss: 1.1765 - val_categorical_accuracy: 0.6991\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.70248\n","Epoch 87/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6066 - categorical_accuracy: 0.9677 - val_loss: 1.1675 - val_categorical_accuracy: 0.6948\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.70248\n","Epoch 88/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5895 - categorical_accuracy: 0.9717 - val_loss: 1.1769 - val_categorical_accuracy: 0.6800\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.70248\n","Epoch 89/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6092 - categorical_accuracy: 0.9656 - val_loss: 1.1687 - val_categorical_accuracy: 0.6724\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.70248\n","Epoch 90/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5922 - categorical_accuracy: 0.9732 - val_loss: 1.1500 - val_categorical_accuracy: 0.7053\n","\n","Epoch 00090: val_categorical_accuracy improved from 0.70248 to 0.70535, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 91/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5687 - categorical_accuracy: 0.9712 - val_loss: 1.1667 - val_categorical_accuracy: 0.7049\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.70535\n","Epoch 92/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5805 - categorical_accuracy: 0.9612 - val_loss: 1.1676 - val_categorical_accuracy: 0.7049\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.70535\n","Epoch 93/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5703 - categorical_accuracy: 0.9670 - val_loss: 1.1698 - val_categorical_accuracy: 0.6987\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.70535\n","Epoch 94/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5852 - categorical_accuracy: 0.9626 - val_loss: 1.1495 - val_categorical_accuracy: 0.6972\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.70535\n","Epoch 95/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5854 - categorical_accuracy: 0.9775 - val_loss: 1.1659 - val_categorical_accuracy: 0.7096\n","\n","Epoch 00095: val_categorical_accuracy improved from 0.70535 to 0.70965, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 96/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5530 - categorical_accuracy: 0.9756 - val_loss: 1.1541 - val_categorical_accuracy: 0.6786\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.70965\n","Epoch 97/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5496 - categorical_accuracy: 0.9764 - val_loss: 1.1446 - val_categorical_accuracy: 0.6934\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.70965\n","Epoch 98/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5727 - categorical_accuracy: 0.9675 - val_loss: 1.1356 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.70965\n","Epoch 99/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5454 - categorical_accuracy: 0.9675 - val_loss: 1.1398 - val_categorical_accuracy: 0.6939\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.70965\n","Epoch 100/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5272 - categorical_accuracy: 0.9719 - val_loss: 1.1293 - val_categorical_accuracy: 0.6925\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.70965\n","Epoch 101/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5397 - categorical_accuracy: 0.9712 - val_loss: 1.1307 - val_categorical_accuracy: 0.6853\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.70965\n","Epoch 102/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5239 - categorical_accuracy: 0.9741 - val_loss: 1.1139 - val_categorical_accuracy: 0.7116\n","\n","Epoch 00102: val_categorical_accuracy improved from 0.70965 to 0.71156, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 103/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5243 - categorical_accuracy: 0.9679 - val_loss: 1.1382 - val_categorical_accuracy: 0.7011\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.71156\n","Epoch 104/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5273 - categorical_accuracy: 0.9701 - val_loss: 1.1351 - val_categorical_accuracy: 0.6886\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.71156\n","Epoch 105/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5100 - categorical_accuracy: 0.9799 - val_loss: 1.1187 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.71156\n","Epoch 106/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5023 - categorical_accuracy: 0.9822 - val_loss: 1.1092 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.71156\n","Epoch 107/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5041 - categorical_accuracy: 0.9770 - val_loss: 1.1223 - val_categorical_accuracy: 0.6886\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.71156\n","Epoch 108/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4975 - categorical_accuracy: 0.9746 - val_loss: 1.1044 - val_categorical_accuracy: 0.7077\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.71156\n","Epoch 109/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4901 - categorical_accuracy: 0.9782 - val_loss: 1.0977 - val_categorical_accuracy: 0.7068\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.71156\n","Epoch 110/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4903 - categorical_accuracy: 0.9748 - val_loss: 1.1171 - val_categorical_accuracy: 0.6882\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.71156\n","Epoch 111/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4868 - categorical_accuracy: 0.9804 - val_loss: 1.1198 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.71156\n","Epoch 112/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4915 - categorical_accuracy: 0.9782 - val_loss: 1.1064 - val_categorical_accuracy: 0.6958\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.71156\n","Epoch 113/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4684 - categorical_accuracy: 0.9742 - val_loss: 1.1154 - val_categorical_accuracy: 0.6829\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.71156\n","Epoch 114/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4696 - categorical_accuracy: 0.9732 - val_loss: 1.1117 - val_categorical_accuracy: 0.6920\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.71156\n","Epoch 115/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4562 - categorical_accuracy: 0.9891 - val_loss: 1.0889 - val_categorical_accuracy: 0.7049\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.71156\n","Epoch 116/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4686 - categorical_accuracy: 0.9742 - val_loss: 1.0996 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.71156\n","Epoch 117/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4709 - categorical_accuracy: 0.9748 - val_loss: 1.0945 - val_categorical_accuracy: 0.6968\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.71156\n","Epoch 118/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4608 - categorical_accuracy: 0.9765 - val_loss: 1.0910 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.71156\n","Epoch 119/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4612 - categorical_accuracy: 0.9776 - val_loss: 1.0909 - val_categorical_accuracy: 0.6934\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.71156\n","Epoch 120/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4385 - categorical_accuracy: 0.9788 - val_loss: 1.1028 - val_categorical_accuracy: 0.6915\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.71156\n","Epoch 121/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4472 - categorical_accuracy: 0.9789 - val_loss: 1.0658 - val_categorical_accuracy: 0.7120\n","\n","Epoch 00121: val_categorical_accuracy improved from 0.71156 to 0.71203, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 122/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4319 - categorical_accuracy: 0.9876 - val_loss: 1.1034 - val_categorical_accuracy: 0.6996\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.71203\n","Epoch 123/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4409 - categorical_accuracy: 0.9765 - val_loss: 1.0744 - val_categorical_accuracy: 0.7030\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.71203\n","Epoch 124/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4386 - categorical_accuracy: 0.9832 - val_loss: 1.0987 - val_categorical_accuracy: 0.6915\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.71203\n","Epoch 125/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4342 - categorical_accuracy: 0.9745 - val_loss: 1.0927 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.71203\n","Epoch 126/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4432 - categorical_accuracy: 0.9757 - val_loss: 1.0930 - val_categorical_accuracy: 0.6963\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.71203\n","Epoch 127/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4315 - categorical_accuracy: 0.9826 - val_loss: 1.0874 - val_categorical_accuracy: 0.7020\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.71203\n","Epoch 128/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4073 - categorical_accuracy: 0.9808 - val_loss: 1.0599 - val_categorical_accuracy: 0.7216\n","\n","Epoch 00128: val_categorical_accuracy improved from 0.71203 to 0.72159, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_8//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 129/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4239 - categorical_accuracy: 0.9798 - val_loss: 1.0761 - val_categorical_accuracy: 0.7077\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.72159\n","Epoch 130/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4121 - categorical_accuracy: 0.9754 - val_loss: 1.0587 - val_categorical_accuracy: 0.7106\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.72159\n","Epoch 131/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4173 - categorical_accuracy: 0.9892 - val_loss: 1.0674 - val_categorical_accuracy: 0.7116\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.72159\n","Epoch 132/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4130 - categorical_accuracy: 0.9692 - val_loss: 1.0852 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.72159\n","Epoch 133/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4045 - categorical_accuracy: 0.9780 - val_loss: 1.0685 - val_categorical_accuracy: 0.7006\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.72159\n","Epoch 134/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4107 - categorical_accuracy: 0.9847 - val_loss: 1.0593 - val_categorical_accuracy: 0.7082\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.72159\n","Epoch 135/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4179 - categorical_accuracy: 0.9717 - val_loss: 1.0776 - val_categorical_accuracy: 0.6858\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.72159\n","Epoch 136/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3903 - categorical_accuracy: 0.9841 - val_loss: 1.0634 - val_categorical_accuracy: 0.7058\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.72159\n","Epoch 137/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4029 - categorical_accuracy: 0.9861 - val_loss: 1.0767 - val_categorical_accuracy: 0.7082\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.72159\n","Epoch 138/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3897 - categorical_accuracy: 0.9720 - val_loss: 1.0678 - val_categorical_accuracy: 0.7101\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.72159\n","Epoch 139/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3897 - categorical_accuracy: 0.9774 - val_loss: 1.0548 - val_categorical_accuracy: 0.7039\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.72159\n","Epoch 140/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3889 - categorical_accuracy: 0.9776 - val_loss: 1.0534 - val_categorical_accuracy: 0.7034\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.72159\n","Epoch 141/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3812 - categorical_accuracy: 0.9887 - val_loss: 1.0628 - val_categorical_accuracy: 0.7082\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.72159\n","Epoch 142/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3891 - categorical_accuracy: 0.9790 - val_loss: 1.0653 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.72159\n","Epoch 143/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3765 - categorical_accuracy: 0.9827 - val_loss: 1.0460 - val_categorical_accuracy: 0.6939\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.72159\n","Epoch 144/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3825 - categorical_accuracy: 0.9867 - val_loss: 1.0503 - val_categorical_accuracy: 0.7106\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.72159\n","Epoch 145/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3615 - categorical_accuracy: 0.9899 - val_loss: 1.0621 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.72159\n","Epoch 146/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3781 - categorical_accuracy: 0.9786 - val_loss: 1.0467 - val_categorical_accuracy: 0.7020\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.72159\n","Epoch 147/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3485 - categorical_accuracy: 0.9921 - val_loss: 1.0333 - val_categorical_accuracy: 0.7001\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.72159\n","Epoch 148/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3757 - categorical_accuracy: 0.9905 - val_loss: 1.0438 - val_categorical_accuracy: 0.7025\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.72159\n","Epoch 149/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3648 - categorical_accuracy: 0.9860 - val_loss: 1.0444 - val_categorical_accuracy: 0.7087\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.72159\n","Epoch 150/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3595 - categorical_accuracy: 0.9809 - val_loss: 1.0390 - val_categorical_accuracy: 0.7030\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.72159\n","66/66 [==============================] - 0s 2ms/step - loss: 1.0599 - categorical_accuracy: 0.7216\n","66/66 [==============================] - 0s 1ms/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VdgxRQRP0_mp"},"source":["# Transfer Learning results on Botswana"]},{"cell_type":"code","metadata":{"id":"R_WJcBsGjtRA","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1615786830104,"user_tz":420,"elapsed":396,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"8a3294ba-3cae-45dd-b7fa-b8989f2d70bb"},"source":["transfer_results"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training samples per class finetuning</th>\n","      <th>Training Samples per class pretraining</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15</td>\n","      <td>200</td>\n","      <td>210</td>\n","      <td>2934</td>\n","      <td>66.84</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>30</td>\n","      <td>200</td>\n","      <td>420</td>\n","      <td>2724</td>\n","      <td>66.84</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45</td>\n","      <td>200</td>\n","      <td>630</td>\n","      <td>2514</td>\n","      <td>70.67</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60</td>\n","      <td>200</td>\n","      <td>840</td>\n","      <td>2304</td>\n","      <td>70.67</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>75</td>\n","      <td>200</td>\n","      <td>1050</td>\n","      <td>2094</td>\n","      <td>71.92</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Training samples per class finetuning  ...  Test_Accuracies\n","0                                     15  ...            66.84\n","1                                     30  ...            66.84\n","2                                     45  ...            70.67\n","3                                     60  ...            70.67\n","4                                     75  ...            71.92\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"1o6mCjHJ01PG"},"source":["# Classification accuracies per class for each model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"BjFASZ9hw-gi","executionInfo":{"status":"ok","timestamp":1615786841906,"user_tz":420,"elapsed":507,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"d49ef74f-780c-41e4-d318-80ba7b1885ab"},"source":["confusion_matrixes[0]"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>61</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66.67</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>85</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>98.84</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>148</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25.42</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>183</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>91.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>107</td>\n","      <td>11</td>\n","      <td>32</td>\n","      <td>17</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>42.13</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>136</td>\n","      <td>0</td>\n","      <td>18.9</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>216</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.52</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>98</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>64</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>52.13</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>250</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>36</td>\n","      <td>0</td>\n","      <td>83.61</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>185</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>79.4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>233</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>89.27</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>111</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94.07</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>75</td>\n","      <td>151</td>\n","      <td>0</td>\n","      <td>66.81</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64</td>\n","      <td>80.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>255</td>\n","      <td>86</td>\n","      <td>236</td>\n","      <td>200</td>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>244</td>\n","      <td>188</td>\n","      <td>299</td>\n","      <td>233</td>\n","      <td>261</td>\n","      <td>118</td>\n","      <td>226</td>\n","      <td>80</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              170   0    0    0  ...    0    0   0                     66.67\n","1                0  85    0    1  ...    0    0   0                     98.84\n","2                0   0   60  148  ...    0    0   0                     25.42\n","3                0  15    1  183  ...    0    1   0                      91.5\n","4               16  16    0   22  ...    0    8   0                     42.13\n","5                0  18    0    7  ...    1  136   0                      18.9\n","6               28   0    0    0  ...    0    0   0                     88.52\n","7                0   0    0    0  ...   64   13   0                     52.13\n","8                0   0    0    0  ...    0   36   0                     83.61\n","9                0   0    0    0  ...    0    3   0                      79.4\n","10               0   0    0    0  ...    0    0   0                     89.27\n","11               0   0    0    0  ...  111    0   0                     94.07\n","12               0   0    0    0  ...   75  151   0                     66.81\n","13               0   0    0    0  ...    0    0  64                      80.0\n","Total Samples  255  86  236  200  ...  118  226  80                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"rh3wq7nYxm1U","executionInfo":{"status":"ok","timestamp":1615786845900,"user_tz":420,"elapsed":430,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"aa4a2876-e920-4381-9682-bd335bd3cf4e"},"source":["confusion_matrixes[1]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>155</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64.58</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>71</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>78</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>54.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>3</td>\n","      <td>159</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>85.95</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>21</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>21</td>\n","      <td>104</td>\n","      <td>8</td>\n","      <td>17</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>43.51</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>135</td>\n","      <td>0</td>\n","      <td>14.64</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>203</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.65</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>28</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>80.92</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>230</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>80.99</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>199</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>91.28</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86.18</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>101</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>98.06</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64</td>\n","      <td>147</td>\n","      <td>0</td>\n","      <td>69.67</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>75.38</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>240</td>\n","      <td>71</td>\n","      <td>221</td>\n","      <td>185</td>\n","      <td>239</td>\n","      <td>239</td>\n","      <td>229</td>\n","      <td>173</td>\n","      <td>284</td>\n","      <td>218</td>\n","      <td>246</td>\n","      <td>103</td>\n","      <td>211</td>\n","      <td>65</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              155   0    0    0  ...    0    0   0                     64.58\n","1                0  71    0    0  ...    0    0   0                     100.0\n","2                0   0  120   78  ...    0    0   0                      54.3\n","3                0  12    3  159  ...    0   11   0                     85.95\n","4               21  15    1   21  ...    0    8   0                     43.51\n","5                0  14    0    7  ...    5  135   0                     14.64\n","6               26   0    0    0  ...    0    0   0                     88.65\n","7                0   0    0    0  ...   28    2   0                     80.92\n","8                0   0    0    4  ...    0   35   0                     80.99\n","9                0   0    0    0  ...    0    0   0                     91.28\n","10               0   0    0    0  ...    0    0   0                     86.18\n","11               0   0    0    0  ...  101    0   0                     98.06\n","12               0   0    0    0  ...   64  147   0                     69.67\n","13               0   0    0    0  ...    0    0  49                     75.38\n","Total Samples  240  71  221  185  ...  103  211  65                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"0DyVuVJbyY9Q","executionInfo":{"status":"ok","timestamp":1615786847022,"user_tz":420,"elapsed":389,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"176d3dc6-6780-45a0-9bf1-c8d3519adba1"},"source":["confusion_matrixes[2]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>157</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>65</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>69.78</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>164</td>\n","      <td>21</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>79.61</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>114</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>67.06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>23</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>91</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>40.62</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>51</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>11.61</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>192</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>89.72</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>136</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>86.08</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>78.44</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>201</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>99.01</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>196</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>84.85</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>87</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>98.86</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>143</td>\n","      <td>0</td>\n","      <td>72.96</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>225</td>\n","      <td>56</td>\n","      <td>206</td>\n","      <td>170</td>\n","      <td>224</td>\n","      <td>224</td>\n","      <td>214</td>\n","      <td>158</td>\n","      <td>269</td>\n","      <td>203</td>\n","      <td>231</td>\n","      <td>88</td>\n","      <td>196</td>\n","      <td>50</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              157   0    0    0  ...   0    0   0                     69.78\n","1                0  56    0    0  ...   0    0   0                     100.0\n","2                0   0  164   21  ...   0    0   0                     79.61\n","3                0   9    6  114  ...   0   41   0                     67.06\n","4               23  10    1   19  ...   0    9   0                     40.62\n","5                0  14    0    0  ...   2  130   0                     11.61\n","6               22   0    0    0  ...   0    0   0                     89.72\n","7                0   0    0    0  ...  19    1   0                     86.08\n","8                0  16    0    0  ...   0   25   0                     78.44\n","9                0   0    0    0  ...   0    0   0                     99.01\n","10               0   0    0    0  ...   0    0   0                     84.85\n","11               0   0    0    0  ...  87    0   0                     98.86\n","12               0   0    0    0  ...  53  143   0                     72.96\n","13               0   0    0    0  ...   0    0  34                      68.0\n","Total Samples  225  56  206  170  ...  88  196  50                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"zxx7uWOPyb4r","executionInfo":{"status":"ok","timestamp":1615786848533,"user_tz":420,"elapsed":389,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"9d2c29dd-da38-439c-df5d-1ae4a62e175d"},"source":["confusion_matrixes[3]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>140</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66.67</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>141</td>\n","      <td>29</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>73.82</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>96</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>61.94</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>18</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>107</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>51.2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>51</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>127</td>\n","      <td>0</td>\n","      <td>7.18</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>189</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94.97</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>126</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.11</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>214</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>84.25</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>183</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>97.34</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>181</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83.8</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>71.82</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>54.29</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>210</td>\n","      <td>41</td>\n","      <td>191</td>\n","      <td>155</td>\n","      <td>209</td>\n","      <td>209</td>\n","      <td>199</td>\n","      <td>143</td>\n","      <td>254</td>\n","      <td>188</td>\n","      <td>216</td>\n","      <td>73</td>\n","      <td>181</td>\n","      <td>35</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              140   0    0    0  ...   0    0   0                     66.67\n","1                0  41    0    0  ...   0    0   0                     100.0\n","2                0   0  141   29  ...   0    0   0                     73.82\n","3                0   0    1   96  ...   0   58   0                     61.94\n","4               18   4    0   26  ...   0    7   0                      51.2\n","5                0  13    0    0  ...   1  127   0                      7.18\n","6               10   0    0    0  ...   0    0   0                     94.97\n","7                0   0    0    0  ...  15    0   0                     88.11\n","8                0  13    0    0  ...   0   11   0                     84.25\n","9                0   0    0    0  ...   0    0   0                     97.34\n","10               0   0    0    0  ...   0    0   0                      83.8\n","11               0   0    0    0  ...  73    0   0                     100.0\n","12               0   0    0    0  ...  51  130   0                     71.82\n","13               1   0    0    0  ...   0    0  19                     54.29\n","Total Samples  210  41  191  155  ...  73  181  35                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"CkclPakQyc_X","executionInfo":{"status":"ok","timestamp":1615786849913,"user_tz":420,"elapsed":379,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"9f354637-2ab3-4c1b-fb11-113961645e79"},"source":["confusion_matrixes[4]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>95</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>53.98</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>0</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>103</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>53.09</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>128</td>\n","      <td>0</td>\n","      <td>9.28</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>184</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>127</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99.22</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>199</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>83.26</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>169</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>97.69</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>167</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83.08</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>119</td>\n","      <td>0</td>\n","      <td>71.69</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>195</td>\n","      <td>26</td>\n","      <td>176</td>\n","      <td>140</td>\n","      <td>194</td>\n","      <td>194</td>\n","      <td>184</td>\n","      <td>128</td>\n","      <td>239</td>\n","      <td>173</td>\n","      <td>201</td>\n","      <td>58</td>\n","      <td>166</td>\n","      <td>20</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              172   0    0    0  ...   0    0   0                     88.21\n","1                0  26    0    0  ...   0    0   0                     100.0\n","2                0   0   95   45  ...   0    0   0                     53.98\n","3                0   0    0   70  ...   0   70   0                      50.0\n","4               17   5    5   12  ...   0   12   0                     53.09\n","5                0   9    0    0  ...   0  128   0                      9.28\n","6                0   0    0    0  ...   0    0   0                     100.0\n","7                0   0    0    0  ...   0    1   0                     99.22\n","8                0  16    0    0  ...   0    7   0                     83.26\n","9                0   0    0    0  ...   0    0   0                     97.69\n","10               0   0    0    0  ...   0    0   0                     83.08\n","11               0   0    0    0  ...  58    0   0                     100.0\n","12               0   0    0    0  ...  45  119   0                     71.69\n","13               2   0    0    0  ...   0    0   4                      20.0\n","Total Samples  195  26  176  140  ...  58  166  20                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"LihPwReQyd_1","executionInfo":{"status":"ok","timestamp":1615786851270,"user_tz":420,"elapsed":317,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":[""],"execution_count":26,"outputs":[]}]}