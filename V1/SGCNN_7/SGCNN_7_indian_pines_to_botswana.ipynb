{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SGCNN_7_indian_pines_to_botswana.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_nG8NlV-lz-"},"source":["## Set up google colab environment"]},{"cell_type":"code","metadata":{"id":"9bq_kqWQtg0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615783726287,"user_tz":420,"elapsed":685,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0866ac0d-f5d3-4bc2-b19a-f590ed290e26"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK95udG-qHAy","executionInfo":{"status":"ok","timestamp":1615784510190,"user_tz":420,"elapsed":1176,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification/V1')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn-wRAH4t3WY","executionInfo":{"status":"ok","timestamp":1615784513906,"user_tz":420,"elapsed":2939,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["from sample_extraction_V1_SGCNN_7 import *\n","import scipy.io as sio"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky2Qzuw_qDdS"},"source":["## Load Indian Pines Dataset - Source"]},{"cell_type":"code","metadata":{"id":"svwF-yzh-l0N","executionInfo":{"status":"ok","timestamp":1615784513907,"user_tz":420,"elapsed":2086,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uIndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_corrected.mat')\n","gt_IndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_gt.mat')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLGpYj4P-l0N","executionInfo":{"status":"ok","timestamp":1615784513908,"user_tz":420,"elapsed":1757,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_source = uIndianPines['indian_pines_corrected']\n","ground_truth_source = gt_IndianPines['indian_pines_gt']"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHQe_Xhwza79","executionInfo":{"status":"ok","timestamp":1615784513910,"user_tz":420,"elapsed":1405,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"94b2ef4f-fe8f-4dd0-9f96-850f98af7acf"},"source":["data_source.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145, 200)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAjjOxj3qDdb","executionInfo":{"status":"ok","timestamp":1615784513911,"user_tz":420,"elapsed":657,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"5adfa4d8-8831-441d-b66b-6e61476dcf80"},"source":["ground_truth_source.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"wmLGB_VlWx6m"},"source":["# Load target dataset"]},{"cell_type":"code","metadata":{"id":"qu6T10joWpmQ","executionInfo":{"status":"ok","timestamp":1615784516290,"user_tz":420,"elapsed":2204,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uBotswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana.mat')\n","gt_Botswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana_gt.mat')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"09gPGGX8W2Us","executionInfo":{"status":"ok","timestamp":1615784516291,"user_tz":420,"elapsed":1775,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_target = uBotswana['Botswana']\n","ground_truth_target = gt_Botswana['Botswana_gt']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qG_LxbHeXBVQ","executionInfo":{"status":"ok","timestamp":1615784516292,"user_tz":420,"elapsed":1438,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"195bfff5-af95-41cc-a29b-f2cfe1fca60f"},"source":["data_target.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256, 145)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYillUc_XDKC","executionInfo":{"status":"ok","timestamp":1615784516294,"user_tz":420,"elapsed":1001,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"3d413623-d75c-4c05-8486-d613cf730e28"},"source":["ground_truth_target.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"5WxjgWNGqDdc"},"source":["## Distrubution of samples for each class in Source"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"yFA7eqA7qDdd","executionInfo":{"status":"ok","timestamp":1615784519153,"user_tz":420,"elapsed":1103,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"a3982660-6b73-4191-b81d-d5433cb6f283"},"source":["class_distribution_source = pd.DataFrame(np.unique(ground_truth_source, return_counts = True))\n","class_distribution_source = class_distribution_source.transpose()\n","class_distribution_source.columns = ['class','samples']\n","class_distribution_source"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>830</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>483</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>730</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>478</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>972</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2455</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>1265</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>386</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0    10776\n","1       1       46\n","2       2     1428\n","3       3      830\n","4       4      237\n","5       5      483\n","6       6      730\n","7       7       28\n","8       8      478\n","9       9       20\n","10     10      972\n","11     11     2455\n","12     12      593\n","13     13      205\n","14     14     1265\n","15     15      386\n","16     16       93"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"7zTsq-yPqDdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615784519504,"user_tz":420,"elapsed":551,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"21d3da1a-a52d-4bdc-8e3a-aa6d4b24b684"},"source":["classes_source , counts_source = np.unique(ground_truth_source, return_counts = True)\n","classes_source = classes_source[[2,3,5,6,8,10,11,12,14]] ## Dropping classes with small number of samples\n","classes_source"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2,  3,  5,  6,  8, 10, 11, 12, 14], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"lwQmdin9Xmeg"},"source":["# Class distribution of samples in Target"]},{"cell_type":"code","metadata":{"id":"8EjIMOQHXU3h","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"ok","timestamp":1615784522177,"user_tz":420,"elapsed":703,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"ae128b73-f3e4-4a64-b229-f9f6079eabac"},"source":["class_distribution_target = pd.DataFrame(np.unique(ground_truth_target, return_counts = True))\n","class_distribution_target = class_distribution_target.transpose()\n","class_distribution_target.columns = ['class','samples']\n","class_distribution_target"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>374608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>270</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>215</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>259</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>203</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>314</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>248</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>305</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>268</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0   374608\n","1       1      270\n","2       2      101\n","3       3      251\n","4       4      215\n","5       5      269\n","6       6      269\n","7       7      259\n","8       8      203\n","9       9      314\n","10     10      248\n","11     11      305\n","12     12      181\n","13     13      268\n","14     14       95"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"CgE2FPXbXtt9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615784524250,"user_tz":420,"elapsed":589,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"b4f6bc2c-cbb1-478b-8aa9-52b8bbf1d3b5"},"source":["classes_target , counts_target = np.unique(ground_truth_target, return_counts = True)\n","classes_target = classes_target[1:] ## Dropping classes with small number of samples\n","classes_target"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n","      dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"l_PESscnqDde"},"source":["## Source : Indian Pines\n","\n","## Train model for samples extracted with different overlap ratios and a percent of  samples picked from each class to be present in the training set. \n","\n","## Model except the final fully connected layer is saved for transfer learning."]},{"cell_type":"code","metadata":{"id":"7vc1sJwRqDdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615784559037,"user_tz":420,"elapsed":28798,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0fa09d4a-084d-4ae9-ff34-e0f80674d12e"},"source":["pretrain_source_models(training_set_size = [200],\n","                      classes = classes_source,\n","                      cube_size = 20,\n","                      overlap_ratio = 1,\n","                      data = data_source,\n","                      ground_truth = ground_truth_source,\n","                      batch_size = 20,\n","                      channels = 64,\n","                      epochs = 50,\n","                      Verbosity = 1,\n","                      accuracies = [],\n","                      learning_rate = 0.0001,\n","                      source_dataset = 'indian_pines')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","=============================================================================================================\n","Model training starts for data with 200 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 1800.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [200 200 200 200 200 200 200 200 200]\n","\n","Total number of samples in test set 6106.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1168  323  123  530  156  637 2024  260  885]\n","\n","X_train => (1800, 20, 20, 64)\n","X_test  => (6106, 20, 20, 64)\n","y_train => (1800, 9)\n","y_test  => (6106, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          33024       global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 67,273\n","Trainable params: 66,377\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","90/90 [==============================] - 4s 8ms/step - loss: 4.6062 - categorical_accuracy: 0.1424\n","\n","Epoch 00001: categorical_accuracy improved from -inf to 0.15833, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 2/50\n","90/90 [==============================] - 1s 8ms/step - loss: 4.2986 - categorical_accuracy: 0.3551\n","\n","Epoch 00002: categorical_accuracy improved from 0.15833 to 0.37444, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 3/50\n","90/90 [==============================] - 1s 8ms/step - loss: 4.1461 - categorical_accuracy: 0.4336\n","\n","Epoch 00003: categorical_accuracy improved from 0.37444 to 0.46278, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 4/50\n","90/90 [==============================] - 1s 8ms/step - loss: 4.0429 - categorical_accuracy: 0.5349\n","\n","Epoch 00004: categorical_accuracy improved from 0.46278 to 0.54222, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 5/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.9457 - categorical_accuracy: 0.5816\n","\n","Epoch 00005: categorical_accuracy improved from 0.54222 to 0.58944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 6/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.8713 - categorical_accuracy: 0.6575\n","\n","Epoch 00006: categorical_accuracy improved from 0.58944 to 0.64778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 7/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.7874 - categorical_accuracy: 0.6843\n","\n","Epoch 00007: categorical_accuracy improved from 0.64778 to 0.67833, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 8/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.7404 - categorical_accuracy: 0.6873\n","\n","Epoch 00008: categorical_accuracy improved from 0.67833 to 0.69444, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 9/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.6696 - categorical_accuracy: 0.7093\n","\n","Epoch 00009: categorical_accuracy improved from 0.69444 to 0.71500, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 10/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5999 - categorical_accuracy: 0.7218\n","\n","Epoch 00010: categorical_accuracy improved from 0.71500 to 0.71944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 11/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5891 - categorical_accuracy: 0.7323\n","\n","Epoch 00011: categorical_accuracy improved from 0.71944 to 0.73389, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 12/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5461 - categorical_accuracy: 0.7133\n","\n","Epoch 00012: categorical_accuracy did not improve from 0.73389\n","Epoch 13/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.5009 - categorical_accuracy: 0.7190\n","\n","Epoch 00013: categorical_accuracy improved from 0.73389 to 0.73722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 14/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.4423 - categorical_accuracy: 0.7585\n","\n","Epoch 00014: categorical_accuracy improved from 0.73722 to 0.74111, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 15/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.4088 - categorical_accuracy: 0.7502\n","\n","Epoch 00015: categorical_accuracy improved from 0.74111 to 0.75222, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 16/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.3466 - categorical_accuracy: 0.7621\n","\n","Epoch 00016: categorical_accuracy did not improve from 0.75222\n","Epoch 17/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.3246 - categorical_accuracy: 0.7685\n","\n","Epoch 00017: categorical_accuracy improved from 0.75222 to 0.76778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 18/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.3035 - categorical_accuracy: 0.7568\n","\n","Epoch 00018: categorical_accuracy did not improve from 0.76778\n","Epoch 19/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.2532 - categorical_accuracy: 0.7760\n","\n","Epoch 00019: categorical_accuracy did not improve from 0.76778\n","Epoch 20/50\n","90/90 [==============================] - 1s 8ms/step - loss: 3.2355 - categorical_accuracy: 0.7601\n","\n","Epoch 00020: categorical_accuracy did not improve from 0.76778\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RkxgCjIejh0l"},"source":["# Fine tune on botswana"]},{"cell_type":"code","metadata":{"id":"SJ1kSkHtCuHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615784950285,"user_tz":420,"elapsed":278199,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"47cfd436-2014-4328-cf5d-c07cebd57b3f"},"source":["transfer_results, confusion_matrixes = transfer_learning(source_dataset = 'indian_pines',\n","                                        target_dataset = 'botswana',\n","                                        data = data_target,\n","                                        ground_truth = ground_truth_target,\n","                                        training_samples_from_each_class = [15,30,45,60,75],\n","                                        source_training_size = [200],\n","                                        classes = classes_target,\n","                                        overlap_ratio = 1,\n","                                        channels = 64,\n","                                        cube_size = 20,\n","                                        learning_rate = 0.0001,\n","                                        epochs = 150,\n","                                        batch_size = 20,\n","                                        test_accuracies = [],\n","                                        )"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\n","================================================================================================================================\n","Model training starts for data with 15 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 210.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [15 15 15 15 15 15 15 15 15 15 15 15 15 15]\n","\n","Total number of samples in test set 2934.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [255  86 236 200 254 254 244 188 299 233 261 118 226  80]\n","\n","X_train_transfer => (210, 128)\n","X_test_transfer  => (2934, 128)\n","y_train => (210, 14)\n","y_test  => (2934, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","11/11 [==============================] - 1s 63ms/step - loss: 4.6728 - categorical_accuracy: 0.0206 - val_loss: 3.0711 - val_categorical_accuracy: 0.1312\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.13122, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","11/11 [==============================] - 0s 30ms/step - loss: 3.1207 - categorical_accuracy: 0.0649 - val_loss: 2.6721 - val_categorical_accuracy: 0.0903\n","\n","Epoch 00002: val_categorical_accuracy did not improve from 0.13122\n","Epoch 3/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.6831 - categorical_accuracy: 0.0842 - val_loss: 2.5786 - val_categorical_accuracy: 0.0685\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.13122\n","Epoch 4/150\n","11/11 [==============================] - 0s 28ms/step - loss: 2.4606 - categorical_accuracy: 0.1199 - val_loss: 2.4677 - val_categorical_accuracy: 0.1708\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.13122 to 0.17076, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.3633 - categorical_accuracy: 0.1865 - val_loss: 2.3985 - val_categorical_accuracy: 0.1561\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.17076\n","Epoch 6/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.2941 - categorical_accuracy: 0.2257 - val_loss: 2.3545 - val_categorical_accuracy: 0.1840\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.17076 to 0.18405, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.1993 - categorical_accuracy: 0.3027 - val_loss: 2.3118 - val_categorical_accuracy: 0.1970\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.18405 to 0.19700, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.1374 - categorical_accuracy: 0.2925 - val_loss: 2.2708 - val_categorical_accuracy: 0.2519\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.19700 to 0.25187, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.1052 - categorical_accuracy: 0.4573 - val_loss: 2.2386 - val_categorical_accuracy: 0.2590\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.25187 to 0.25903, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 10/150\n","11/11 [==============================] - 0s 29ms/step - loss: 2.0819 - categorical_accuracy: 0.3968 - val_loss: 2.1880 - val_categorical_accuracy: 0.2822\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.25903 to 0.28221, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","11/11 [==============================] - 0s 31ms/step - loss: 2.0018 - categorical_accuracy: 0.4227 - val_loss: 2.1593 - val_categorical_accuracy: 0.2676\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.28221\n","Epoch 12/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.9559 - categorical_accuracy: 0.4745 - val_loss: 2.1364 - val_categorical_accuracy: 0.3078\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.28221 to 0.30777, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.9116 - categorical_accuracy: 0.5195 - val_loss: 2.1062 - val_categorical_accuracy: 0.2962\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.30777\n","Epoch 14/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.8566 - categorical_accuracy: 0.4889 - val_loss: 2.0880 - val_categorical_accuracy: 0.3023\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.30777\n","Epoch 15/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.8195 - categorical_accuracy: 0.5467 - val_loss: 2.0633 - val_categorical_accuracy: 0.3637\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.30777 to 0.36367, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.8292 - categorical_accuracy: 0.6095 - val_loss: 2.0343 - val_categorical_accuracy: 0.4032\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.36367 to 0.40320, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 17/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.8049 - categorical_accuracy: 0.7183 - val_loss: 2.0100 - val_categorical_accuracy: 0.4117\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.40320 to 0.41172, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 18/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.7627 - categorical_accuracy: 0.6286 - val_loss: 1.9988 - val_categorical_accuracy: 0.3879\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.41172\n","Epoch 19/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.7355 - categorical_accuracy: 0.7235 - val_loss: 1.9740 - val_categorical_accuracy: 0.4540\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.41172 to 0.45399, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 20/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.7543 - categorical_accuracy: 0.7169 - val_loss: 1.9699 - val_categorical_accuracy: 0.4765\n","\n","Epoch 00020: val_categorical_accuracy improved from 0.45399 to 0.47648, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 21/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.6869 - categorical_accuracy: 0.7147 - val_loss: 1.9512 - val_categorical_accuracy: 0.4530\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.47648\n","Epoch 22/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.6683 - categorical_accuracy: 0.7083 - val_loss: 1.9293 - val_categorical_accuracy: 0.5065\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.47648 to 0.50648, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 23/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.6634 - categorical_accuracy: 0.7738 - val_loss: 1.9099 - val_categorical_accuracy: 0.4768\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.50648\n","Epoch 24/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5943 - categorical_accuracy: 0.7639 - val_loss: 1.8983 - val_categorical_accuracy: 0.4819\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.50648\n","Epoch 25/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.6326 - categorical_accuracy: 0.7323 - val_loss: 1.8881 - val_categorical_accuracy: 0.4932\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.50648\n","Epoch 26/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.5875 - categorical_accuracy: 0.7246 - val_loss: 1.8750 - val_categorical_accuracy: 0.4778\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.50648\n","Epoch 27/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.6335 - categorical_accuracy: 0.7423 - val_loss: 1.8722 - val_categorical_accuracy: 0.4765\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.50648\n","Epoch 28/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5790 - categorical_accuracy: 0.7198 - val_loss: 1.8517 - val_categorical_accuracy: 0.5508\n","\n","Epoch 00028: val_categorical_accuracy improved from 0.50648 to 0.55078, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 29/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5649 - categorical_accuracy: 0.8139 - val_loss: 1.8273 - val_categorical_accuracy: 0.5631\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.55078 to 0.56305, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 30/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5911 - categorical_accuracy: 0.8039 - val_loss: 1.8125 - val_categorical_accuracy: 0.5385\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.56305\n","Epoch 31/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.5148 - categorical_accuracy: 0.9007 - val_loss: 1.8074 - val_categorical_accuracy: 0.5259\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.56305\n","Epoch 32/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.5102 - categorical_accuracy: 0.8148 - val_loss: 1.7951 - val_categorical_accuracy: 0.5395\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.56305\n","Epoch 33/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.4657 - categorical_accuracy: 0.8395 - val_loss: 1.7714 - val_categorical_accuracy: 0.5801\n","\n","Epoch 00033: val_categorical_accuracy improved from 0.56305 to 0.58010, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 34/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.4587 - categorical_accuracy: 0.8464 - val_loss: 1.7793 - val_categorical_accuracy: 0.5150\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.58010\n","Epoch 35/150\n","11/11 [==============================] - 0s 32ms/step - loss: 1.4982 - categorical_accuracy: 0.7718 - val_loss: 1.7703 - val_categorical_accuracy: 0.5078\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.58010\n","Epoch 36/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.4967 - categorical_accuracy: 0.7777 - val_loss: 1.7589 - val_categorical_accuracy: 0.5372\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.58010\n","Epoch 37/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.3961 - categorical_accuracy: 0.8122 - val_loss: 1.7448 - val_categorical_accuracy: 0.5862\n","\n","Epoch 00037: val_categorical_accuracy improved from 0.58010 to 0.58623, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 38/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.4351 - categorical_accuracy: 0.8510 - val_loss: 1.7477 - val_categorical_accuracy: 0.5147\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.58623\n","Epoch 39/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.3623 - categorical_accuracy: 0.8723 - val_loss: 1.7281 - val_categorical_accuracy: 0.5467\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.58623\n","Epoch 40/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.4178 - categorical_accuracy: 0.8526 - val_loss: 1.7120 - val_categorical_accuracy: 0.6312\n","\n","Epoch 00040: val_categorical_accuracy improved from 0.58623 to 0.63122, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 41/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3489 - categorical_accuracy: 0.8822 - val_loss: 1.7092 - val_categorical_accuracy: 0.5719\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.63122\n","Epoch 42/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3660 - categorical_accuracy: 0.8609 - val_loss: 1.7081 - val_categorical_accuracy: 0.5937\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.63122\n","Epoch 43/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.3208 - categorical_accuracy: 0.9203 - val_loss: 1.6908 - val_categorical_accuracy: 0.5804\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.63122\n","Epoch 44/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.3885 - categorical_accuracy: 0.8662 - val_loss: 1.6926 - val_categorical_accuracy: 0.5808\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.63122\n","Epoch 45/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.3340 - categorical_accuracy: 0.8942 - val_loss: 1.6797 - val_categorical_accuracy: 0.6183\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.63122\n","Epoch 46/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.3253 - categorical_accuracy: 0.9443 - val_loss: 1.6679 - val_categorical_accuracy: 0.5736\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.63122\n","Epoch 47/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2795 - categorical_accuracy: 0.8688 - val_loss: 1.6708 - val_categorical_accuracy: 0.5412\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.63122\n","Epoch 48/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2873 - categorical_accuracy: 0.8648 - val_loss: 1.6501 - val_categorical_accuracy: 0.6053\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.63122\n","Epoch 49/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2916 - categorical_accuracy: 0.9486 - val_loss: 1.6464 - val_categorical_accuracy: 0.5975\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.63122\n","Epoch 50/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2665 - categorical_accuracy: 0.8674 - val_loss: 1.6443 - val_categorical_accuracy: 0.6063\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.63122\n","Epoch 51/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2931 - categorical_accuracy: 0.8535 - val_loss: 1.6295 - val_categorical_accuracy: 0.5787\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.63122\n","Epoch 52/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2953 - categorical_accuracy: 0.8370 - val_loss: 1.6251 - val_categorical_accuracy: 0.5729\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.63122\n","Epoch 53/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.2461 - categorical_accuracy: 0.8993 - val_loss: 1.6214 - val_categorical_accuracy: 0.6070\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.63122\n","Epoch 54/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2647 - categorical_accuracy: 0.8686 - val_loss: 1.6143 - val_categorical_accuracy: 0.6050\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.63122\n","Epoch 55/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.2599 - categorical_accuracy: 0.8918 - val_loss: 1.6080 - val_categorical_accuracy: 0.6462\n","\n","Epoch 00055: val_categorical_accuracy improved from 0.63122 to 0.64622, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 56/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1881 - categorical_accuracy: 0.9571 - val_loss: 1.6051 - val_categorical_accuracy: 0.5948\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.64622\n","Epoch 57/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1881 - categorical_accuracy: 0.8716 - val_loss: 1.5958 - val_categorical_accuracy: 0.6111\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.64622\n","Epoch 58/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1037 - categorical_accuracy: 0.9323 - val_loss: 1.5903 - val_categorical_accuracy: 0.6176\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.64622\n","Epoch 59/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1771 - categorical_accuracy: 0.9602 - val_loss: 1.5795 - val_categorical_accuracy: 0.6578\n","\n","Epoch 00059: val_categorical_accuracy improved from 0.64622 to 0.65781, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 60/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2167 - categorical_accuracy: 0.9955 - val_loss: 1.5835 - val_categorical_accuracy: 0.6210\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.65781\n","Epoch 61/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.2177 - categorical_accuracy: 0.9208 - val_loss: 1.5730 - val_categorical_accuracy: 0.6510\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.65781\n","Epoch 62/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1236 - categorical_accuracy: 0.8756 - val_loss: 1.5734 - val_categorical_accuracy: 0.6022\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.65781\n","Epoch 63/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1562 - categorical_accuracy: 0.8968 - val_loss: 1.5672 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.65781\n","Epoch 64/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.1880 - categorical_accuracy: 0.9970 - val_loss: 1.5547 - val_categorical_accuracy: 0.6370\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.65781\n","Epoch 65/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0722 - categorical_accuracy: 0.9174 - val_loss: 1.5597 - val_categorical_accuracy: 0.6264\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.65781\n","Epoch 66/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1769 - categorical_accuracy: 0.9665 - val_loss: 1.5361 - val_categorical_accuracy: 0.6251\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.65781\n","Epoch 67/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1673 - categorical_accuracy: 0.9266 - val_loss: 1.5477 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.65781\n","Epoch 68/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.1654 - categorical_accuracy: 0.9014 - val_loss: 1.5408 - val_categorical_accuracy: 0.6264\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.65781\n","Epoch 69/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0787 - categorical_accuracy: 0.9194 - val_loss: 1.5367 - val_categorical_accuracy: 0.6258\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.65781\n","Epoch 70/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0901 - categorical_accuracy: 0.9551 - val_loss: 1.5298 - val_categorical_accuracy: 0.6704\n","\n","Epoch 00070: val_categorical_accuracy improved from 0.65781 to 0.67042, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 71/150\n","11/11 [==============================] - 0s 31ms/step - loss: 1.0846 - categorical_accuracy: 0.9879 - val_loss: 1.5289 - val_categorical_accuracy: 0.6391\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.67042\n","Epoch 72/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1222 - categorical_accuracy: 0.9479 - val_loss: 1.5172 - val_categorical_accuracy: 0.6513\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.67042\n","Epoch 73/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0431 - categorical_accuracy: 0.9719 - val_loss: 1.5245 - val_categorical_accuracy: 0.6097\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.67042\n","Epoch 74/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0885 - categorical_accuracy: 0.9221 - val_loss: 1.5092 - val_categorical_accuracy: 0.6588\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.67042\n","Epoch 75/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0645 - categorical_accuracy: 0.9864 - val_loss: 1.4994 - val_categorical_accuracy: 0.6462\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.67042\n","Epoch 76/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0203 - categorical_accuracy: 1.0000 - val_loss: 1.5058 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.67042\n","Epoch 77/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0519 - categorical_accuracy: 0.9613 - val_loss: 1.5026 - val_categorical_accuracy: 0.6578\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.67042\n","Epoch 78/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0653 - categorical_accuracy: 0.9749 - val_loss: 1.4880 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.67042\n","Epoch 79/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0304 - categorical_accuracy: 0.9972 - val_loss: 1.4914 - val_categorical_accuracy: 0.6411\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.67042\n","Epoch 80/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0499 - categorical_accuracy: 1.0000 - val_loss: 1.4894 - val_categorical_accuracy: 0.6524\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.67042\n","Epoch 81/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0131 - categorical_accuracy: 0.9503 - val_loss: 1.4874 - val_categorical_accuracy: 0.6619\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.67042\n","Epoch 82/150\n","11/11 [==============================] - 0s 29ms/step - loss: 1.0271 - categorical_accuracy: 0.9607 - val_loss: 1.4822 - val_categorical_accuracy: 0.6145\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.67042\n","Epoch 83/150\n","11/11 [==============================] - 0s 32ms/step - loss: 1.0133 - categorical_accuracy: 0.9411 - val_loss: 1.4858 - val_categorical_accuracy: 0.6251\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.67042\n","Epoch 84/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9901 - categorical_accuracy: 0.9942 - val_loss: 1.4740 - val_categorical_accuracy: 0.6612\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.67042\n","Epoch 85/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0029 - categorical_accuracy: 0.9988 - val_loss: 1.4594 - val_categorical_accuracy: 0.6704\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.67042\n","Epoch 86/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0010 - categorical_accuracy: 1.0000 - val_loss: 1.4667 - val_categorical_accuracy: 0.6694\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.67042\n","Epoch 87/150\n","11/11 [==============================] - 0s 30ms/step - loss: 1.0038 - categorical_accuracy: 0.9579 - val_loss: 1.4597 - val_categorical_accuracy: 0.6585\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.67042\n","Epoch 88/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9913 - categorical_accuracy: 1.0000 - val_loss: 1.4606 - val_categorical_accuracy: 0.6663\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.67042\n","Epoch 89/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9996 - categorical_accuracy: 0.9934 - val_loss: 1.4656 - val_categorical_accuracy: 0.6295\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.67042\n","Epoch 90/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.9494 - categorical_accuracy: 0.9978 - val_loss: 1.4477 - val_categorical_accuracy: 0.6875\n","\n","Epoch 00090: val_categorical_accuracy improved from 0.67042 to 0.68746, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 91/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9233 - categorical_accuracy: 0.9900 - val_loss: 1.4438 - val_categorical_accuracy: 0.6830\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.68746\n","Epoch 92/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9385 - categorical_accuracy: 1.0000 - val_loss: 1.4470 - val_categorical_accuracy: 0.6670\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.68746\n","Epoch 93/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9658 - categorical_accuracy: 0.9881 - val_loss: 1.4391 - val_categorical_accuracy: 0.6800\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.68746\n","Epoch 94/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8885 - categorical_accuracy: 0.9855 - val_loss: 1.4336 - val_categorical_accuracy: 0.6909\n","\n","Epoch 00094: val_categorical_accuracy improved from 0.68746 to 0.69087, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 95/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9615 - categorical_accuracy: 1.0000 - val_loss: 1.4286 - val_categorical_accuracy: 0.6503\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.69087\n","Epoch 96/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9773 - categorical_accuracy: 1.0000 - val_loss: 1.4436 - val_categorical_accuracy: 0.6656\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.69087\n","Epoch 97/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.9015 - categorical_accuracy: 0.9739 - val_loss: 1.4349 - val_categorical_accuracy: 0.6551\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.69087\n","Epoch 98/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.9352 - categorical_accuracy: 0.9725 - val_loss: 1.4214 - val_categorical_accuracy: 0.6166\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.69087\n","Epoch 99/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.9399 - categorical_accuracy: 0.9452 - val_loss: 1.4323 - val_categorical_accuracy: 0.6466\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.69087\n","Epoch 100/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.8981 - categorical_accuracy: 0.9469 - val_loss: 1.4156 - val_categorical_accuracy: 0.6663\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.69087\n","Epoch 101/150\n","11/11 [==============================] - 0s 33ms/step - loss: 0.9031 - categorical_accuracy: 1.0000 - val_loss: 1.4164 - val_categorical_accuracy: 0.6486\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.69087\n","Epoch 102/150\n","11/11 [==============================] - 0s 33ms/step - loss: 0.9049 - categorical_accuracy: 0.9965 - val_loss: 1.4168 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.69087\n","Epoch 103/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8912 - categorical_accuracy: 0.9950 - val_loss: 1.4144 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.69087\n","Epoch 104/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8642 - categorical_accuracy: 0.9921 - val_loss: 1.4121 - val_categorical_accuracy: 0.6905\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.69087\n","Epoch 105/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8859 - categorical_accuracy: 0.9983 - val_loss: 1.4071 - val_categorical_accuracy: 0.6766\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.69087\n","Epoch 106/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8372 - categorical_accuracy: 0.9897 - val_loss: 1.4081 - val_categorical_accuracy: 0.6701\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.69087\n","Epoch 107/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.8920 - categorical_accuracy: 0.9988 - val_loss: 1.3987 - val_categorical_accuracy: 0.6605\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.69087\n","Epoch 108/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8730 - categorical_accuracy: 1.0000 - val_loss: 1.3903 - val_categorical_accuracy: 0.6885\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.69087\n","Epoch 109/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8317 - categorical_accuracy: 1.0000 - val_loss: 1.3979 - val_categorical_accuracy: 0.6881\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.69087\n","Epoch 110/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8277 - categorical_accuracy: 1.0000 - val_loss: 1.3863 - val_categorical_accuracy: 0.7052\n","\n","Epoch 00110: val_categorical_accuracy improved from 0.69087 to 0.70518, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 111/150\n","11/11 [==============================] - 0s 32ms/step - loss: 0.8452 - categorical_accuracy: 1.0000 - val_loss: 1.3906 - val_categorical_accuracy: 0.6885\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.70518\n","Epoch 112/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8910 - categorical_accuracy: 0.9978 - val_loss: 1.3884 - val_categorical_accuracy: 0.6803\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.70518\n","Epoch 113/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8473 - categorical_accuracy: 1.0000 - val_loss: 1.3767 - val_categorical_accuracy: 0.7048\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.70518\n","Epoch 114/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7762 - categorical_accuracy: 0.9964 - val_loss: 1.3921 - val_categorical_accuracy: 0.6483\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.70518\n","Epoch 115/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.8136 - categorical_accuracy: 0.9884 - val_loss: 1.3859 - val_categorical_accuracy: 0.6653\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.70518\n","Epoch 116/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8362 - categorical_accuracy: 0.9901 - val_loss: 1.3779 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.70518\n","Epoch 117/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8136 - categorical_accuracy: 1.0000 - val_loss: 1.3650 - val_categorical_accuracy: 0.6677\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.70518\n","Epoch 118/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8134 - categorical_accuracy: 0.9915 - val_loss: 1.3798 - val_categorical_accuracy: 0.6823\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.70518\n","Epoch 119/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.8160 - categorical_accuracy: 1.0000 - val_loss: 1.3805 - val_categorical_accuracy: 0.6800\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.70518\n","Epoch 120/150\n","11/11 [==============================] - 0s 32ms/step - loss: 0.8248 - categorical_accuracy: 0.9816 - val_loss: 1.3715 - val_categorical_accuracy: 0.6834\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.70518\n","Epoch 121/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7940 - categorical_accuracy: 0.9960 - val_loss: 1.3643 - val_categorical_accuracy: 0.6864\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.70518\n","Epoch 122/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7556 - categorical_accuracy: 1.0000 - val_loss: 1.3526 - val_categorical_accuracy: 0.6970\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.70518\n","Epoch 123/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.8395 - categorical_accuracy: 1.0000 - val_loss: 1.3530 - val_categorical_accuracy: 0.6636\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.70518\n","Epoch 124/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7807 - categorical_accuracy: 1.0000 - val_loss: 1.3559 - val_categorical_accuracy: 0.6990\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.70518\n","Epoch 125/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7962 - categorical_accuracy: 1.0000 - val_loss: 1.3564 - val_categorical_accuracy: 0.6646\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.70518\n","Epoch 126/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7447 - categorical_accuracy: 1.0000 - val_loss: 1.3599 - val_categorical_accuracy: 0.6823\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.70518\n","Epoch 127/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7730 - categorical_accuracy: 0.9972 - val_loss: 1.3508 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.70518\n","Epoch 128/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7698 - categorical_accuracy: 1.0000 - val_loss: 1.3505 - val_categorical_accuracy: 0.7001\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.70518\n","Epoch 129/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7724 - categorical_accuracy: 0.9978 - val_loss: 1.3393 - val_categorical_accuracy: 0.7045\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.70518\n","Epoch 130/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7680 - categorical_accuracy: 1.0000 - val_loss: 1.3462 - val_categorical_accuracy: 0.6776\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.70518\n","Epoch 131/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7227 - categorical_accuracy: 0.9946 - val_loss: 1.3431 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.70518\n","Epoch 132/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7753 - categorical_accuracy: 0.9972 - val_loss: 1.3386 - val_categorical_accuracy: 0.7062\n","\n","Epoch 00132: val_categorical_accuracy improved from 0.70518 to 0.70620, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 133/150\n","11/11 [==============================] - 0s 33ms/step - loss: 0.7425 - categorical_accuracy: 1.0000 - val_loss: 1.3430 - val_categorical_accuracy: 0.6895\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.70620\n","Epoch 134/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7279 - categorical_accuracy: 1.0000 - val_loss: 1.3352 - val_categorical_accuracy: 0.6844\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.70620\n","Epoch 135/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7816 - categorical_accuracy: 1.0000 - val_loss: 1.3410 - val_categorical_accuracy: 0.6898\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.70620\n","Epoch 136/150\n","11/11 [==============================] - 0s 31ms/step - loss: 0.7747 - categorical_accuracy: 1.0000 - val_loss: 1.3283 - val_categorical_accuracy: 0.7106\n","\n","Epoch 00136: val_categorical_accuracy improved from 0.70620 to 0.71063, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 137/150\n","11/11 [==============================] - 0s 32ms/step - loss: 0.7140 - categorical_accuracy: 1.0000 - val_loss: 1.3275 - val_categorical_accuracy: 0.7055\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.71063\n","Epoch 138/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7559 - categorical_accuracy: 1.0000 - val_loss: 1.3315 - val_categorical_accuracy: 0.6834\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.71063\n","Epoch 139/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7125 - categorical_accuracy: 1.0000 - val_loss: 1.3265 - val_categorical_accuracy: 0.6888\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.71063\n","Epoch 140/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7063 - categorical_accuracy: 1.0000 - val_loss: 1.3264 - val_categorical_accuracy: 0.6997\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.71063\n","Epoch 141/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7315 - categorical_accuracy: 1.0000 - val_loss: 1.3174 - val_categorical_accuracy: 0.6864\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.71063\n","Epoch 142/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7321 - categorical_accuracy: 1.0000 - val_loss: 1.3218 - val_categorical_accuracy: 0.6527\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.71063\n","Epoch 143/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7494 - categorical_accuracy: 0.9988 - val_loss: 1.3189 - val_categorical_accuracy: 0.7038\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.71063\n","Epoch 144/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7147 - categorical_accuracy: 0.9874 - val_loss: 1.3213 - val_categorical_accuracy: 0.6830\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.71063\n","Epoch 145/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7186 - categorical_accuracy: 1.0000 - val_loss: 1.3160 - val_categorical_accuracy: 0.6936\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.71063\n","Epoch 146/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.6820 - categorical_accuracy: 1.0000 - val_loss: 1.3117 - val_categorical_accuracy: 0.6871\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.71063\n","Epoch 147/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.6964 - categorical_accuracy: 1.0000 - val_loss: 1.3070 - val_categorical_accuracy: 0.6953\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.71063\n","Epoch 148/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.6574 - categorical_accuracy: 1.0000 - val_loss: 1.3125 - val_categorical_accuracy: 0.7011\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.71063\n","Epoch 149/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.6789 - categorical_accuracy: 0.9983 - val_loss: 1.3145 - val_categorical_accuracy: 0.6830\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.71063\n","Epoch 150/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7016 - categorical_accuracy: 0.9988 - val_loss: 1.3056 - val_categorical_accuracy: 0.6629\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.71063\n","92/92 [==============================] - 0s 2ms/step - loss: 1.3283 - categorical_accuracy: 0.7106\n","92/92 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 30 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 420.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n","\n","Total number of samples in test set 2724.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [240  71 221 185 239 239 229 173 284 218 246 103 211  65]\n","\n","X_train_transfer => (420, 128)\n","X_test_transfer  => (2724, 128)\n","y_train => (420, 14)\n","y_test  => (2724, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","21/21 [==============================] - 1s 22ms/step - loss: 4.2850 - categorical_accuracy: 0.0331 - val_loss: 2.7448 - val_categorical_accuracy: 0.1032\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.10316, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","21/21 [==============================] - 0s 16ms/step - loss: 2.6225 - categorical_accuracy: 0.1440 - val_loss: 2.5067 - val_categorical_accuracy: 0.0881\n","\n","Epoch 00002: val_categorical_accuracy did not improve from 0.10316\n","Epoch 3/150\n","21/21 [==============================] - 0s 18ms/step - loss: 2.3574 - categorical_accuracy: 0.1181 - val_loss: 2.3894 - val_categorical_accuracy: 0.1847\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.10316 to 0.18465, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","21/21 [==============================] - 0s 16ms/step - loss: 2.2067 - categorical_accuracy: 0.3049 - val_loss: 2.2921 - val_categorical_accuracy: 0.2155\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.18465 to 0.21549, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","21/21 [==============================] - 0s 15ms/step - loss: 2.0968 - categorical_accuracy: 0.3520 - val_loss: 2.2673 - val_categorical_accuracy: 0.1307\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.21549\n","Epoch 6/150\n","21/21 [==============================] - 0s 16ms/step - loss: 2.0383 - categorical_accuracy: 0.3916 - val_loss: 2.1721 - val_categorical_accuracy: 0.2974\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.21549 to 0.29736, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.9425 - categorical_accuracy: 0.4830 - val_loss: 2.1189 - val_categorical_accuracy: 0.3150\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.29736 to 0.31498, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.8920 - categorical_accuracy: 0.4241 - val_loss: 2.0762 - val_categorical_accuracy: 0.3532\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.31498 to 0.35316, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.8279 - categorical_accuracy: 0.6172 - val_loss: 2.0413 - val_categorical_accuracy: 0.3264\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.35316\n","Epoch 10/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.7658 - categorical_accuracy: 0.7145 - val_loss: 2.0046 - val_categorical_accuracy: 0.3374\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.35316\n","Epoch 11/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.7022 - categorical_accuracy: 0.6662 - val_loss: 1.9580 - val_categorical_accuracy: 0.4255\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.35316 to 0.42548, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 12/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.6891 - categorical_accuracy: 0.6190 - val_loss: 1.9430 - val_categorical_accuracy: 0.3576\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.42548\n","Epoch 13/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.6308 - categorical_accuracy: 0.7523 - val_loss: 1.8890 - val_categorical_accuracy: 0.4919\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.42548 to 0.49192, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.6073 - categorical_accuracy: 0.7131 - val_loss: 1.8757 - val_categorical_accuracy: 0.4600\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.49192\n","Epoch 15/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5540 - categorical_accuracy: 0.7036 - val_loss: 1.8772 - val_categorical_accuracy: 0.5536\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.49192 to 0.55360, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5853 - categorical_accuracy: 0.7284 - val_loss: 1.8368 - val_categorical_accuracy: 0.4710\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.55360\n","Epoch 17/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5392 - categorical_accuracy: 0.7487 - val_loss: 1.8102 - val_categorical_accuracy: 0.5239\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.55360\n","Epoch 18/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.5173 - categorical_accuracy: 0.7756 - val_loss: 1.7971 - val_categorical_accuracy: 0.5433\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.55360\n","Epoch 19/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.4880 - categorical_accuracy: 0.7632 - val_loss: 1.7485 - val_categorical_accuracy: 0.5485\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.55360\n","Epoch 20/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.4402 - categorical_accuracy: 0.7362 - val_loss: 1.7934 - val_categorical_accuracy: 0.4141\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.55360\n","Epoch 21/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3695 - categorical_accuracy: 0.7848 - val_loss: 1.7244 - val_categorical_accuracy: 0.5833\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.55360 to 0.58333, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.3737 - categorical_accuracy: 0.7556 - val_loss: 1.7281 - val_categorical_accuracy: 0.5481\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.58333\n","Epoch 23/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3855 - categorical_accuracy: 0.7858 - val_loss: 1.7085 - val_categorical_accuracy: 0.5404\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.58333\n","Epoch 24/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3304 - categorical_accuracy: 0.8416 - val_loss: 1.6757 - val_categorical_accuracy: 0.6057\n","\n","Epoch 00024: val_categorical_accuracy improved from 0.58333 to 0.60573, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 25/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3354 - categorical_accuracy: 0.8135 - val_loss: 1.6676 - val_categorical_accuracy: 0.6002\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.60573\n","Epoch 26/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2985 - categorical_accuracy: 0.9391 - val_loss: 1.6673 - val_categorical_accuracy: 0.5760\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.60573\n","Epoch 27/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2947 - categorical_accuracy: 0.8629 - val_loss: 1.6396 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.60573 to 0.60866, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.3026 - categorical_accuracy: 0.8965 - val_loss: 1.6424 - val_categorical_accuracy: 0.5239\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.60866\n","Epoch 29/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.2720 - categorical_accuracy: 0.8548 - val_loss: 1.6361 - val_categorical_accuracy: 0.6105\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.60866 to 0.61050, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 30/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2179 - categorical_accuracy: 0.8948 - val_loss: 1.6214 - val_categorical_accuracy: 0.5888\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.61050\n","Epoch 31/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2236 - categorical_accuracy: 0.8724 - val_loss: 1.6173 - val_categorical_accuracy: 0.5529\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.61050\n","Epoch 32/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.1557 - categorical_accuracy: 0.9050 - val_loss: 1.5960 - val_categorical_accuracy: 0.6182\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.61050 to 0.61821, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 33/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.1644 - categorical_accuracy: 0.9165 - val_loss: 1.5886 - val_categorical_accuracy: 0.6267\n","\n","Epoch 00033: val_categorical_accuracy improved from 0.61821 to 0.62665, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 34/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.1715 - categorical_accuracy: 0.9004 - val_loss: 1.5880 - val_categorical_accuracy: 0.6123\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.62665\n","Epoch 35/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.1742 - categorical_accuracy: 0.9022 - val_loss: 1.5669 - val_categorical_accuracy: 0.5896\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.62665\n","Epoch 36/150\n","21/21 [==============================] - 0s 16ms/step - loss: 1.0948 - categorical_accuracy: 0.9159 - val_loss: 1.5607 - val_categorical_accuracy: 0.6472\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.62665 to 0.64721, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 37/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.1145 - categorical_accuracy: 0.9539 - val_loss: 1.5442 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.64721\n","Epoch 38/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0936 - categorical_accuracy: 0.9115 - val_loss: 1.5378 - val_categorical_accuracy: 0.6281\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.64721\n","Epoch 39/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0811 - categorical_accuracy: 0.9609 - val_loss: 1.5362 - val_categorical_accuracy: 0.6487\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.64721 to 0.64868, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 40/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0838 - categorical_accuracy: 0.9272 - val_loss: 1.5313 - val_categorical_accuracy: 0.6322\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.64868\n","Epoch 41/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0402 - categorical_accuracy: 0.9515 - val_loss: 1.5128 - val_categorical_accuracy: 0.6204\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.64868\n","Epoch 42/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0108 - categorical_accuracy: 0.9223 - val_loss: 1.5175 - val_categorical_accuracy: 0.6164\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.64868\n","Epoch 43/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0024 - categorical_accuracy: 0.9845 - val_loss: 1.5039 - val_categorical_accuracy: 0.6740\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.64868 to 0.67401, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0753 - categorical_accuracy: 0.9513 - val_loss: 1.5167 - val_categorical_accuracy: 0.5720\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.67401\n","Epoch 45/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9885 - categorical_accuracy: 0.9443 - val_loss: 1.4902 - val_categorical_accuracy: 0.6120\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.67401\n","Epoch 46/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9686 - categorical_accuracy: 0.9182 - val_loss: 1.4769 - val_categorical_accuracy: 0.6439\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.67401\n","Epoch 47/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.9541 - categorical_accuracy: 0.9824 - val_loss: 1.4839 - val_categorical_accuracy: 0.6417\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.67401\n","Epoch 48/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.0054 - categorical_accuracy: 0.9592 - val_loss: 1.4738 - val_categorical_accuracy: 0.6656\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.67401\n","Epoch 49/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9882 - categorical_accuracy: 0.9384 - val_loss: 1.4552 - val_categorical_accuracy: 0.6182\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.67401\n","Epoch 50/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9871 - categorical_accuracy: 0.9693 - val_loss: 1.4812 - val_categorical_accuracy: 0.6200\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.67401\n","Epoch 51/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9166 - categorical_accuracy: 0.9358 - val_loss: 1.4438 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.67401\n","Epoch 52/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9404 - categorical_accuracy: 0.9886 - val_loss: 1.4496 - val_categorical_accuracy: 0.6366\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.67401\n","Epoch 53/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9490 - categorical_accuracy: 0.9822 - val_loss: 1.4346 - val_categorical_accuracy: 0.6446\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.67401\n","Epoch 54/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.9073 - categorical_accuracy: 0.9809 - val_loss: 1.4609 - val_categorical_accuracy: 0.6189\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.67401\n","Epoch 55/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8879 - categorical_accuracy: 0.9648 - val_loss: 1.4267 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.67401\n","Epoch 56/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8697 - categorical_accuracy: 0.9366 - val_loss: 1.4486 - val_categorical_accuracy: 0.6439\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.67401\n","Epoch 57/150\n","21/21 [==============================] - 0s 17ms/step - loss: 0.8736 - categorical_accuracy: 0.9696 - val_loss: 1.4245 - val_categorical_accuracy: 0.6417\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.67401\n","Epoch 58/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8828 - categorical_accuracy: 0.9579 - val_loss: 1.4345 - val_categorical_accuracy: 0.6340\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.67401\n","Epoch 59/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8487 - categorical_accuracy: 0.9419 - val_loss: 1.4026 - val_categorical_accuracy: 0.6615\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.67401\n","Epoch 60/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8638 - categorical_accuracy: 0.9681 - val_loss: 1.4112 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00060: val_categorical_accuracy improved from 0.67401 to 0.67878, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 61/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8436 - categorical_accuracy: 0.9808 - val_loss: 1.3979 - val_categorical_accuracy: 0.6494\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.67878\n","Epoch 62/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7774 - categorical_accuracy: 0.9963 - val_loss: 1.3923 - val_categorical_accuracy: 0.6825\n","\n","Epoch 00062: val_categorical_accuracy improved from 0.67878 to 0.68245, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 63/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8342 - categorical_accuracy: 0.9948 - val_loss: 1.3963 - val_categorical_accuracy: 0.6366\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.68245\n","Epoch 64/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8075 - categorical_accuracy: 0.9885 - val_loss: 1.3866 - val_categorical_accuracy: 0.6663\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.68245\n","Epoch 65/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.8269 - categorical_accuracy: 1.0000 - val_loss: 1.3894 - val_categorical_accuracy: 0.6762\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.68245\n","Epoch 66/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.7697 - categorical_accuracy: 1.0000 - val_loss: 1.3790 - val_categorical_accuracy: 0.6905\n","\n","Epoch 00066: val_categorical_accuracy improved from 0.68245 to 0.69053, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 67/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.7940 - categorical_accuracy: 0.9857 - val_loss: 1.3743 - val_categorical_accuracy: 0.6608\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.69053\n","Epoch 68/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.7534 - categorical_accuracy: 1.0000 - val_loss: 1.3703 - val_categorical_accuracy: 0.6935\n","\n","Epoch 00068: val_categorical_accuracy improved from 0.69053 to 0.69347, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 69/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.7530 - categorical_accuracy: 1.0000 - val_loss: 1.3688 - val_categorical_accuracy: 0.6843\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.69347\n","Epoch 70/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7341 - categorical_accuracy: 1.0000 - val_loss: 1.3744 - val_categorical_accuracy: 0.6626\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.69347\n","Epoch 71/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7516 - categorical_accuracy: 0.9885 - val_loss: 1.3597 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.69347\n","Epoch 72/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7165 - categorical_accuracy: 1.0000 - val_loss: 1.3510 - val_categorical_accuracy: 0.6865\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.69347\n","Epoch 73/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7272 - categorical_accuracy: 1.0000 - val_loss: 1.3600 - val_categorical_accuracy: 0.6733\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.69347\n","Epoch 74/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7244 - categorical_accuracy: 1.0000 - val_loss: 1.3483 - val_categorical_accuracy: 0.6590\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.69347\n","Epoch 75/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.7168 - categorical_accuracy: 0.9997 - val_loss: 1.3493 - val_categorical_accuracy: 0.6773\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.69347\n","Epoch 76/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6808 - categorical_accuracy: 1.0000 - val_loss: 1.3408 - val_categorical_accuracy: 0.6891\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.69347\n","Epoch 77/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6837 - categorical_accuracy: 1.0000 - val_loss: 1.3400 - val_categorical_accuracy: 0.6843\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.69347\n","Epoch 78/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6988 - categorical_accuracy: 1.0000 - val_loss: 1.3325 - val_categorical_accuracy: 0.6817\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.69347\n","Epoch 79/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6774 - categorical_accuracy: 1.0000 - val_loss: 1.3462 - val_categorical_accuracy: 0.6465\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.69347\n","Epoch 80/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6683 - categorical_accuracy: 0.9855 - val_loss: 1.3303 - val_categorical_accuracy: 0.6601\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.69347\n","Epoch 81/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6976 - categorical_accuracy: 1.0000 - val_loss: 1.3272 - val_categorical_accuracy: 0.6729\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.69347\n","Epoch 82/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6548 - categorical_accuracy: 1.0000 - val_loss: 1.3144 - val_categorical_accuracy: 0.6802\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.69347\n","Epoch 83/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6701 - categorical_accuracy: 1.0000 - val_loss: 1.3104 - val_categorical_accuracy: 0.6718\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.69347\n","Epoch 84/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6512 - categorical_accuracy: 1.0000 - val_loss: 1.3255 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.69347\n","Epoch 85/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6319 - categorical_accuracy: 0.9975 - val_loss: 1.2980 - val_categorical_accuracy: 0.6318\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.69347\n","Epoch 86/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6760 - categorical_accuracy: 1.0000 - val_loss: 1.3082 - val_categorical_accuracy: 0.6773\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.69347\n","Epoch 87/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6754 - categorical_accuracy: 1.0000 - val_loss: 1.3074 - val_categorical_accuracy: 0.6847\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.69347\n","Epoch 88/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.6403 - categorical_accuracy: 1.0000 - val_loss: 1.3061 - val_categorical_accuracy: 0.6766\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.69347\n","Epoch 89/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6044 - categorical_accuracy: 0.9990 - val_loss: 1.2957 - val_categorical_accuracy: 0.7015\n","\n","Epoch 00089: val_categorical_accuracy improved from 0.69347 to 0.70154, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 90/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5946 - categorical_accuracy: 1.0000 - val_loss: 1.3043 - val_categorical_accuracy: 0.6597\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.70154\n","Epoch 91/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6428 - categorical_accuracy: 1.0000 - val_loss: 1.2982 - val_categorical_accuracy: 0.6993\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.70154\n","Epoch 92/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6141 - categorical_accuracy: 1.0000 - val_loss: 1.2873 - val_categorical_accuracy: 0.6509\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.70154\n","Epoch 93/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5907 - categorical_accuracy: 1.0000 - val_loss: 1.2923 - val_categorical_accuracy: 0.7019\n","\n","Epoch 00093: val_categorical_accuracy improved from 0.70154 to 0.70191, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 94/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5876 - categorical_accuracy: 1.0000 - val_loss: 1.2914 - val_categorical_accuracy: 0.6990\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.70191\n","Epoch 95/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6046 - categorical_accuracy: 1.0000 - val_loss: 1.2865 - val_categorical_accuracy: 0.6887\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.70191\n","Epoch 96/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5840 - categorical_accuracy: 1.0000 - val_loss: 1.2961 - val_categorical_accuracy: 0.6935\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.70191\n","Epoch 97/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6192 - categorical_accuracy: 1.0000 - val_loss: 1.2929 - val_categorical_accuracy: 0.6546\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.70191\n","Epoch 98/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.5880 - categorical_accuracy: 1.0000 - val_loss: 1.2862 - val_categorical_accuracy: 0.6946\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.70191\n","Epoch 99/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5917 - categorical_accuracy: 1.0000 - val_loss: 1.2759 - val_categorical_accuracy: 0.6979\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.70191\n","Epoch 100/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5619 - categorical_accuracy: 1.0000 - val_loss: 1.2712 - val_categorical_accuracy: 0.6788\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.70191\n","Epoch 101/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5598 - categorical_accuracy: 1.0000 - val_loss: 1.2714 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.70191\n","Epoch 102/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5654 - categorical_accuracy: 1.0000 - val_loss: 1.2689 - val_categorical_accuracy: 0.6964\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.70191\n","Epoch 103/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5769 - categorical_accuracy: 1.0000 - val_loss: 1.2773 - val_categorical_accuracy: 0.6869\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.70191\n","Epoch 104/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5733 - categorical_accuracy: 1.0000 - val_loss: 1.2629 - val_categorical_accuracy: 0.6773\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.70191\n","Epoch 105/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5329 - categorical_accuracy: 1.0000 - val_loss: 1.2615 - val_categorical_accuracy: 0.6942\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.70191\n","Epoch 106/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5192 - categorical_accuracy: 1.0000 - val_loss: 1.2550 - val_categorical_accuracy: 0.6902\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.70191\n","Epoch 107/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5297 - categorical_accuracy: 1.0000 - val_loss: 1.2580 - val_categorical_accuracy: 0.6942\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.70191\n","Epoch 108/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5348 - categorical_accuracy: 0.9905 - val_loss: 1.2758 - val_categorical_accuracy: 0.7048\n","\n","Epoch 00108: val_categorical_accuracy improved from 0.70191 to 0.70485, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 109/150\n","21/21 [==============================] - 0s 17ms/step - loss: 0.5331 - categorical_accuracy: 0.9936 - val_loss: 1.2540 - val_categorical_accuracy: 0.6725\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.70485\n","Epoch 110/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5406 - categorical_accuracy: 0.9938 - val_loss: 1.2572 - val_categorical_accuracy: 0.6927\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.70485\n","Epoch 111/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.4985 - categorical_accuracy: 1.0000 - val_loss: 1.2567 - val_categorical_accuracy: 0.6968\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.70485\n","Epoch 112/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5215 - categorical_accuracy: 1.0000 - val_loss: 1.2488 - val_categorical_accuracy: 0.7012\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.70485\n","Epoch 113/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5354 - categorical_accuracy: 1.0000 - val_loss: 1.2421 - val_categorical_accuracy: 0.6942\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.70485\n","Epoch 114/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.4836 - categorical_accuracy: 1.0000 - val_loss: 1.2437 - val_categorical_accuracy: 0.6854\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.70485\n","Epoch 115/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5224 - categorical_accuracy: 1.0000 - val_loss: 1.2408 - val_categorical_accuracy: 0.6479\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.70485\n","Epoch 116/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4981 - categorical_accuracy: 1.0000 - val_loss: 1.2435 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.70485\n","Epoch 117/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.5065 - categorical_accuracy: 1.0000 - val_loss: 1.2462 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.70485\n","Epoch 118/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4840 - categorical_accuracy: 1.0000 - val_loss: 1.2386 - val_categorical_accuracy: 0.7037\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.70485\n","Epoch 119/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4753 - categorical_accuracy: 1.0000 - val_loss: 1.2373 - val_categorical_accuracy: 0.6799\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.70485\n","Epoch 120/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4801 - categorical_accuracy: 1.0000 - val_loss: 1.2333 - val_categorical_accuracy: 0.7030\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.70485\n","Epoch 121/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4529 - categorical_accuracy: 1.0000 - val_loss: 1.2342 - val_categorical_accuracy: 0.6733\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.70485\n","Epoch 122/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4955 - categorical_accuracy: 1.0000 - val_loss: 1.2247 - val_categorical_accuracy: 0.6564\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.70485\n","Epoch 123/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4784 - categorical_accuracy: 1.0000 - val_loss: 1.2328 - val_categorical_accuracy: 0.7104\n","\n","Epoch 00123: val_categorical_accuracy improved from 0.70485 to 0.71035, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 124/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.4713 - categorical_accuracy: 1.0000 - val_loss: 1.2383 - val_categorical_accuracy: 0.6700\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.71035\n","Epoch 125/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.4880 - categorical_accuracy: 0.9975 - val_loss: 1.2257 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.71035\n","Epoch 126/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4676 - categorical_accuracy: 1.0000 - val_loss: 1.2247 - val_categorical_accuracy: 0.6905\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.71035\n","Epoch 127/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4632 - categorical_accuracy: 1.0000 - val_loss: 1.2222 - val_categorical_accuracy: 0.6814\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.71035\n","Epoch 128/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4308 - categorical_accuracy: 1.0000 - val_loss: 1.2234 - val_categorical_accuracy: 0.6960\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.71035\n","Epoch 129/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4586 - categorical_accuracy: 1.0000 - val_loss: 1.2142 - val_categorical_accuracy: 0.6887\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.71035\n","Epoch 130/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4513 - categorical_accuracy: 1.0000 - val_loss: 1.2231 - val_categorical_accuracy: 0.6861\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.71035\n","Epoch 131/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4355 - categorical_accuracy: 1.0000 - val_loss: 1.2184 - val_categorical_accuracy: 0.6887\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.71035\n","Epoch 132/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4298 - categorical_accuracy: 1.0000 - val_loss: 1.2183 - val_categorical_accuracy: 0.7056\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.71035\n","Epoch 133/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4460 - categorical_accuracy: 1.0000 - val_loss: 1.2198 - val_categorical_accuracy: 0.7001\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.71035\n","Epoch 134/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4172 - categorical_accuracy: 1.0000 - val_loss: 1.2119 - val_categorical_accuracy: 0.6795\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.71035\n","Epoch 135/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4180 - categorical_accuracy: 1.0000 - val_loss: 1.2173 - val_categorical_accuracy: 0.6747\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.71035\n","Epoch 136/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4255 - categorical_accuracy: 1.0000 - val_loss: 1.2137 - val_categorical_accuracy: 0.6960\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.71035\n","Epoch 137/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4332 - categorical_accuracy: 1.0000 - val_loss: 1.2088 - val_categorical_accuracy: 0.6898\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.71035\n","Epoch 138/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4268 - categorical_accuracy: 1.0000 - val_loss: 1.2100 - val_categorical_accuracy: 0.7008\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.71035\n","Epoch 139/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4242 - categorical_accuracy: 1.0000 - val_loss: 1.2188 - val_categorical_accuracy: 0.6957\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.71035\n","Epoch 140/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.4031 - categorical_accuracy: 1.0000 - val_loss: 1.2028 - val_categorical_accuracy: 0.7048\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.71035\n","Epoch 141/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3940 - categorical_accuracy: 1.0000 - val_loss: 1.2008 - val_categorical_accuracy: 0.6990\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.71035\n","Epoch 142/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4075 - categorical_accuracy: 1.0000 - val_loss: 1.2052 - val_categorical_accuracy: 0.6850\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.71035\n","Epoch 143/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3822 - categorical_accuracy: 1.0000 - val_loss: 1.1999 - val_categorical_accuracy: 0.6707\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.71035\n","Epoch 144/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3973 - categorical_accuracy: 1.0000 - val_loss: 1.2024 - val_categorical_accuracy: 0.6630\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.71035\n","Epoch 145/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.4090 - categorical_accuracy: 1.0000 - val_loss: 1.1932 - val_categorical_accuracy: 0.6612\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.71035\n","Epoch 146/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3835 - categorical_accuracy: 1.0000 - val_loss: 1.2019 - val_categorical_accuracy: 0.6894\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.71035\n","Epoch 147/150\n","21/21 [==============================] - 0s 16ms/step - loss: 0.3973 - categorical_accuracy: 1.0000 - val_loss: 1.1973 - val_categorical_accuracy: 0.6949\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.71035\n","Epoch 148/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3715 - categorical_accuracy: 1.0000 - val_loss: 1.1928 - val_categorical_accuracy: 0.6751\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.71035\n","Epoch 149/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3790 - categorical_accuracy: 1.0000 - val_loss: 1.2020 - val_categorical_accuracy: 0.7052\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.71035\n","Epoch 150/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.3829 - categorical_accuracy: 1.0000 - val_loss: 1.1892 - val_categorical_accuracy: 0.6527\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.71035\n","86/86 [==============================] - 0s 2ms/step - loss: 1.2328 - categorical_accuracy: 0.7104\n","86/86 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 45 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 630.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [45 45 45 45 45 45 45 45 45 45 45 45 45 45]\n","\n","Total number of samples in test set 2514.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [225  56 206 170 224 224 214 158 269 203 231  88 196  50]\n","\n","X_train_transfer => (630, 128)\n","X_test_transfer  => (2514, 128)\n","y_train => (630, 14)\n","y_test  => (2514, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","32/32 [==============================] - 1s 14ms/step - loss: 3.8999 - categorical_accuracy: 0.0550 - val_loss: 2.6920 - val_categorical_accuracy: 0.0370\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.03699, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.4576 - categorical_accuracy: 0.1412 - val_loss: 2.4605 - val_categorical_accuracy: 0.0760\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.03699 to 0.07597, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","32/32 [==============================] - 0s 11ms/step - loss: 2.2415 - categorical_accuracy: 0.1895 - val_loss: 2.2527 - val_categorical_accuracy: 0.2649\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.07597 to 0.26492, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","32/32 [==============================] - 0s 10ms/step - loss: 2.0691 - categorical_accuracy: 0.4387 - val_loss: 2.1904 - val_categorical_accuracy: 0.1671\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.26492\n","Epoch 5/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.9271 - categorical_accuracy: 0.4571 - val_loss: 2.1447 - val_categorical_accuracy: 0.2363\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.26492\n","Epoch 6/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.8187 - categorical_accuracy: 0.4857 - val_loss: 2.0364 - val_categorical_accuracy: 0.4447\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.26492 to 0.44471, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.7353 - categorical_accuracy: 0.6921 - val_loss: 1.9977 - val_categorical_accuracy: 0.3866\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.44471\n","Epoch 8/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.6727 - categorical_accuracy: 0.6615 - val_loss: 1.9269 - val_categorical_accuracy: 0.5302\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.44471 to 0.53023, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.6338 - categorical_accuracy: 0.7007 - val_loss: 1.8984 - val_categorical_accuracy: 0.4865\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.53023\n","Epoch 10/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.5750 - categorical_accuracy: 0.7803 - val_loss: 1.8831 - val_categorical_accuracy: 0.4328\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.53023\n","Epoch 11/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.5262 - categorical_accuracy: 0.7279 - val_loss: 1.8322 - val_categorical_accuracy: 0.5350\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.53023 to 0.53500, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 12/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.4713 - categorical_accuracy: 0.7306 - val_loss: 1.7948 - val_categorical_accuracy: 0.5235\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.53500\n","Epoch 13/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.4510 - categorical_accuracy: 0.8016 - val_loss: 1.7855 - val_categorical_accuracy: 0.4893\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.53500\n","Epoch 14/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3998 - categorical_accuracy: 0.7508 - val_loss: 1.7561 - val_categorical_accuracy: 0.4336\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.53500\n","Epoch 15/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.3631 - categorical_accuracy: 0.7223 - val_loss: 1.7177 - val_categorical_accuracy: 0.4909\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.53500\n","Epoch 16/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.3261 - categorical_accuracy: 0.8718 - val_loss: 1.7165 - val_categorical_accuracy: 0.5111\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.53500\n","Epoch 17/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2907 - categorical_accuracy: 0.8155 - val_loss: 1.7087 - val_categorical_accuracy: 0.5024\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.53500\n","Epoch 18/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.2731 - categorical_accuracy: 0.8434 - val_loss: 1.6601 - val_categorical_accuracy: 0.5676\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.53500 to 0.56762, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 19/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2423 - categorical_accuracy: 0.8783 - val_loss: 1.6695 - val_categorical_accuracy: 0.5330\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.56762\n","Epoch 20/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2417 - categorical_accuracy: 0.8186 - val_loss: 1.6310 - val_categorical_accuracy: 0.5601\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.56762\n","Epoch 21/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2190 - categorical_accuracy: 0.8050 - val_loss: 1.6279 - val_categorical_accuracy: 0.4029\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.56762\n","Epoch 22/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1539 - categorical_accuracy: 0.8625 - val_loss: 1.6016 - val_categorical_accuracy: 0.5839\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.56762 to 0.58393, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 23/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.8834 - val_loss: 1.6030 - val_categorical_accuracy: 0.5239\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.58393\n","Epoch 24/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.1305 - categorical_accuracy: 0.8597 - val_loss: 1.5973 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.58393\n","Epoch 25/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0588 - categorical_accuracy: 0.9097 - val_loss: 1.5619 - val_categorical_accuracy: 0.5764\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.58393\n","Epoch 26/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0892 - categorical_accuracy: 0.9322 - val_loss: 1.5643 - val_categorical_accuracy: 0.5963\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.58393 to 0.59626, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 27/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0331 - categorical_accuracy: 0.9169 - val_loss: 1.5234 - val_categorical_accuracy: 0.5975\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.59626 to 0.59745, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.0225 - categorical_accuracy: 0.8542 - val_loss: 1.5262 - val_categorical_accuracy: 0.5700\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.59745\n","Epoch 29/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.0157 - categorical_accuracy: 0.8999 - val_loss: 1.5147 - val_categorical_accuracy: 0.6368\n","\n","Epoch 00029: val_categorical_accuracy improved from 0.59745 to 0.63683, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 30/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0389 - categorical_accuracy: 0.9451 - val_loss: 1.5217 - val_categorical_accuracy: 0.5831\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.63683\n","Epoch 31/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.9944 - categorical_accuracy: 0.9659 - val_loss: 1.5172 - val_categorical_accuracy: 0.6070\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.63683\n","Epoch 32/150\n","32/32 [==============================] - 0s 11ms/step - loss: 1.0033 - categorical_accuracy: 0.9609 - val_loss: 1.5152 - val_categorical_accuracy: 0.5887\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.63683\n","Epoch 33/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9911 - categorical_accuracy: 0.9296 - val_loss: 1.4718 - val_categorical_accuracy: 0.5696\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.63683\n","Epoch 34/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.9127 - categorical_accuracy: 0.9549 - val_loss: 1.4741 - val_categorical_accuracy: 0.6516\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.63683 to 0.65155, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8916 - categorical_accuracy: 0.9583 - val_loss: 1.4821 - val_categorical_accuracy: 0.5716\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.65155\n","Epoch 36/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8898 - categorical_accuracy: 0.9314 - val_loss: 1.4457 - val_categorical_accuracy: 0.5748\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.65155\n","Epoch 37/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8868 - categorical_accuracy: 0.9743 - val_loss: 1.4554 - val_categorical_accuracy: 0.6531\n","\n","Epoch 00037: val_categorical_accuracy improved from 0.65155 to 0.65314, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 38/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8684 - categorical_accuracy: 0.9416 - val_loss: 1.4490 - val_categorical_accuracy: 0.6277\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.65314\n","Epoch 39/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8581 - categorical_accuracy: 0.9801 - val_loss: 1.4447 - val_categorical_accuracy: 0.6480\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.65314\n","Epoch 40/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8302 - categorical_accuracy: 0.9588 - val_loss: 1.4605 - val_categorical_accuracy: 0.5768\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.65314\n","Epoch 41/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8331 - categorical_accuracy: 0.9327 - val_loss: 1.4241 - val_categorical_accuracy: 0.6074\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.65314\n","Epoch 42/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8212 - categorical_accuracy: 0.9624 - val_loss: 1.4381 - val_categorical_accuracy: 0.6297\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.65314\n","Epoch 43/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7904 - categorical_accuracy: 0.9512 - val_loss: 1.4220 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.65314 to 0.65434, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7797 - categorical_accuracy: 0.9844 - val_loss: 1.4206 - val_categorical_accuracy: 0.5871\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.65434\n","Epoch 45/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7799 - categorical_accuracy: 0.9821 - val_loss: 1.3874 - val_categorical_accuracy: 0.5943\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.65434\n","Epoch 46/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7959 - categorical_accuracy: 0.9496 - val_loss: 1.3779 - val_categorical_accuracy: 0.6309\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.65434\n","Epoch 47/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7369 - categorical_accuracy: 0.9928 - val_loss: 1.4065 - val_categorical_accuracy: 0.6519\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.65434\n","Epoch 48/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7402 - categorical_accuracy: 0.9869 - val_loss: 1.3783 - val_categorical_accuracy: 0.6623\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.65434 to 0.66229, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 49/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7211 - categorical_accuracy: 0.9731 - val_loss: 1.3943 - val_categorical_accuracy: 0.6388\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.66229\n","Epoch 50/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7139 - categorical_accuracy: 0.9881 - val_loss: 1.3814 - val_categorical_accuracy: 0.6372\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.66229\n","Epoch 51/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7292 - categorical_accuracy: 0.9843 - val_loss: 1.3699 - val_categorical_accuracy: 0.6539\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.66229\n","Epoch 52/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6734 - categorical_accuracy: 0.9692 - val_loss: 1.3642 - val_categorical_accuracy: 0.6325\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.66229\n","Epoch 53/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7121 - categorical_accuracy: 0.9907 - val_loss: 1.3566 - val_categorical_accuracy: 0.6400\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.66229\n","Epoch 54/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6763 - categorical_accuracy: 0.9633 - val_loss: 1.3448 - val_categorical_accuracy: 0.6309\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.66229\n","Epoch 55/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6809 - categorical_accuracy: 0.9882 - val_loss: 1.3428 - val_categorical_accuracy: 0.6531\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.66229\n","Epoch 56/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6587 - categorical_accuracy: 0.9859 - val_loss: 1.3684 - val_categorical_accuracy: 0.6611\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.66229\n","Epoch 57/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6317 - categorical_accuracy: 0.9946 - val_loss: 1.3495 - val_categorical_accuracy: 0.6396\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.66229\n","Epoch 58/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6403 - categorical_accuracy: 0.9980 - val_loss: 1.3398 - val_categorical_accuracy: 0.5979\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.66229\n","Epoch 59/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6454 - categorical_accuracy: 0.9911 - val_loss: 1.3341 - val_categorical_accuracy: 0.6488\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.66229\n","Epoch 60/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6307 - categorical_accuracy: 0.9893 - val_loss: 1.3268 - val_categorical_accuracy: 0.6519\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.66229\n","Epoch 61/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6191 - categorical_accuracy: 0.9870 - val_loss: 1.3137 - val_categorical_accuracy: 0.6309\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.66229\n","Epoch 62/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6181 - categorical_accuracy: 0.9910 - val_loss: 1.3284 - val_categorical_accuracy: 0.6333\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.66229\n","Epoch 63/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5822 - categorical_accuracy: 0.9899 - val_loss: 1.3184 - val_categorical_accuracy: 0.6535\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.66229\n","Epoch 64/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5692 - categorical_accuracy: 0.9921 - val_loss: 1.3272 - val_categorical_accuracy: 0.6269\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.66229\n","Epoch 65/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.6006 - categorical_accuracy: 0.9905 - val_loss: 1.3073 - val_categorical_accuracy: 0.6297\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.66229\n","Epoch 66/150\n","32/32 [==============================] - 0s 12ms/step - loss: 0.5544 - categorical_accuracy: 0.9899 - val_loss: 1.2977 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.66229\n","Epoch 67/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5886 - categorical_accuracy: 0.9902 - val_loss: 1.3350 - val_categorical_accuracy: 0.6154\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.66229\n","Epoch 68/150\n","32/32 [==============================] - 0s 12ms/step - loss: 0.5711 - categorical_accuracy: 0.9872 - val_loss: 1.3147 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.66229\n","Epoch 69/150\n","32/32 [==============================] - 0s 12ms/step - loss: 0.5756 - categorical_accuracy: 0.9908 - val_loss: 1.3075 - val_categorical_accuracy: 0.6225\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.66229\n","Epoch 70/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5265 - categorical_accuracy: 0.9979 - val_loss: 1.2899 - val_categorical_accuracy: 0.6221\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.66229\n","Epoch 71/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5348 - categorical_accuracy: 0.9889 - val_loss: 1.2818 - val_categorical_accuracy: 0.6364\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.66229\n","Epoch 72/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5255 - categorical_accuracy: 0.9958 - val_loss: 1.2747 - val_categorical_accuracy: 0.6325\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.66229\n","Epoch 73/150\n","32/32 [==============================] - 0s 12ms/step - loss: 0.4914 - categorical_accuracy: 0.9972 - val_loss: 1.2871 - val_categorical_accuracy: 0.6675\n","\n","Epoch 00073: val_categorical_accuracy improved from 0.66229 to 0.66746, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 74/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5119 - categorical_accuracy: 0.9940 - val_loss: 1.2815 - val_categorical_accuracy: 0.6269\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.66746\n","Epoch 75/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.5079 - categorical_accuracy: 0.9953 - val_loss: 1.2683 - val_categorical_accuracy: 0.6464\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.66746\n","Epoch 76/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4901 - categorical_accuracy: 0.9966 - val_loss: 1.2797 - val_categorical_accuracy: 0.6591\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.66746\n","Epoch 77/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4810 - categorical_accuracy: 0.9938 - val_loss: 1.2937 - val_categorical_accuracy: 0.6217\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.66746\n","Epoch 78/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5053 - categorical_accuracy: 0.9956 - val_loss: 1.2660 - val_categorical_accuracy: 0.6893\n","\n","Epoch 00078: val_categorical_accuracy improved from 0.66746 to 0.68934, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 79/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4771 - categorical_accuracy: 0.9891 - val_loss: 1.2639 - val_categorical_accuracy: 0.6734\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.68934\n","Epoch 80/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4924 - categorical_accuracy: 0.9856 - val_loss: 1.2700 - val_categorical_accuracy: 0.6615\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.68934\n","Epoch 81/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4927 - categorical_accuracy: 0.9914 - val_loss: 1.2576 - val_categorical_accuracy: 0.6838\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.68934\n","Epoch 82/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4696 - categorical_accuracy: 0.9905 - val_loss: 1.2690 - val_categorical_accuracy: 0.6225\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.68934\n","Epoch 83/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4545 - categorical_accuracy: 0.9948 - val_loss: 1.2697 - val_categorical_accuracy: 0.6150\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.68934\n","Epoch 84/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4588 - categorical_accuracy: 0.9938 - val_loss: 1.2392 - val_categorical_accuracy: 0.6337\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.68934\n","Epoch 85/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4582 - categorical_accuracy: 0.9911 - val_loss: 1.2512 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.68934\n","Epoch 86/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4506 - categorical_accuracy: 0.9992 - val_loss: 1.2426 - val_categorical_accuracy: 0.6376\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.68934\n","Epoch 87/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4375 - categorical_accuracy: 0.9875 - val_loss: 1.2480 - val_categorical_accuracy: 0.6631\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.68934\n","Epoch 88/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4259 - categorical_accuracy: 0.9895 - val_loss: 1.2507 - val_categorical_accuracy: 0.6340\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.68934\n","Epoch 89/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4331 - categorical_accuracy: 0.9961 - val_loss: 1.2515 - val_categorical_accuracy: 0.6420\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.68934\n","Epoch 90/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4258 - categorical_accuracy: 0.9969 - val_loss: 1.2405 - val_categorical_accuracy: 0.6695\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.68934\n","Epoch 91/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3959 - categorical_accuracy: 0.9968 - val_loss: 1.2359 - val_categorical_accuracy: 0.6360\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.68934\n","Epoch 92/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4174 - categorical_accuracy: 0.9983 - val_loss: 1.2473 - val_categorical_accuracy: 0.6173\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.68934\n","Epoch 93/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4281 - categorical_accuracy: 0.9952 - val_loss: 1.2269 - val_categorical_accuracy: 0.6575\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.68934\n","Epoch 94/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4247 - categorical_accuracy: 0.9856 - val_loss: 1.2379 - val_categorical_accuracy: 0.6508\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.68934\n","Epoch 95/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4067 - categorical_accuracy: 0.9921 - val_loss: 1.2407 - val_categorical_accuracy: 0.6384\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.68934\n","Epoch 96/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3970 - categorical_accuracy: 0.9946 - val_loss: 1.2457 - val_categorical_accuracy: 0.6213\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.68934\n","Epoch 97/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.4043 - categorical_accuracy: 0.9918 - val_loss: 1.2421 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.68934\n","Epoch 98/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3974 - categorical_accuracy: 0.9940 - val_loss: 1.2288 - val_categorical_accuracy: 0.6396\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.68934\n","Epoch 99/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3995 - categorical_accuracy: 0.9984 - val_loss: 1.2288 - val_categorical_accuracy: 0.6516\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.68934\n","Epoch 100/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3859 - categorical_accuracy: 0.9930 - val_loss: 1.2221 - val_categorical_accuracy: 0.6416\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.68934\n","Epoch 101/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3783 - categorical_accuracy: 0.9959 - val_loss: 1.2234 - val_categorical_accuracy: 0.6169\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.68934\n","Epoch 102/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3857 - categorical_accuracy: 0.9931 - val_loss: 1.2266 - val_categorical_accuracy: 0.6412\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.68934\n","Epoch 103/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3694 - categorical_accuracy: 0.9960 - val_loss: 1.2370 - val_categorical_accuracy: 0.6607\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.68934\n","Epoch 104/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3591 - categorical_accuracy: 0.9970 - val_loss: 1.2124 - val_categorical_accuracy: 0.6476\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.68934\n","Epoch 105/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3541 - categorical_accuracy: 0.9964 - val_loss: 1.2275 - val_categorical_accuracy: 0.6197\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.68934\n","Epoch 106/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3518 - categorical_accuracy: 0.9967 - val_loss: 1.2190 - val_categorical_accuracy: 0.6456\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.68934\n","Epoch 107/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3568 - categorical_accuracy: 0.9938 - val_loss: 1.2151 - val_categorical_accuracy: 0.6539\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.68934\n","Epoch 108/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3425 - categorical_accuracy: 0.9869 - val_loss: 1.2166 - val_categorical_accuracy: 0.6293\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.68934\n","Epoch 109/150\n","32/32 [==============================] - 0s 12ms/step - loss: 0.3476 - categorical_accuracy: 0.9969 - val_loss: 1.2244 - val_categorical_accuracy: 0.6523\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.68934\n","Epoch 110/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3349 - categorical_accuracy: 0.9993 - val_loss: 1.2090 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.68934\n","Epoch 111/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3450 - categorical_accuracy: 0.9949 - val_loss: 1.2148 - val_categorical_accuracy: 0.6396\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.68934\n","Epoch 112/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3189 - categorical_accuracy: 0.9970 - val_loss: 1.2211 - val_categorical_accuracy: 0.6866\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.68934\n","Epoch 113/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3385 - categorical_accuracy: 0.9979 - val_loss: 1.2024 - val_categorical_accuracy: 0.6559\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.68934\n","Epoch 114/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3168 - categorical_accuracy: 0.9989 - val_loss: 1.2151 - val_categorical_accuracy: 0.6213\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.68934\n","Epoch 115/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3291 - categorical_accuracy: 0.9938 - val_loss: 1.2141 - val_categorical_accuracy: 0.6408\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.68934\n","Epoch 116/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3256 - categorical_accuracy: 0.9994 - val_loss: 1.1951 - val_categorical_accuracy: 0.6436\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.68934\n","Epoch 117/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3042 - categorical_accuracy: 0.9971 - val_loss: 1.2138 - val_categorical_accuracy: 0.6309\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.68934\n","Epoch 118/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3058 - categorical_accuracy: 0.9975 - val_loss: 1.2207 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.68934\n","Epoch 119/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2987 - categorical_accuracy: 0.9965 - val_loss: 1.2142 - val_categorical_accuracy: 0.6460\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.68934\n","Epoch 120/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3014 - categorical_accuracy: 0.9958 - val_loss: 1.2079 - val_categorical_accuracy: 0.6356\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.68934\n","Epoch 121/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2951 - categorical_accuracy: 0.9961 - val_loss: 1.2066 - val_categorical_accuracy: 0.6384\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.68934\n","Epoch 122/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2995 - categorical_accuracy: 0.9966 - val_loss: 1.2012 - val_categorical_accuracy: 0.6706\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.68934\n","Epoch 123/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.3042 - categorical_accuracy: 0.9942 - val_loss: 1.2022 - val_categorical_accuracy: 0.6476\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.68934\n","Epoch 124/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2803 - categorical_accuracy: 0.9964 - val_loss: 1.2152 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.68934\n","Epoch 125/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2795 - categorical_accuracy: 0.9984 - val_loss: 1.2110 - val_categorical_accuracy: 0.6360\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.68934\n","Epoch 126/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2930 - categorical_accuracy: 0.9971 - val_loss: 1.2092 - val_categorical_accuracy: 0.6277\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.68934\n","Epoch 127/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2978 - categorical_accuracy: 0.9958 - val_loss: 1.1931 - val_categorical_accuracy: 0.6523\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.68934\n","Epoch 128/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2932 - categorical_accuracy: 0.9857 - val_loss: 1.1965 - val_categorical_accuracy: 0.6460\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.68934\n","Epoch 129/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2831 - categorical_accuracy: 0.9906 - val_loss: 1.2008 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.68934\n","Epoch 130/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2902 - categorical_accuracy: 0.9903 - val_loss: 1.2023 - val_categorical_accuracy: 0.6460\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.68934\n","Epoch 131/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2725 - categorical_accuracy: 0.9993 - val_loss: 1.1881 - val_categorical_accuracy: 0.6476\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.68934\n","Epoch 132/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2710 - categorical_accuracy: 0.9975 - val_loss: 1.2003 - val_categorical_accuracy: 0.6523\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.68934\n","Epoch 133/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2850 - categorical_accuracy: 0.9983 - val_loss: 1.1903 - val_categorical_accuracy: 0.6337\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.68934\n","Epoch 134/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2663 - categorical_accuracy: 0.9957 - val_loss: 1.1970 - val_categorical_accuracy: 0.6388\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.68934\n","Epoch 135/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2627 - categorical_accuracy: 0.9985 - val_loss: 1.1969 - val_categorical_accuracy: 0.6372\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.68934\n","Epoch 136/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2645 - categorical_accuracy: 0.9919 - val_loss: 1.1851 - val_categorical_accuracy: 0.6563\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.68934\n","Epoch 137/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2592 - categorical_accuracy: 0.9976 - val_loss: 1.1839 - val_categorical_accuracy: 0.6408\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.68934\n","Epoch 138/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2516 - categorical_accuracy: 0.9996 - val_loss: 1.1906 - val_categorical_accuracy: 0.6480\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.68934\n","Epoch 139/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2600 - categorical_accuracy: 0.9970 - val_loss: 1.2055 - val_categorical_accuracy: 0.6539\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.68934\n","Epoch 140/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2508 - categorical_accuracy: 0.9986 - val_loss: 1.1928 - val_categorical_accuracy: 0.6472\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.68934\n","Epoch 141/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2477 - categorical_accuracy: 0.9983 - val_loss: 1.1911 - val_categorical_accuracy: 0.6587\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.68934\n","Epoch 142/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2406 - categorical_accuracy: 0.9967 - val_loss: 1.1819 - val_categorical_accuracy: 0.6579\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.68934\n","Epoch 143/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2514 - categorical_accuracy: 0.9953 - val_loss: 1.1873 - val_categorical_accuracy: 0.6607\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.68934\n","Epoch 144/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2336 - categorical_accuracy: 0.9976 - val_loss: 1.1876 - val_categorical_accuracy: 0.6535\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.68934\n","Epoch 145/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2504 - categorical_accuracy: 0.9959 - val_loss: 1.1954 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.68934\n","Epoch 146/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2436 - categorical_accuracy: 0.9960 - val_loss: 1.1866 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.68934\n","Epoch 147/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2297 - categorical_accuracy: 0.9976 - val_loss: 1.1875 - val_categorical_accuracy: 0.6504\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.68934\n","Epoch 148/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2379 - categorical_accuracy: 0.9974 - val_loss: 1.1847 - val_categorical_accuracy: 0.6559\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.68934\n","Epoch 149/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2499 - categorical_accuracy: 0.9965 - val_loss: 1.1752 - val_categorical_accuracy: 0.6615\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.68934\n","Epoch 150/150\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2343 - categorical_accuracy: 0.9948 - val_loss: 1.1796 - val_categorical_accuracy: 0.6559\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.68934\n","79/79 [==============================] - 0s 2ms/step - loss: 1.2660 - categorical_accuracy: 0.6893\n","79/79 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 60 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 840.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [60 60 60 60 60 60 60 60 60 60 60 60 60 60]\n","\n","Total number of samples in test set 2304.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [210  41 191 155 209 209 199 143 254 188 216  73 181  35]\n","\n","X_train_transfer => (840, 128)\n","X_test_transfer  => (2304, 128)\n","y_train => (840, 14)\n","y_test  => (2304, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","42/42 [==============================] - 1s 11ms/step - loss: 3.7426 - categorical_accuracy: 0.0941 - val_loss: 2.6469 - val_categorical_accuracy: 0.0833\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.08333, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","42/42 [==============================] - 0s 9ms/step - loss: 2.3641 - categorical_accuracy: 0.1635 - val_loss: 2.3092 - val_categorical_accuracy: 0.2487\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.08333 to 0.24870, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","42/42 [==============================] - 0s 8ms/step - loss: 2.1126 - categorical_accuracy: 0.3143 - val_loss: 2.1907 - val_categorical_accuracy: 0.3177\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.24870 to 0.31771, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.9425 - categorical_accuracy: 0.5040 - val_loss: 2.1139 - val_categorical_accuracy: 0.3355\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.31771 to 0.33550, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.8367 - categorical_accuracy: 0.5600 - val_loss: 2.0333 - val_categorical_accuracy: 0.2925\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.33550\n","Epoch 6/150\n","42/42 [==============================] - 0s 9ms/step - loss: 1.7676 - categorical_accuracy: 0.5625 - val_loss: 1.9736 - val_categorical_accuracy: 0.3876\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.33550 to 0.38759, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.6726 - categorical_accuracy: 0.6018 - val_loss: 1.9330 - val_categorical_accuracy: 0.4462\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.38759 to 0.44618, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.5781 - categorical_accuracy: 0.6934 - val_loss: 1.8627 - val_categorical_accuracy: 0.4970\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.44618 to 0.49696, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.5127 - categorical_accuracy: 0.7771 - val_loss: 1.8246 - val_categorical_accuracy: 0.5069\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.49696 to 0.50694, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 10/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.4722 - categorical_accuracy: 0.7914 - val_loss: 1.7836 - val_categorical_accuracy: 0.5434\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.50694 to 0.54340, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.4472 - categorical_accuracy: 0.7826 - val_loss: 1.7778 - val_categorical_accuracy: 0.5278\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.54340\n","Epoch 12/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.3904 - categorical_accuracy: 0.7946 - val_loss: 1.7386 - val_categorical_accuracy: 0.5095\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.54340\n","Epoch 13/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.3309 - categorical_accuracy: 0.8273 - val_loss: 1.7051 - val_categorical_accuracy: 0.5799\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.54340 to 0.57986, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","42/42 [==============================] - 0s 9ms/step - loss: 1.2998 - categorical_accuracy: 0.7894 - val_loss: 1.6702 - val_categorical_accuracy: 0.5551\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.57986\n","Epoch 15/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2288 - categorical_accuracy: 0.8476 - val_loss: 1.6789 - val_categorical_accuracy: 0.5161\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.57986\n","Epoch 16/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.2471 - categorical_accuracy: 0.8294 - val_loss: 1.6520 - val_categorical_accuracy: 0.4766\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.57986\n","Epoch 17/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1932 - categorical_accuracy: 0.8221 - val_loss: 1.6114 - val_categorical_accuracy: 0.5061\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.57986\n","Epoch 18/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1179 - categorical_accuracy: 0.9070 - val_loss: 1.6316 - val_categorical_accuracy: 0.5243\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.57986\n","Epoch 19/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1668 - categorical_accuracy: 0.8381 - val_loss: 1.5941 - val_categorical_accuracy: 0.5586\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.57986\n","Epoch 20/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1033 - categorical_accuracy: 0.9196 - val_loss: 1.5763 - val_categorical_accuracy: 0.5664\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.57986\n","Epoch 21/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.1154 - categorical_accuracy: 0.9223 - val_loss: 1.5474 - val_categorical_accuracy: 0.5846\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.57986 to 0.58464, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0581 - categorical_accuracy: 0.9109 - val_loss: 1.5327 - val_categorical_accuracy: 0.5751\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.58464\n","Epoch 23/150\n","42/42 [==============================] - 0s 9ms/step - loss: 1.0484 - categorical_accuracy: 0.9077 - val_loss: 1.5077 - val_categorical_accuracy: 0.5026\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.58464\n","Epoch 24/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0211 - categorical_accuracy: 0.8956 - val_loss: 1.5236 - val_categorical_accuracy: 0.5998\n","\n","Epoch 00024: val_categorical_accuracy improved from 0.58464 to 0.59983, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 25/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.0144 - categorical_accuracy: 0.8908 - val_loss: 1.4993 - val_categorical_accuracy: 0.6207\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.59983 to 0.62066, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9586 - categorical_accuracy: 0.9591 - val_loss: 1.5110 - val_categorical_accuracy: 0.6111\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.62066\n","Epoch 27/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9164 - categorical_accuracy: 0.9296 - val_loss: 1.4651 - val_categorical_accuracy: 0.5634\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.62066\n","Epoch 28/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9591 - categorical_accuracy: 0.9515 - val_loss: 1.4851 - val_categorical_accuracy: 0.5629\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.62066\n","Epoch 29/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8958 - categorical_accuracy: 0.9460 - val_loss: 1.4526 - val_categorical_accuracy: 0.5964\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.62066\n","Epoch 30/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8548 - categorical_accuracy: 0.9589 - val_loss: 1.4566 - val_categorical_accuracy: 0.5985\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.62066\n","Epoch 31/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8424 - categorical_accuracy: 0.9687 - val_loss: 1.4859 - val_categorical_accuracy: 0.5599\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.62066\n","Epoch 32/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8347 - categorical_accuracy: 0.9517 - val_loss: 1.4526 - val_categorical_accuracy: 0.5603\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.62066\n","Epoch 33/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.8364 - categorical_accuracy: 0.9784 - val_loss: 1.4566 - val_categorical_accuracy: 0.5864\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.62066\n","Epoch 34/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.7905 - categorical_accuracy: 0.9521 - val_loss: 1.4073 - val_categorical_accuracy: 0.6332\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.62066 to 0.63325, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.8116 - categorical_accuracy: 0.9698 - val_loss: 1.4205 - val_categorical_accuracy: 0.5946\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.63325\n","Epoch 36/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7892 - categorical_accuracy: 0.9516 - val_loss: 1.4060 - val_categorical_accuracy: 0.6471\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.63325 to 0.64714, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 37/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.7724 - categorical_accuracy: 0.9674 - val_loss: 1.4064 - val_categorical_accuracy: 0.5820\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.64714\n","Epoch 38/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7346 - categorical_accuracy: 0.9664 - val_loss: 1.4072 - val_categorical_accuracy: 0.6007\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.64714\n","Epoch 39/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.7448 - categorical_accuracy: 0.9505 - val_loss: 1.3784 - val_categorical_accuracy: 0.6063\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.64714\n","Epoch 40/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6966 - categorical_accuracy: 0.9754 - val_loss: 1.3788 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.64714\n","Epoch 41/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7351 - categorical_accuracy: 0.9891 - val_loss: 1.3721 - val_categorical_accuracy: 0.6536\n","\n","Epoch 00041: val_categorical_accuracy improved from 0.64714 to 0.65365, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 42/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.6886 - categorical_accuracy: 0.9851 - val_loss: 1.3625 - val_categorical_accuracy: 0.5955\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.65365\n","Epoch 43/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6695 - categorical_accuracy: 0.9640 - val_loss: 1.3376 - val_categorical_accuracy: 0.6102\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.65365\n","Epoch 44/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.6629 - categorical_accuracy: 0.9825 - val_loss: 1.3710 - val_categorical_accuracy: 0.5916\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.65365\n","Epoch 45/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6431 - categorical_accuracy: 0.9938 - val_loss: 1.3763 - val_categorical_accuracy: 0.5942\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.65365\n","Epoch 46/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6637 - categorical_accuracy: 0.9922 - val_loss: 1.3522 - val_categorical_accuracy: 0.6202\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.65365\n","Epoch 47/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6058 - categorical_accuracy: 0.9868 - val_loss: 1.3160 - val_categorical_accuracy: 0.6311\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.65365\n","Epoch 48/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6334 - categorical_accuracy: 0.9924 - val_loss: 1.3258 - val_categorical_accuracy: 0.6723\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.65365 to 0.67231, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 49/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6198 - categorical_accuracy: 0.9911 - val_loss: 1.3128 - val_categorical_accuracy: 0.6280\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.67231\n","Epoch 50/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.6048 - categorical_accuracy: 0.9899 - val_loss: 1.3196 - val_categorical_accuracy: 0.6189\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.67231\n","Epoch 51/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.5913 - categorical_accuracy: 0.9950 - val_loss: 1.3079 - val_categorical_accuracy: 0.6120\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.67231\n","Epoch 52/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5657 - categorical_accuracy: 0.9949 - val_loss: 1.2971 - val_categorical_accuracy: 0.6176\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.67231\n","Epoch 53/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5979 - categorical_accuracy: 0.9906 - val_loss: 1.2959 - val_categorical_accuracy: 0.6185\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.67231\n","Epoch 54/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.5399 - categorical_accuracy: 0.9955 - val_loss: 1.2983 - val_categorical_accuracy: 0.6315\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.67231\n","Epoch 55/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5477 - categorical_accuracy: 0.9928 - val_loss: 1.3262 - val_categorical_accuracy: 0.6111\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.67231\n","Epoch 56/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5639 - categorical_accuracy: 0.9892 - val_loss: 1.2871 - val_categorical_accuracy: 0.6319\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.67231\n","Epoch 57/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.5570 - categorical_accuracy: 0.9826 - val_loss: 1.2977 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.67231\n","Epoch 58/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5046 - categorical_accuracy: 0.9941 - val_loss: 1.2886 - val_categorical_accuracy: 0.6332\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.67231\n","Epoch 59/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4919 - categorical_accuracy: 0.9950 - val_loss: 1.2795 - val_categorical_accuracy: 0.6189\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.67231\n","Epoch 60/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5220 - categorical_accuracy: 0.9917 - val_loss: 1.3069 - val_categorical_accuracy: 0.6124\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.67231\n","Epoch 61/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5045 - categorical_accuracy: 0.9950 - val_loss: 1.2735 - val_categorical_accuracy: 0.6367\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.67231\n","Epoch 62/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5001 - categorical_accuracy: 0.9986 - val_loss: 1.2644 - val_categorical_accuracy: 0.6415\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.67231\n","Epoch 63/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4739 - categorical_accuracy: 0.9951 - val_loss: 1.2782 - val_categorical_accuracy: 0.6224\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.67231\n","Epoch 64/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4826 - categorical_accuracy: 0.9913 - val_loss: 1.2586 - val_categorical_accuracy: 0.6311\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.67231\n","Epoch 65/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4678 - categorical_accuracy: 0.9982 - val_loss: 1.2619 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.67231\n","Epoch 66/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4701 - categorical_accuracy: 0.9966 - val_loss: 1.2636 - val_categorical_accuracy: 0.6398\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.67231\n","Epoch 67/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4329 - categorical_accuracy: 0.9954 - val_loss: 1.2439 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.67231\n","Epoch 68/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4360 - categorical_accuracy: 0.9988 - val_loss: 1.2539 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.67231\n","Epoch 69/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4445 - categorical_accuracy: 0.9968 - val_loss: 1.2507 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.67231\n","Epoch 70/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4468 - categorical_accuracy: 0.9966 - val_loss: 1.2601 - val_categorical_accuracy: 0.6250\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.67231\n","Epoch 71/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4434 - categorical_accuracy: 0.9977 - val_loss: 1.2431 - val_categorical_accuracy: 0.6536\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.67231\n","Epoch 72/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4097 - categorical_accuracy: 0.9927 - val_loss: 1.2488 - val_categorical_accuracy: 0.6220\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.67231\n","Epoch 73/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.4047 - categorical_accuracy: 0.9950 - val_loss: 1.2495 - val_categorical_accuracy: 0.6319\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.67231\n","Epoch 74/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4234 - categorical_accuracy: 0.9985 - val_loss: 1.2579 - val_categorical_accuracy: 0.6050\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.67231\n","Epoch 75/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3929 - categorical_accuracy: 0.9995 - val_loss: 1.2425 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.67231\n","Epoch 76/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.4001 - categorical_accuracy: 0.9941 - val_loss: 1.2342 - val_categorical_accuracy: 0.6341\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.67231\n","Epoch 77/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3970 - categorical_accuracy: 0.9962 - val_loss: 1.2349 - val_categorical_accuracy: 0.6198\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.67231\n","Epoch 78/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.4042 - categorical_accuracy: 0.9874 - val_loss: 1.2335 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.67231\n","Epoch 79/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3979 - categorical_accuracy: 0.9958 - val_loss: 1.2375 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.67231\n","Epoch 80/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3743 - categorical_accuracy: 0.9994 - val_loss: 1.2389 - val_categorical_accuracy: 0.6207\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.67231\n","Epoch 81/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3752 - categorical_accuracy: 0.9959 - val_loss: 1.2149 - val_categorical_accuracy: 0.6450\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.67231\n","Epoch 82/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3639 - categorical_accuracy: 0.9959 - val_loss: 1.2219 - val_categorical_accuracy: 0.6155\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.67231\n","Epoch 83/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3631 - categorical_accuracy: 0.9952 - val_loss: 1.2188 - val_categorical_accuracy: 0.6319\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.67231\n","Epoch 84/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3594 - categorical_accuracy: 0.9975 - val_loss: 1.2248 - val_categorical_accuracy: 0.6385\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.67231\n","Epoch 85/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3371 - categorical_accuracy: 0.9989 - val_loss: 1.2282 - val_categorical_accuracy: 0.6376\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.67231\n","Epoch 86/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3604 - categorical_accuracy: 0.9986 - val_loss: 1.2259 - val_categorical_accuracy: 0.6220\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.67231\n","Epoch 87/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3455 - categorical_accuracy: 0.9985 - val_loss: 1.2188 - val_categorical_accuracy: 0.6467\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.67231\n","Epoch 88/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3279 - categorical_accuracy: 0.9973 - val_loss: 1.2213 - val_categorical_accuracy: 0.6332\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.67231\n","Epoch 89/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3423 - categorical_accuracy: 0.9967 - val_loss: 1.2315 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.67231\n","Epoch 90/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3321 - categorical_accuracy: 0.9985 - val_loss: 1.2139 - val_categorical_accuracy: 0.6115\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.67231\n","Epoch 91/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3352 - categorical_accuracy: 0.9987 - val_loss: 1.2145 - val_categorical_accuracy: 0.6354\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.67231\n","Epoch 92/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3325 - categorical_accuracy: 0.9978 - val_loss: 1.1976 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.67231\n","Epoch 93/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3108 - categorical_accuracy: 0.9953 - val_loss: 1.2262 - val_categorical_accuracy: 0.6293\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.67231\n","Epoch 94/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3171 - categorical_accuracy: 0.9942 - val_loss: 1.2604 - val_categorical_accuracy: 0.6163\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.67231\n","Epoch 95/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3126 - categorical_accuracy: 0.9973 - val_loss: 1.2024 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.67231\n","Epoch 96/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.3042 - categorical_accuracy: 0.9966 - val_loss: 1.2232 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.67231\n","Epoch 97/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3089 - categorical_accuracy: 0.9989 - val_loss: 1.2087 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.67231\n","Epoch 98/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2909 - categorical_accuracy: 0.9982 - val_loss: 1.1976 - val_categorical_accuracy: 0.6458\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.67231\n","Epoch 99/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2833 - categorical_accuracy: 0.9987 - val_loss: 1.1945 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.67231\n","Epoch 100/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2863 - categorical_accuracy: 0.9934 - val_loss: 1.1906 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.67231\n","Epoch 101/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2906 - categorical_accuracy: 0.9973 - val_loss: 1.1823 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.67231\n","Epoch 102/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2797 - categorical_accuracy: 0.9934 - val_loss: 1.2128 - val_categorical_accuracy: 0.6302\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.67231\n","Epoch 103/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2784 - categorical_accuracy: 0.9948 - val_loss: 1.2284 - val_categorical_accuracy: 0.6328\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.67231\n","Epoch 104/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2795 - categorical_accuracy: 0.9977 - val_loss: 1.2183 - val_categorical_accuracy: 0.6367\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.67231\n","Epoch 105/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2828 - categorical_accuracy: 0.9948 - val_loss: 1.2004 - val_categorical_accuracy: 0.6445\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.67231\n","Epoch 106/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2660 - categorical_accuracy: 0.9974 - val_loss: 1.2050 - val_categorical_accuracy: 0.6141\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.67231\n","Epoch 107/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2622 - categorical_accuracy: 0.9975 - val_loss: 1.2084 - val_categorical_accuracy: 0.6319\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.67231\n","Epoch 108/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2688 - categorical_accuracy: 0.9994 - val_loss: 1.2038 - val_categorical_accuracy: 0.6393\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.67231\n","Epoch 109/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2609 - categorical_accuracy: 0.9983 - val_loss: 1.2012 - val_categorical_accuracy: 0.6389\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.67231\n","Epoch 110/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2613 - categorical_accuracy: 0.9992 - val_loss: 1.1879 - val_categorical_accuracy: 0.6519\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.67231\n","Epoch 111/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2651 - categorical_accuracy: 0.9945 - val_loss: 1.2286 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.67231\n","Epoch 112/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2563 - categorical_accuracy: 0.9933 - val_loss: 1.1761 - val_categorical_accuracy: 0.6450\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.67231\n","Epoch 113/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2496 - categorical_accuracy: 0.9980 - val_loss: 1.1916 - val_categorical_accuracy: 0.6441\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.67231\n","Epoch 114/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2540 - categorical_accuracy: 0.9956 - val_loss: 1.2033 - val_categorical_accuracy: 0.6393\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.67231\n","Epoch 115/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2485 - categorical_accuracy: 0.9985 - val_loss: 1.1945 - val_categorical_accuracy: 0.6363\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.67231\n","Epoch 116/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2438 - categorical_accuracy: 0.9988 - val_loss: 1.1860 - val_categorical_accuracy: 0.6571\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.67231\n","Epoch 117/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2565 - categorical_accuracy: 0.9933 - val_loss: 1.1910 - val_categorical_accuracy: 0.6406\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.67231\n","Epoch 118/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2398 - categorical_accuracy: 0.9945 - val_loss: 1.1983 - val_categorical_accuracy: 0.6385\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.67231\n","Epoch 119/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2338 - categorical_accuracy: 0.9912 - val_loss: 1.1963 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.67231\n","Epoch 120/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2333 - categorical_accuracy: 0.9982 - val_loss: 1.1824 - val_categorical_accuracy: 0.6506\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.67231\n","Epoch 121/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2248 - categorical_accuracy: 0.9978 - val_loss: 1.1727 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.67231\n","Epoch 122/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2333 - categorical_accuracy: 0.9961 - val_loss: 1.1759 - val_categorical_accuracy: 0.6454\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.67231\n","Epoch 123/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2248 - categorical_accuracy: 0.9992 - val_loss: 1.1889 - val_categorical_accuracy: 0.6398\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.67231\n","Epoch 124/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2279 - categorical_accuracy: 0.9964 - val_loss: 1.1872 - val_categorical_accuracy: 0.6419\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.67231\n","Epoch 125/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2181 - categorical_accuracy: 0.9959 - val_loss: 1.1863 - val_categorical_accuracy: 0.6267\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.67231\n","Epoch 126/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2176 - categorical_accuracy: 0.9951 - val_loss: 1.1911 - val_categorical_accuracy: 0.6228\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.67231\n","Epoch 127/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2154 - categorical_accuracy: 0.9968 - val_loss: 1.1762 - val_categorical_accuracy: 0.6363\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.67231\n","Epoch 128/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2157 - categorical_accuracy: 0.9965 - val_loss: 1.1953 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.67231\n","Epoch 129/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2182 - categorical_accuracy: 0.9943 - val_loss: 1.1746 - val_categorical_accuracy: 0.6341\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.67231\n","Epoch 130/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.2125 - categorical_accuracy: 0.9952 - val_loss: 1.1827 - val_categorical_accuracy: 0.6359\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.67231\n","Epoch 131/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1992 - categorical_accuracy: 0.9982 - val_loss: 1.1784 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.67231\n","Epoch 132/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2007 - categorical_accuracy: 0.9992 - val_loss: 1.1994 - val_categorical_accuracy: 0.6402\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.67231\n","Epoch 133/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1997 - categorical_accuracy: 0.9983 - val_loss: 1.1891 - val_categorical_accuracy: 0.6398\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.67231\n","Epoch 134/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2005 - categorical_accuracy: 0.9970 - val_loss: 1.1924 - val_categorical_accuracy: 0.6389\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.67231\n","Epoch 135/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2049 - categorical_accuracy: 0.9982 - val_loss: 1.1811 - val_categorical_accuracy: 0.6432\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.67231\n","Epoch 136/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.1949 - categorical_accuracy: 0.9990 - val_loss: 1.1902 - val_categorical_accuracy: 0.6280\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.67231\n","Epoch 137/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1936 - categorical_accuracy: 0.9988 - val_loss: 1.1865 - val_categorical_accuracy: 0.6415\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.67231\n","Epoch 138/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1937 - categorical_accuracy: 0.9992 - val_loss: 1.1931 - val_categorical_accuracy: 0.6411\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.67231\n","Epoch 139/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1972 - categorical_accuracy: 0.9986 - val_loss: 1.1706 - val_categorical_accuracy: 0.6454\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.67231\n","Epoch 140/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1843 - categorical_accuracy: 0.9961 - val_loss: 1.1943 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.67231\n","Epoch 141/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1888 - categorical_accuracy: 0.9969 - val_loss: 1.1797 - val_categorical_accuracy: 0.6545\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.67231\n","Epoch 142/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1928 - categorical_accuracy: 0.9960 - val_loss: 1.1861 - val_categorical_accuracy: 0.6428\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.67231\n","Epoch 143/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1775 - categorical_accuracy: 0.9989 - val_loss: 1.1929 - val_categorical_accuracy: 0.6332\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.67231\n","Epoch 144/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.1840 - categorical_accuracy: 0.9968 - val_loss: 1.1849 - val_categorical_accuracy: 0.6298\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.67231\n","Epoch 145/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1839 - categorical_accuracy: 0.9995 - val_loss: 1.1867 - val_categorical_accuracy: 0.6424\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.67231\n","Epoch 146/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1761 - categorical_accuracy: 0.9989 - val_loss: 1.1889 - val_categorical_accuracy: 0.6411\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.67231\n","Epoch 147/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1725 - categorical_accuracy: 0.9985 - val_loss: 1.1895 - val_categorical_accuracy: 0.6411\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.67231\n","Epoch 148/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1765 - categorical_accuracy: 0.9961 - val_loss: 1.1953 - val_categorical_accuracy: 0.6324\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.67231\n","Epoch 149/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1776 - categorical_accuracy: 0.9968 - val_loss: 1.1915 - val_categorical_accuracy: 0.6380\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.67231\n","Epoch 150/150\n","42/42 [==============================] - 0s 9ms/step - loss: 0.1830 - categorical_accuracy: 0.9975 - val_loss: 1.1709 - val_categorical_accuracy: 0.6372\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.67231\n","72/72 [==============================] - 0s 2ms/step - loss: 1.3258 - categorical_accuracy: 0.6723\n","72/72 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 75 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_5[0][0]               \n","==================================================================================================\n","Total params: 31,936\n","Trainable params: 31,040\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 1050.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [75 75 75 75 75 75 75 75 75 75 75 75 75 75]\n","\n","Total number of samples in test set 2094.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [195  26 176 140 194 194 184 128 239 173 201  58 166  20]\n","\n","X_train_transfer => (1050, 128)\n","X_test_transfer  => (2094, 128)\n","y_train => (1050, 14)\n","y_test  => (2094, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               33024     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 36,622\n","Trainable params: 36,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","53/53 [==============================] - 1s 10ms/step - loss: 3.5666 - categorical_accuracy: 0.0721 - val_loss: 2.5177 - val_categorical_accuracy: 0.1208\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.12082, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","53/53 [==============================] - 0s 7ms/step - loss: 2.2868 - categorical_accuracy: 0.2103 - val_loss: 2.2391 - val_categorical_accuracy: 0.2646\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.12082 to 0.26457, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","53/53 [==============================] - 0s 6ms/step - loss: 2.0545 - categorical_accuracy: 0.4117 - val_loss: 2.1179 - val_categorical_accuracy: 0.3209\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.26457 to 0.32092, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.8915 - categorical_accuracy: 0.4667 - val_loss: 1.9929 - val_categorical_accuracy: 0.3247\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.32092 to 0.32474, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.7876 - categorical_accuracy: 0.5946 - val_loss: 1.9537 - val_categorical_accuracy: 0.3634\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.32474 to 0.36342, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.6760 - categorical_accuracy: 0.6507 - val_loss: 1.9226 - val_categorical_accuracy: 0.5038\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.36342 to 0.50382, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.5698 - categorical_accuracy: 0.6888 - val_loss: 1.8754 - val_categorical_accuracy: 0.5119\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.50382 to 0.51194, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.5165 - categorical_accuracy: 0.6656 - val_loss: 1.7999 - val_categorical_accuracy: 0.4670\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.51194\n","Epoch 9/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.4491 - categorical_accuracy: 0.7363 - val_loss: 1.7406 - val_categorical_accuracy: 0.5124\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.51194 to 0.51242, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 10/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.4218 - categorical_accuracy: 0.6980 - val_loss: 1.7258 - val_categorical_accuracy: 0.5420\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.51242 to 0.54202, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.3360 - categorical_accuracy: 0.7565 - val_loss: 1.7101 - val_categorical_accuracy: 0.3644\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.54202\n","Epoch 12/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.2851 - categorical_accuracy: 0.7826 - val_loss: 1.6397 - val_categorical_accuracy: 0.5654\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.54202 to 0.56543, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","53/53 [==============================] - 0s 8ms/step - loss: 1.2292 - categorical_accuracy: 0.8702 - val_loss: 1.6336 - val_categorical_accuracy: 0.5487\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.56543\n","Epoch 14/150\n","53/53 [==============================] - 0s 8ms/step - loss: 1.2128 - categorical_accuracy: 0.8351 - val_loss: 1.6477 - val_categorical_accuracy: 0.5110\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.56543\n","Epoch 15/150\n","53/53 [==============================] - 0s 8ms/step - loss: 1.1966 - categorical_accuracy: 0.8245 - val_loss: 1.5917 - val_categorical_accuracy: 0.5062\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.56543\n","Epoch 16/150\n","53/53 [==============================] - 0s 8ms/step - loss: 1.1647 - categorical_accuracy: 0.8497 - val_loss: 1.5582 - val_categorical_accuracy: 0.5516\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.56543\n","Epoch 17/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0931 - categorical_accuracy: 0.8176 - val_loss: 1.5692 - val_categorical_accuracy: 0.5224\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.56543\n","Epoch 18/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0722 - categorical_accuracy: 0.8874 - val_loss: 1.5343 - val_categorical_accuracy: 0.5511\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.56543\n","Epoch 19/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0348 - categorical_accuracy: 0.8730 - val_loss: 1.5370 - val_categorical_accuracy: 0.5559\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.56543\n","Epoch 20/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0396 - categorical_accuracy: 0.8992 - val_loss: 1.4854 - val_categorical_accuracy: 0.5649\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.56543\n","Epoch 21/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9893 - categorical_accuracy: 0.8882 - val_loss: 1.4563 - val_categorical_accuracy: 0.6528\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.56543 to 0.65282, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9773 - categorical_accuracy: 0.9147 - val_loss: 1.4742 - val_categorical_accuracy: 0.5630\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.65282\n","Epoch 23/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9229 - categorical_accuracy: 0.9199 - val_loss: 1.4543 - val_categorical_accuracy: 0.5979\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.65282\n","Epoch 24/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9110 - categorical_accuracy: 0.9422 - val_loss: 1.4596 - val_categorical_accuracy: 0.6165\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.65282\n","Epoch 25/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8834 - categorical_accuracy: 0.9267 - val_loss: 1.4366 - val_categorical_accuracy: 0.6576\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.65282 to 0.65759, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8594 - categorical_accuracy: 0.9547 - val_loss: 1.4125 - val_categorical_accuracy: 0.5840\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.65759\n","Epoch 27/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8250 - categorical_accuracy: 0.9653 - val_loss: 1.4159 - val_categorical_accuracy: 0.6347\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.65759\n","Epoch 28/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.8399 - categorical_accuracy: 0.9419 - val_loss: 1.4179 - val_categorical_accuracy: 0.6132\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.65759\n","Epoch 29/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8070 - categorical_accuracy: 0.9393 - val_loss: 1.3996 - val_categorical_accuracy: 0.5879\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.65759\n","Epoch 30/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7840 - categorical_accuracy: 0.9659 - val_loss: 1.3704 - val_categorical_accuracy: 0.5611\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.65759\n","Epoch 31/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7685 - categorical_accuracy: 0.9603 - val_loss: 1.4000 - val_categorical_accuracy: 0.5755\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.65759\n","Epoch 32/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7511 - categorical_accuracy: 0.9791 - val_loss: 1.3693 - val_categorical_accuracy: 0.6356\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.65759\n","Epoch 33/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7378 - categorical_accuracy: 0.9360 - val_loss: 1.3509 - val_categorical_accuracy: 0.5993\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.65759\n","Epoch 34/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7247 - categorical_accuracy: 0.9669 - val_loss: 1.3373 - val_categorical_accuracy: 0.5941\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.65759\n","Epoch 35/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6972 - categorical_accuracy: 0.9710 - val_loss: 1.3373 - val_categorical_accuracy: 0.5888\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.65759\n","Epoch 36/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6672 - categorical_accuracy: 0.9783 - val_loss: 1.3203 - val_categorical_accuracy: 0.6055\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.65759\n","Epoch 37/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6903 - categorical_accuracy: 0.9690 - val_loss: 1.3354 - val_categorical_accuracy: 0.5745\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.65759\n","Epoch 38/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6549 - categorical_accuracy: 0.9560 - val_loss: 1.3096 - val_categorical_accuracy: 0.6127\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.65759\n","Epoch 39/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6648 - categorical_accuracy: 0.9706 - val_loss: 1.2850 - val_categorical_accuracy: 0.6266\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.65759\n","Epoch 40/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6454 - categorical_accuracy: 0.9669 - val_loss: 1.2852 - val_categorical_accuracy: 0.6070\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.65759\n","Epoch 41/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6379 - categorical_accuracy: 0.9716 - val_loss: 1.3071 - val_categorical_accuracy: 0.6065\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.65759\n","Epoch 42/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6061 - categorical_accuracy: 0.9804 - val_loss: 1.3023 - val_categorical_accuracy: 0.6032\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.65759\n","Epoch 43/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6084 - categorical_accuracy: 0.9713 - val_loss: 1.2966 - val_categorical_accuracy: 0.6017\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.65759\n","Epoch 44/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.6000 - categorical_accuracy: 0.9816 - val_loss: 1.2707 - val_categorical_accuracy: 0.6380\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.65759\n","Epoch 45/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5947 - categorical_accuracy: 0.9860 - val_loss: 1.2972 - val_categorical_accuracy: 0.6380\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.65759\n","Epoch 46/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5618 - categorical_accuracy: 0.9821 - val_loss: 1.2680 - val_categorical_accuracy: 0.6227\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.65759\n","Epoch 47/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5683 - categorical_accuracy: 0.9818 - val_loss: 1.2975 - val_categorical_accuracy: 0.6280\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.65759\n","Epoch 48/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5408 - categorical_accuracy: 0.9753 - val_loss: 1.2640 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.65759\n","Epoch 49/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5207 - categorical_accuracy: 0.9754 - val_loss: 1.2680 - val_categorical_accuracy: 0.6074\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.65759\n","Epoch 50/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5345 - categorical_accuracy: 0.9858 - val_loss: 1.2639 - val_categorical_accuracy: 0.6270\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.65759\n","Epoch 51/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5121 - categorical_accuracy: 0.9791 - val_loss: 1.2510 - val_categorical_accuracy: 0.6371\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.65759\n","Epoch 52/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.4859 - categorical_accuracy: 0.9833 - val_loss: 1.2671 - val_categorical_accuracy: 0.6137\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.65759\n","Epoch 53/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4947 - categorical_accuracy: 0.9687 - val_loss: 1.2392 - val_categorical_accuracy: 0.6256\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.65759\n","Epoch 54/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4918 - categorical_accuracy: 0.9865 - val_loss: 1.2501 - val_categorical_accuracy: 0.6218\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.65759\n","Epoch 55/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4814 - categorical_accuracy: 0.9857 - val_loss: 1.2349 - val_categorical_accuracy: 0.6246\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.65759\n","Epoch 56/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.4689 - categorical_accuracy: 0.9737 - val_loss: 1.2623 - val_categorical_accuracy: 0.6347\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.65759\n","Epoch 57/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4502 - categorical_accuracy: 0.9850 - val_loss: 1.2277 - val_categorical_accuracy: 0.6275\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.65759\n","Epoch 58/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4428 - categorical_accuracy: 0.9887 - val_loss: 1.2334 - val_categorical_accuracy: 0.6170\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.65759\n","Epoch 59/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4628 - categorical_accuracy: 0.9872 - val_loss: 1.2238 - val_categorical_accuracy: 0.6409\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.65759\n","Epoch 60/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4494 - categorical_accuracy: 0.9804 - val_loss: 1.2360 - val_categorical_accuracy: 0.6328\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.65759\n","Epoch 61/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4156 - categorical_accuracy: 0.9896 - val_loss: 1.2197 - val_categorical_accuracy: 0.6399\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.65759\n","Epoch 62/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4191 - categorical_accuracy: 0.9840 - val_loss: 1.2007 - val_categorical_accuracy: 0.6390\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.65759\n","Epoch 63/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4136 - categorical_accuracy: 0.9895 - val_loss: 1.2145 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.65759\n","Epoch 64/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4267 - categorical_accuracy: 0.9756 - val_loss: 1.2031 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.65759\n","Epoch 65/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4315 - categorical_accuracy: 0.9828 - val_loss: 1.1895 - val_categorical_accuracy: 0.6409\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.65759\n","Epoch 66/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3873 - categorical_accuracy: 0.9912 - val_loss: 1.2083 - val_categorical_accuracy: 0.6351\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.65759\n","Epoch 67/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3986 - categorical_accuracy: 0.9887 - val_loss: 1.2061 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.65759\n","Epoch 68/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4093 - categorical_accuracy: 0.9768 - val_loss: 1.2267 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.65759\n","Epoch 69/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3823 - categorical_accuracy: 0.9773 - val_loss: 1.2028 - val_categorical_accuracy: 0.6533\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.65759\n","Epoch 70/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3837 - categorical_accuracy: 0.9881 - val_loss: 1.2119 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.65759\n","Epoch 71/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3771 - categorical_accuracy: 0.9883 - val_loss: 1.2443 - val_categorical_accuracy: 0.6480\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.65759\n","Epoch 72/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3693 - categorical_accuracy: 0.9931 - val_loss: 1.1881 - val_categorical_accuracy: 0.6270\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.65759\n","Epoch 73/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3601 - categorical_accuracy: 0.9864 - val_loss: 1.1810 - val_categorical_accuracy: 0.6466\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.65759\n","Epoch 74/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3480 - categorical_accuracy: 0.9880 - val_loss: 1.2026 - val_categorical_accuracy: 0.6280\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.65759\n","Epoch 75/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3401 - categorical_accuracy: 0.9872 - val_loss: 1.1878 - val_categorical_accuracy: 0.6433\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.65759\n","Epoch 76/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3484 - categorical_accuracy: 0.9824 - val_loss: 1.1675 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00076: val_categorical_accuracy improved from 0.65759 to 0.68386, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 77/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3350 - categorical_accuracy: 0.9808 - val_loss: 1.1778 - val_categorical_accuracy: 0.6294\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.68386\n","Epoch 78/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3291 - categorical_accuracy: 0.9890 - val_loss: 1.1914 - val_categorical_accuracy: 0.6309\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.68386\n","Epoch 79/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3335 - categorical_accuracy: 0.9813 - val_loss: 1.1515 - val_categorical_accuracy: 0.6705\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.68386\n","Epoch 80/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3119 - categorical_accuracy: 0.9872 - val_loss: 1.1863 - val_categorical_accuracy: 0.6447\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.68386\n","Epoch 81/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3165 - categorical_accuracy: 0.9857 - val_loss: 1.1769 - val_categorical_accuracy: 0.6528\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.68386\n","Epoch 82/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3168 - categorical_accuracy: 0.9874 - val_loss: 1.1752 - val_categorical_accuracy: 0.6734\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.68386\n","Epoch 83/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3134 - categorical_accuracy: 0.9914 - val_loss: 1.1618 - val_categorical_accuracy: 0.6624\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.68386\n","Epoch 84/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3029 - categorical_accuracy: 0.9979 - val_loss: 1.1937 - val_categorical_accuracy: 0.6242\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.68386\n","Epoch 85/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3013 - categorical_accuracy: 0.9829 - val_loss: 1.1755 - val_categorical_accuracy: 0.6504\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.68386\n","Epoch 86/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.3004 - categorical_accuracy: 0.9878 - val_loss: 1.1850 - val_categorical_accuracy: 0.6414\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.68386\n","Epoch 87/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2906 - categorical_accuracy: 0.9926 - val_loss: 1.1416 - val_categorical_accuracy: 0.6805\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.68386\n","Epoch 88/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2979 - categorical_accuracy: 0.9886 - val_loss: 1.1690 - val_categorical_accuracy: 0.6442\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.68386\n","Epoch 89/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.2962 - categorical_accuracy: 0.9748 - val_loss: 1.1608 - val_categorical_accuracy: 0.6571\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.68386\n","Epoch 90/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2798 - categorical_accuracy: 0.9873 - val_loss: 1.1827 - val_categorical_accuracy: 0.6442\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.68386\n","Epoch 91/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2752 - categorical_accuracy: 0.9858 - val_loss: 1.1511 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.68386\n","Epoch 92/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2737 - categorical_accuracy: 0.9830 - val_loss: 1.1628 - val_categorical_accuracy: 0.6485\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.68386\n","Epoch 93/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2742 - categorical_accuracy: 0.9896 - val_loss: 1.1486 - val_categorical_accuracy: 0.6547\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.68386\n","Epoch 94/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2698 - categorical_accuracy: 0.9944 - val_loss: 1.1495 - val_categorical_accuracy: 0.6461\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.68386\n","Epoch 95/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2740 - categorical_accuracy: 0.9907 - val_loss: 1.1784 - val_categorical_accuracy: 0.6323\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.68386\n","Epoch 96/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.2659 - categorical_accuracy: 0.9885 - val_loss: 1.1737 - val_categorical_accuracy: 0.6351\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.68386\n","Epoch 97/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2632 - categorical_accuracy: 0.9855 - val_loss: 1.1728 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.68386\n","Epoch 98/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2564 - categorical_accuracy: 0.9834 - val_loss: 1.1585 - val_categorical_accuracy: 0.6375\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.68386\n","Epoch 99/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2680 - categorical_accuracy: 0.9810 - val_loss: 1.1504 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.68386\n","Epoch 100/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2495 - categorical_accuracy: 0.9861 - val_loss: 1.1762 - val_categorical_accuracy: 0.6399\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.68386\n","Epoch 101/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2484 - categorical_accuracy: 0.9826 - val_loss: 1.1530 - val_categorical_accuracy: 0.6590\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.68386\n","Epoch 102/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2325 - categorical_accuracy: 0.9925 - val_loss: 1.1630 - val_categorical_accuracy: 0.6442\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.68386\n","Epoch 103/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2428 - categorical_accuracy: 0.9898 - val_loss: 1.1450 - val_categorical_accuracy: 0.6509\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.68386\n","Epoch 104/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2408 - categorical_accuracy: 0.9939 - val_loss: 1.1596 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.68386\n","Epoch 105/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2436 - categorical_accuracy: 0.9869 - val_loss: 1.1506 - val_categorical_accuracy: 0.6848\n","\n","Epoch 00105: val_categorical_accuracy improved from 0.68386 to 0.68481, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 106/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2458 - categorical_accuracy: 0.9922 - val_loss: 1.1369 - val_categorical_accuracy: 0.6767\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.68481\n","Epoch 107/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2392 - categorical_accuracy: 0.9890 - val_loss: 1.1346 - val_categorical_accuracy: 0.6657\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.68481\n","Epoch 108/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2257 - categorical_accuracy: 0.9939 - val_loss: 1.1545 - val_categorical_accuracy: 0.6461\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.68481\n","Epoch 109/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2366 - categorical_accuracy: 0.9818 - val_loss: 1.1336 - val_categorical_accuracy: 0.6657\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.68481\n","Epoch 110/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2301 - categorical_accuracy: 0.9959 - val_loss: 1.1475 - val_categorical_accuracy: 0.6523\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.68481\n","Epoch 111/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2250 - categorical_accuracy: 0.9878 - val_loss: 1.1404 - val_categorical_accuracy: 0.6557\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.68481\n","Epoch 112/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2291 - categorical_accuracy: 0.9911 - val_loss: 1.1489 - val_categorical_accuracy: 0.6619\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.68481\n","Epoch 113/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2249 - categorical_accuracy: 0.9908 - val_loss: 1.1437 - val_categorical_accuracy: 0.6948\n","\n","Epoch 00113: val_categorical_accuracy improved from 0.68481 to 0.69484, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1/Trained_models/transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 114/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2205 - categorical_accuracy: 0.9902 - val_loss: 1.1316 - val_categorical_accuracy: 0.6714\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.69484\n","Epoch 115/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2029 - categorical_accuracy: 0.9967 - val_loss: 1.1394 - val_categorical_accuracy: 0.6614\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.69484\n","Epoch 116/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2073 - categorical_accuracy: 0.9899 - val_loss: 1.1370 - val_categorical_accuracy: 0.6581\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.69484\n","Epoch 117/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2057 - categorical_accuracy: 0.9928 - val_loss: 1.1543 - val_categorical_accuracy: 0.6490\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.69484\n","Epoch 118/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2039 - categorical_accuracy: 0.9946 - val_loss: 1.1596 - val_categorical_accuracy: 0.6457\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.69484\n","Epoch 119/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.1982 - categorical_accuracy: 0.9883 - val_loss: 1.1489 - val_categorical_accuracy: 0.6585\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.69484\n","Epoch 120/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1923 - categorical_accuracy: 0.9930 - val_loss: 1.1227 - val_categorical_accuracy: 0.6628\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.69484\n","Epoch 121/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2018 - categorical_accuracy: 0.9917 - val_loss: 1.1360 - val_categorical_accuracy: 0.6595\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.69484\n","Epoch 122/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.1996 - categorical_accuracy: 0.9893 - val_loss: 1.1288 - val_categorical_accuracy: 0.6514\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.69484\n","Epoch 123/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1998 - categorical_accuracy: 0.9914 - val_loss: 1.1462 - val_categorical_accuracy: 0.6538\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.69484\n","Epoch 124/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1861 - categorical_accuracy: 0.9937 - val_loss: 1.1357 - val_categorical_accuracy: 0.6528\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.69484\n","Epoch 125/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1907 - categorical_accuracy: 0.9940 - val_loss: 1.1358 - val_categorical_accuracy: 0.6504\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.69484\n","Epoch 126/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1855 - categorical_accuracy: 0.9862 - val_loss: 1.1601 - val_categorical_accuracy: 0.6471\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.69484\n","Epoch 127/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.1867 - categorical_accuracy: 0.9954 - val_loss: 1.1254 - val_categorical_accuracy: 0.6437\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.69484\n","Epoch 128/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1992 - categorical_accuracy: 0.9811 - val_loss: 1.1466 - val_categorical_accuracy: 0.6447\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.69484\n","Epoch 129/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.1839 - categorical_accuracy: 0.9889 - val_loss: 1.1589 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.69484\n","Epoch 130/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1885 - categorical_accuracy: 0.9858 - val_loss: 1.1464 - val_categorical_accuracy: 0.6562\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.69484\n","Epoch 131/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1797 - categorical_accuracy: 0.9961 - val_loss: 1.1385 - val_categorical_accuracy: 0.6447\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.69484\n","Epoch 132/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1755 - categorical_accuracy: 0.9941 - val_loss: 1.1290 - val_categorical_accuracy: 0.6614\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.69484\n","Epoch 133/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1828 - categorical_accuracy: 0.9936 - val_loss: 1.1284 - val_categorical_accuracy: 0.6562\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.69484\n","Epoch 134/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1805 - categorical_accuracy: 0.9943 - val_loss: 1.1304 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.69484\n","Epoch 135/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1747 - categorical_accuracy: 0.9966 - val_loss: 1.1235 - val_categorical_accuracy: 0.6624\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.69484\n","Epoch 136/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1741 - categorical_accuracy: 0.9979 - val_loss: 1.1381 - val_categorical_accuracy: 0.6547\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.69484\n","Epoch 137/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1729 - categorical_accuracy: 0.9948 - val_loss: 1.1476 - val_categorical_accuracy: 0.6471\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.69484\n","Epoch 138/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1770 - categorical_accuracy: 0.9935 - val_loss: 1.1369 - val_categorical_accuracy: 0.6500\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.69484\n","Epoch 139/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1657 - categorical_accuracy: 0.9908 - val_loss: 1.1235 - val_categorical_accuracy: 0.6667\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.69484\n","Epoch 140/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1769 - categorical_accuracy: 0.9930 - val_loss: 1.1346 - val_categorical_accuracy: 0.6609\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.69484\n","Epoch 141/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1745 - categorical_accuracy: 0.9855 - val_loss: 1.1324 - val_categorical_accuracy: 0.6519\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.69484\n","Epoch 142/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1638 - categorical_accuracy: 0.9913 - val_loss: 1.1322 - val_categorical_accuracy: 0.6595\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.69484\n","Epoch 143/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1650 - categorical_accuracy: 0.9950 - val_loss: 1.1238 - val_categorical_accuracy: 0.6590\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.69484\n","Epoch 144/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1570 - categorical_accuracy: 0.9969 - val_loss: 1.1499 - val_categorical_accuracy: 0.6652\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.69484\n","Epoch 145/150\n","53/53 [==============================] - 0s 8ms/step - loss: 0.1573 - categorical_accuracy: 0.9979 - val_loss: 1.1239 - val_categorical_accuracy: 0.6705\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.69484\n","Epoch 146/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1544 - categorical_accuracy: 0.9958 - val_loss: 1.1364 - val_categorical_accuracy: 0.6576\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.69484\n","Epoch 147/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1585 - categorical_accuracy: 0.9972 - val_loss: 1.1352 - val_categorical_accuracy: 0.6543\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.69484\n","Epoch 148/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1567 - categorical_accuracy: 0.9951 - val_loss: 1.1308 - val_categorical_accuracy: 0.6585\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.69484\n","Epoch 149/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1511 - categorical_accuracy: 0.9966 - val_loss: 1.1324 - val_categorical_accuracy: 0.6614\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.69484\n","Epoch 150/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1545 - categorical_accuracy: 0.9960 - val_loss: 1.1287 - val_categorical_accuracy: 0.6504\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.69484\n","66/66 [==============================] - 0s 3ms/step - loss: 1.1437 - categorical_accuracy: 0.6948\n","66/66 [==============================] - 0s 1ms/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VdgxRQRP0_mp"},"source":["# Transfer Learning results on Botswana"]},{"cell_type":"code","metadata":{"id":"R_WJcBsGjtRA","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1615785011796,"user_tz":420,"elapsed":617,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"3a8185f9-e2a6-4003-e466-358c3a9d0933"},"source":["transfer_results"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training samples per class finetuning</th>\n","      <th>Training Samples per class pretraining</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15</td>\n","      <td>200</td>\n","      <td>210</td>\n","      <td>2934</td>\n","      <td>71.06</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>30</td>\n","      <td>200</td>\n","      <td>420</td>\n","      <td>2724</td>\n","      <td>71.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45</td>\n","      <td>200</td>\n","      <td>630</td>\n","      <td>2514</td>\n","      <td>71.04</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60</td>\n","      <td>200</td>\n","      <td>840</td>\n","      <td>2304</td>\n","      <td>71.04</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>75</td>\n","      <td>200</td>\n","      <td>1050</td>\n","      <td>2094</td>\n","      <td>68.93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Training samples per class finetuning  ...  Test_Accuracies\n","0                                     15  ...            71.06\n","1                                     30  ...            71.06\n","2                                     45  ...            71.04\n","3                                     60  ...            71.04\n","4                                     75  ...            68.93\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"1o6mCjHJ01PG"},"source":["# Classification accuracies per class for each model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"BjFASZ9hw-gi","executionInfo":{"status":"ok","timestamp":1615785024462,"user_tz":420,"elapsed":696,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"5874f02d-b92a-4274-dbd8-f68db89da9b4"},"source":["confusion_matrixes[0]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>175</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>67</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>68.63</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96.51</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>116</td>\n","      <td>81</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>18</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49.15</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>192</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>157</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>61.81</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>22.83</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>222</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90.98</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>123</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>14.36</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>258</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>86.29</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>233</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>81.23</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>75.22</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64</td>\n","      <td>80.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>255</td>\n","      <td>86</td>\n","      <td>236</td>\n","      <td>200</td>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>244</td>\n","      <td>188</td>\n","      <td>299</td>\n","      <td>233</td>\n","      <td>261</td>\n","      <td>118</td>\n","      <td>226</td>\n","      <td>80</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              175   0    0    0  ...    0    0   0                     68.63\n","1                0  83    0    0  ...    0    0   0                     96.51\n","2                0   0  116   81  ...    0    0   0                     49.15\n","3                0   0    2  192  ...    0    0   0                      96.0\n","4                7  17    0   48  ...   14    6   0                     61.81\n","5                0  18    0   22  ...    6   99   0                     22.83\n","6               22   0    0    0  ...    0    0   0                     90.98\n","7                0   0   15    0  ...  123   23   0                     14.36\n","8                0   0    0   10  ...    0   18   0                     86.29\n","9                0   0    0    0  ...    0    0   0                     100.0\n","10               0   0    0    0  ...    0    0   0                     81.23\n","11               0   0    0    0  ...  118    0   0                     100.0\n","12               0   0    0    0  ...   56  170   0                     75.22\n","13               0  13    0    0  ...    0    0  64                      80.0\n","Total Samples  255  86  236  200  ...  118  226  80                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"rh3wq7nYxm1U","executionInfo":{"status":"ok","timestamp":1615785051073,"user_tz":420,"elapsed":743,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"a6c71d0a-9293-4f9e-e6f5-ba6c071fadf1"},"source":["confusion_matrixes[1]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>159</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66.25</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>71</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>107</td>\n","      <td>78</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>21</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48.42</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>181</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>97.84</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>55</td>\n","      <td>148</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>61.92</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>108</td>\n","      <td>0</td>\n","      <td>18.41</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>208</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90.83</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>121</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>12.72</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>256</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>90.14</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>218</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>47</td>\n","      <td>199</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>80.89</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>103</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>80.57</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>75.38</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>240</td>\n","      <td>71</td>\n","      <td>221</td>\n","      <td>185</td>\n","      <td>239</td>\n","      <td>239</td>\n","      <td>229</td>\n","      <td>173</td>\n","      <td>284</td>\n","      <td>218</td>\n","      <td>246</td>\n","      <td>103</td>\n","      <td>211</td>\n","      <td>65</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              159   0    0    0  ...    0    0   0                     66.25\n","1                0  71    0    0  ...    0    0   0                     100.0\n","2                0   0  107   78  ...    0    0   0                     48.42\n","3                0   0    0  181  ...    0    0   0                     97.84\n","4               11   7    0   55  ...   15    0   0                     61.92\n","5                0  17    0   23  ...    5  108   0                     18.41\n","6               21   0    0    0  ...    0    0   0                     90.83\n","7                0   0   12    0  ...  121   18   0                     12.72\n","8                0   0    0    0  ...    0   13   0                     90.14\n","9                0   0    0    0  ...    0    0   0                     100.0\n","10               0   0    0    0  ...    0    0   0                     80.89\n","11               0   0    0    0  ...  103    0   0                     100.0\n","12               0   0    0    0  ...   41  170   0                     80.57\n","13               0   9    0    0  ...    0    0  49                     75.38\n","Total Samples  240  71  221  185  ...  103  211  65                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"0DyVuVJbyY9Q","executionInfo":{"status":"ok","timestamp":1615785052033,"user_tz":420,"elapsed":1087,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"9a95e49e-0637-46a4-feea-0dbd2beb6ab3"},"source":["confusion_matrixes[2]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>153</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>74</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>35</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.92</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>151</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.82</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>54</td>\n","      <td>134</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>59.82</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>101</td>\n","      <td>0</td>\n","      <td>15.18</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>194</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90.65</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>123</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>10.13</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>254</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94.42</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>202</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>99.51</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>80.09</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>158</td>\n","      <td>0</td>\n","      <td>80.61</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>225</td>\n","      <td>56</td>\n","      <td>206</td>\n","      <td>170</td>\n","      <td>224</td>\n","      <td>224</td>\n","      <td>214</td>\n","      <td>158</td>\n","      <td>269</td>\n","      <td>203</td>\n","      <td>231</td>\n","      <td>88</td>\n","      <td>196</td>\n","      <td>50</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              153   0    0    0  ...    0    0   0                      68.0\n","1                0  56    0    0  ...    0    0   0                     100.0\n","2                0   0   74   80  ...    0    0   0                     35.92\n","3                0   0    0  151  ...    0    0   0                     88.82\n","4               12   5    0   54  ...   17    1   0                     59.82\n","5                0  11    0   26  ...    5  101   0                     15.18\n","6               20   0    0    0  ...    0    0   0                     90.65\n","7                0   0    1    0  ...  123   18   0                     10.13\n","8                0   0    0    0  ...    0    0   0                     94.42\n","9                0   0    0    0  ...    0    0   0                     99.51\n","10               0   0    0    0  ...    0    0   0                     80.09\n","11               0   0    0    0  ...   88    0   0                     100.0\n","12               0   0    0    0  ...   38  158   0                     80.61\n","13               0   9    0    0  ...    0    0  34                      68.0\n","Total Samples  225  56  206  170  ...   88  196  50                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"zxx7uWOPyb4r","executionInfo":{"status":"ok","timestamp":1615785052968,"user_tz":420,"elapsed":630,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"d970d868-ee69-4b08-bc81-50496b06ba96"},"source":["confusion_matrixes[3]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>164</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>78.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>68.29</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>92</td>\n","      <td>82</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48.17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>121</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>78.06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>131</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>62.68</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>101</td>\n","      <td>0</td>\n","      <td>10.53</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>179</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>89.95</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>125</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>2.1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>219</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>86.22</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>182</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96.81</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>175</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>81.02</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>141</td>\n","      <td>0</td>\n","      <td>77.9</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>54.29</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>210</td>\n","      <td>41</td>\n","      <td>191</td>\n","      <td>155</td>\n","      <td>209</td>\n","      <td>209</td>\n","      <td>199</td>\n","      <td>143</td>\n","      <td>254</td>\n","      <td>188</td>\n","      <td>216</td>\n","      <td>73</td>\n","      <td>181</td>\n","      <td>35</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              164   0    0    0  ...    0    0   0                      78.1\n","1                0  28    0    0  ...    0    0   0                     68.29\n","2                0   0   92   82  ...    0    0   0                     48.17\n","3                0   0    0  121  ...    0    0   0                     78.06\n","4               13   0    0   46  ...   15    0   0                     62.68\n","5                0   0    0   40  ...    6  101   0                     10.53\n","6               20   0    0    0  ...    0    0   0                     89.95\n","7                0   0    0    0  ...  125   15   0                       2.1\n","8                0   2    0    0  ...    0   15   0                     86.22\n","9                0   0    0    0  ...    0    0   0                     96.81\n","10               0   0    0    0  ...    0    0   0                     81.02\n","11               0   0    0    0  ...   73    0   0                     100.0\n","12               0   0    0    0  ...   40  141   0                      77.9\n","13               0   4    0    0  ...    0    0  19                     54.29\n","Total Samples  210  41  191  155  ...   73  181  35                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"CkclPakQyc_X","executionInfo":{"status":"ok","timestamp":1615785054373,"user_tz":420,"elapsed":1287,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"358a4901-3ce3-4370-fbcf-6e30d8665d90"},"source":["confusion_matrixes[4]"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83.08</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>77</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31.82</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.43</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>39</td>\n","      <td>126</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64.95</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>91</td>\n","      <td>0</td>\n","      <td>4.64</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>164</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>89.13</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>79</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>61.72</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>220</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>92.05</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>149</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86.13</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>163</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>81.09</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>139</td>\n","      <td>0</td>\n","      <td>83.73</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>195</td>\n","      <td>26</td>\n","      <td>176</td>\n","      <td>140</td>\n","      <td>194</td>\n","      <td>194</td>\n","      <td>184</td>\n","      <td>128</td>\n","      <td>239</td>\n","      <td>173</td>\n","      <td>201</td>\n","      <td>58</td>\n","      <td>166</td>\n","      <td>20</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              162   0    1    0  ...   0    0   0                     83.08\n","1                0  26    0    0  ...   0    0   0                     100.0\n","2                0   0   56   77  ...   0    0   0                     31.82\n","3                0   0    0  100  ...   0    0   0                     71.43\n","4               14   1    0   39  ...   0    0   0                     64.95\n","5                0   7    0   17  ...   2   91   0                      4.64\n","6               20   0    0    0  ...   0    0   0                     89.13\n","7                0   0    0    0  ...  49    0   0                     61.72\n","8                0   6    0    0  ...   0    0   0                     92.05\n","9                0   0    0    0  ...   0    0   0                     86.13\n","10               0   0    0    0  ...   0    0   0                     81.09\n","11               0   0    0    0  ...  58    0   0                     100.0\n","12               0   0    0    0  ...  27  139   0                     83.73\n","13               0  10    0    0  ...   0    0   4                      20.0\n","Total Samples  195  26  176  140  ...  58  166  20                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"LihPwReQyd_1"},"source":[""],"execution_count":null,"outputs":[]}]}