{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SGCNN8_model_training_indian_pines.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f_nG8NlV-lz-"},"source":["## Set up google colab environment"]},{"cell_type":"code","metadata":{"id":"9bq_kqWQtg0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608519311633,"user_tz":480,"elapsed":20120,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"97f529ec-61c5-4ed6-85db-e1cabe8e1f76"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK95udG-qHAy","executionInfo":{"status":"ok","timestamp":1608520979911,"user_tz":480,"elapsed":345,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification/')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn-wRAH4t3WY","executionInfo":{"status":"ok","timestamp":1608520982936,"user_tz":480,"elapsed":2488,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["from sample_extraction_V1_utils import *\n","import scipy.io as sio"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky2Qzuw_qDdS"},"source":["## Load Indian Pines Dataset"]},{"cell_type":"code","metadata":{"id":"svwF-yzh-l0N","executionInfo":{"status":"ok","timestamp":1608520984407,"user_tz":480,"elapsed":378,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uIndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_corrected.mat')\n","gt_IndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_gt.mat')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLGpYj4P-l0N","executionInfo":{"status":"ok","timestamp":1608520984835,"user_tz":480,"elapsed":270,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data = uIndianPines['indian_pines_corrected']\n","ground_truth = gt_IndianPines['indian_pines_gt']"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdMIhVj9qDdb","executionInfo":{"status":"ok","timestamp":1608520985922,"user_tz":480,"elapsed":356,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"c4c1432f-59c3-4e24-9730-5feb04561f13"},"source":["data.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145, 200)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAjjOxj3qDdb","executionInfo":{"status":"ok","timestamp":1608520986716,"user_tz":480,"elapsed":370,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"5ced11f4-e70b-41e4-cfdb-9453cc93f9e3"},"source":["ground_truth.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"5WxjgWNGqDdc"},"source":["## Distrubution of samples for each class"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"yFA7eqA7qDdd","executionInfo":{"status":"ok","timestamp":1608520988624,"user_tz":480,"elapsed":352,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0de7c910-6389-4564-8d1e-9ba79f9bc3bb"},"source":["class_distribution = pd.DataFrame(np.unique(ground_truth, return_counts = True))\n","class_distribution = class_distribution.transpose()\n","class_distribution.columns = ['class','samples']\n","class_distribution"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>830</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>483</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>730</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>478</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>972</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2455</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>1265</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>386</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0    10776\n","1       1       46\n","2       2     1428\n","3       3      830\n","4       4      237\n","5       5      483\n","6       6      730\n","7       7       28\n","8       8      478\n","9       9       20\n","10     10      972\n","11     11     2455\n","12     12      593\n","13     13      205\n","14     14     1265\n","15     15      386\n","16     16       93"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zTsq-yPqDdd","executionInfo":{"status":"ok","timestamp":1608520997441,"user_tz":480,"elapsed":722,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"f748e251-23f4-482f-dda4-a751840238bb"},"source":["classes , counts = np.unique(ground_truth, return_counts = True)\n","classes = classes[[2,3,5,6,8,10,11,12,14]] ## Dropping classes with small number of samples\n","classes"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2,  3,  5,  6,  8, 10, 11, 12, 14], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"l_PESscnqDde"},"source":["## Source : Indian Pines\n","\n","## Train model for samples extracted with overlap ratio 1 and varied number of samples picked from each class to be present in the training set. \n","\n","## Rest of the samples from each class are added to the test set.\n","\n","## Model except the final fully connected layer is saved for transfer learning."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vc1sJwRqDdf","executionInfo":{"status":"ok","timestamp":1608521790958,"user_tz":480,"elapsed":719124,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"e08b9545-f44b-44b6-c288-d141e2a69e74"},"source":["pretrain_results = pretrain_source_models(training_set_size = [200,250,300],\n","                                          classes = classes,\n","                                          cube_size = 20,\n","                                          overlap_ratio = 1,\n","                                          data = data,\n","                                          ground_truth = ground_truth,\n","                                          batch_size = 20,\n","                                          channels = 64,\n","                                          epochs = 100,\n","                                          Verbosity = 1,\n","                                          accuracies = [],\n","                                          learning_rate = 0.0001,\n","                                          source_dataset = 'indian_pines')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\n","=============================================================================================================\n","Model training starts for data with 200 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 1800.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [200 200 200 200 200 200 200 200 200]\n","\n","Total number of samples in test set 6106.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1168  323  123  530  156  637 2024  260  885]\n","\n","X_train => (1800, 20, 20, 64)\n","X_test  => (6106, 20, 20, 64)\n","y_train => (1800, 9)\n","y_test  => (6106, 9)\n","\n","After shuffle : (None, 5, 5, 128)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 16)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 16, 8)  0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           tf.reshape_1[0][0]               \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          33024       global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 104,201\n","Trainable params: 103,305\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","90/90 [==============================] - 11s 28ms/step - loss: 4.5280 - categorical_accuracy: 0.1759 - val_loss: 4.3817 - val_categorical_accuracy: 0.4892\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.48919, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","90/90 [==============================] - 2s 23ms/step - loss: 4.2291 - categorical_accuracy: 0.5001 - val_loss: 4.3684 - val_categorical_accuracy: 0.0981\n","\n","Epoch 00002: val_categorical_accuracy did not improve from 0.48919\n","Epoch 3/100\n","90/90 [==============================] - 2s 21ms/step - loss: 4.0958 - categorical_accuracy: 0.5957 - val_loss: 4.3462 - val_categorical_accuracy: 0.0773\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.48919\n","Epoch 4/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.9983 - categorical_accuracy: 0.6227 - val_loss: 4.3330 - val_categorical_accuracy: 0.0853\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.48919\n","Epoch 5/100\n","90/90 [==============================] - 2s 22ms/step - loss: 3.8986 - categorical_accuracy: 0.6761 - val_loss: 4.2668 - val_categorical_accuracy: 0.1073\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.48919\n","Epoch 6/100\n","90/90 [==============================] - 2s 23ms/step - loss: 3.7898 - categorical_accuracy: 0.7190 - val_loss: 4.2545 - val_categorical_accuracy: 0.1366\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.48919\n","Epoch 7/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.7151 - categorical_accuracy: 0.7116 - val_loss: 4.2289 - val_categorical_accuracy: 0.1422\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.48919\n","Epoch 8/100\n","90/90 [==============================] - 2s 22ms/step - loss: 3.6267 - categorical_accuracy: 0.7277 - val_loss: 4.2642 - val_categorical_accuracy: 0.1472\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.48919\n","Epoch 9/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.5780 - categorical_accuracy: 0.7384 - val_loss: 4.2361 - val_categorical_accuracy: 0.1847\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.48919\n","Epoch 10/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.4872 - categorical_accuracy: 0.7664 - val_loss: 4.2474 - val_categorical_accuracy: 0.1335\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.48919\n","Epoch 11/100\n","90/90 [==============================] - 2s 22ms/step - loss: 3.4234 - categorical_accuracy: 0.7792 - val_loss: 4.1956 - val_categorical_accuracy: 0.1978\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.48919\n","Epoch 12/100\n","90/90 [==============================] - 2s 25ms/step - loss: 3.3691 - categorical_accuracy: 0.7997 - val_loss: 4.1903 - val_categorical_accuracy: 0.2001\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.48919\n","Epoch 13/100\n","90/90 [==============================] - 2s 22ms/step - loss: 3.3288 - categorical_accuracy: 0.8091 - val_loss: 4.3008 - val_categorical_accuracy: 0.1612\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.48919\n","Epoch 14/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.2532 - categorical_accuracy: 0.8119 - val_loss: 4.0888 - val_categorical_accuracy: 0.2005\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.48919\n","Epoch 15/100\n","90/90 [==============================] - 2s 23ms/step - loss: 3.2178 - categorical_accuracy: 0.8089 - val_loss: 4.0416 - val_categorical_accuracy: 0.2607\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.48919\n","Epoch 16/100\n","90/90 [==============================] - 2s 23ms/step - loss: 3.1838 - categorical_accuracy: 0.8399 - val_loss: 3.9975 - val_categorical_accuracy: 0.2596\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.48919\n","Epoch 17/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.1459 - categorical_accuracy: 0.8386 - val_loss: 4.1287 - val_categorical_accuracy: 0.2299\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.48919\n","Epoch 18/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.0731 - categorical_accuracy: 0.8583 - val_loss: 3.9771 - val_categorical_accuracy: 0.2706\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.48919\n","Epoch 19/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.0679 - categorical_accuracy: 0.8690 - val_loss: 4.1995 - val_categorical_accuracy: 0.2896\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.48919\n","Epoch 20/100\n","90/90 [==============================] - 2s 21ms/step - loss: 3.0222 - categorical_accuracy: 0.8803 - val_loss: 4.2082 - val_categorical_accuracy: 0.2417\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.48919\n","Epoch 21/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.9587 - categorical_accuracy: 0.8906 - val_loss: 4.2393 - val_categorical_accuracy: 0.2899\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.48919\n","Epoch 22/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.9041 - categorical_accuracy: 0.8945 - val_loss: 4.1579 - val_categorical_accuracy: 0.3323\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.48919\n","Epoch 23/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.8687 - categorical_accuracy: 0.9138 - val_loss: 3.9322 - val_categorical_accuracy: 0.3275\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.48919\n","Epoch 24/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.8286 - categorical_accuracy: 0.9305 - val_loss: 4.0287 - val_categorical_accuracy: 0.2704\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.48919\n","Epoch 25/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.7951 - categorical_accuracy: 0.9313 - val_loss: 4.3380 - val_categorical_accuracy: 0.3027\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.48919\n","Epoch 26/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.7723 - categorical_accuracy: 0.9255 - val_loss: 3.8401 - val_categorical_accuracy: 0.3113\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.48919\n","Epoch 27/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.7298 - categorical_accuracy: 0.9266 - val_loss: 4.5021 - val_categorical_accuracy: 0.3402\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.48919\n","Epoch 28/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.6909 - categorical_accuracy: 0.9344 - val_loss: 4.3292 - val_categorical_accuracy: 0.4129\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.48919\n","Epoch 29/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.6670 - categorical_accuracy: 0.9428 - val_loss: 4.4688 - val_categorical_accuracy: 0.3179\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.48919\n","Epoch 30/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.6594 - categorical_accuracy: 0.9365 - val_loss: 4.2046 - val_categorical_accuracy: 0.3878\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.48919\n","Epoch 31/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.5922 - categorical_accuracy: 0.9540 - val_loss: 5.5572 - val_categorical_accuracy: 0.2216\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.48919\n","Epoch 32/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.5822 - categorical_accuracy: 0.9449 - val_loss: 4.9266 - val_categorical_accuracy: 0.3413\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.48919\n","Epoch 33/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.5331 - categorical_accuracy: 0.9564 - val_loss: 4.8209 - val_categorical_accuracy: 0.3217\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.48919\n","Epoch 34/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.5350 - categorical_accuracy: 0.9451 - val_loss: 4.5183 - val_categorical_accuracy: 0.3785\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.48919\n","Epoch 35/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.4775 - categorical_accuracy: 0.9541 - val_loss: 4.7566 - val_categorical_accuracy: 0.4152\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.48919\n","Epoch 36/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.4837 - categorical_accuracy: 0.9536 - val_loss: 5.9971 - val_categorical_accuracy: 0.2439\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.48919\n","Epoch 37/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.4536 - categorical_accuracy: 0.9520 - val_loss: 4.9916 - val_categorical_accuracy: 0.3310\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.48919\n","Epoch 38/100\n","90/90 [==============================] - 2s 26ms/step - loss: 2.4400 - categorical_accuracy: 0.9478 - val_loss: 5.7883 - val_categorical_accuracy: 0.2877\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.48919\n","Epoch 39/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.3900 - categorical_accuracy: 0.9710 - val_loss: 5.6807 - val_categorical_accuracy: 0.3110\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.48919\n","Epoch 40/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.3965 - categorical_accuracy: 0.9573 - val_loss: 4.9979 - val_categorical_accuracy: 0.3968\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.48919\n","Epoch 41/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.3767 - categorical_accuracy: 0.9688 - val_loss: 5.1420 - val_categorical_accuracy: 0.3626\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.48919\n","Epoch 42/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.3511 - categorical_accuracy: 0.9605 - val_loss: 5.2770 - val_categorical_accuracy: 0.3705\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.48919\n","Epoch 43/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.3206 - categorical_accuracy: 0.9806 - val_loss: 5.2606 - val_categorical_accuracy: 0.3877\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.48919\n","Epoch 44/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.3220 - categorical_accuracy: 0.9688 - val_loss: 4.4952 - val_categorical_accuracy: 0.4268\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.48919\n","Epoch 45/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.2777 - categorical_accuracy: 0.9830 - val_loss: 5.6081 - val_categorical_accuracy: 0.2683\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.48919\n","Epoch 46/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.2813 - categorical_accuracy: 0.9761 - val_loss: 5.0070 - val_categorical_accuracy: 0.3316\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.48919\n","Epoch 47/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.2711 - categorical_accuracy: 0.9727 - val_loss: 4.7368 - val_categorical_accuracy: 0.4351\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.48919\n","Epoch 48/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.2314 - categorical_accuracy: 0.9802 - val_loss: 4.7089 - val_categorical_accuracy: 0.4217\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.48919\n","Epoch 49/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.2290 - categorical_accuracy: 0.9755 - val_loss: 4.3682 - val_categorical_accuracy: 0.3624\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.48919\n","Epoch 50/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.2262 - categorical_accuracy: 0.9765 - val_loss: 4.7577 - val_categorical_accuracy: 0.4230\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.48919\n","Epoch 51/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1973 - categorical_accuracy: 0.9794 - val_loss: 5.8563 - val_categorical_accuracy: 0.3362\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.48919\n","Epoch 52/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.1997 - categorical_accuracy: 0.9746 - val_loss: 5.7290 - val_categorical_accuracy: 0.2154\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.48919\n","Epoch 53/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1699 - categorical_accuracy: 0.9808 - val_loss: 5.0872 - val_categorical_accuracy: 0.3213\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.48919\n","Epoch 54/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1655 - categorical_accuracy: 0.9789 - val_loss: 4.8999 - val_categorical_accuracy: 0.4001\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.48919\n","Epoch 55/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1463 - categorical_accuracy: 0.9755 - val_loss: 5.1904 - val_categorical_accuracy: 0.3282\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.48919\n","Epoch 56/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.1441 - categorical_accuracy: 0.9771 - val_loss: 5.4890 - val_categorical_accuracy: 0.3657\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.48919\n","Epoch 57/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1208 - categorical_accuracy: 0.9845 - val_loss: 4.6234 - val_categorical_accuracy: 0.3513\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.48919\n","Epoch 58/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.1060 - categorical_accuracy: 0.9908 - val_loss: 6.5092 - val_categorical_accuracy: 0.3279\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.48919\n","Epoch 59/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.0999 - categorical_accuracy: 0.9797 - val_loss: 5.9816 - val_categorical_accuracy: 0.3144\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.48919\n","Epoch 60/100\n","90/90 [==============================] - 2s 21ms/step - loss: 2.1080 - categorical_accuracy: 0.9759 - val_loss: 5.0529 - val_categorical_accuracy: 0.4294\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.48919\n","Epoch 61/100\n","90/90 [==============================] - 2s 25ms/step - loss: 2.0830 - categorical_accuracy: 0.9865 - val_loss: 5.0597 - val_categorical_accuracy: 0.4089\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.48919\n","Epoch 62/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.0922 - categorical_accuracy: 0.9710 - val_loss: 4.7576 - val_categorical_accuracy: 0.4085\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.48919\n","Epoch 63/100\n","90/90 [==============================] - 2s 23ms/step - loss: 2.0540 - categorical_accuracy: 0.9854 - val_loss: 5.4971 - val_categorical_accuracy: 0.4012\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.48919\n","Epoch 64/100\n","90/90 [==============================] - 2s 22ms/step - loss: 2.0472 - categorical_accuracy: 0.9865 - val_loss: 6.3598 - val_categorical_accuracy: 0.3980\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.48919\n","Epoch 65/100\n","90/90 [==============================] - 2s 26ms/step - loss: 2.0468 - categorical_accuracy: 0.9825 - val_loss: 5.3502 - val_categorical_accuracy: 0.2462\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.48919\n","Epoch 66/100\n","90/90 [==============================] - 2s 26ms/step - loss: 2.0296 - categorical_accuracy: 0.9828 - val_loss: 5.1955 - val_categorical_accuracy: 0.3893\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.48919\n","Epoch 67/100\n","90/90 [==============================] - 2s 25ms/step - loss: 2.0122 - categorical_accuracy: 0.9905 - val_loss: 6.2151 - val_categorical_accuracy: 0.2668\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.48919\n","Epoch 68/100\n","90/90 [==============================] - 2s 24ms/step - loss: 2.0004 - categorical_accuracy: 0.9890 - val_loss: 4.9894 - val_categorical_accuracy: 0.3790\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.48919\n","Epoch 69/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.9967 - categorical_accuracy: 0.9845 - val_loss: 4.0147 - val_categorical_accuracy: 0.3610\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.48919\n","Epoch 70/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.9966 - categorical_accuracy: 0.9734 - val_loss: 4.1702 - val_categorical_accuracy: 0.4219\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.48919\n","Epoch 71/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.9754 - categorical_accuracy: 0.9915 - val_loss: 5.9379 - val_categorical_accuracy: 0.3862\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.48919\n","Epoch 72/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.9579 - categorical_accuracy: 0.9908 - val_loss: 5.4361 - val_categorical_accuracy: 0.3778\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.48919\n","Epoch 73/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.9541 - categorical_accuracy: 0.9875 - val_loss: 6.0617 - val_categorical_accuracy: 0.3672\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.48919\n","Epoch 74/100\n","90/90 [==============================] - 2s 25ms/step - loss: 1.9522 - categorical_accuracy: 0.9820 - val_loss: 5.1265 - val_categorical_accuracy: 0.4247\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.48919\n","Epoch 75/100\n","90/90 [==============================] - 2s 24ms/step - loss: 1.9435 - categorical_accuracy: 0.9871 - val_loss: 4.3646 - val_categorical_accuracy: 0.3321\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.48919\n","Epoch 76/100\n","90/90 [==============================] - 2s 24ms/step - loss: 1.9269 - categorical_accuracy: 0.9893 - val_loss: 4.7693 - val_categorical_accuracy: 0.4276\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.48919\n","Epoch 77/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.9296 - categorical_accuracy: 0.9878 - val_loss: 5.4644 - val_categorical_accuracy: 0.4230\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.48919\n","Epoch 78/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.9210 - categorical_accuracy: 0.9872 - val_loss: 5.3303 - val_categorical_accuracy: 0.4168\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.48919\n","Epoch 79/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8975 - categorical_accuracy: 0.9896 - val_loss: 5.2042 - val_categorical_accuracy: 0.2452\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.48919\n","Epoch 80/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8953 - categorical_accuracy: 0.9886 - val_loss: 6.7528 - val_categorical_accuracy: 0.3207\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.48919\n","Epoch 81/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8942 - categorical_accuracy: 0.9848 - val_loss: 6.1849 - val_categorical_accuracy: 0.3804\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.48919\n","Epoch 82/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.8937 - categorical_accuracy: 0.9828 - val_loss: 7.7291 - val_categorical_accuracy: 0.3112\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.48919\n","Epoch 83/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.8831 - categorical_accuracy: 0.9815 - val_loss: 4.4657 - val_categorical_accuracy: 0.3156\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.48919\n","Epoch 84/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.8687 - categorical_accuracy: 0.9925 - val_loss: 5.8831 - val_categorical_accuracy: 0.2724\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.48919\n","Epoch 85/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.8639 - categorical_accuracy: 0.9862 - val_loss: 4.2558 - val_categorical_accuracy: 0.3465\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.48919\n","Epoch 86/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8695 - categorical_accuracy: 0.9823 - val_loss: 4.5488 - val_categorical_accuracy: 0.4274\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.48919\n","Epoch 87/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.8398 - categorical_accuracy: 0.9878 - val_loss: 4.0024 - val_categorical_accuracy: 0.3256\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.48919\n","Epoch 88/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.8315 - categorical_accuracy: 0.9858 - val_loss: 3.8787 - val_categorical_accuracy: 0.3364\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.48919\n","Epoch 89/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8334 - categorical_accuracy: 0.9902 - val_loss: 5.8480 - val_categorical_accuracy: 0.2350\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.48919\n","Epoch 90/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8202 - categorical_accuracy: 0.9890 - val_loss: 5.2108 - val_categorical_accuracy: 0.4453\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.48919\n","Epoch 91/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8080 - categorical_accuracy: 0.9913 - val_loss: 8.1640 - val_categorical_accuracy: 0.2864\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.48919\n","Epoch 92/100\n","90/90 [==============================] - 2s 24ms/step - loss: 1.8046 - categorical_accuracy: 0.9893 - val_loss: 4.6964 - val_categorical_accuracy: 0.4273\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.48919\n","Epoch 93/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.7903 - categorical_accuracy: 0.9913 - val_loss: 5.0606 - val_categorical_accuracy: 0.4240\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.48919\n","Epoch 94/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.8039 - categorical_accuracy: 0.9875 - val_loss: 7.2330 - val_categorical_accuracy: 0.3685\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.48919\n","Epoch 95/100\n","90/90 [==============================] - 2s 21ms/step - loss: 1.7869 - categorical_accuracy: 0.9884 - val_loss: 8.6203 - val_categorical_accuracy: 0.2404\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.48919\n","Epoch 96/100\n","90/90 [==============================] - 2s 24ms/step - loss: 1.7911 - categorical_accuracy: 0.9867 - val_loss: 6.2516 - val_categorical_accuracy: 0.3850\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.48919\n","Epoch 97/100\n","90/90 [==============================] - 2s 24ms/step - loss: 1.7698 - categorical_accuracy: 0.9896 - val_loss: 5.3484 - val_categorical_accuracy: 0.3908\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.48919\n","Epoch 98/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.7595 - categorical_accuracy: 0.9913 - val_loss: 7.2548 - val_categorical_accuracy: 0.3479\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.48919\n","Epoch 99/100\n","90/90 [==============================] - 2s 22ms/step - loss: 1.7600 - categorical_accuracy: 0.9872 - val_loss: 4.7722 - val_categorical_accuracy: 0.4448\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.48919\n","Epoch 100/100\n","90/90 [==============================] - 2s 23ms/step - loss: 1.7543 - categorical_accuracy: 0.9905 - val_loss: 7.2906 - val_categorical_accuracy: 0.3570\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.48919\n","191/191 [==============================] - 2s 6ms/step - loss: 4.3817 - categorical_accuracy: 0.4892\n","191/191 [==============================] - 1s 4ms/step\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 10, 10, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 5, 5, 8)      584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 5, 5, 8)      584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 5, 5, 8)      584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 5, 5, 8)      584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 5, 5, 8)      584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 5, 5, 8)      584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 5, 5, 8)      584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 5, 5, 8)      0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 5, 5, 8)      584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 5, 5, 8)      584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 5, 5, 8)      584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 5, 5, 8)      584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 5, 5, 8)      584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 5, 5, 8)      584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 5, 5, 8)      584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 5, 5, 8)      584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 5, 5, 8)      584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 5, 5, 64)     0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 5, 5, 128)    8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 5, 5, 8, 16)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 5, 5, 16, 8)  0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 5, 5, 128)    512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 5, 5, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 5, 5, 128)    0           tf.reshape_1[0][0]               \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 5, 5, 128)    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           activation_4[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with 250 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 2250.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [250 250 250 250 250 250 250 250 250]\n","\n","Total number of samples in test set 5656.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1118  273   73  480  106  587 1974  210  835]\n","\n","X_train => (2250, 20, 20, 64)\n","X_test  => (5656, 20, 20, 64)\n","y_train => (2250, 9)\n","y_test  => (5656, 9)\n","\n","After shuffle : (None, 5, 5, 128)\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 10, 10, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 5, 5, 64)     256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 5, 5, 64)     0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 5, 5, 8)      584         lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 5, 5, 8)      584         lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 5, 5, 8)      584         lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 5, 5, 8)      584         lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 5, 5, 8)      584         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 5, 5, 8)      584         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 5, 5, 8)      584         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 5, 5, 8)      584         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 5, 5, 8)      584         lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 5, 5, 8)      584         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 5, 5, 8)      584         lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 5, 5, 8)      584         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 5, 5, 8)      584         lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 5, 5, 8)      584         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 5, 5, 8)      584         lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 5, 5, 8)      584         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 5, 5, 64)     0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 5, 5, 64)     256         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 5, 5, 64)     0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 5, 5, 128)    8320        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 5, 5, 128)    512         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 5, 5, 128)    0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 5, 5, 8, 16)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 5, 5, 16, 8)  0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 5, 5, 128)    512         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 5, 5, 128)    0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 5, 5, 128)    0           tf.reshape_3[0][0]               \n","                                                                 activation_8[0][0]               \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 5, 5, 128)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 128)          0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          33024       global_average_pooling2d_1[0][0] \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 104,201\n","Trainable params: 103,305\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","113/113 [==============================] - 4s 26ms/step - loss: 4.6722 - categorical_accuracy: 0.1182 - val_loss: 5.1726 - val_categorical_accuracy: 0.0318\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.03182, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","113/113 [==============================] - 2s 22ms/step - loss: 4.2598 - categorical_accuracy: 0.3801 - val_loss: 4.6934 - val_categorical_accuracy: 0.0585\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.03182 to 0.05852, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","113/113 [==============================] - 2s 21ms/step - loss: 4.1090 - categorical_accuracy: 0.4896 - val_loss: 4.4992 - val_categorical_accuracy: 0.1066\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.05852 to 0.10661, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","113/113 [==============================] - 2s 19ms/step - loss: 3.9865 - categorical_accuracy: 0.5689 - val_loss: 4.4032 - val_categorical_accuracy: 0.1209\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.10661 to 0.12093, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","113/113 [==============================] - 2s 20ms/step - loss: 3.8810 - categorical_accuracy: 0.6333 - val_loss: 4.3701 - val_categorical_accuracy: 0.0930\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.12093\n","Epoch 6/100\n","113/113 [==============================] - 2s 21ms/step - loss: 3.8015 - categorical_accuracy: 0.6472 - val_loss: 4.3700 - val_categorical_accuracy: 0.1188\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.12093\n","Epoch 7/100\n","113/113 [==============================] - 2s 21ms/step - loss: 3.7116 - categorical_accuracy: 0.7141 - val_loss: 4.3318 - val_categorical_accuracy: 0.0852\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.12093\n","Epoch 8/100\n","113/113 [==============================] - 3s 23ms/step - loss: 3.6551 - categorical_accuracy: 0.7239 - val_loss: 4.2931 - val_categorical_accuracy: 0.1114\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.12093\n","Epoch 9/100\n","113/113 [==============================] - 2s 20ms/step - loss: 3.5659 - categorical_accuracy: 0.7188 - val_loss: 4.3538 - val_categorical_accuracy: 0.1443\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.12093 to 0.14427, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 10/100\n","113/113 [==============================] - 2s 19ms/step - loss: 3.4940 - categorical_accuracy: 0.7499 - val_loss: 4.3667 - val_categorical_accuracy: 0.1310\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.14427\n","Epoch 11/100\n","113/113 [==============================] - 2s 20ms/step - loss: 3.4065 - categorical_accuracy: 0.7910 - val_loss: 4.2624 - val_categorical_accuracy: 0.1911\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.14427 to 0.19112, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 12/100\n","113/113 [==============================] - 2s 21ms/step - loss: 3.3667 - categorical_accuracy: 0.7807 - val_loss: 4.3621 - val_categorical_accuracy: 0.1710\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.19112\n","Epoch 13/100\n","113/113 [==============================] - 2s 22ms/step - loss: 3.2860 - categorical_accuracy: 0.8153 - val_loss: 4.2333 - val_categorical_accuracy: 0.1941\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.19112 to 0.19413, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 14/100\n","113/113 [==============================] - 2s 21ms/step - loss: 3.2550 - categorical_accuracy: 0.8041 - val_loss: 4.2507 - val_categorical_accuracy: 0.1172\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.19413\n","Epoch 15/100\n","113/113 [==============================] - 2s 20ms/step - loss: 3.1421 - categorical_accuracy: 0.8403 - val_loss: 4.1813 - val_categorical_accuracy: 0.2382\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.19413 to 0.23815, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 16/100\n","113/113 [==============================] - 2s 19ms/step - loss: 3.1036 - categorical_accuracy: 0.8530 - val_loss: 4.0922 - val_categorical_accuracy: 0.1927\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.23815\n","Epoch 17/100\n","113/113 [==============================] - 2s 19ms/step - loss: 3.0931 - categorical_accuracy: 0.8256 - val_loss: 3.9925 - val_categorical_accuracy: 0.2385\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.23815 to 0.23851, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 18/100\n","113/113 [==============================] - 2s 20ms/step - loss: 3.0089 - categorical_accuracy: 0.8582 - val_loss: 3.9080 - val_categorical_accuracy: 0.2567\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.23851 to 0.25672, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.9604 - categorical_accuracy: 0.8523 - val_loss: 4.2542 - val_categorical_accuracy: 0.2268\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.25672\n","Epoch 20/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.9076 - categorical_accuracy: 0.8702 - val_loss: 3.9578 - val_categorical_accuracy: 0.2956\n","\n","Epoch 00020: val_categorical_accuracy improved from 0.25672 to 0.29562, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 21/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.8853 - categorical_accuracy: 0.8658 - val_loss: 3.7528 - val_categorical_accuracy: 0.3112\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.29562 to 0.31117, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 22/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.8470 - categorical_accuracy: 0.8636 - val_loss: 4.2176 - val_categorical_accuracy: 0.2364\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.31117\n","Epoch 23/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.7900 - categorical_accuracy: 0.8769 - val_loss: 4.0361 - val_categorical_accuracy: 0.3308\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.31117 to 0.33080, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 24/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.7542 - categorical_accuracy: 0.8992 - val_loss: 4.0770 - val_categorical_accuracy: 0.2021\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.33080\n","Epoch 25/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.7258 - categorical_accuracy: 0.8923 - val_loss: 3.8094 - val_categorical_accuracy: 0.3412\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.33080 to 0.34123, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 26/100\n","113/113 [==============================] - 2s 22ms/step - loss: 2.6947 - categorical_accuracy: 0.8945 - val_loss: 3.7437 - val_categorical_accuracy: 0.3821\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.34123 to 0.38207, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 27/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.6744 - categorical_accuracy: 0.8831 - val_loss: 3.5229 - val_categorical_accuracy: 0.3944\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.38207 to 0.39445, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 28/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.6297 - categorical_accuracy: 0.8964 - val_loss: 3.7828 - val_categorical_accuracy: 0.3193\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.39445\n","Epoch 29/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.5801 - categorical_accuracy: 0.9006 - val_loss: 4.5843 - val_categorical_accuracy: 0.3349\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.39445\n","Epoch 30/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.5690 - categorical_accuracy: 0.9058 - val_loss: 3.6077 - val_categorical_accuracy: 0.3759\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.39445\n","Epoch 31/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.5378 - categorical_accuracy: 0.9119 - val_loss: 4.2670 - val_categorical_accuracy: 0.3495\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.39445\n","Epoch 32/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.5443 - categorical_accuracy: 0.8991 - val_loss: 3.9499 - val_categorical_accuracy: 0.4051\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.39445 to 0.40506, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 33/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.4922 - categorical_accuracy: 0.9198 - val_loss: 3.6326 - val_categorical_accuracy: 0.3518\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.40506\n","Epoch 34/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.4784 - categorical_accuracy: 0.9201 - val_loss: 4.8121 - val_categorical_accuracy: 0.3315\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.40506\n","Epoch 35/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.4490 - categorical_accuracy: 0.9267 - val_loss: 4.0511 - val_categorical_accuracy: 0.3883\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.40506\n","Epoch 36/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.4242 - categorical_accuracy: 0.9290 - val_loss: 4.4885 - val_categorical_accuracy: 0.4038\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.40506\n","Epoch 37/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.4092 - categorical_accuracy: 0.9198 - val_loss: 4.2503 - val_categorical_accuracy: 0.3322\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.40506\n","Epoch 38/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.3836 - categorical_accuracy: 0.9264 - val_loss: 4.3829 - val_categorical_accuracy: 0.3685\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.40506\n","Epoch 39/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.3612 - categorical_accuracy: 0.9370 - val_loss: 4.3063 - val_categorical_accuracy: 0.3642\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.40506\n","Epoch 40/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.3361 - categorical_accuracy: 0.9417 - val_loss: 4.2793 - val_categorical_accuracy: 0.4295\n","\n","Epoch 00040: val_categorical_accuracy improved from 0.40506 to 0.42946, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 41/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.3140 - categorical_accuracy: 0.9376 - val_loss: 4.5816 - val_categorical_accuracy: 0.3660\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.42946\n","Epoch 42/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.2879 - categorical_accuracy: 0.9495 - val_loss: 5.0823 - val_categorical_accuracy: 0.3425\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.42946\n","Epoch 43/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.2922 - categorical_accuracy: 0.9393 - val_loss: 3.7337 - val_categorical_accuracy: 0.4164\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.42946\n","Epoch 44/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.2531 - categorical_accuracy: 0.9517 - val_loss: 4.7595 - val_categorical_accuracy: 0.3600\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.42946\n","Epoch 45/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.2238 - categorical_accuracy: 0.9553 - val_loss: 3.9716 - val_categorical_accuracy: 0.4250\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.42946\n","Epoch 46/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.2275 - categorical_accuracy: 0.9538 - val_loss: 4.1478 - val_categorical_accuracy: 0.3941\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.42946\n","Epoch 47/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.1922 - categorical_accuracy: 0.9617 - val_loss: 4.9628 - val_categorical_accuracy: 0.3785\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.42946\n","Epoch 48/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.2071 - categorical_accuracy: 0.9445 - val_loss: 4.0740 - val_categorical_accuracy: 0.4558\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.42946 to 0.45580, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 49/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.1763 - categorical_accuracy: 0.9579 - val_loss: 3.9479 - val_categorical_accuracy: 0.3796\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.45580\n","Epoch 50/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.1644 - categorical_accuracy: 0.9514 - val_loss: 6.1930 - val_categorical_accuracy: 0.3626\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.45580\n","Epoch 51/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.1342 - categorical_accuracy: 0.9645 - val_loss: 3.5167 - val_categorical_accuracy: 0.4710\n","\n","Epoch 00051: val_categorical_accuracy improved from 0.45580 to 0.47100, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 52/100\n","113/113 [==============================] - 2s 22ms/step - loss: 2.1306 - categorical_accuracy: 0.9558 - val_loss: 4.2441 - val_categorical_accuracy: 0.3920\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.47100\n","Epoch 53/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.1178 - categorical_accuracy: 0.9655 - val_loss: 4.5347 - val_categorical_accuracy: 0.2583\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.47100\n","Epoch 54/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.1151 - categorical_accuracy: 0.9526 - val_loss: 5.1769 - val_categorical_accuracy: 0.3605\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.47100\n","Epoch 55/100\n","113/113 [==============================] - 2s 22ms/step - loss: 2.0894 - categorical_accuracy: 0.9633 - val_loss: 5.3224 - val_categorical_accuracy: 0.3787\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.47100\n","Epoch 56/100\n","113/113 [==============================] - 2s 22ms/step - loss: 2.0696 - categorical_accuracy: 0.9609 - val_loss: 3.3663 - val_categorical_accuracy: 0.3980\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.47100\n","Epoch 57/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.0733 - categorical_accuracy: 0.9644 - val_loss: 3.9721 - val_categorical_accuracy: 0.4328\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.47100\n","Epoch 58/100\n","113/113 [==============================] - 2s 19ms/step - loss: 2.0386 - categorical_accuracy: 0.9683 - val_loss: 6.6337 - val_categorical_accuracy: 0.2102\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.47100\n","Epoch 59/100\n","113/113 [==============================] - 2s 21ms/step - loss: 2.0430 - categorical_accuracy: 0.9683 - val_loss: 6.2817 - val_categorical_accuracy: 0.2419\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.47100\n","Epoch 60/100\n","113/113 [==============================] - 2s 20ms/step - loss: 2.0007 - categorical_accuracy: 0.9787 - val_loss: 4.1303 - val_categorical_accuracy: 0.4726\n","\n","Epoch 00060: val_categorical_accuracy improved from 0.47100 to 0.47260, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 61/100\n","113/113 [==============================] - 2s 22ms/step - loss: 1.9989 - categorical_accuracy: 0.9699 - val_loss: 4.0298 - val_categorical_accuracy: 0.4531\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.47260\n","Epoch 62/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.9984 - categorical_accuracy: 0.9737 - val_loss: 3.6632 - val_categorical_accuracy: 0.4033\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.47260\n","Epoch 63/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.9898 - categorical_accuracy: 0.9732 - val_loss: 3.9420 - val_categorical_accuracy: 0.3426\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.47260\n","Epoch 64/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.9547 - categorical_accuracy: 0.9753 - val_loss: 4.2660 - val_categorical_accuracy: 0.3085\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.47260\n","Epoch 65/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.9595 - categorical_accuracy: 0.9684 - val_loss: 6.0646 - val_categorical_accuracy: 0.4029\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.47260\n","Epoch 66/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.9323 - categorical_accuracy: 0.9783 - val_loss: 5.8923 - val_categorical_accuracy: 0.2870\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.47260\n","Epoch 67/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.9415 - categorical_accuracy: 0.9657 - val_loss: 4.3392 - val_categorical_accuracy: 0.3209\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.47260\n","Epoch 68/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.9058 - categorical_accuracy: 0.9804 - val_loss: 3.7361 - val_categorical_accuracy: 0.3739\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.47260\n","Epoch 69/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.9142 - categorical_accuracy: 0.9760 - val_loss: 4.9094 - val_categorical_accuracy: 0.3025\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.47260\n","Epoch 70/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.8955 - categorical_accuracy: 0.9833 - val_loss: 6.5148 - val_categorical_accuracy: 0.3147\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.47260\n","Epoch 71/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.8856 - categorical_accuracy: 0.9800 - val_loss: 7.9521 - val_categorical_accuracy: 0.1213\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.47260\n","Epoch 72/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.8846 - categorical_accuracy: 0.9755 - val_loss: 5.8228 - val_categorical_accuracy: 0.2178\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.47260\n","Epoch 73/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.8641 - categorical_accuracy: 0.9799 - val_loss: 4.7751 - val_categorical_accuracy: 0.3013\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.47260\n","Epoch 74/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.8526 - categorical_accuracy: 0.9766 - val_loss: 2.9932 - val_categorical_accuracy: 0.5338\n","\n","Epoch 00074: val_categorical_accuracy improved from 0.47260 to 0.53377, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_250_samples_from_each_class_in_training_set.h5\n","Epoch 75/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.8363 - categorical_accuracy: 0.9815 - val_loss: 4.8410 - val_categorical_accuracy: 0.4063\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.53377\n","Epoch 76/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.8341 - categorical_accuracy: 0.9820 - val_loss: 4.5631 - val_categorical_accuracy: 0.2870\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.53377\n","Epoch 77/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.8321 - categorical_accuracy: 0.9778 - val_loss: 5.4408 - val_categorical_accuracy: 0.2999\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.53377\n","Epoch 78/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.8071 - categorical_accuracy: 0.9838 - val_loss: 4.9251 - val_categorical_accuracy: 0.3258\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.53377\n","Epoch 79/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.7961 - categorical_accuracy: 0.9856 - val_loss: 4.0886 - val_categorical_accuracy: 0.4116\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.53377\n","Epoch 80/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.7897 - categorical_accuracy: 0.9875 - val_loss: 5.2182 - val_categorical_accuracy: 0.4003\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.53377\n","Epoch 81/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.7865 - categorical_accuracy: 0.9833 - val_loss: 6.8180 - val_categorical_accuracy: 0.2306\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.53377\n","Epoch 82/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.7802 - categorical_accuracy: 0.9817 - val_loss: 5.1438 - val_categorical_accuracy: 0.2424\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.53377\n","Epoch 83/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.7582 - categorical_accuracy: 0.9872 - val_loss: 3.3151 - val_categorical_accuracy: 0.4889\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.53377\n","Epoch 84/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.7731 - categorical_accuracy: 0.9849 - val_loss: 3.8979 - val_categorical_accuracy: 0.4158\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.53377\n","Epoch 85/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.7465 - categorical_accuracy: 0.9804 - val_loss: 3.6899 - val_categorical_accuracy: 0.4275\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.53377\n","Epoch 86/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.7374 - categorical_accuracy: 0.9840 - val_loss: 8.2263 - val_categorical_accuracy: 0.1920\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.53377\n","Epoch 87/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.7243 - categorical_accuracy: 0.9873 - val_loss: 3.7028 - val_categorical_accuracy: 0.3874\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.53377\n","Epoch 88/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.7159 - categorical_accuracy: 0.9905 - val_loss: 3.6082 - val_categorical_accuracy: 0.3911\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.53377\n","Epoch 89/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.7075 - categorical_accuracy: 0.9884 - val_loss: 7.1147 - val_categorical_accuracy: 0.2915\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.53377\n","Epoch 90/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.7071 - categorical_accuracy: 0.9828 - val_loss: 4.6643 - val_categorical_accuracy: 0.4001\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.53377\n","Epoch 91/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.6885 - categorical_accuracy: 0.9921 - val_loss: 5.8665 - val_categorical_accuracy: 0.3550\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.53377\n","Epoch 92/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.6757 - categorical_accuracy: 0.9908 - val_loss: 3.4894 - val_categorical_accuracy: 0.3144\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.53377\n","Epoch 93/100\n","113/113 [==============================] - 2s 19ms/step - loss: 1.6824 - categorical_accuracy: 0.9815 - val_loss: 5.2392 - val_categorical_accuracy: 0.3329\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.53377\n","Epoch 94/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.6658 - categorical_accuracy: 0.9884 - val_loss: 8.2157 - val_categorical_accuracy: 0.2417\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.53377\n","Epoch 95/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.6693 - categorical_accuracy: 0.9832 - val_loss: 6.1974 - val_categorical_accuracy: 0.3303\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.53377\n","Epoch 96/100\n","113/113 [==============================] - 3s 23ms/step - loss: 1.6615 - categorical_accuracy: 0.9860 - val_loss: 7.5118 - val_categorical_accuracy: 0.2343\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.53377\n","Epoch 97/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.6500 - categorical_accuracy: 0.9871 - val_loss: 6.3491 - val_categorical_accuracy: 0.3400\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.53377\n","Epoch 98/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.6348 - categorical_accuracy: 0.9891 - val_loss: 3.3533 - val_categorical_accuracy: 0.5262\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.53377\n","Epoch 99/100\n","113/113 [==============================] - 2s 20ms/step - loss: 1.6299 - categorical_accuracy: 0.9884 - val_loss: 4.7292 - val_categorical_accuracy: 0.4070\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.53377\n","Epoch 100/100\n","113/113 [==============================] - 2s 21ms/step - loss: 1.6198 - categorical_accuracy: 0.9901 - val_loss: 7.4309 - val_categorical_accuracy: 0.1282\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.53377\n","177/177 [==============================] - 1s 6ms/step - loss: 2.9932 - categorical_accuracy: 0.5338\n","177/177 [==============================] - 1s 5ms/step\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 10, 10, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 5, 5, 64)     256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 5, 5, 64)     0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 5, 5, 8)      584         lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 5, 5, 8)      584         lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 5, 5, 8)      584         lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 5, 5, 8)      584         lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 5, 5, 8)      584         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 5, 5, 8)      584         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 5, 5, 8)      584         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 5, 5, 8)      0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 5, 5, 8)      584         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 5, 5, 8)      584         lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 5, 5, 8)      584         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 5, 5, 8)      584         lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 5, 5, 8)      584         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 5, 5, 8)      584         lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 5, 5, 8)      584         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 5, 5, 8)      584         lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 5, 5, 8)      584         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 5, 5, 64)     0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 5, 5, 64)     256         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 5, 5, 64)     0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 5, 5, 128)    8320        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 5, 5, 128)    512         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 5, 5, 128)    0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 5, 5, 8, 16)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 5, 5, 16, 8)  0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 5, 5, 128)    512         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 5, 5, 128)    0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 5, 5, 128)    0           tf.reshape_3[0][0]               \n","                                                                 activation_8[0][0]               \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 5, 5, 128)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 128)          0           activation_9[0][0]               \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","\n","=============================================================================================================\n","Model training starts for data with 300 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 2700.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [300 300 300 300 300 300 300 300 300]\n","\n","Total number of samples in test set 5206.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1068  223   23  430   56  537 1924  160  785]\n","\n","X_train => (2700, 20, 20, 64)\n","X_test  => (5206, 20, 20, 64)\n","y_train => (2700, 9)\n","y_test  => (5206, 9)\n","\n","After shuffle : (None, 5, 5, 128)\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 10, 10, 64)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 5, 5, 64)     256         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 5, 5, 64)     0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","lambda_17 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_19 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_21 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_23 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 5, 5, 8)      584         lambda_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 5, 5, 8)      584         lambda_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 5, 5, 8)      584         lambda_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 5, 5, 8)      584         lambda_23[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_16 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 5, 5, 8)      584         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_18 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 5, 5, 8)      584         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_20 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 5, 5, 8)      584         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_22 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 5, 5, 8)      584         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 5, 5, 8)      584         lambda_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 5, 5, 8)      584         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 5, 5, 8)      584         lambda_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 5, 5, 8)      584         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 5, 5, 8)      584         lambda_20[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 5, 5, 8)      584         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 5, 5, 8)      584         lambda_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 5, 5, 8)      584         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 5, 5, 64)     0           conv2d_39[0][0]                  \n","                                                                 conv2d_42[0][0]                  \n","                                                                 conv2d_43[0][0]                  \n","                                                                 conv2d_46[0][0]                  \n","                                                                 conv2d_47[0][0]                  \n","                                                                 conv2d_50[0][0]                  \n","                                                                 conv2d_51[0][0]                  \n","                                                                 conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 5, 5, 64)     256         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 5, 5, 64)     0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 5, 5, 128)    8320        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 5, 5, 128)    512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 5, 5, 128)    0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_4 (TFOpLambda)       (None, 5, 5, 8, 16)  0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_2 (TFOpL (None, 5, 5, 16, 8)  0           tf.reshape_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_2 (TFOpLambda)       (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose_2[0][0]   \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 5, 5, 128)    512         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_5 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 5, 5, 128)    0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 5, 5, 128)    0           tf.reshape_5[0][0]               \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 5, 5, 128)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 128)          0           activation_14[0][0]              \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          33024       global_average_pooling2d_2[0][0] \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 104,201\n","Trainable params: 103,305\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","135/135 [==============================] - 4s 21ms/step - loss: 4.6458 - categorical_accuracy: 0.1643 - val_loss: 4.7387 - val_categorical_accuracy: 0.0275\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.02747, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 2/100\n","135/135 [==============================] - 2s 16ms/step - loss: 4.2268 - categorical_accuracy: 0.4507 - val_loss: 4.4689 - val_categorical_accuracy: 0.0693\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.02747 to 0.06934, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 3/100\n","135/135 [==============================] - 2s 17ms/step - loss: 4.0441 - categorical_accuracy: 0.5566 - val_loss: 4.3674 - val_categorical_accuracy: 0.1074\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.06934 to 0.10738, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 4/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.9112 - categorical_accuracy: 0.6208 - val_loss: 4.2810 - val_categorical_accuracy: 0.1992\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.10738 to 0.19919, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 5/100\n","135/135 [==============================] - 2s 18ms/step - loss: 3.8144 - categorical_accuracy: 0.6609 - val_loss: 4.2197 - val_categorical_accuracy: 0.2113\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.19919 to 0.21129, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 6/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.7229 - categorical_accuracy: 0.6995 - val_loss: 4.0919 - val_categorical_accuracy: 0.2751\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.21129 to 0.27507, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 7/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.6459 - categorical_accuracy: 0.7073 - val_loss: 4.1520 - val_categorical_accuracy: 0.2207\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.27507\n","Epoch 8/100\n","135/135 [==============================] - 2s 16ms/step - loss: 3.5760 - categorical_accuracy: 0.7180 - val_loss: 4.0451 - val_categorical_accuracy: 0.2751\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.27507\n","Epoch 9/100\n","135/135 [==============================] - 2s 16ms/step - loss: 3.4865 - categorical_accuracy: 0.7407 - val_loss: 3.9649 - val_categorical_accuracy: 0.2897\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.27507 to 0.28967, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 10/100\n","135/135 [==============================] - 2s 18ms/step - loss: 3.4278 - categorical_accuracy: 0.7513 - val_loss: 3.9282 - val_categorical_accuracy: 0.2916\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.28967 to 0.29159, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 11/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.3637 - categorical_accuracy: 0.7582 - val_loss: 3.8751 - val_categorical_accuracy: 0.3196\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.29159 to 0.31963, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 12/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.2776 - categorical_accuracy: 0.7639 - val_loss: 3.7440 - val_categorical_accuracy: 0.3592\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.31963 to 0.35920, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 13/100\n","135/135 [==============================] - 2s 16ms/step - loss: 3.2295 - categorical_accuracy: 0.7905 - val_loss: 3.8694 - val_categorical_accuracy: 0.3160\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.35920\n","Epoch 14/100\n","135/135 [==============================] - 2s 16ms/step - loss: 3.1771 - categorical_accuracy: 0.7983 - val_loss: 3.8136 - val_categorical_accuracy: 0.3425\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.35920\n","Epoch 15/100\n","135/135 [==============================] - 2s 18ms/step - loss: 3.1094 - categorical_accuracy: 0.8137 - val_loss: 3.9284 - val_categorical_accuracy: 0.2059\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.35920\n","Epoch 16/100\n","135/135 [==============================] - 2s 17ms/step - loss: 3.0648 - categorical_accuracy: 0.8192 - val_loss: 3.8617 - val_categorical_accuracy: 0.3050\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.35920\n","Epoch 17/100\n","135/135 [==============================] - 3s 19ms/step - loss: 2.9678 - categorical_accuracy: 0.8479 - val_loss: 3.7952 - val_categorical_accuracy: 0.2866\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.35920\n","Epoch 18/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.9337 - categorical_accuracy: 0.8598 - val_loss: 3.5498 - val_categorical_accuracy: 0.3659\n","\n","Epoch 00018: val_categorical_accuracy improved from 0.35920 to 0.36592, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 19/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.8894 - categorical_accuracy: 0.8569 - val_loss: 3.9824 - val_categorical_accuracy: 0.2662\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.36592\n","Epoch 20/100\n","135/135 [==============================] - 2s 19ms/step - loss: 2.8251 - categorical_accuracy: 0.8667 - val_loss: 4.4035 - val_categorical_accuracy: 0.2393\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.36592\n","Epoch 21/100\n","135/135 [==============================] - 3s 19ms/step - loss: 2.7704 - categorical_accuracy: 0.8779 - val_loss: 3.5275 - val_categorical_accuracy: 0.3194\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.36592\n","Epoch 22/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.7644 - categorical_accuracy: 0.8744 - val_loss: 3.4037 - val_categorical_accuracy: 0.4445\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.36592 to 0.44449, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 23/100\n","135/135 [==============================] - 3s 20ms/step - loss: 2.6994 - categorical_accuracy: 0.8982 - val_loss: 3.3224 - val_categorical_accuracy: 0.4593\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.44449 to 0.45928, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 24/100\n","135/135 [==============================] - 3s 19ms/step - loss: 2.6784 - categorical_accuracy: 0.8873 - val_loss: 3.8623 - val_categorical_accuracy: 0.2766\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.45928\n","Epoch 25/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.6140 - categorical_accuracy: 0.8912 - val_loss: 3.7027 - val_categorical_accuracy: 0.2902\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.45928\n","Epoch 26/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.5927 - categorical_accuracy: 0.9036 - val_loss: 4.0466 - val_categorical_accuracy: 0.1990\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.45928\n","Epoch 27/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.5419 - categorical_accuracy: 0.9126 - val_loss: 3.6838 - val_categorical_accuracy: 0.2860\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.45928\n","Epoch 28/100\n","135/135 [==============================] - 3s 20ms/step - loss: 2.5215 - categorical_accuracy: 0.9060 - val_loss: 3.5818 - val_categorical_accuracy: 0.3436\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.45928\n","Epoch 29/100\n","135/135 [==============================] - 3s 19ms/step - loss: 2.4810 - categorical_accuracy: 0.9246 - val_loss: 3.3683 - val_categorical_accuracy: 0.3761\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.45928\n","Epoch 30/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.4468 - categorical_accuracy: 0.9171 - val_loss: 3.6138 - val_categorical_accuracy: 0.3488\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.45928\n","Epoch 31/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.4253 - categorical_accuracy: 0.9228 - val_loss: 4.3315 - val_categorical_accuracy: 0.2386\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.45928\n","Epoch 32/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.4007 - categorical_accuracy: 0.9300 - val_loss: 3.1762 - val_categorical_accuracy: 0.4689\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.45928 to 0.46888, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 33/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.3863 - categorical_accuracy: 0.9229 - val_loss: 3.5509 - val_categorical_accuracy: 0.3312\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.46888\n","Epoch 34/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.3479 - categorical_accuracy: 0.9349 - val_loss: 3.3630 - val_categorical_accuracy: 0.3475\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.46888\n","Epoch 35/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.3307 - categorical_accuracy: 0.9381 - val_loss: 4.4239 - val_categorical_accuracy: 0.2530\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.46888\n","Epoch 36/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.3075 - categorical_accuracy: 0.9416 - val_loss: 3.5021 - val_categorical_accuracy: 0.3792\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.46888\n","Epoch 37/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.2898 - categorical_accuracy: 0.9344 - val_loss: 3.7398 - val_categorical_accuracy: 0.3730\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.46888\n","Epoch 38/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.2512 - categorical_accuracy: 0.9376 - val_loss: 3.4312 - val_categorical_accuracy: 0.4287\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.46888\n","Epoch 39/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.2466 - categorical_accuracy: 0.9439 - val_loss: 3.1784 - val_categorical_accuracy: 0.4700\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.46888 to 0.47003, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 40/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.2208 - categorical_accuracy: 0.9474 - val_loss: 3.8331 - val_categorical_accuracy: 0.2683\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.47003\n","Epoch 41/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.1965 - categorical_accuracy: 0.9550 - val_loss: 4.8330 - val_categorical_accuracy: 0.1721\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.47003\n","Epoch 42/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.2038 - categorical_accuracy: 0.9387 - val_loss: 3.1613 - val_categorical_accuracy: 0.5146\n","\n","Epoch 00042: val_categorical_accuracy improved from 0.47003 to 0.51460, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 43/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.1715 - categorical_accuracy: 0.9528 - val_loss: 3.6944 - val_categorical_accuracy: 0.3494\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.51460\n","Epoch 44/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.1547 - categorical_accuracy: 0.9524 - val_loss: 5.0361 - val_categorical_accuracy: 0.1819\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.51460\n","Epoch 45/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.1371 - categorical_accuracy: 0.9510 - val_loss: 3.6490 - val_categorical_accuracy: 0.3325\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.51460\n","Epoch 46/100\n","135/135 [==============================] - 3s 20ms/step - loss: 2.0941 - categorical_accuracy: 0.9633 - val_loss: 3.0515 - val_categorical_accuracy: 0.5715\n","\n","Epoch 00046: val_categorical_accuracy improved from 0.51460 to 0.57146, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 47/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.0904 - categorical_accuracy: 0.9567 - val_loss: 4.1877 - val_categorical_accuracy: 0.2747\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.57146\n","Epoch 48/100\n","135/135 [==============================] - 2s 17ms/step - loss: 2.0745 - categorical_accuracy: 0.9653 - val_loss: 4.2149 - val_categorical_accuracy: 0.2353\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.57146\n","Epoch 49/100\n","135/135 [==============================] - 2s 16ms/step - loss: 2.0681 - categorical_accuracy: 0.9609 - val_loss: 3.8942 - val_categorical_accuracy: 0.3636\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.57146\n","Epoch 50/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.0580 - categorical_accuracy: 0.9587 - val_loss: 6.8782 - val_categorical_accuracy: 0.0841\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.57146\n","Epoch 51/100\n","135/135 [==============================] - 2s 18ms/step - loss: 2.0259 - categorical_accuracy: 0.9685 - val_loss: 3.9745 - val_categorical_accuracy: 0.3110\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.57146\n","Epoch 52/100\n","135/135 [==============================] - 3s 19ms/step - loss: 2.0152 - categorical_accuracy: 0.9648 - val_loss: 3.9636 - val_categorical_accuracy: 0.3750\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.57146\n","Epoch 53/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.9958 - categorical_accuracy: 0.9652 - val_loss: 5.7078 - val_categorical_accuracy: 0.2420\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.57146\n","Epoch 54/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.9932 - categorical_accuracy: 0.9687 - val_loss: 3.8162 - val_categorical_accuracy: 0.3185\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.57146\n","Epoch 55/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.9773 - categorical_accuracy: 0.9650 - val_loss: 7.9382 - val_categorical_accuracy: 0.1560\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.57146\n","Epoch 56/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.9591 - categorical_accuracy: 0.9667 - val_loss: 4.2146 - val_categorical_accuracy: 0.2207\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.57146\n","Epoch 57/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.9468 - categorical_accuracy: 0.9686 - val_loss: 3.2936 - val_categorical_accuracy: 0.4624\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.57146\n","Epoch 58/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.9473 - categorical_accuracy: 0.9698 - val_loss: 2.8747 - val_categorical_accuracy: 0.5993\n","\n","Epoch 00058: val_categorical_accuracy improved from 0.57146 to 0.59931, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//Trained_models//full_models/indian_pines_with_300_samples_from_each_class_in_training_set.h5\n","Epoch 59/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.9155 - categorical_accuracy: 0.9750 - val_loss: 4.1837 - val_categorical_accuracy: 0.3876\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.59931\n","Epoch 60/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.9092 - categorical_accuracy: 0.9729 - val_loss: 3.3093 - val_categorical_accuracy: 0.5778\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.59931\n","Epoch 61/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.9022 - categorical_accuracy: 0.9773 - val_loss: 3.2946 - val_categorical_accuracy: 0.4539\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.59931\n","Epoch 62/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8884 - categorical_accuracy: 0.9724 - val_loss: 2.9362 - val_categorical_accuracy: 0.5705\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.59931\n","Epoch 63/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8630 - categorical_accuracy: 0.9779 - val_loss: 6.4507 - val_categorical_accuracy: 0.2557\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.59931\n","Epoch 64/100\n","135/135 [==============================] - 3s 19ms/step - loss: 1.8565 - categorical_accuracy: 0.9774 - val_loss: 5.0105 - val_categorical_accuracy: 0.2845\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.59931\n","Epoch 65/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8403 - categorical_accuracy: 0.9759 - val_loss: 3.5875 - val_categorical_accuracy: 0.4220\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.59931\n","Epoch 66/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8313 - categorical_accuracy: 0.9833 - val_loss: 3.2321 - val_categorical_accuracy: 0.4987\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.59931\n","Epoch 67/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8147 - categorical_accuracy: 0.9809 - val_loss: 6.8144 - val_categorical_accuracy: 0.1260\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.59931\n","Epoch 68/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.7992 - categorical_accuracy: 0.9866 - val_loss: 3.6454 - val_categorical_accuracy: 0.4727\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.59931\n","Epoch 69/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.8044 - categorical_accuracy: 0.9801 - val_loss: 4.1588 - val_categorical_accuracy: 0.3857\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.59931\n","Epoch 70/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.7901 - categorical_accuracy: 0.9824 - val_loss: 4.0564 - val_categorical_accuracy: 0.3828\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.59931\n","Epoch 71/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.7711 - categorical_accuracy: 0.9803 - val_loss: 7.5438 - val_categorical_accuracy: 0.1934\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.59931\n","Epoch 72/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.7664 - categorical_accuracy: 0.9787 - val_loss: 3.3366 - val_categorical_accuracy: 0.5106\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.59931\n","Epoch 73/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.7536 - categorical_accuracy: 0.9746 - val_loss: 4.0344 - val_categorical_accuracy: 0.3642\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.59931\n","Epoch 74/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.7702 - categorical_accuracy: 0.9740 - val_loss: 3.5074 - val_categorical_accuracy: 0.4201\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.59931\n","Epoch 75/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.7306 - categorical_accuracy: 0.9838 - val_loss: 5.2729 - val_categorical_accuracy: 0.2313\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.59931\n","Epoch 76/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.7356 - categorical_accuracy: 0.9751 - val_loss: 3.9361 - val_categorical_accuracy: 0.3467\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.59931\n","Epoch 77/100\n","135/135 [==============================] - 3s 20ms/step - loss: 1.7134 - categorical_accuracy: 0.9829 - val_loss: 4.5163 - val_categorical_accuracy: 0.2580\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.59931\n","Epoch 78/100\n","135/135 [==============================] - 3s 19ms/step - loss: 1.7093 - categorical_accuracy: 0.9815 - val_loss: 5.2468 - val_categorical_accuracy: 0.2568\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.59931\n","Epoch 79/100\n","135/135 [==============================] - 2s 19ms/step - loss: 1.7039 - categorical_accuracy: 0.9770 - val_loss: 5.2710 - val_categorical_accuracy: 0.3362\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.59931\n","Epoch 80/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.6817 - categorical_accuracy: 0.9891 - val_loss: 3.9821 - val_categorical_accuracy: 0.3089\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.59931\n","Epoch 81/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.6801 - categorical_accuracy: 0.9831 - val_loss: 4.1049 - val_categorical_accuracy: 0.3849\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.59931\n","Epoch 82/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.6724 - categorical_accuracy: 0.9859 - val_loss: 6.6887 - val_categorical_accuracy: 0.2353\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.59931\n","Epoch 83/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.6544 - categorical_accuracy: 0.9833 - val_loss: 3.0779 - val_categorical_accuracy: 0.5280\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.59931\n","Epoch 84/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.6425 - categorical_accuracy: 0.9855 - val_loss: 4.9686 - val_categorical_accuracy: 0.2382\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.59931\n","Epoch 85/100\n","135/135 [==============================] - 3s 20ms/step - loss: 1.6422 - categorical_accuracy: 0.9821 - val_loss: 3.3610 - val_categorical_accuracy: 0.3809\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.59931\n","Epoch 86/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.6235 - categorical_accuracy: 0.9867 - val_loss: 3.6738 - val_categorical_accuracy: 0.3198\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.59931\n","Epoch 87/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.6233 - categorical_accuracy: 0.9801 - val_loss: 3.6710 - val_categorical_accuracy: 0.4599\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.59931\n","Epoch 88/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.5980 - categorical_accuracy: 0.9882 - val_loss: 3.6615 - val_categorical_accuracy: 0.3434\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.59931\n","Epoch 89/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.6028 - categorical_accuracy: 0.9873 - val_loss: 3.7269 - val_categorical_accuracy: 0.4581\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.59931\n","Epoch 90/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.5974 - categorical_accuracy: 0.9846 - val_loss: 5.3921 - val_categorical_accuracy: 0.2843\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.59931\n","Epoch 91/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.5758 - categorical_accuracy: 0.9897 - val_loss: 3.6165 - val_categorical_accuracy: 0.3177\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.59931\n","Epoch 92/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.5733 - categorical_accuracy: 0.9874 - val_loss: 6.7039 - val_categorical_accuracy: 0.1089\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.59931\n","Epoch 93/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.5611 - categorical_accuracy: 0.9861 - val_loss: 3.3381 - val_categorical_accuracy: 0.4716\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.59931\n","Epoch 94/100\n","135/135 [==============================] - 3s 19ms/step - loss: 1.5492 - categorical_accuracy: 0.9890 - val_loss: 4.0641 - val_categorical_accuracy: 0.4239\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.59931\n","Epoch 95/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.5549 - categorical_accuracy: 0.9853 - val_loss: 4.7058 - val_categorical_accuracy: 0.2297\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.59931\n","Epoch 96/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.5410 - categorical_accuracy: 0.9896 - val_loss: 4.8166 - val_categorical_accuracy: 0.3062\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.59931\n","Epoch 97/100\n","135/135 [==============================] - 2s 17ms/step - loss: 1.5339 - categorical_accuracy: 0.9859 - val_loss: 3.8427 - val_categorical_accuracy: 0.3408\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.59931\n","Epoch 98/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.5309 - categorical_accuracy: 0.9804 - val_loss: 4.9320 - val_categorical_accuracy: 0.2073\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.59931\n","Epoch 99/100\n","135/135 [==============================] - 2s 16ms/step - loss: 1.5205 - categorical_accuracy: 0.9829 - val_loss: 9.2313 - val_categorical_accuracy: 0.1047\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.59931\n","Epoch 100/100\n","135/135 [==============================] - 2s 18ms/step - loss: 1.5168 - categorical_accuracy: 0.9844 - val_loss: 3.3055 - val_categorical_accuracy: 0.4357\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.59931\n","163/163 [==============================] - 1s 6ms/step - loss: 2.8747 - categorical_accuracy: 0.5993\n","163/163 [==============================] - 1s 5ms/step\n","Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv_initial (Conv2D)           (None, 10, 10, 64)   36928       input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 10, 10, 64)   256         conv_initial[0][0]               \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 10, 10, 64)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","MaxPooling_0 (MaxPooling2D)     (None, 5, 5, 64)     0           re_lu_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 5, 5, 64)     4160        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 5, 5, 64)     256         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 5, 5, 64)     0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","lambda_17 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_19 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_21 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","lambda_23 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 5, 5, 8)      584         lambda_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 5, 5, 8)      584         lambda_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 5, 5, 8)      584         lambda_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 5, 5, 8)      584         lambda_23[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_16 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 5, 5, 8)      584         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_18 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 5, 5, 8)      584         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_20 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 5, 5, 8)      584         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_22 (Lambda)              (None, 5, 5, 8)      0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 5, 5, 8)      584         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 5, 5, 8)      584         lambda_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 5, 5, 8)      584         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 5, 5, 8)      584         lambda_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 5, 5, 8)      584         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 5, 5, 8)      584         lambda_20[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 5, 5, 8)      584         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 5, 5, 8)      584         lambda_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 5, 5, 8)      584         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 5, 5, 64)     0           conv2d_39[0][0]                  \n","                                                                 conv2d_42[0][0]                  \n","                                                                 conv2d_43[0][0]                  \n","                                                                 conv2d_46[0][0]                  \n","                                                                 conv2d_47[0][0]                  \n","                                                                 conv2d_50[0][0]                  \n","                                                                 conv2d_51[0][0]                  \n","                                                                 conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 5, 5, 64)     256         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 5, 5, 64)     0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 5, 5, 128)    8320        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 5, 5, 128)    512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 5, 5, 128)    0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_4 (TFOpLambda)       (None, 5, 5, 8, 16)  0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_2 (TFOpL (None, 5, 5, 16, 8)  0           tf.reshape_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 5, 5, 128)    8320        MaxPooling_0[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_2 (TFOpLambda)       (None, 5, 5, 16, 8)  0           tf.compat.v1.transpose_2[0][0]   \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 5, 5, 128)    512         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","tf.reshape_5 (TFOpLambda)       (None, 5, 5, 128)    0           tf.reverse_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 5, 5, 128)    0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 5, 5, 128)    0           tf.reshape_5[0][0]               \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 5, 5, 128)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 128)          0           activation_14[0][0]              \n","==================================================================================================\n","Total params: 68,864\n","Trainable params: 67,968\n","Non-trainable params: 896\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0dMGS4sr-z33","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1608521859761,"user_tz":480,"elapsed":557,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0e5215be-8239-46fe-cf4a-c2ff463163c2"},"source":["pretrain_results"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Samples from each class</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>200</td>\n","      <td>1800</td>\n","      <td>6106</td>\n","      <td>48.919097</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>250</td>\n","      <td>2250</td>\n","      <td>5656</td>\n","      <td>53.376943</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>300</td>\n","      <td>2700</td>\n","      <td>5206</td>\n","      <td>59.930849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Training Samples from each class  ...  Test_Accuracies\n","0                               200  ...        48.919097\n","1                               250  ...        53.376943\n","2                               300  ...        59.930849\n","\n","[3 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"0rREFfqPX8Ah"},"source":[""],"execution_count":null,"outputs":[]}]}