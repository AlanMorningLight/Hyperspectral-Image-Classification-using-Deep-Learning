{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SGCNN_12_indian_pines_to_botswana.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_nG8NlV-lz-"},"source":["## Set up google colab environment"]},{"cell_type":"code","metadata":{"id":"9bq_kqWQtg0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787429168,"user_tz":420,"elapsed":23614,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"bb08deca-acb7-4640-df7f-be171c5a2b92"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK95udG-qHAy","executionInfo":{"status":"ok","timestamp":1615787431467,"user_tz":420,"elapsed":514,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Hyperspectral_Image_Classification/V1/SGCNN_12')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn-wRAH4t3WY","executionInfo":{"status":"ok","timestamp":1615787438032,"user_tz":420,"elapsed":2729,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["from sample_extraction_V1_SGCNN_12 import *\n","import scipy.io as sio"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky2Qzuw_qDdS"},"source":["## Load Indian Pines Dataset - Source"]},{"cell_type":"code","metadata":{"id":"svwF-yzh-l0N","executionInfo":{"status":"ok","timestamp":1615787441596,"user_tz":420,"elapsed":1850,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uIndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_corrected.mat')\n","gt_IndianPines = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Indian_pines_gt.mat')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLGpYj4P-l0N","executionInfo":{"status":"ok","timestamp":1615787441597,"user_tz":420,"elapsed":1073,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_source = uIndianPines['indian_pines_corrected']\n","ground_truth_source = gt_IndianPines['indian_pines_gt']"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHQe_Xhwza79","executionInfo":{"status":"ok","timestamp":1615787441598,"user_tz":420,"elapsed":384,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"206b7a86-a9d5-49dd-fe28-04a4a09a7f69"},"source":["data_source.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145, 200)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAjjOxj3qDdb","executionInfo":{"status":"ok","timestamp":1615787442496,"user_tz":420,"elapsed":751,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"4bea2927-7e6c-48c3-d3b8-9afb9c7f12fd"},"source":["ground_truth_source.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 145)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"wmLGB_VlWx6m"},"source":["# Load target dataset"]},{"cell_type":"code","metadata":{"id":"qu6T10joWpmQ","executionInfo":{"status":"ok","timestamp":1615787446654,"user_tz":420,"elapsed":1932,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["uBotswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana.mat')\n","gt_Botswana = sio.loadmat('/content/drive/My Drive/Hyperspectral_Image_Classification/Datasets/Botswana_gt.mat')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"09gPGGX8W2Us","executionInfo":{"status":"ok","timestamp":1615787446658,"user_tz":420,"elapsed":1399,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}}},"source":["data_target = uBotswana['Botswana']\n","ground_truth_target = gt_Botswana['Botswana_gt']"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qG_LxbHeXBVQ","executionInfo":{"status":"ok","timestamp":1615787446659,"user_tz":420,"elapsed":829,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"2e859d74-06b6-4434-ef1e-992f3e63e006"},"source":["data_target.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256, 145)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYillUc_XDKC","executionInfo":{"status":"ok","timestamp":1615787446659,"user_tz":420,"elapsed":319,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"fae68288-6f73-4962-fd00-04db369284e3"},"source":["ground_truth_target.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1476, 256)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"5WxjgWNGqDdc"},"source":["## Distrubution of samples for each class in Source"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"id":"yFA7eqA7qDdd","executionInfo":{"status":"ok","timestamp":1615787451427,"user_tz":420,"elapsed":525,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"46b8967f-aa57-4e47-c8ba-879816320f74"},"source":["class_distribution_source = pd.DataFrame(np.unique(ground_truth_source, return_counts = True))\n","class_distribution_source = class_distribution_source.transpose()\n","class_distribution_source.columns = ['class','samples']\n","class_distribution_source"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>830</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>483</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>730</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>478</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>972</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2455</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>205</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>1265</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>386</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0    10776\n","1       1       46\n","2       2     1428\n","3       3      830\n","4       4      237\n","5       5      483\n","6       6      730\n","7       7       28\n","8       8      478\n","9       9       20\n","10     10      972\n","11     11     2455\n","12     12      593\n","13     13      205\n","14     14     1265\n","15     15      386\n","16     16       93"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"7zTsq-yPqDdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787456226,"user_tz":420,"elapsed":324,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"10390b06-633d-4342-a96b-cb1affb39e42"},"source":["classes_source , counts_source = np.unique(ground_truth_source, return_counts = True)\n","classes_source = classes_source[[2,3,5,6,8,10,11,12,14]] ## Dropping classes with small number of samples\n","classes_source"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2,  3,  5,  6,  8, 10, 11, 12, 14], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"lwQmdin9Xmeg"},"source":["# Class distribution of samples in Target"]},{"cell_type":"code","metadata":{"id":"8EjIMOQHXU3h","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"ok","timestamp":1615787459303,"user_tz":420,"elapsed":416,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"0fee38ef-ad29-4bf8-c858-b9e6c456850e"},"source":["class_distribution_target = pd.DataFrame(np.unique(ground_truth_target, return_counts = True))\n","class_distribution_target = class_distribution_target.transpose()\n","class_distribution_target.columns = ['class','samples']\n","class_distribution_target"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>374608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>270</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>215</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>269</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>259</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>203</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>314</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>248</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>305</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>268</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    class  samples\n","0       0   374608\n","1       1      270\n","2       2      101\n","3       3      251\n","4       4      215\n","5       5      269\n","6       6      269\n","7       7      259\n","8       8      203\n","9       9      314\n","10     10      248\n","11     11      305\n","12     12      181\n","13     13      268\n","14     14       95"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"CgE2FPXbXtt9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787461859,"user_tz":420,"elapsed":454,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"972a6a4c-a335-435d-e239-0a8d7a70bcb7"},"source":["classes_target , counts_target = np.unique(ground_truth_target, return_counts = True)\n","classes_target = classes_target[1:] ## Dropping classes with small number of samples\n","classes_target"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n","      dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"l_PESscnqDde"},"source":["## Source : Indian Pines\n","\n","## Train model for samples extracted with different overlap ratios and a percent of  samples picked from each class to be present in the training set. \n","\n","## Model except the final fully connected layer is saved for transfer learning."]},{"cell_type":"code","metadata":{"id":"7vc1sJwRqDdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787558637,"user_tz":420,"elapsed":82865,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"feb66dac-d315-49b4-bd82-eb7894594a46"},"source":["pretrain_source_models(training_set_size = [200],\n","                      classes = classes_source,\n","                      cube_size = 20,\n","                      overlap_ratio = 1,\n","                      data = data_source,\n","                      ground_truth = ground_truth_source,\n","                      batch_size = 20,\n","                      channels = 64,\n","                      epochs = 50,\n","                      Verbosity = 1,\n","                      accuracies = [],\n","                      learning_rate = 0.0001,\n","                      source_dataset = 'indian_pines')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","=============================================================================================================\n","Model training starts for data with 200 samples from each class in training set\n","==============================================================================================================\n","\n","Samples per class: [1368, 523, 323, 730, 356, 837, 2224, 460, 1085]\n","Total number of samples 7906.\n","\n","Total number of samples in training set 1800.\n","unique classes in training set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in training set: [200 200 200 200 200 200 200 200 200]\n","\n","Total number of samples in test set 6106.\n","unique classes in test set: [ 2  3  5  6  8 10 11 12 14]\n","Samples per class in test set: [1168  323  123  530  156  637 2024  260  885]\n","\n","X_train => (1800, 20, 20, 64)\n","X_test  => (6106, 20, 20, 64)\n","y_train => (1800, 9)\n","y_test  => (6106, 9)\n","\n","Group convolution output:  (None, 20, 20, 64)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","__________________________________________________________________________________________________\n","final_fully_connected (Dense)   (None, 256)          65792       global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 9)            2313        final_fully_connected[0][0]      \n","==================================================================================================\n","Total params: 223,305\n","Trainable params: 220,617\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","90/90 [==============================] - 19s 17ms/step - loss: 9.3708 - categorical_accuracy: 0.1820\n","\n","Epoch 00001: categorical_accuracy improved from -inf to 0.24944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 2/50\n","90/90 [==============================] - 1s 17ms/step - loss: 8.9383 - categorical_accuracy: 0.3496\n","\n","Epoch 00002: categorical_accuracy improved from 0.24944 to 0.41167, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 3/50\n","90/90 [==============================] - 2s 17ms/step - loss: 8.7302 - categorical_accuracy: 0.5451\n","\n","Epoch 00003: categorical_accuracy improved from 0.41167 to 0.61944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 4/50\n","90/90 [==============================] - 1s 17ms/step - loss: 8.5358 - categorical_accuracy: 0.6825\n","\n","Epoch 00004: categorical_accuracy improved from 0.61944 to 0.68667, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 5/50\n","90/90 [==============================] - 1s 17ms/step - loss: 8.3692 - categorical_accuracy: 0.7518\n","\n","Epoch 00005: categorical_accuracy improved from 0.68667 to 0.73778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 6/50\n","90/90 [==============================] - 2s 17ms/step - loss: 8.2361 - categorical_accuracy: 0.7776\n","\n","Epoch 00006: categorical_accuracy improved from 0.73778 to 0.77222, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 7/50\n","90/90 [==============================] - 2s 17ms/step - loss: 8.1268 - categorical_accuracy: 0.7867\n","\n","Epoch 00007: categorical_accuracy improved from 0.77222 to 0.79000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 8/50\n","90/90 [==============================] - 2s 17ms/step - loss: 8.0223 - categorical_accuracy: 0.7963\n","\n","Epoch 00008: categorical_accuracy improved from 0.79000 to 0.80722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 9/50\n","90/90 [==============================] - 1s 17ms/step - loss: 7.9293 - categorical_accuracy: 0.8040\n","\n","Epoch 00009: categorical_accuracy improved from 0.80722 to 0.80944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 10/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.8587 - categorical_accuracy: 0.8242\n","\n","Epoch 00010: categorical_accuracy improved from 0.80944 to 0.83667, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 11/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.7818 - categorical_accuracy: 0.8222\n","\n","Epoch 00011: categorical_accuracy did not improve from 0.83667\n","Epoch 12/50\n","90/90 [==============================] - 1s 17ms/step - loss: 7.6670 - categorical_accuracy: 0.8488\n","\n","Epoch 00012: categorical_accuracy improved from 0.83667 to 0.84833, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 13/50\n","90/90 [==============================] - 2s 18ms/step - loss: 7.5928 - categorical_accuracy: 0.8702\n","\n","Epoch 00013: categorical_accuracy improved from 0.84833 to 0.86167, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 14/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.5352 - categorical_accuracy: 0.8555\n","\n","Epoch 00014: categorical_accuracy did not improve from 0.86167\n","Epoch 15/50\n","90/90 [==============================] - 1s 17ms/step - loss: 7.4769 - categorical_accuracy: 0.8642\n","\n","Epoch 00015: categorical_accuracy did not improve from 0.86167\n","Epoch 16/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.3848 - categorical_accuracy: 0.8848\n","\n","Epoch 00016: categorical_accuracy improved from 0.86167 to 0.88000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 17/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.3510 - categorical_accuracy: 0.8786\n","\n","Epoch 00017: categorical_accuracy did not improve from 0.88000\n","Epoch 18/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.2689 - categorical_accuracy: 0.8985\n","\n","Epoch 00018: categorical_accuracy improved from 0.88000 to 0.88667, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 19/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.2241 - categorical_accuracy: 0.8909\n","\n","Epoch 00019: categorical_accuracy did not improve from 0.88667\n","Epoch 20/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.1883 - categorical_accuracy: 0.8868\n","\n","Epoch 00020: categorical_accuracy improved from 0.88667 to 0.88944, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 21/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.1395 - categorical_accuracy: 0.8998\n","\n","Epoch 00021: categorical_accuracy improved from 0.88944 to 0.89444, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 22/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.0947 - categorical_accuracy: 0.8902\n","\n","Epoch 00022: categorical_accuracy did not improve from 0.89444\n","Epoch 23/50\n","90/90 [==============================] - 1s 17ms/step - loss: 7.0329 - categorical_accuracy: 0.9055\n","\n","Epoch 00023: categorical_accuracy improved from 0.89444 to 0.89778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 24/50\n","90/90 [==============================] - 2s 17ms/step - loss: 7.0111 - categorical_accuracy: 0.9037\n","\n","Epoch 00024: categorical_accuracy improved from 0.89778 to 0.90778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 25/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.9548 - categorical_accuracy: 0.9084\n","\n","Epoch 00025: categorical_accuracy improved from 0.90778 to 0.91000, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 26/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.9228 - categorical_accuracy: 0.9044\n","\n","Epoch 00026: categorical_accuracy did not improve from 0.91000\n","Epoch 27/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.8851 - categorical_accuracy: 0.9209\n","\n","Epoch 00027: categorical_accuracy improved from 0.91000 to 0.91778, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 28/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.8538 - categorical_accuracy: 0.9104\n","\n","Epoch 00028: categorical_accuracy improved from 0.91778 to 0.91889, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 29/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.7913 - categorical_accuracy: 0.9247\n","\n","Epoch 00029: categorical_accuracy improved from 0.91889 to 0.92889, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//full_models/indian_pines_with_200_samples_from_each_class_in_training_set.h5\n","Epoch 30/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.7866 - categorical_accuracy: 0.9106\n","\n","Epoch 00030: categorical_accuracy did not improve from 0.92889\n","Epoch 31/50\n","90/90 [==============================] - 2s 17ms/step - loss: 6.7418 - categorical_accuracy: 0.9122\n","\n","Epoch 00031: categorical_accuracy did not improve from 0.92889\n","Epoch 32/50\n","90/90 [==============================] - 1s 17ms/step - loss: 6.6794 - categorical_accuracy: 0.9300\n","\n","Epoch 00032: categorical_accuracy did not improve from 0.92889\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n","=============================================================================================================\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RkxgCjIejh0l"},"source":["# Fine tune on botswana"]},{"cell_type":"code","metadata":{"id":"SJ1kSkHtCuHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787996266,"user_tz":420,"elapsed":256185,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"fe51d14c-befc-4e25-ca5d-6422164bb191"},"source":["transfer_results, confusion_matrixes = transfer_learning(source_dataset = 'indian_pines',\n","                                        target_dataset = 'botswana',\n","                                        data = data_target,\n","                                        ground_truth = ground_truth_target,\n","                                        training_samples_from_each_class = [15,30,45,60,75],\n","                                        source_training_size = [200],\n","                                        classes = classes_target,\n","                                        overlap_ratio = 1,\n","                                        channels = 64,\n","                                        cube_size = 20,\n","                                        learning_rate = 0.0001,\n","                                        epochs = 150,\n","                                        batch_size = 20,\n","                                        test_accuracies = [],\n","                                        )"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\n","================================================================================================================================\n","Model training starts for data with 15 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 210.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [15 15 15 15 15 15 15 15 15 15 15 15 15 15]\n","\n","Total number of samples in test set 2934.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [255  86 236 200 254 254 244 188 299 233 261 118 226  80]\n","\n","X_train_transfer => (210, 256)\n","X_test_transfer  => (2934, 256)\n","y_train => (210, 14)\n","y_test  => (2934, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","11/11 [==============================] - 1s 56ms/step - loss: 5.7268 - categorical_accuracy: 0.0978 - val_loss: 3.3043 - val_categorical_accuracy: 0.1046\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.10464, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","11/11 [==============================] - 0s 27ms/step - loss: 3.3807 - categorical_accuracy: 0.1466 - val_loss: 2.8198 - val_categorical_accuracy: 0.1513\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.10464 to 0.15133, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","11/11 [==============================] - 0s 27ms/step - loss: 2.6562 - categorical_accuracy: 0.2117 - val_loss: 2.6287 - val_categorical_accuracy: 0.1339\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.15133\n","Epoch 4/150\n","11/11 [==============================] - 0s 26ms/step - loss: 2.2875 - categorical_accuracy: 0.2804 - val_loss: 2.4564 - val_categorical_accuracy: 0.1653\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.15133 to 0.16530, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","11/11 [==============================] - 0s 26ms/step - loss: 2.0977 - categorical_accuracy: 0.3260 - val_loss: 2.3579 - val_categorical_accuracy: 0.1578\n","\n","Epoch 00005: val_categorical_accuracy did not improve from 0.16530\n","Epoch 6/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.9945 - categorical_accuracy: 0.4197 - val_loss: 2.3276 - val_categorical_accuracy: 0.2096\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.16530 to 0.20961, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.9765 - categorical_accuracy: 0.3417 - val_loss: 2.2523 - val_categorical_accuracy: 0.2389\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.20961 to 0.23892, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.9400 - categorical_accuracy: 0.3546 - val_loss: 2.2212 - val_categorical_accuracy: 0.2638\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.23892 to 0.26380, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.8913 - categorical_accuracy: 0.4392 - val_loss: 2.2017 - val_categorical_accuracy: 0.2584\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.26380\n","Epoch 10/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.7608 - categorical_accuracy: 0.5089 - val_loss: 2.1524 - val_categorical_accuracy: 0.2539\n","\n","Epoch 00010: val_categorical_accuracy did not improve from 0.26380\n","Epoch 11/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.7477 - categorical_accuracy: 0.4698 - val_loss: 2.1073 - val_categorical_accuracy: 0.2686\n","\n","Epoch 00011: val_categorical_accuracy improved from 0.26380 to 0.26858, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 12/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.7291 - categorical_accuracy: 0.5109 - val_loss: 2.1104 - val_categorical_accuracy: 0.2662\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.26858\n","Epoch 13/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.7561 - categorical_accuracy: 0.4305 - val_loss: 2.0621 - val_categorical_accuracy: 0.2590\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.26858\n","Epoch 14/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.6695 - categorical_accuracy: 0.5195 - val_loss: 2.0342 - val_categorical_accuracy: 0.3470\n","\n","Epoch 00014: val_categorical_accuracy improved from 0.26858 to 0.34697, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 15/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.6326 - categorical_accuracy: 0.5651 - val_loss: 2.0145 - val_categorical_accuracy: 0.3166\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.34697\n","Epoch 16/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.6137 - categorical_accuracy: 0.5125 - val_loss: 1.9887 - val_categorical_accuracy: 0.3661\n","\n","Epoch 00016: val_categorical_accuracy improved from 0.34697 to 0.36605, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 17/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.6138 - categorical_accuracy: 0.6560 - val_loss: 1.9704 - val_categorical_accuracy: 0.3504\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.36605\n","Epoch 18/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.5378 - categorical_accuracy: 0.6346 - val_loss: 1.9695 - val_categorical_accuracy: 0.3517\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.36605\n","Epoch 19/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.5169 - categorical_accuracy: 0.6326 - val_loss: 1.9441 - val_categorical_accuracy: 0.3736\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.36605 to 0.37355, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 20/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4622 - categorical_accuracy: 0.7308 - val_loss: 1.9206 - val_categorical_accuracy: 0.3582\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.37355\n","Epoch 21/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4953 - categorical_accuracy: 0.7351 - val_loss: 1.9035 - val_categorical_accuracy: 0.4117\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.37355 to 0.41172, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.4032 - categorical_accuracy: 0.6807 - val_loss: 1.8906 - val_categorical_accuracy: 0.4322\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.41172 to 0.43217, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 23/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3811 - categorical_accuracy: 0.8108 - val_loss: 1.8827 - val_categorical_accuracy: 0.4025\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.43217\n","Epoch 24/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.3937 - categorical_accuracy: 0.7510 - val_loss: 1.8660 - val_categorical_accuracy: 0.4312\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.43217\n","Epoch 25/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.3564 - categorical_accuracy: 0.7700 - val_loss: 1.8438 - val_categorical_accuracy: 0.4605\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.43217 to 0.46046, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.3414 - categorical_accuracy: 0.8287 - val_loss: 1.8351 - val_categorical_accuracy: 0.4502\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.46046\n","Epoch 27/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3297 - categorical_accuracy: 0.8106 - val_loss: 1.8148 - val_categorical_accuracy: 0.4717\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.46046 to 0.47171, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2454 - categorical_accuracy: 0.7558 - val_loss: 1.8260 - val_categorical_accuracy: 0.4145\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.47171\n","Epoch 29/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.3036 - categorical_accuracy: 0.7733 - val_loss: 1.8008 - val_categorical_accuracy: 0.4588\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.47171\n","Epoch 30/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.2475 - categorical_accuracy: 0.8058 - val_loss: 1.7859 - val_categorical_accuracy: 0.4721\n","\n","Epoch 00030: val_categorical_accuracy improved from 0.47171 to 0.47205, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 31/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.2600 - categorical_accuracy: 0.8881 - val_loss: 1.7710 - val_categorical_accuracy: 0.4792\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.47205 to 0.47921, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 32/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.2507 - categorical_accuracy: 0.9104 - val_loss: 1.7613 - val_categorical_accuracy: 0.5010\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.47921 to 0.50102, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 33/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.1839 - categorical_accuracy: 0.8049 - val_loss: 1.7558 - val_categorical_accuracy: 0.4833\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.50102\n","Epoch 34/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.2357 - categorical_accuracy: 0.8413 - val_loss: 1.7363 - val_categorical_accuracy: 0.5068\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.50102 to 0.50682, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1916 - categorical_accuracy: 0.9534 - val_loss: 1.7287 - val_categorical_accuracy: 0.5211\n","\n","Epoch 00035: val_categorical_accuracy improved from 0.50682 to 0.52113, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 36/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.1303 - categorical_accuracy: 0.9103 - val_loss: 1.7272 - val_categorical_accuracy: 0.4922\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.52113\n","Epoch 37/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1298 - categorical_accuracy: 0.8294 - val_loss: 1.7054 - val_categorical_accuracy: 0.5290\n","\n","Epoch 00037: val_categorical_accuracy improved from 0.52113 to 0.52897, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 38/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0702 - categorical_accuracy: 0.9428 - val_loss: 1.6977 - val_categorical_accuracy: 0.5402\n","\n","Epoch 00038: val_categorical_accuracy improved from 0.52897 to 0.54022, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 39/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.1255 - categorical_accuracy: 0.9140 - val_loss: 1.6893 - val_categorical_accuracy: 0.5106\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.54022\n","Epoch 40/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0865 - categorical_accuracy: 0.8717 - val_loss: 1.6882 - val_categorical_accuracy: 0.4956\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.54022\n","Epoch 41/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.1004 - categorical_accuracy: 0.9044 - val_loss: 1.6766 - val_categorical_accuracy: 0.5174\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.54022\n","Epoch 42/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0650 - categorical_accuracy: 0.8576 - val_loss: 1.6913 - val_categorical_accuracy: 0.4686\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.54022\n","Epoch 43/150\n","11/11 [==============================] - 0s 27ms/step - loss: 1.0430 - categorical_accuracy: 0.9151 - val_loss: 1.6682 - val_categorical_accuracy: 0.5119\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.54022\n","Epoch 44/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0688 - categorical_accuracy: 0.9117 - val_loss: 1.6588 - val_categorical_accuracy: 0.5375\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.54022\n","Epoch 45/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0194 - categorical_accuracy: 0.9360 - val_loss: 1.6552 - val_categorical_accuracy: 0.5150\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.54022\n","Epoch 46/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0796 - categorical_accuracy: 0.8964 - val_loss: 1.6434 - val_categorical_accuracy: 0.5341\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.54022\n","Epoch 47/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0088 - categorical_accuracy: 0.9461 - val_loss: 1.6453 - val_categorical_accuracy: 0.4935\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.54022\n","Epoch 48/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0309 - categorical_accuracy: 0.8801 - val_loss: 1.6373 - val_categorical_accuracy: 0.5010\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.54022\n","Epoch 49/150\n","11/11 [==============================] - 0s 28ms/step - loss: 1.0059 - categorical_accuracy: 0.9398 - val_loss: 1.6293 - val_categorical_accuracy: 0.5068\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.54022\n","Epoch 50/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.9787 - categorical_accuracy: 0.9296 - val_loss: 1.6254 - val_categorical_accuracy: 0.5204\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.54022\n","Epoch 51/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.9990 - categorical_accuracy: 0.8440 - val_loss: 1.6228 - val_categorical_accuracy: 0.5279\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.54022\n","Epoch 52/150\n","11/11 [==============================] - 0s 26ms/step - loss: 1.0060 - categorical_accuracy: 0.9411 - val_loss: 1.6007 - val_categorical_accuracy: 0.5474\n","\n","Epoch 00052: val_categorical_accuracy improved from 0.54022 to 0.54738, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 53/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.9433 - categorical_accuracy: 0.9267 - val_loss: 1.6146 - val_categorical_accuracy: 0.5450\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.54738\n","Epoch 54/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.9522 - categorical_accuracy: 0.8972 - val_loss: 1.6023 - val_categorical_accuracy: 0.5395\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.54738\n","Epoch 55/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.9610 - categorical_accuracy: 0.9730 - val_loss: 1.5896 - val_categorical_accuracy: 0.5460\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.54738\n","Epoch 56/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8911 - categorical_accuracy: 0.9684 - val_loss: 1.5977 - val_categorical_accuracy: 0.5317\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.54738\n","Epoch 57/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.8803 - categorical_accuracy: 0.9772 - val_loss: 1.5860 - val_categorical_accuracy: 0.5627\n","\n","Epoch 00057: val_categorical_accuracy improved from 0.54738 to 0.56271, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 58/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8845 - categorical_accuracy: 0.9870 - val_loss: 1.5680 - val_categorical_accuracy: 0.5648\n","\n","Epoch 00058: val_categorical_accuracy improved from 0.56271 to 0.56476, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 59/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.9124 - categorical_accuracy: 0.9273 - val_loss: 1.5813 - val_categorical_accuracy: 0.5392\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.56476\n","Epoch 60/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8478 - categorical_accuracy: 0.9354 - val_loss: 1.5890 - val_categorical_accuracy: 0.5191\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.56476\n","Epoch 61/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8515 - categorical_accuracy: 0.9807 - val_loss: 1.5628 - val_categorical_accuracy: 0.5528\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.56476\n","Epoch 62/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8844 - categorical_accuracy: 0.9816 - val_loss: 1.5664 - val_categorical_accuracy: 0.5501\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.56476\n","Epoch 63/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8286 - categorical_accuracy: 0.9085 - val_loss: 1.5541 - val_categorical_accuracy: 0.5651\n","\n","Epoch 00063: val_categorical_accuracy improved from 0.56476 to 0.56510, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 64/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8467 - categorical_accuracy: 0.9586 - val_loss: 1.5625 - val_categorical_accuracy: 0.5515\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.56510\n","Epoch 65/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8509 - categorical_accuracy: 0.9517 - val_loss: 1.5468 - val_categorical_accuracy: 0.5549\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.56510\n","Epoch 66/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.8086 - categorical_accuracy: 0.9988 - val_loss: 1.5530 - val_categorical_accuracy: 0.5361\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.56510\n","Epoch 67/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8192 - categorical_accuracy: 0.9755 - val_loss: 1.5466 - val_categorical_accuracy: 0.5579\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.56510\n","Epoch 68/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8189 - categorical_accuracy: 0.9748 - val_loss: 1.5402 - val_categorical_accuracy: 0.5566\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.56510\n","Epoch 69/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.8299 - categorical_accuracy: 0.9820 - val_loss: 1.5342 - val_categorical_accuracy: 0.5586\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.56510\n","Epoch 70/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7590 - categorical_accuracy: 0.9746 - val_loss: 1.5269 - val_categorical_accuracy: 0.5634\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.56510\n","Epoch 71/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7500 - categorical_accuracy: 1.0000 - val_loss: 1.5240 - val_categorical_accuracy: 0.5852\n","\n","Epoch 00071: val_categorical_accuracy improved from 0.56510 to 0.58521, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 72/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.8246 - categorical_accuracy: 0.9988 - val_loss: 1.5274 - val_categorical_accuracy: 0.5620\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.58521\n","Epoch 73/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7940 - categorical_accuracy: 0.9537 - val_loss: 1.5205 - val_categorical_accuracy: 0.5576\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.58521\n","Epoch 74/150\n","11/11 [==============================] - 0s 30ms/step - loss: 0.7595 - categorical_accuracy: 1.0000 - val_loss: 1.5156 - val_categorical_accuracy: 0.5787\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.58521\n","Epoch 75/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.7666 - categorical_accuracy: 0.9972 - val_loss: 1.5158 - val_categorical_accuracy: 0.5593\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.58521\n","Epoch 76/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7852 - categorical_accuracy: 0.9988 - val_loss: 1.5095 - val_categorical_accuracy: 0.5668\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.58521\n","Epoch 77/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.7283 - categorical_accuracy: 0.9646 - val_loss: 1.5057 - val_categorical_accuracy: 0.5971\n","\n","Epoch 00077: val_categorical_accuracy improved from 0.58521 to 0.59714, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 78/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7420 - categorical_accuracy: 0.9966 - val_loss: 1.4934 - val_categorical_accuracy: 0.5740\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.59714\n","Epoch 79/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7580 - categorical_accuracy: 0.9709 - val_loss: 1.5099 - val_categorical_accuracy: 0.5491\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.59714\n","Epoch 80/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.7219 - categorical_accuracy: 0.9978 - val_loss: 1.4913 - val_categorical_accuracy: 0.5835\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.59714\n","Epoch 81/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7492 - categorical_accuracy: 0.9933 - val_loss: 1.5000 - val_categorical_accuracy: 0.5774\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.59714\n","Epoch 82/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7415 - categorical_accuracy: 1.0000 - val_loss: 1.4834 - val_categorical_accuracy: 0.5883\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.59714\n","Epoch 83/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6862 - categorical_accuracy: 0.9796 - val_loss: 1.4903 - val_categorical_accuracy: 0.5907\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.59714\n","Epoch 84/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6904 - categorical_accuracy: 0.9853 - val_loss: 1.4800 - val_categorical_accuracy: 0.5757\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.59714\n","Epoch 85/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.7044 - categorical_accuracy: 0.9953 - val_loss: 1.4833 - val_categorical_accuracy: 0.5862\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.59714\n","Epoch 86/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6789 - categorical_accuracy: 1.0000 - val_loss: 1.4792 - val_categorical_accuracy: 0.5876\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.59714\n","Epoch 87/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6717 - categorical_accuracy: 1.0000 - val_loss: 1.4808 - val_categorical_accuracy: 0.5890\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.59714\n","Epoch 88/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.6928 - categorical_accuracy: 0.9946 - val_loss: 1.4741 - val_categorical_accuracy: 0.5804\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.59714\n","Epoch 89/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6761 - categorical_accuracy: 0.9944 - val_loss: 1.4726 - val_categorical_accuracy: 0.5583\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.59714\n","Epoch 90/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6436 - categorical_accuracy: 1.0000 - val_loss: 1.4705 - val_categorical_accuracy: 0.5910\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.59714\n","Epoch 91/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6868 - categorical_accuracy: 1.0000 - val_loss: 1.4659 - val_categorical_accuracy: 0.5907\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.59714\n","Epoch 92/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.6660 - categorical_accuracy: 1.0000 - val_loss: 1.4624 - val_categorical_accuracy: 0.5958\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.59714\n","Epoch 93/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6811 - categorical_accuracy: 0.9933 - val_loss: 1.4597 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.59714\n","Epoch 94/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6653 - categorical_accuracy: 0.9956 - val_loss: 1.4602 - val_categorical_accuracy: 0.5862\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.59714\n","Epoch 95/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6888 - categorical_accuracy: 1.0000 - val_loss: 1.4668 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.59714\n","Epoch 96/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6359 - categorical_accuracy: 1.0000 - val_loss: 1.4544 - val_categorical_accuracy: 0.5791\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.59714\n","Epoch 97/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6462 - categorical_accuracy: 0.9850 - val_loss: 1.4604 - val_categorical_accuracy: 0.5811\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.59714\n","Epoch 98/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6247 - categorical_accuracy: 0.9766 - val_loss: 1.4573 - val_categorical_accuracy: 0.5903\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.59714\n","Epoch 99/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6467 - categorical_accuracy: 0.9992 - val_loss: 1.4528 - val_categorical_accuracy: 0.5903\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.59714\n","Epoch 100/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6518 - categorical_accuracy: 1.0000 - val_loss: 1.4560 - val_categorical_accuracy: 0.5876\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.59714\n","Epoch 101/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6032 - categorical_accuracy: 1.0000 - val_loss: 1.4559 - val_categorical_accuracy: 0.6012\n","\n","Epoch 00101: val_categorical_accuracy improved from 0.59714 to 0.60123, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 102/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.6219 - categorical_accuracy: 0.9972 - val_loss: 1.4396 - val_categorical_accuracy: 0.5927\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.60123\n","Epoch 103/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.6151 - categorical_accuracy: 1.0000 - val_loss: 1.4342 - val_categorical_accuracy: 0.6033\n","\n","Epoch 00103: val_categorical_accuracy improved from 0.60123 to 0.60327, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 104/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.6080 - categorical_accuracy: 0.9890 - val_loss: 1.4301 - val_categorical_accuracy: 0.5978\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.60327\n","Epoch 105/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.6141 - categorical_accuracy: 0.9983 - val_loss: 1.4387 - val_categorical_accuracy: 0.5965\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.60327\n","Epoch 106/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.5698 - categorical_accuracy: 1.0000 - val_loss: 1.4373 - val_categorical_accuracy: 0.5913\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.60327\n","Epoch 107/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5897 - categorical_accuracy: 0.9943 - val_loss: 1.4309 - val_categorical_accuracy: 0.5855\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.60327\n","Epoch 108/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.5740 - categorical_accuracy: 1.0000 - val_loss: 1.4303 - val_categorical_accuracy: 0.5988\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.60327\n","Epoch 109/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5873 - categorical_accuracy: 1.0000 - val_loss: 1.4387 - val_categorical_accuracy: 0.5825\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.60327\n","Epoch 110/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5611 - categorical_accuracy: 0.9912 - val_loss: 1.4182 - val_categorical_accuracy: 0.6022\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.60327\n","Epoch 111/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5585 - categorical_accuracy: 0.9965 - val_loss: 1.4254 - val_categorical_accuracy: 0.6179\n","\n","Epoch 00111: val_categorical_accuracy improved from 0.60327 to 0.61793, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 112/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5369 - categorical_accuracy: 1.0000 - val_loss: 1.4286 - val_categorical_accuracy: 0.5934\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.61793\n","Epoch 113/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.5832 - categorical_accuracy: 0.9978 - val_loss: 1.4218 - val_categorical_accuracy: 0.5937\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.61793\n","Epoch 114/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.5460 - categorical_accuracy: 1.0000 - val_loss: 1.4235 - val_categorical_accuracy: 0.6166\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.61793\n","Epoch 115/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.5565 - categorical_accuracy: 1.0000 - val_loss: 1.4134 - val_categorical_accuracy: 0.6091\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.61793\n","Epoch 116/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5516 - categorical_accuracy: 0.9965 - val_loss: 1.4252 - val_categorical_accuracy: 0.5958\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.61793\n","Epoch 117/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.5709 - categorical_accuracy: 1.0000 - val_loss: 1.4119 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.61793\n","Epoch 118/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.5428 - categorical_accuracy: 1.0000 - val_loss: 1.4238 - val_categorical_accuracy: 0.5961\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.61793\n","Epoch 119/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5459 - categorical_accuracy: 1.0000 - val_loss: 1.4090 - val_categorical_accuracy: 0.6077\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.61793\n","Epoch 120/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.5265 - categorical_accuracy: 0.9957 - val_loss: 1.4252 - val_categorical_accuracy: 0.5896\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.61793\n","Epoch 121/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5165 - categorical_accuracy: 1.0000 - val_loss: 1.4112 - val_categorical_accuracy: 0.6169\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.61793\n","Epoch 122/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5227 - categorical_accuracy: 1.0000 - val_loss: 1.4014 - val_categorical_accuracy: 0.6043\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.61793\n","Epoch 123/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5455 - categorical_accuracy: 1.0000 - val_loss: 1.4116 - val_categorical_accuracy: 0.5821\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.61793\n","Epoch 124/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.5102 - categorical_accuracy: 0.9933 - val_loss: 1.4022 - val_categorical_accuracy: 0.6179\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.61793\n","Epoch 125/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.5048 - categorical_accuracy: 1.0000 - val_loss: 1.4101 - val_categorical_accuracy: 0.6067\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.61793\n","Epoch 126/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5000 - categorical_accuracy: 1.0000 - val_loss: 1.3995 - val_categorical_accuracy: 0.5982\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.61793\n","Epoch 127/150\n","11/11 [==============================] - 0s 29ms/step - loss: 0.5188 - categorical_accuracy: 1.0000 - val_loss: 1.4008 - val_categorical_accuracy: 0.6196\n","\n","Epoch 00127: val_categorical_accuracy improved from 0.61793 to 0.61963, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 128/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.5054 - categorical_accuracy: 0.9965 - val_loss: 1.4029 - val_categorical_accuracy: 0.6097\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.61963\n","Epoch 129/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4990 - categorical_accuracy: 1.0000 - val_loss: 1.3947 - val_categorical_accuracy: 0.6224\n","\n","Epoch 00129: val_categorical_accuracy improved from 0.61963 to 0.62236, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 130/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4867 - categorical_accuracy: 1.0000 - val_loss: 1.3951 - val_categorical_accuracy: 0.6043\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.62236\n","Epoch 131/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.5105 - categorical_accuracy: 0.9983 - val_loss: 1.3955 - val_categorical_accuracy: 0.5968\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.62236\n","Epoch 132/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.4805 - categorical_accuracy: 1.0000 - val_loss: 1.4031 - val_categorical_accuracy: 0.6237\n","\n","Epoch 00132: val_categorical_accuracy improved from 0.62236 to 0.62372, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 133/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.4832 - categorical_accuracy: 1.0000 - val_loss: 1.3940 - val_categorical_accuracy: 0.6022\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.62372\n","Epoch 134/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.4711 - categorical_accuracy: 0.9992 - val_loss: 1.3943 - val_categorical_accuracy: 0.6040\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.62372\n","Epoch 135/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4809 - categorical_accuracy: 1.0000 - val_loss: 1.4030 - val_categorical_accuracy: 0.6244\n","\n","Epoch 00135: val_categorical_accuracy improved from 0.62372 to 0.62440, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 136/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4997 - categorical_accuracy: 1.0000 - val_loss: 1.3937 - val_categorical_accuracy: 0.6077\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.62440\n","Epoch 137/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4920 - categorical_accuracy: 0.9938 - val_loss: 1.3848 - val_categorical_accuracy: 0.6005\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.62440\n","Epoch 138/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4796 - categorical_accuracy: 0.9933 - val_loss: 1.3854 - val_categorical_accuracy: 0.6016\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.62440\n","Epoch 139/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.4775 - categorical_accuracy: 1.0000 - val_loss: 1.3880 - val_categorical_accuracy: 0.6234\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.62440\n","Epoch 140/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.4632 - categorical_accuracy: 1.0000 - val_loss: 1.3787 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.62440\n","Epoch 141/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4581 - categorical_accuracy: 0.9972 - val_loss: 1.3774 - val_categorical_accuracy: 0.6179\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.62440\n","Epoch 142/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4486 - categorical_accuracy: 1.0000 - val_loss: 1.3838 - val_categorical_accuracy: 0.6162\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.62440\n","Epoch 143/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4566 - categorical_accuracy: 1.0000 - val_loss: 1.3819 - val_categorical_accuracy: 0.6060\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.62440\n","Epoch 144/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4372 - categorical_accuracy: 0.9972 - val_loss: 1.3736 - val_categorical_accuracy: 0.6292\n","\n","Epoch 00144: val_categorical_accuracy improved from 0.62440 to 0.62918, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_15_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 145/150\n","11/11 [==============================] - 0s 28ms/step - loss: 0.4587 - categorical_accuracy: 1.0000 - val_loss: 1.3858 - val_categorical_accuracy: 0.6060\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.62918\n","Epoch 146/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.4556 - categorical_accuracy: 1.0000 - val_loss: 1.3790 - val_categorical_accuracy: 0.6162\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.62918\n","Epoch 147/150\n","11/11 [==============================] - 0s 26ms/step - loss: 0.4575 - categorical_accuracy: 1.0000 - val_loss: 1.3763 - val_categorical_accuracy: 0.6186\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.62918\n","Epoch 148/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4545 - categorical_accuracy: 1.0000 - val_loss: 1.3742 - val_categorical_accuracy: 0.6050\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.62918\n","Epoch 149/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4331 - categorical_accuracy: 0.9965 - val_loss: 1.3650 - val_categorical_accuracy: 0.6172\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.62918\n","Epoch 150/150\n","11/11 [==============================] - 0s 27ms/step - loss: 0.4508 - categorical_accuracy: 1.0000 - val_loss: 1.3793 - val_categorical_accuracy: 0.6227\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.62918\n","92/92 [==============================] - 0s 2ms/step - loss: 1.3736 - categorical_accuracy: 0.6292\n","92/92 [==============================] - 0s 979us/step\n","\n","================================================================================================================================\n","Model training starts for data with 30 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 420.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n","\n","Total number of samples in test set 2724.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [240  71 221 185 239 239 229 173 284 218 246 103 211  65]\n","\n","X_train_transfer => (420, 256)\n","X_test_transfer  => (2724, 256)\n","y_train => (420, 14)\n","y_test  => (2724, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","21/21 [==============================] - 1s 20ms/step - loss: 5.0557 - categorical_accuracy: 0.1106 - val_loss: 2.8687 - val_categorical_accuracy: 0.1083\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.10830, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","21/21 [==============================] - 0s 13ms/step - loss: 2.5877 - categorical_accuracy: 0.2049 - val_loss: 2.4996 - val_categorical_accuracy: 0.1479\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.10830 to 0.14794, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","21/21 [==============================] - 0s 14ms/step - loss: 2.1631 - categorical_accuracy: 0.2761 - val_loss: 2.3763 - val_categorical_accuracy: 0.1791\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.14794 to 0.17915, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","21/21 [==============================] - 0s 13ms/step - loss: 2.0458 - categorical_accuracy: 0.3172 - val_loss: 2.2681 - val_categorical_accuracy: 0.1938\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.17915 to 0.19383, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.8775 - categorical_accuracy: 0.4519 - val_loss: 2.1980 - val_categorical_accuracy: 0.2544\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.19383 to 0.25441, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.8295 - categorical_accuracy: 0.4524 - val_loss: 2.1472 - val_categorical_accuracy: 0.2030\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.25441\n","Epoch 7/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.7356 - categorical_accuracy: 0.4413 - val_loss: 2.0914 - val_categorical_accuracy: 0.2863\n","\n","Epoch 00007: val_categorical_accuracy improved from 0.25441 to 0.28634, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 8/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.6075 - categorical_accuracy: 0.5954 - val_loss: 2.0413 - val_categorical_accuracy: 0.2206\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.28634\n","Epoch 9/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.6150 - categorical_accuracy: 0.4872 - val_loss: 2.0335 - val_categorical_accuracy: 0.2621\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.28634\n","Epoch 10/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.5326 - categorical_accuracy: 0.6112 - val_loss: 1.9601 - val_categorical_accuracy: 0.3344\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.28634 to 0.33443, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4969 - categorical_accuracy: 0.6033 - val_loss: 1.9790 - val_categorical_accuracy: 0.3194\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.33443\n","Epoch 12/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4377 - categorical_accuracy: 0.6362 - val_loss: 1.8781 - val_categorical_accuracy: 0.4688\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.33443 to 0.46880, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.4165 - categorical_accuracy: 0.6970 - val_loss: 1.8901 - val_categorical_accuracy: 0.4247\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.46880\n","Epoch 14/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3772 - categorical_accuracy: 0.7507 - val_loss: 1.8384 - val_categorical_accuracy: 0.4181\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.46880\n","Epoch 15/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.3479 - categorical_accuracy: 0.7988 - val_loss: 1.8399 - val_categorical_accuracy: 0.3770\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.46880\n","Epoch 16/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.3211 - categorical_accuracy: 0.7450 - val_loss: 1.8161 - val_categorical_accuracy: 0.3829\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.46880\n","Epoch 17/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2825 - categorical_accuracy: 0.7557 - val_loss: 1.7751 - val_categorical_accuracy: 0.4537\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.46880\n","Epoch 18/150\n","21/21 [==============================] - 0s 15ms/step - loss: 1.2565 - categorical_accuracy: 0.7995 - val_loss: 1.7775 - val_categorical_accuracy: 0.4369\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.46880\n","Epoch 19/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.2145 - categorical_accuracy: 0.7981 - val_loss: 1.7594 - val_categorical_accuracy: 0.4604\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.46880\n","Epoch 20/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.1277 - categorical_accuracy: 0.8571 - val_loss: 1.7343 - val_categorical_accuracy: 0.4659\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.46880\n","Epoch 21/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1492 - categorical_accuracy: 0.9028 - val_loss: 1.7223 - val_categorical_accuracy: 0.5151\n","\n","Epoch 00021: val_categorical_accuracy improved from 0.46880 to 0.51505, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 22/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1177 - categorical_accuracy: 0.8633 - val_loss: 1.6958 - val_categorical_accuracy: 0.5125\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.51505\n","Epoch 23/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.1016 - categorical_accuracy: 0.8022 - val_loss: 1.6959 - val_categorical_accuracy: 0.5173\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.51505 to 0.51725, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 24/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0703 - categorical_accuracy: 0.8583 - val_loss: 1.6793 - val_categorical_accuracy: 0.4604\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.51725\n","Epoch 25/150\n","21/21 [==============================] - 0s 14ms/step - loss: 1.0554 - categorical_accuracy: 0.8415 - val_loss: 1.6464 - val_categorical_accuracy: 0.5521\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.51725 to 0.55213, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","21/21 [==============================] - 0s 13ms/step - loss: 1.0294 - categorical_accuracy: 0.9420 - val_loss: 1.6442 - val_categorical_accuracy: 0.4956\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.55213\n","Epoch 27/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9908 - categorical_accuracy: 0.9161 - val_loss: 1.6407 - val_categorical_accuracy: 0.4886\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.55213\n","Epoch 28/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9569 - categorical_accuracy: 0.9325 - val_loss: 1.6236 - val_categorical_accuracy: 0.5385\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.55213\n","Epoch 29/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9575 - categorical_accuracy: 0.8749 - val_loss: 1.6342 - val_categorical_accuracy: 0.4703\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.55213\n","Epoch 30/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9387 - categorical_accuracy: 0.9533 - val_loss: 1.6127 - val_categorical_accuracy: 0.5228\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.55213\n","Epoch 31/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9170 - categorical_accuracy: 0.9076 - val_loss: 1.5989 - val_categorical_accuracy: 0.5198\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.55213\n","Epoch 32/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.9105 - categorical_accuracy: 0.9769 - val_loss: 1.5961 - val_categorical_accuracy: 0.4912\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.55213\n","Epoch 33/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.8532 - categorical_accuracy: 0.9454 - val_loss: 1.5810 - val_categorical_accuracy: 0.5301\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.55213\n","Epoch 34/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8314 - categorical_accuracy: 0.9518 - val_loss: 1.5679 - val_categorical_accuracy: 0.5084\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.55213\n","Epoch 35/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8376 - categorical_accuracy: 0.9853 - val_loss: 1.5552 - val_categorical_accuracy: 0.5540\n","\n","Epoch 00035: val_categorical_accuracy improved from 0.55213 to 0.55396, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 36/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8385 - categorical_accuracy: 0.9291 - val_loss: 1.5654 - val_categorical_accuracy: 0.5584\n","\n","Epoch 00036: val_categorical_accuracy improved from 0.55396 to 0.55837, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 37/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8220 - categorical_accuracy: 0.9463 - val_loss: 1.5374 - val_categorical_accuracy: 0.5745\n","\n","Epoch 00037: val_categorical_accuracy improved from 0.55837 to 0.57452, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 38/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8360 - categorical_accuracy: 0.9572 - val_loss: 1.5538 - val_categorical_accuracy: 0.5569\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.57452\n","Epoch 39/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8011 - categorical_accuracy: 0.9943 - val_loss: 1.5378 - val_categorical_accuracy: 0.5470\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.57452\n","Epoch 40/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.8073 - categorical_accuracy: 0.9271 - val_loss: 1.5185 - val_categorical_accuracy: 0.5411\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.57452\n","Epoch 41/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7624 - categorical_accuracy: 0.9233 - val_loss: 1.5205 - val_categorical_accuracy: 0.5459\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.57452\n","Epoch 42/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7795 - categorical_accuracy: 0.9197 - val_loss: 1.5369 - val_categorical_accuracy: 0.5140\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.57452\n","Epoch 43/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7502 - categorical_accuracy: 0.9884 - val_loss: 1.5023 - val_categorical_accuracy: 0.5591\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.57452\n","Epoch 44/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7177 - categorical_accuracy: 0.9914 - val_loss: 1.5349 - val_categorical_accuracy: 0.5441\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.57452\n","Epoch 45/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.7297 - categorical_accuracy: 0.9609 - val_loss: 1.5114 - val_categorical_accuracy: 0.5789\n","\n","Epoch 00045: val_categorical_accuracy improved from 0.57452 to 0.57893, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 46/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.7131 - categorical_accuracy: 0.9931 - val_loss: 1.4915 - val_categorical_accuracy: 0.5573\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.57893\n","Epoch 47/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6996 - categorical_accuracy: 0.9834 - val_loss: 1.5026 - val_categorical_accuracy: 0.5753\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.57893\n","Epoch 48/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6971 - categorical_accuracy: 0.9947 - val_loss: 1.4942 - val_categorical_accuracy: 0.5492\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.57893\n","Epoch 49/150\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6824 - categorical_accuracy: 0.9847 - val_loss: 1.4915 - val_categorical_accuracy: 0.5885\n","\n","Epoch 00049: val_categorical_accuracy improved from 0.57893 to 0.58847, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 50/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.6588 - categorical_accuracy: 0.9805 - val_loss: 1.4961 - val_categorical_accuracy: 0.5349\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.58847\n","Epoch 51/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6640 - categorical_accuracy: 0.9948 - val_loss: 1.4694 - val_categorical_accuracy: 0.5844\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.58847\n","Epoch 52/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6466 - categorical_accuracy: 0.9979 - val_loss: 1.4730 - val_categorical_accuracy: 0.5749\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.58847\n","Epoch 53/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.6309 - categorical_accuracy: 1.0000 - val_loss: 1.4536 - val_categorical_accuracy: 0.5569\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.58847\n","Epoch 54/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6339 - categorical_accuracy: 0.9934 - val_loss: 1.4649 - val_categorical_accuracy: 0.5800\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.58847\n","Epoch 55/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6398 - categorical_accuracy: 0.9883 - val_loss: 1.4602 - val_categorical_accuracy: 0.5841\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.58847\n","Epoch 56/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5923 - categorical_accuracy: 0.9961 - val_loss: 1.4638 - val_categorical_accuracy: 0.5753\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.58847\n","Epoch 57/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5741 - categorical_accuracy: 0.9941 - val_loss: 1.4483 - val_categorical_accuracy: 0.5844\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.58847\n","Epoch 58/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.6117 - categorical_accuracy: 1.0000 - val_loss: 1.4597 - val_categorical_accuracy: 0.5698\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.58847\n","Epoch 59/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5824 - categorical_accuracy: 0.9898 - val_loss: 1.4485 - val_categorical_accuracy: 0.5999\n","\n","Epoch 00059: val_categorical_accuracy improved from 0.58847 to 0.59985, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 60/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5747 - categorical_accuracy: 0.9941 - val_loss: 1.4456 - val_categorical_accuracy: 0.5683\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.59985\n","Epoch 61/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5475 - categorical_accuracy: 0.9914 - val_loss: 1.4361 - val_categorical_accuracy: 0.5819\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.59985\n","Epoch 62/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5704 - categorical_accuracy: 0.9987 - val_loss: 1.4398 - val_categorical_accuracy: 0.5657\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.59985\n","Epoch 63/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5474 - categorical_accuracy: 0.9993 - val_loss: 1.4386 - val_categorical_accuracy: 0.5797\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.59985\n","Epoch 64/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5351 - categorical_accuracy: 0.9953 - val_loss: 1.4321 - val_categorical_accuracy: 0.6131\n","\n","Epoch 00064: val_categorical_accuracy improved from 0.59985 to 0.61307, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 65/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5324 - categorical_accuracy: 0.9958 - val_loss: 1.4257 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.61307\n","Epoch 66/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5430 - categorical_accuracy: 1.0000 - val_loss: 1.4322 - val_categorical_accuracy: 0.5881\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.61307\n","Epoch 67/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5058 - categorical_accuracy: 0.9998 - val_loss: 1.4272 - val_categorical_accuracy: 0.5984\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.61307\n","Epoch 68/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5293 - categorical_accuracy: 0.9967 - val_loss: 1.4276 - val_categorical_accuracy: 0.5620\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.61307\n","Epoch 69/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4875 - categorical_accuracy: 0.9898 - val_loss: 1.4218 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.61307\n","Epoch 70/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.5100 - categorical_accuracy: 0.9944 - val_loss: 1.4243 - val_categorical_accuracy: 0.5841\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.61307\n","Epoch 71/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.5008 - categorical_accuracy: 1.0000 - val_loss: 1.4023 - val_categorical_accuracy: 0.5973\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.61307\n","Epoch 72/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4785 - categorical_accuracy: 0.9887 - val_loss: 1.4285 - val_categorical_accuracy: 0.5837\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.61307\n","Epoch 73/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4770 - categorical_accuracy: 1.0000 - val_loss: 1.3943 - val_categorical_accuracy: 0.5936\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.61307\n","Epoch 74/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4587 - categorical_accuracy: 0.9950 - val_loss: 1.4076 - val_categorical_accuracy: 0.5866\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.61307\n","Epoch 75/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4521 - categorical_accuracy: 0.9965 - val_loss: 1.4012 - val_categorical_accuracy: 0.5921\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.61307\n","Epoch 76/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4556 - categorical_accuracy: 1.0000 - val_loss: 1.3995 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.61307\n","Epoch 77/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4675 - categorical_accuracy: 1.0000 - val_loss: 1.3941 - val_categorical_accuracy: 0.6057\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.61307\n","Epoch 78/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4309 - categorical_accuracy: 0.9983 - val_loss: 1.4137 - val_categorical_accuracy: 0.5995\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.61307\n","Epoch 79/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4430 - categorical_accuracy: 1.0000 - val_loss: 1.3977 - val_categorical_accuracy: 0.5995\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.61307\n","Epoch 80/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4359 - categorical_accuracy: 1.0000 - val_loss: 1.3831 - val_categorical_accuracy: 0.6028\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.61307\n","Epoch 81/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4270 - categorical_accuracy: 1.0000 - val_loss: 1.3790 - val_categorical_accuracy: 0.6013\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.61307\n","Epoch 82/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4425 - categorical_accuracy: 0.9983 - val_loss: 1.3892 - val_categorical_accuracy: 0.6215\n","\n","Epoch 00082: val_categorical_accuracy improved from 0.61307 to 0.62151, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 83/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4319 - categorical_accuracy: 1.0000 - val_loss: 1.3845 - val_categorical_accuracy: 0.5991\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.62151\n","Epoch 84/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4089 - categorical_accuracy: 0.9963 - val_loss: 1.3853 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.62151\n","Epoch 85/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4372 - categorical_accuracy: 0.9980 - val_loss: 1.3828 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.62151\n","Epoch 86/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4071 - categorical_accuracy: 1.0000 - val_loss: 1.3771 - val_categorical_accuracy: 0.5958\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.62151\n","Epoch 87/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.4136 - categorical_accuracy: 1.0000 - val_loss: 1.3793 - val_categorical_accuracy: 0.5962\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.62151\n","Epoch 88/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.4129 - categorical_accuracy: 0.9978 - val_loss: 1.3715 - val_categorical_accuracy: 0.6017\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.62151\n","Epoch 89/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3803 - categorical_accuracy: 1.0000 - val_loss: 1.3735 - val_categorical_accuracy: 0.5991\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.62151\n","Epoch 90/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3912 - categorical_accuracy: 1.0000 - val_loss: 1.3713 - val_categorical_accuracy: 0.5958\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.62151\n","Epoch 91/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3979 - categorical_accuracy: 0.9943 - val_loss: 1.3700 - val_categorical_accuracy: 0.6035\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.62151\n","Epoch 92/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3749 - categorical_accuracy: 1.0000 - val_loss: 1.3682 - val_categorical_accuracy: 0.6116\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.62151\n","Epoch 93/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3744 - categorical_accuracy: 1.0000 - val_loss: 1.3647 - val_categorical_accuracy: 0.6278\n","\n","Epoch 00093: val_categorical_accuracy improved from 0.62151 to 0.62775, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 94/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3875 - categorical_accuracy: 1.0000 - val_loss: 1.3596 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.62775\n","Epoch 95/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3632 - categorical_accuracy: 1.0000 - val_loss: 1.3700 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.62775\n","Epoch 96/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3760 - categorical_accuracy: 1.0000 - val_loss: 1.3607 - val_categorical_accuracy: 0.6061\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.62775\n","Epoch 97/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3528 - categorical_accuracy: 0.9980 - val_loss: 1.3810 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.62775\n","Epoch 98/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3681 - categorical_accuracy: 1.0000 - val_loss: 1.3583 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.62775\n","Epoch 99/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3662 - categorical_accuracy: 1.0000 - val_loss: 1.3661 - val_categorical_accuracy: 0.6256\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.62775\n","Epoch 100/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3409 - categorical_accuracy: 1.0000 - val_loss: 1.3577 - val_categorical_accuracy: 0.5943\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.62775\n","Epoch 101/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3556 - categorical_accuracy: 1.0000 - val_loss: 1.3665 - val_categorical_accuracy: 0.6197\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.62775\n","Epoch 102/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3426 - categorical_accuracy: 1.0000 - val_loss: 1.3665 - val_categorical_accuracy: 0.6123\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.62775\n","Epoch 103/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3414 - categorical_accuracy: 1.0000 - val_loss: 1.3561 - val_categorical_accuracy: 0.6131\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.62775\n","Epoch 104/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3361 - categorical_accuracy: 1.0000 - val_loss: 1.3635 - val_categorical_accuracy: 0.6116\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.62775\n","Epoch 105/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3487 - categorical_accuracy: 1.0000 - val_loss: 1.3617 - val_categorical_accuracy: 0.6149\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.62775\n","Epoch 106/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3307 - categorical_accuracy: 1.0000 - val_loss: 1.3570 - val_categorical_accuracy: 0.6116\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.62775\n","Epoch 107/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3312 - categorical_accuracy: 1.0000 - val_loss: 1.3569 - val_categorical_accuracy: 0.6087\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.62775\n","Epoch 108/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3202 - categorical_accuracy: 1.0000 - val_loss: 1.3596 - val_categorical_accuracy: 0.6167\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.62775\n","Epoch 109/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3310 - categorical_accuracy: 1.0000 - val_loss: 1.3529 - val_categorical_accuracy: 0.6233\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.62775\n","Epoch 110/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3181 - categorical_accuracy: 1.0000 - val_loss: 1.3620 - val_categorical_accuracy: 0.6204\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.62775\n","Epoch 111/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3218 - categorical_accuracy: 1.0000 - val_loss: 1.3515 - val_categorical_accuracy: 0.6200\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.62775\n","Epoch 112/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3223 - categorical_accuracy: 1.0000 - val_loss: 1.3554 - val_categorical_accuracy: 0.6116\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.62775\n","Epoch 113/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3117 - categorical_accuracy: 1.0000 - val_loss: 1.3442 - val_categorical_accuracy: 0.6186\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.62775\n","Epoch 114/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3132 - categorical_accuracy: 1.0000 - val_loss: 1.3556 - val_categorical_accuracy: 0.6061\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.62775\n","Epoch 115/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.3033 - categorical_accuracy: 1.0000 - val_loss: 1.3449 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.62775\n","Epoch 116/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3074 - categorical_accuracy: 1.0000 - val_loss: 1.3445 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.62775\n","Epoch 117/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2955 - categorical_accuracy: 1.0000 - val_loss: 1.3521 - val_categorical_accuracy: 0.6322\n","\n","Epoch 00117: val_categorical_accuracy improved from 0.62775 to 0.63216, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_30_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 118/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2971 - categorical_accuracy: 0.9998 - val_loss: 1.3493 - val_categorical_accuracy: 0.6116\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.63216\n","Epoch 119/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2894 - categorical_accuracy: 0.9894 - val_loss: 1.3514 - val_categorical_accuracy: 0.6237\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.63216\n","Epoch 120/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.3002 - categorical_accuracy: 1.0000 - val_loss: 1.3502 - val_categorical_accuracy: 0.6131\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.63216\n","Epoch 121/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2924 - categorical_accuracy: 1.0000 - val_loss: 1.3439 - val_categorical_accuracy: 0.6208\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.63216\n","Epoch 122/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2951 - categorical_accuracy: 1.0000 - val_loss: 1.3535 - val_categorical_accuracy: 0.6233\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.63216\n","Epoch 123/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2823 - categorical_accuracy: 1.0000 - val_loss: 1.3476 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.63216\n","Epoch 124/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2762 - categorical_accuracy: 1.0000 - val_loss: 1.3338 - val_categorical_accuracy: 0.6211\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.63216\n","Epoch 125/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2732 - categorical_accuracy: 1.0000 - val_loss: 1.3529 - val_categorical_accuracy: 0.6175\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.63216\n","Epoch 126/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2818 - categorical_accuracy: 0.9958 - val_loss: 1.3454 - val_categorical_accuracy: 0.6215\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.63216\n","Epoch 127/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2729 - categorical_accuracy: 1.0000 - val_loss: 1.3388 - val_categorical_accuracy: 0.6222\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.63216\n","Epoch 128/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2763 - categorical_accuracy: 1.0000 - val_loss: 1.3410 - val_categorical_accuracy: 0.6237\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.63216\n","Epoch 129/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2553 - categorical_accuracy: 1.0000 - val_loss: 1.3550 - val_categorical_accuracy: 0.6145\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.63216\n","Epoch 130/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2731 - categorical_accuracy: 1.0000 - val_loss: 1.3448 - val_categorical_accuracy: 0.6164\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.63216\n","Epoch 131/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2623 - categorical_accuracy: 1.0000 - val_loss: 1.3470 - val_categorical_accuracy: 0.6156\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.63216\n","Epoch 132/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2629 - categorical_accuracy: 1.0000 - val_loss: 1.3418 - val_categorical_accuracy: 0.6281\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.63216\n","Epoch 133/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2685 - categorical_accuracy: 1.0000 - val_loss: 1.3367 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.63216\n","Epoch 134/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2552 - categorical_accuracy: 1.0000 - val_loss: 1.3496 - val_categorical_accuracy: 0.6230\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.63216\n","Epoch 135/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2402 - categorical_accuracy: 1.0000 - val_loss: 1.3385 - val_categorical_accuracy: 0.6292\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.63216\n","Epoch 136/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2339 - categorical_accuracy: 1.0000 - val_loss: 1.3380 - val_categorical_accuracy: 0.6226\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.63216\n","Epoch 137/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2691 - categorical_accuracy: 1.0000 - val_loss: 1.3395 - val_categorical_accuracy: 0.6296\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.63216\n","Epoch 138/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2608 - categorical_accuracy: 1.0000 - val_loss: 1.3341 - val_categorical_accuracy: 0.6233\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.63216\n","Epoch 139/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2506 - categorical_accuracy: 1.0000 - val_loss: 1.3405 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.63216\n","Epoch 140/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2368 - categorical_accuracy: 1.0000 - val_loss: 1.3372 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.63216\n","Epoch 141/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2335 - categorical_accuracy: 1.0000 - val_loss: 1.3427 - val_categorical_accuracy: 0.6267\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.63216\n","Epoch 142/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2324 - categorical_accuracy: 1.0000 - val_loss: 1.3362 - val_categorical_accuracy: 0.6263\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.63216\n","Epoch 143/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2469 - categorical_accuracy: 1.0000 - val_loss: 1.3419 - val_categorical_accuracy: 0.6285\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.63216\n","Epoch 144/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2302 - categorical_accuracy: 1.0000 - val_loss: 1.3304 - val_categorical_accuracy: 0.6208\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.63216\n","Epoch 145/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2382 - categorical_accuracy: 1.0000 - val_loss: 1.3374 - val_categorical_accuracy: 0.6270\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.63216\n","Epoch 146/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2298 - categorical_accuracy: 1.0000 - val_loss: 1.3412 - val_categorical_accuracy: 0.6237\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.63216\n","Epoch 147/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2203 - categorical_accuracy: 1.0000 - val_loss: 1.3268 - val_categorical_accuracy: 0.6197\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.63216\n","Epoch 148/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2450 - categorical_accuracy: 1.0000 - val_loss: 1.3359 - val_categorical_accuracy: 0.6311\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.63216\n","Epoch 149/150\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2152 - categorical_accuracy: 1.0000 - val_loss: 1.3406 - val_categorical_accuracy: 0.6303\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.63216\n","Epoch 150/150\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2290 - categorical_accuracy: 1.0000 - val_loss: 1.3405 - val_categorical_accuracy: 0.6289\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.63216\n","86/86 [==============================] - 1s 2ms/step - loss: 1.3521 - categorical_accuracy: 0.6322\n","86/86 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 45 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 630.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [45 45 45 45 45 45 45 45 45 45 45 45 45 45]\n","\n","Total number of samples in test set 2514.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [225  56 206 170 224 224 214 158 269 203 231  88 196  50]\n","\n","X_train_transfer => (630, 256)\n","X_test_transfer  => (2514, 256)\n","y_train => (630, 14)\n","y_test  => (2514, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","32/32 [==============================] - 1s 13ms/step - loss: 4.6367 - categorical_accuracy: 0.1178 - val_loss: 2.7034 - val_categorical_accuracy: 0.1229\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.12291, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","32/32 [==============================] - 0s 9ms/step - loss: 2.2681 - categorical_accuracy: 0.2489 - val_loss: 2.4264 - val_categorical_accuracy: 0.1460\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.12291 to 0.14598, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","32/32 [==============================] - 0s 9ms/step - loss: 2.0211 - categorical_accuracy: 0.3214 - val_loss: 2.2457 - val_categorical_accuracy: 0.1937\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.14598 to 0.19372, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.8272 - categorical_accuracy: 0.4452 - val_loss: 2.2148 - val_categorical_accuracy: 0.2212\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.19372 to 0.22116, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.7074 - categorical_accuracy: 0.4152 - val_loss: 2.0980 - val_categorical_accuracy: 0.3126\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.22116 to 0.31265, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.6732 - categorical_accuracy: 0.5005 - val_loss: 2.0486 - val_categorical_accuracy: 0.3258\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.31265 to 0.32578, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.5991 - categorical_accuracy: 0.5710 - val_loss: 2.0221 - val_categorical_accuracy: 0.2796\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.32578\n","Epoch 8/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.4398 - categorical_accuracy: 0.6750 - val_loss: 1.9165 - val_categorical_accuracy: 0.3695\n","\n","Epoch 00008: val_categorical_accuracy improved from 0.32578 to 0.36953, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 9/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.4464 - categorical_accuracy: 0.5838 - val_loss: 1.9039 - val_categorical_accuracy: 0.3413\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.36953\n","Epoch 10/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3503 - categorical_accuracy: 0.7098 - val_loss: 1.8285 - val_categorical_accuracy: 0.4415\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.36953 to 0.44153, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2935 - categorical_accuracy: 0.7090 - val_loss: 1.8298 - val_categorical_accuracy: 0.4049\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.44153\n","Epoch 12/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.2723 - categorical_accuracy: 0.6963 - val_loss: 1.8212 - val_categorical_accuracy: 0.4304\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.44153\n","Epoch 13/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1898 - categorical_accuracy: 0.7607 - val_loss: 1.7510 - val_categorical_accuracy: 0.5060\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.44153 to 0.50597, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1708 - categorical_accuracy: 0.8200 - val_loss: 1.7321 - val_categorical_accuracy: 0.4698\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.50597\n","Epoch 15/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.1207 - categorical_accuracy: 0.8873 - val_loss: 1.7532 - val_categorical_accuracy: 0.4686\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.50597\n","Epoch 16/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0616 - categorical_accuracy: 0.8542 - val_loss: 1.6975 - val_categorical_accuracy: 0.4375\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.50597\n","Epoch 17/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0482 - categorical_accuracy: 0.8553 - val_loss: 1.6742 - val_categorical_accuracy: 0.5390\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.50597 to 0.53898, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 18/150\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0262 - categorical_accuracy: 0.8794 - val_loss: 1.6907 - val_categorical_accuracy: 0.5056\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.53898\n","Epoch 19/150\n","32/32 [==============================] - 0s 10ms/step - loss: 1.0155 - categorical_accuracy: 0.8888 - val_loss: 1.6705 - val_categorical_accuracy: 0.4745\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.53898\n","Epoch 20/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9522 - categorical_accuracy: 0.9134 - val_loss: 1.6444 - val_categorical_accuracy: 0.4881\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.53898\n","Epoch 21/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.9223 - categorical_accuracy: 0.8865 - val_loss: 1.6230 - val_categorical_accuracy: 0.5020\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.53898\n","Epoch 22/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9059 - categorical_accuracy: 0.8997 - val_loss: 1.6193 - val_categorical_accuracy: 0.4853\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.53898\n","Epoch 23/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8973 - categorical_accuracy: 0.8658 - val_loss: 1.6016 - val_categorical_accuracy: 0.5644\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.53898 to 0.56444, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 24/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8481 - categorical_accuracy: 0.9402 - val_loss: 1.6151 - val_categorical_accuracy: 0.4610\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.56444\n","Epoch 25/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8625 - categorical_accuracy: 0.9461 - val_loss: 1.5690 - val_categorical_accuracy: 0.5501\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.56444\n","Epoch 26/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8070 - categorical_accuracy: 0.9585 - val_loss: 1.5980 - val_categorical_accuracy: 0.5267\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.56444\n","Epoch 27/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7714 - categorical_accuracy: 0.9252 - val_loss: 1.5684 - val_categorical_accuracy: 0.5127\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.56444\n","Epoch 28/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7625 - categorical_accuracy: 0.9774 - val_loss: 1.5422 - val_categorical_accuracy: 0.5617\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.56444\n","Epoch 29/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7689 - categorical_accuracy: 0.9473 - val_loss: 1.5484 - val_categorical_accuracy: 0.4924\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.56444\n","Epoch 30/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7390 - categorical_accuracy: 0.9565 - val_loss: 1.5403 - val_categorical_accuracy: 0.5485\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.56444\n","Epoch 31/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7143 - categorical_accuracy: 0.9716 - val_loss: 1.4977 - val_categorical_accuracy: 0.5800\n","\n","Epoch 00031: val_categorical_accuracy improved from 0.56444 to 0.57995, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 32/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6980 - categorical_accuracy: 0.9767 - val_loss: 1.5084 - val_categorical_accuracy: 0.5446\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.57995\n","Epoch 33/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7005 - categorical_accuracy: 0.9788 - val_loss: 1.5188 - val_categorical_accuracy: 0.5688\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.57995\n","Epoch 34/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6775 - categorical_accuracy: 0.9512 - val_loss: 1.4982 - val_categorical_accuracy: 0.5696\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.57995\n","Epoch 35/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6434 - categorical_accuracy: 0.9797 - val_loss: 1.4791 - val_categorical_accuracy: 0.5724\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.57995\n","Epoch 36/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.6568 - categorical_accuracy: 0.9751 - val_loss: 1.4733 - val_categorical_accuracy: 0.5529\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.57995\n","Epoch 37/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6486 - categorical_accuracy: 0.9856 - val_loss: 1.4839 - val_categorical_accuracy: 0.5644\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.57995\n","Epoch 38/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.6346 - categorical_accuracy: 0.9904 - val_loss: 1.4687 - val_categorical_accuracy: 0.5986\n","\n","Epoch 00038: val_categorical_accuracy improved from 0.57995 to 0.59865, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 39/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5719 - categorical_accuracy: 0.9962 - val_loss: 1.4527 - val_categorical_accuracy: 0.6018\n","\n","Epoch 00039: val_categorical_accuracy improved from 0.59865 to 0.60183, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 40/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5893 - categorical_accuracy: 0.9994 - val_loss: 1.4616 - val_categorical_accuracy: 0.5581\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.60183\n","Epoch 41/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5799 - categorical_accuracy: 0.9874 - val_loss: 1.4459 - val_categorical_accuracy: 0.5807\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.60183\n","Epoch 42/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5627 - categorical_accuracy: 0.9943 - val_loss: 1.4622 - val_categorical_accuracy: 0.5489\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.60183\n","Epoch 43/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5657 - categorical_accuracy: 0.9961 - val_loss: 1.4686 - val_categorical_accuracy: 0.6082\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.60183 to 0.60819, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5527 - categorical_accuracy: 0.9944 - val_loss: 1.4399 - val_categorical_accuracy: 0.5760\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.60819\n","Epoch 45/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5401 - categorical_accuracy: 0.9901 - val_loss: 1.4538 - val_categorical_accuracy: 0.5692\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.60819\n","Epoch 46/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5399 - categorical_accuracy: 0.9863 - val_loss: 1.4532 - val_categorical_accuracy: 0.5847\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.60819\n","Epoch 47/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5304 - categorical_accuracy: 0.9853 - val_loss: 1.4443 - val_categorical_accuracy: 0.5680\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.60819\n","Epoch 48/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5252 - categorical_accuracy: 0.9937 - val_loss: 1.4256 - val_categorical_accuracy: 0.5998\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.60819\n","Epoch 49/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4975 - categorical_accuracy: 0.9972 - val_loss: 1.4390 - val_categorical_accuracy: 0.5310\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.60819\n","Epoch 50/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.4800 - categorical_accuracy: 0.9818 - val_loss: 1.4341 - val_categorical_accuracy: 0.5720\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.60819\n","Epoch 51/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.4865 - categorical_accuracy: 0.9860 - val_loss: 1.4181 - val_categorical_accuracy: 0.5871\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.60819\n","Epoch 52/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4674 - categorical_accuracy: 0.9949 - val_loss: 1.4211 - val_categorical_accuracy: 0.5700\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.60819\n","Epoch 53/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4657 - categorical_accuracy: 0.9924 - val_loss: 1.4091 - val_categorical_accuracy: 0.5656\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.60819\n","Epoch 54/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4623 - categorical_accuracy: 0.9984 - val_loss: 1.3994 - val_categorical_accuracy: 0.5990\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.60819\n","Epoch 55/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4488 - categorical_accuracy: 0.9906 - val_loss: 1.4170 - val_categorical_accuracy: 0.5748\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.60819\n","Epoch 56/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4333 - categorical_accuracy: 0.9979 - val_loss: 1.4047 - val_categorical_accuracy: 0.5979\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.60819\n","Epoch 57/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4490 - categorical_accuracy: 0.9891 - val_loss: 1.4064 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.60819\n","Epoch 58/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3941 - categorical_accuracy: 0.9984 - val_loss: 1.4007 - val_categorical_accuracy: 0.5843\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.60819\n","Epoch 59/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4162 - categorical_accuracy: 0.9963 - val_loss: 1.3984 - val_categorical_accuracy: 0.5796\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.60819\n","Epoch 60/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4073 - categorical_accuracy: 0.9952 - val_loss: 1.3930 - val_categorical_accuracy: 0.5871\n","\n","Epoch 00060: val_categorical_accuracy did not improve from 0.60819\n","Epoch 61/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3959 - categorical_accuracy: 0.9919 - val_loss: 1.3886 - val_categorical_accuracy: 0.5784\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.60819\n","Epoch 62/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3880 - categorical_accuracy: 0.9942 - val_loss: 1.3685 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.60819\n","Epoch 63/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3898 - categorical_accuracy: 0.9980 - val_loss: 1.3828 - val_categorical_accuracy: 0.5931\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.60819\n","Epoch 64/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.4016 - categorical_accuracy: 0.9958 - val_loss: 1.3843 - val_categorical_accuracy: 0.5660\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.60819\n","Epoch 65/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3811 - categorical_accuracy: 0.9990 - val_loss: 1.3807 - val_categorical_accuracy: 0.5748\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.60819\n","Epoch 66/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3735 - categorical_accuracy: 0.9977 - val_loss: 1.3675 - val_categorical_accuracy: 0.5871\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.60819\n","Epoch 67/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3615 - categorical_accuracy: 0.9949 - val_loss: 1.3939 - val_categorical_accuracy: 0.5883\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.60819\n","Epoch 68/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3661 - categorical_accuracy: 0.9946 - val_loss: 1.3728 - val_categorical_accuracy: 0.6058\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.60819\n","Epoch 69/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3589 - categorical_accuracy: 0.9935 - val_loss: 1.3632 - val_categorical_accuracy: 0.5994\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.60819\n","Epoch 70/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3575 - categorical_accuracy: 0.9982 - val_loss: 1.3599 - val_categorical_accuracy: 0.5831\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.60819\n","Epoch 71/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3429 - categorical_accuracy: 0.9977 - val_loss: 1.3489 - val_categorical_accuracy: 0.6026\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.60819\n","Epoch 72/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3324 - categorical_accuracy: 0.9947 - val_loss: 1.3931 - val_categorical_accuracy: 0.6002\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.60819\n","Epoch 73/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3439 - categorical_accuracy: 0.9947 - val_loss: 1.3690 - val_categorical_accuracy: 0.5788\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.60819\n","Epoch 74/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3298 - categorical_accuracy: 0.9960 - val_loss: 1.3646 - val_categorical_accuracy: 0.5939\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.60819\n","Epoch 75/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3277 - categorical_accuracy: 0.9977 - val_loss: 1.3797 - val_categorical_accuracy: 0.6010\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.60819\n","Epoch 76/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3299 - categorical_accuracy: 0.9950 - val_loss: 1.3755 - val_categorical_accuracy: 0.6161\n","\n","Epoch 00076: val_categorical_accuracy improved from 0.60819 to 0.61615, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 77/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3068 - categorical_accuracy: 0.9941 - val_loss: 1.3601 - val_categorical_accuracy: 0.5895\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.61615\n","Epoch 78/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3161 - categorical_accuracy: 0.9936 - val_loss: 1.3414 - val_categorical_accuracy: 0.5963\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.61615\n","Epoch 79/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3007 - categorical_accuracy: 0.9983 - val_loss: 1.3529 - val_categorical_accuracy: 0.5899\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.61615\n","Epoch 80/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3138 - categorical_accuracy: 0.9982 - val_loss: 1.3524 - val_categorical_accuracy: 0.5943\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.61615\n","Epoch 81/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2896 - categorical_accuracy: 0.9986 - val_loss: 1.3456 - val_categorical_accuracy: 0.6225\n","\n","Epoch 00081: val_categorical_accuracy improved from 0.61615 to 0.62251, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 82/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3009 - categorical_accuracy: 0.9976 - val_loss: 1.3610 - val_categorical_accuracy: 0.5815\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.62251\n","Epoch 83/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2996 - categorical_accuracy: 0.9988 - val_loss: 1.3407 - val_categorical_accuracy: 0.5963\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.62251\n","Epoch 84/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2867 - categorical_accuracy: 0.9971 - val_loss: 1.3550 - val_categorical_accuracy: 0.5939\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.62251\n","Epoch 85/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2885 - categorical_accuracy: 0.9958 - val_loss: 1.3584 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.62251\n","Epoch 86/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2883 - categorical_accuracy: 0.9994 - val_loss: 1.3495 - val_categorical_accuracy: 0.5947\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.62251\n","Epoch 87/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2726 - categorical_accuracy: 0.9982 - val_loss: 1.3539 - val_categorical_accuracy: 0.5903\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.62251\n","Epoch 88/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2690 - categorical_accuracy: 0.9977 - val_loss: 1.3421 - val_categorical_accuracy: 0.6082\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.62251\n","Epoch 89/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2750 - categorical_accuracy: 0.9959 - val_loss: 1.3418 - val_categorical_accuracy: 0.5967\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.62251\n","Epoch 90/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2803 - categorical_accuracy: 0.9965 - val_loss: 1.3456 - val_categorical_accuracy: 0.5879\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.62251\n","Epoch 91/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2602 - categorical_accuracy: 0.9958 - val_loss: 1.3478 - val_categorical_accuracy: 0.6030\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.62251\n","Epoch 92/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2588 - categorical_accuracy: 0.9966 - val_loss: 1.3548 - val_categorical_accuracy: 0.6014\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.62251\n","Epoch 93/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2650 - categorical_accuracy: 0.9913 - val_loss: 1.3439 - val_categorical_accuracy: 0.5994\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.62251\n","Epoch 94/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2531 - categorical_accuracy: 0.9961 - val_loss: 1.3443 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.62251\n","Epoch 95/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2562 - categorical_accuracy: 0.9977 - val_loss: 1.3304 - val_categorical_accuracy: 0.6022\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.62251\n","Epoch 96/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2526 - categorical_accuracy: 0.9950 - val_loss: 1.3400 - val_categorical_accuracy: 0.5883\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.62251\n","Epoch 97/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2471 - categorical_accuracy: 0.9996 - val_loss: 1.3295 - val_categorical_accuracy: 0.6010\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.62251\n","Epoch 98/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2503 - categorical_accuracy: 0.9948 - val_loss: 1.3227 - val_categorical_accuracy: 0.6201\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.62251\n","Epoch 99/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2276 - categorical_accuracy: 0.9984 - val_loss: 1.3501 - val_categorical_accuracy: 0.5931\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.62251\n","Epoch 100/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2383 - categorical_accuracy: 0.9955 - val_loss: 1.3347 - val_categorical_accuracy: 0.5971\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.62251\n","Epoch 101/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2349 - categorical_accuracy: 0.9988 - val_loss: 1.3325 - val_categorical_accuracy: 0.6086\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.62251\n","Epoch 102/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2249 - categorical_accuracy: 0.9978 - val_loss: 1.3308 - val_categorical_accuracy: 0.5982\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.62251\n","Epoch 103/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2277 - categorical_accuracy: 0.9997 - val_loss: 1.3425 - val_categorical_accuracy: 0.6018\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.62251\n","Epoch 104/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2332 - categorical_accuracy: 0.9970 - val_loss: 1.3304 - val_categorical_accuracy: 0.6078\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.62251\n","Epoch 105/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2243 - categorical_accuracy: 0.9930 - val_loss: 1.3302 - val_categorical_accuracy: 0.6042\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.62251\n","Epoch 106/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2194 - categorical_accuracy: 0.9971 - val_loss: 1.3317 - val_categorical_accuracy: 0.6054\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.62251\n","Epoch 107/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2215 - categorical_accuracy: 0.9917 - val_loss: 1.3269 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.62251\n","Epoch 108/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2171 - categorical_accuracy: 0.9934 - val_loss: 1.3231 - val_categorical_accuracy: 0.6026\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.62251\n","Epoch 109/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1960 - categorical_accuracy: 0.9996 - val_loss: 1.3278 - val_categorical_accuracy: 0.6181\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.62251\n","Epoch 110/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2293 - categorical_accuracy: 0.9928 - val_loss: 1.3391 - val_categorical_accuracy: 0.6090\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.62251\n","Epoch 111/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2082 - categorical_accuracy: 0.9982 - val_loss: 1.3183 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.62251\n","Epoch 112/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2023 - categorical_accuracy: 0.9988 - val_loss: 1.3327 - val_categorical_accuracy: 0.6205\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.62251\n","Epoch 113/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2075 - categorical_accuracy: 0.9993 - val_loss: 1.3172 - val_categorical_accuracy: 0.6161\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.62251\n","Epoch 114/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2009 - categorical_accuracy: 0.9964 - val_loss: 1.3366 - val_categorical_accuracy: 0.6090\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.62251\n","Epoch 115/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2065 - categorical_accuracy: 0.9948 - val_loss: 1.3369 - val_categorical_accuracy: 0.6118\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.62251\n","Epoch 116/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1965 - categorical_accuracy: 0.9966 - val_loss: 1.3397 - val_categorical_accuracy: 0.6130\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.62251\n","Epoch 117/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1877 - categorical_accuracy: 0.9991 - val_loss: 1.3458 - val_categorical_accuracy: 0.6082\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.62251\n","Epoch 118/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1961 - categorical_accuracy: 0.9976 - val_loss: 1.3220 - val_categorical_accuracy: 0.6078\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.62251\n","Epoch 119/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2039 - categorical_accuracy: 0.9990 - val_loss: 1.3275 - val_categorical_accuracy: 0.5986\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.62251\n","Epoch 120/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1989 - categorical_accuracy: 0.9999 - val_loss: 1.3326 - val_categorical_accuracy: 0.6213\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.62251\n","Epoch 121/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1820 - categorical_accuracy: 0.9977 - val_loss: 1.3282 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.62251\n","Epoch 122/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1965 - categorical_accuracy: 0.9961 - val_loss: 1.3239 - val_categorical_accuracy: 0.6169\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.62251\n","Epoch 123/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1831 - categorical_accuracy: 0.9995 - val_loss: 1.3159 - val_categorical_accuracy: 0.6161\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.62251\n","Epoch 124/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1844 - categorical_accuracy: 0.9975 - val_loss: 1.3252 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.62251\n","Epoch 125/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1920 - categorical_accuracy: 0.9937 - val_loss: 1.3394 - val_categorical_accuracy: 0.6122\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.62251\n","Epoch 126/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1809 - categorical_accuracy: 0.9999 - val_loss: 1.3257 - val_categorical_accuracy: 0.6173\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.62251\n","Epoch 127/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1720 - categorical_accuracy: 0.9996 - val_loss: 1.3228 - val_categorical_accuracy: 0.6122\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.62251\n","Epoch 128/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1738 - categorical_accuracy: 0.9981 - val_loss: 1.3301 - val_categorical_accuracy: 0.6018\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.62251\n","Epoch 129/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1716 - categorical_accuracy: 0.9986 - val_loss: 1.3237 - val_categorical_accuracy: 0.6221\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.62251\n","Epoch 130/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1747 - categorical_accuracy: 0.9987 - val_loss: 1.3314 - val_categorical_accuracy: 0.6169\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.62251\n","Epoch 131/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1678 - categorical_accuracy: 0.9982 - val_loss: 1.3202 - val_categorical_accuracy: 0.6197\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.62251\n","Epoch 132/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1732 - categorical_accuracy: 0.9990 - val_loss: 1.3217 - val_categorical_accuracy: 0.6058\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.62251\n","Epoch 133/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1720 - categorical_accuracy: 1.0000 - val_loss: 1.3137 - val_categorical_accuracy: 0.6114\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.62251\n","Epoch 134/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1742 - categorical_accuracy: 0.9975 - val_loss: 1.3222 - val_categorical_accuracy: 0.6173\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.62251\n","Epoch 135/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1678 - categorical_accuracy: 0.9996 - val_loss: 1.3205 - val_categorical_accuracy: 0.6205\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.62251\n","Epoch 136/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1683 - categorical_accuracy: 0.9973 - val_loss: 1.3328 - val_categorical_accuracy: 0.6249\n","\n","Epoch 00136: val_categorical_accuracy improved from 0.62251 to 0.62490, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 137/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1611 - categorical_accuracy: 0.9990 - val_loss: 1.3220 - val_categorical_accuracy: 0.6261\n","\n","Epoch 00137: val_categorical_accuracy improved from 0.62490 to 0.62609, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 138/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1694 - categorical_accuracy: 1.0000 - val_loss: 1.3180 - val_categorical_accuracy: 0.6185\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.62609\n","Epoch 139/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1572 - categorical_accuracy: 0.9961 - val_loss: 1.3220 - val_categorical_accuracy: 0.6118\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.62609\n","Epoch 140/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1583 - categorical_accuracy: 0.9983 - val_loss: 1.3176 - val_categorical_accuracy: 0.6142\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.62609\n","Epoch 141/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1668 - categorical_accuracy: 0.9993 - val_loss: 1.3207 - val_categorical_accuracy: 0.6360\n","\n","Epoch 00141: val_categorical_accuracy improved from 0.62609 to 0.63604, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_45_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 142/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1528 - categorical_accuracy: 0.9995 - val_loss: 1.3191 - val_categorical_accuracy: 0.6161\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.63604\n","Epoch 143/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1465 - categorical_accuracy: 1.0000 - val_loss: 1.3170 - val_categorical_accuracy: 0.6066\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.63604\n","Epoch 144/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1581 - categorical_accuracy: 0.9997 - val_loss: 1.3407 - val_categorical_accuracy: 0.6154\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.63604\n","Epoch 145/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1594 - categorical_accuracy: 0.9966 - val_loss: 1.3244 - val_categorical_accuracy: 0.6122\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.63604\n","Epoch 146/150\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1406 - categorical_accuracy: 0.9981 - val_loss: 1.3187 - val_categorical_accuracy: 0.6297\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.63604\n","Epoch 147/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1562 - categorical_accuracy: 0.9977 - val_loss: 1.3261 - val_categorical_accuracy: 0.6257\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.63604\n","Epoch 148/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1495 - categorical_accuracy: 1.0000 - val_loss: 1.3138 - val_categorical_accuracy: 0.6197\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.63604\n","Epoch 149/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1549 - categorical_accuracy: 1.0000 - val_loss: 1.3223 - val_categorical_accuracy: 0.6257\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.63604\n","Epoch 150/150\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1554 - categorical_accuracy: 0.9938 - val_loss: 1.3136 - val_categorical_accuracy: 0.6134\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.63604\n","79/79 [==============================] - 0s 2ms/step - loss: 1.3207 - categorical_accuracy: 0.6360\n","79/79 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 60 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 840.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [60 60 60 60 60 60 60 60 60 60 60 60 60 60]\n","\n","Total number of samples in test set 2304.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [210  41 191 155 209 209 199 143 254 188 216  73 181  35]\n","\n","X_train_transfer => (840, 256)\n","X_test_transfer  => (2304, 256)\n","y_train => (840, 14)\n","y_test  => (2304, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","42/42 [==============================] - 1s 10ms/step - loss: 4.2860 - categorical_accuracy: 0.1270 - val_loss: 2.5773 - val_categorical_accuracy: 0.1185\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.11849, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","42/42 [==============================] - 0s 7ms/step - loss: 2.1858 - categorical_accuracy: 0.2729 - val_loss: 2.3007 - val_categorical_accuracy: 0.2070\n","\n","Epoch 00002: val_categorical_accuracy improved from 0.11849 to 0.20703, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 3/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.9391 - categorical_accuracy: 0.3637 - val_loss: 2.1390 - val_categorical_accuracy: 0.2964\n","\n","Epoch 00003: val_categorical_accuracy improved from 0.20703 to 0.29644, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 4/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.7482 - categorical_accuracy: 0.4790 - val_loss: 2.0644 - val_categorical_accuracy: 0.2565\n","\n","Epoch 00004: val_categorical_accuracy did not improve from 0.29644\n","Epoch 5/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.6375 - categorical_accuracy: 0.5358 - val_loss: 1.9839 - val_categorical_accuracy: 0.4041\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.29644 to 0.40408, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.5441 - categorical_accuracy: 0.6048 - val_loss: 1.9020 - val_categorical_accuracy: 0.3963\n","\n","Epoch 00006: val_categorical_accuracy did not improve from 0.40408\n","Epoch 7/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.4467 - categorical_accuracy: 0.6514 - val_loss: 1.9075 - val_categorical_accuracy: 0.3581\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.40408\n","Epoch 8/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.3748 - categorical_accuracy: 0.7091 - val_loss: 1.8509 - val_categorical_accuracy: 0.3641\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.40408\n","Epoch 9/150\n","42/42 [==============================] - 0s 8ms/step - loss: 1.3191 - categorical_accuracy: 0.7488 - val_loss: 1.8146 - val_categorical_accuracy: 0.4284\n","\n","Epoch 00009: val_categorical_accuracy improved from 0.40408 to 0.42839, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 10/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.2405 - categorical_accuracy: 0.7803 - val_loss: 1.7520 - val_categorical_accuracy: 0.4844\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.42839 to 0.48438, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1930 - categorical_accuracy: 0.7962 - val_loss: 1.7393 - val_categorical_accuracy: 0.4536\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.48438\n","Epoch 12/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.1725 - categorical_accuracy: 0.7702 - val_loss: 1.7159 - val_categorical_accuracy: 0.4688\n","\n","Epoch 00012: val_categorical_accuracy did not improve from 0.48438\n","Epoch 13/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0887 - categorical_accuracy: 0.8647 - val_loss: 1.6740 - val_categorical_accuracy: 0.4709\n","\n","Epoch 00013: val_categorical_accuracy did not improve from 0.48438\n","Epoch 14/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0430 - categorical_accuracy: 0.8037 - val_loss: 1.6878 - val_categorical_accuracy: 0.5234\n","\n","Epoch 00014: val_categorical_accuracy improved from 0.48438 to 0.52344, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 15/150\n","42/42 [==============================] - 0s 7ms/step - loss: 1.0671 - categorical_accuracy: 0.8311 - val_loss: 1.6597 - val_categorical_accuracy: 0.4583\n","\n","Epoch 00015: val_categorical_accuracy did not improve from 0.52344\n","Epoch 16/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9505 - categorical_accuracy: 0.9105 - val_loss: 1.6120 - val_categorical_accuracy: 0.5234\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.52344\n","Epoch 17/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.9466 - categorical_accuracy: 0.9094 - val_loss: 1.6445 - val_categorical_accuracy: 0.4492\n","\n","Epoch 00017: val_categorical_accuracy did not improve from 0.52344\n","Epoch 18/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.9332 - categorical_accuracy: 0.8936 - val_loss: 1.6365 - val_categorical_accuracy: 0.4271\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.52344\n","Epoch 19/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8942 - categorical_accuracy: 0.8841 - val_loss: 1.5844 - val_categorical_accuracy: 0.4809\n","\n","Epoch 00019: val_categorical_accuracy did not improve from 0.52344\n","Epoch 20/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8736 - categorical_accuracy: 0.9114 - val_loss: 1.5699 - val_categorical_accuracy: 0.5256\n","\n","Epoch 00020: val_categorical_accuracy improved from 0.52344 to 0.52561, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 21/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.8550 - categorical_accuracy: 0.9123 - val_loss: 1.5596 - val_categorical_accuracy: 0.5204\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.52561\n","Epoch 22/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.7922 - categorical_accuracy: 0.9423 - val_loss: 1.5210 - val_categorical_accuracy: 0.5399\n","\n","Epoch 00022: val_categorical_accuracy improved from 0.52561 to 0.53993, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 23/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7682 - categorical_accuracy: 0.9350 - val_loss: 1.5160 - val_categorical_accuracy: 0.4991\n","\n","Epoch 00023: val_categorical_accuracy did not improve from 0.53993\n","Epoch 24/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7434 - categorical_accuracy: 0.9606 - val_loss: 1.5373 - val_categorical_accuracy: 0.5482\n","\n","Epoch 00024: val_categorical_accuracy improved from 0.53993 to 0.54818, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 25/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7262 - categorical_accuracy: 0.9501 - val_loss: 1.4956 - val_categorical_accuracy: 0.5139\n","\n","Epoch 00025: val_categorical_accuracy did not improve from 0.54818\n","Epoch 26/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7251 - categorical_accuracy: 0.9685 - val_loss: 1.4775 - val_categorical_accuracy: 0.5417\n","\n","Epoch 00026: val_categorical_accuracy did not improve from 0.54818\n","Epoch 27/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.7079 - categorical_accuracy: 0.9459 - val_loss: 1.4626 - val_categorical_accuracy: 0.5538\n","\n","Epoch 00027: val_categorical_accuracy improved from 0.54818 to 0.55382, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 28/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6776 - categorical_accuracy: 0.9715 - val_loss: 1.4634 - val_categorical_accuracy: 0.5608\n","\n","Epoch 00028: val_categorical_accuracy improved from 0.55382 to 0.56076, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 29/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6560 - categorical_accuracy: 0.9784 - val_loss: 1.4512 - val_categorical_accuracy: 0.5590\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.56076\n","Epoch 30/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6475 - categorical_accuracy: 0.9886 - val_loss: 1.4655 - val_categorical_accuracy: 0.5391\n","\n","Epoch 00030: val_categorical_accuracy did not improve from 0.56076\n","Epoch 31/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6371 - categorical_accuracy: 0.9788 - val_loss: 1.4784 - val_categorical_accuracy: 0.5469\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.56076\n","Epoch 32/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.6066 - categorical_accuracy: 0.9881 - val_loss: 1.4198 - val_categorical_accuracy: 0.5629\n","\n","Epoch 00032: val_categorical_accuracy improved from 0.56076 to 0.56293, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 33/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5940 - categorical_accuracy: 0.9951 - val_loss: 1.4120 - val_categorical_accuracy: 0.5712\n","\n","Epoch 00033: val_categorical_accuracy improved from 0.56293 to 0.57118, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 34/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5779 - categorical_accuracy: 0.9823 - val_loss: 1.4029 - val_categorical_accuracy: 0.5464\n","\n","Epoch 00034: val_categorical_accuracy did not improve from 0.57118\n","Epoch 35/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5643 - categorical_accuracy: 0.9868 - val_loss: 1.4456 - val_categorical_accuracy: 0.5260\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.57118\n","Epoch 36/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5532 - categorical_accuracy: 0.9813 - val_loss: 1.3940 - val_categorical_accuracy: 0.5490\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.57118\n","Epoch 37/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.5367 - categorical_accuracy: 0.9930 - val_loss: 1.3783 - val_categorical_accuracy: 0.5833\n","\n","Epoch 00037: val_categorical_accuracy improved from 0.57118 to 0.58333, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 38/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5286 - categorical_accuracy: 0.9949 - val_loss: 1.4286 - val_categorical_accuracy: 0.5404\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.58333\n","Epoch 39/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5141 - categorical_accuracy: 0.9897 - val_loss: 1.4148 - val_categorical_accuracy: 0.5399\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.58333\n","Epoch 40/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.5455 - categorical_accuracy: 0.9813 - val_loss: 1.3949 - val_categorical_accuracy: 0.5551\n","\n","Epoch 00040: val_categorical_accuracy did not improve from 0.58333\n","Epoch 41/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4845 - categorical_accuracy: 0.9892 - val_loss: 1.3817 - val_categorical_accuracy: 0.5651\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.58333\n","Epoch 42/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4732 - categorical_accuracy: 0.9888 - val_loss: 1.4000 - val_categorical_accuracy: 0.5603\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.58333\n","Epoch 43/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4700 - categorical_accuracy: 0.9961 - val_loss: 1.3560 - val_categorical_accuracy: 0.5655\n","\n","Epoch 00043: val_categorical_accuracy did not improve from 0.58333\n","Epoch 44/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4539 - categorical_accuracy: 0.9909 - val_loss: 1.3781 - val_categorical_accuracy: 0.5499\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.58333\n","Epoch 45/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4489 - categorical_accuracy: 0.9946 - val_loss: 1.3321 - val_categorical_accuracy: 0.5842\n","\n","Epoch 00045: val_categorical_accuracy improved from 0.58333 to 0.58420, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 46/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4408 - categorical_accuracy: 0.9943 - val_loss: 1.3590 - val_categorical_accuracy: 0.5516\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.58420\n","Epoch 47/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4390 - categorical_accuracy: 0.9888 - val_loss: 1.3145 - val_categorical_accuracy: 0.5972\n","\n","Epoch 00047: val_categorical_accuracy improved from 0.58420 to 0.59722, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 48/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4205 - categorical_accuracy: 0.9973 - val_loss: 1.3274 - val_categorical_accuracy: 0.5621\n","\n","Epoch 00048: val_categorical_accuracy did not improve from 0.59722\n","Epoch 49/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4215 - categorical_accuracy: 0.9926 - val_loss: 1.3497 - val_categorical_accuracy: 0.5534\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.59722\n","Epoch 50/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4129 - categorical_accuracy: 0.9935 - val_loss: 1.3237 - val_categorical_accuracy: 0.5569\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.59722\n","Epoch 51/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4042 - categorical_accuracy: 0.9954 - val_loss: 1.3278 - val_categorical_accuracy: 0.5673\n","\n","Epoch 00051: val_categorical_accuracy did not improve from 0.59722\n","Epoch 52/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4051 - categorical_accuracy: 0.9893 - val_loss: 1.3395 - val_categorical_accuracy: 0.5755\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.59722\n","Epoch 53/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.4032 - categorical_accuracy: 0.9927 - val_loss: 1.3124 - val_categorical_accuracy: 0.5794\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.59722\n","Epoch 54/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3716 - categorical_accuracy: 0.9978 - val_loss: 1.3347 - val_categorical_accuracy: 0.5972\n","\n","Epoch 00054: val_categorical_accuracy did not improve from 0.59722\n","Epoch 55/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3640 - categorical_accuracy: 0.9960 - val_loss: 1.3402 - val_categorical_accuracy: 0.5729\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.59722\n","Epoch 56/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3616 - categorical_accuracy: 0.9954 - val_loss: 1.2992 - val_categorical_accuracy: 0.5764\n","\n","Epoch 00056: val_categorical_accuracy did not improve from 0.59722\n","Epoch 57/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3587 - categorical_accuracy: 0.9937 - val_loss: 1.3219 - val_categorical_accuracy: 0.5734\n","\n","Epoch 00057: val_categorical_accuracy did not improve from 0.59722\n","Epoch 58/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3448 - categorical_accuracy: 0.9931 - val_loss: 1.3060 - val_categorical_accuracy: 0.5877\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.59722\n","Epoch 59/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3422 - categorical_accuracy: 0.9955 - val_loss: 1.2963 - val_categorical_accuracy: 0.5816\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.59722\n","Epoch 60/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3328 - categorical_accuracy: 0.9971 - val_loss: 1.2766 - val_categorical_accuracy: 0.6128\n","\n","Epoch 00060: val_categorical_accuracy improved from 0.59722 to 0.61285, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 61/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3352 - categorical_accuracy: 0.9947 - val_loss: 1.3047 - val_categorical_accuracy: 0.6037\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.61285\n","Epoch 62/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3171 - categorical_accuracy: 0.9959 - val_loss: 1.2941 - val_categorical_accuracy: 0.5768\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.61285\n","Epoch 63/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3261 - categorical_accuracy: 0.9928 - val_loss: 1.3040 - val_categorical_accuracy: 0.5751\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.61285\n","Epoch 64/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.3081 - categorical_accuracy: 0.9950 - val_loss: 1.3119 - val_categorical_accuracy: 0.5807\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.61285\n","Epoch 65/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3052 - categorical_accuracy: 0.9962 - val_loss: 1.2796 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.61285\n","Epoch 66/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3113 - categorical_accuracy: 0.9865 - val_loss: 1.2841 - val_categorical_accuracy: 0.5933\n","\n","Epoch 00066: val_categorical_accuracy did not improve from 0.61285\n","Epoch 67/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2910 - categorical_accuracy: 0.9988 - val_loss: 1.3034 - val_categorical_accuracy: 0.5760\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.61285\n","Epoch 68/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2867 - categorical_accuracy: 0.9982 - val_loss: 1.2829 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.61285\n","Epoch 69/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.3014 - categorical_accuracy: 0.9855 - val_loss: 1.2861 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.61285\n","Epoch 70/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2907 - categorical_accuracy: 0.9947 - val_loss: 1.3066 - val_categorical_accuracy: 0.5868\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.61285\n","Epoch 71/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2823 - categorical_accuracy: 0.9953 - val_loss: 1.2955 - val_categorical_accuracy: 0.5838\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.61285\n","Epoch 72/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2799 - categorical_accuracy: 0.9966 - val_loss: 1.3160 - val_categorical_accuracy: 0.5764\n","\n","Epoch 00072: val_categorical_accuracy did not improve from 0.61285\n","Epoch 73/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2723 - categorical_accuracy: 0.9972 - val_loss: 1.2753 - val_categorical_accuracy: 0.5855\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.61285\n","Epoch 74/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2819 - categorical_accuracy: 0.9946 - val_loss: 1.3100 - val_categorical_accuracy: 0.5877\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.61285\n","Epoch 75/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2689 - categorical_accuracy: 0.9980 - val_loss: 1.3049 - val_categorical_accuracy: 0.5694\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.61285\n","Epoch 76/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2536 - categorical_accuracy: 0.9981 - val_loss: 1.2860 - val_categorical_accuracy: 0.5916\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.61285\n","Epoch 77/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2564 - categorical_accuracy: 0.9940 - val_loss: 1.2937 - val_categorical_accuracy: 0.5764\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.61285\n","Epoch 78/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2640 - categorical_accuracy: 0.9987 - val_loss: 1.2848 - val_categorical_accuracy: 0.5777\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.61285\n","Epoch 79/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2560 - categorical_accuracy: 0.9982 - val_loss: 1.2901 - val_categorical_accuracy: 0.5877\n","\n","Epoch 00079: val_categorical_accuracy did not improve from 0.61285\n","Epoch 80/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2419 - categorical_accuracy: 0.9968 - val_loss: 1.2741 - val_categorical_accuracy: 0.5959\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.61285\n","Epoch 81/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2545 - categorical_accuracy: 0.9948 - val_loss: 1.2602 - val_categorical_accuracy: 0.6272\n","\n","Epoch 00081: val_categorical_accuracy improved from 0.61285 to 0.62717, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_60_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 82/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2395 - categorical_accuracy: 0.9965 - val_loss: 1.2783 - val_categorical_accuracy: 0.5751\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.62717\n","Epoch 83/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2257 - categorical_accuracy: 0.9961 - val_loss: 1.2924 - val_categorical_accuracy: 0.5924\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.62717\n","Epoch 84/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2366 - categorical_accuracy: 0.9961 - val_loss: 1.2810 - val_categorical_accuracy: 0.5890\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.62717\n","Epoch 85/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2283 - categorical_accuracy: 0.9957 - val_loss: 1.2693 - val_categorical_accuracy: 0.6033\n","\n","Epoch 00085: val_categorical_accuracy did not improve from 0.62717\n","Epoch 86/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2212 - categorical_accuracy: 0.9953 - val_loss: 1.2631 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00086: val_categorical_accuracy did not improve from 0.62717\n","Epoch 87/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2322 - categorical_accuracy: 0.9959 - val_loss: 1.2728 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.62717\n","Epoch 88/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2224 - categorical_accuracy: 0.9944 - val_loss: 1.2662 - val_categorical_accuracy: 0.6029\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.62717\n","Epoch 89/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2229 - categorical_accuracy: 0.9967 - val_loss: 1.2635 - val_categorical_accuracy: 0.5942\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.62717\n","Epoch 90/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2136 - categorical_accuracy: 0.9955 - val_loss: 1.2640 - val_categorical_accuracy: 0.6072\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.62717\n","Epoch 91/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2164 - categorical_accuracy: 0.9969 - val_loss: 1.2590 - val_categorical_accuracy: 0.6007\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.62717\n","Epoch 92/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2148 - categorical_accuracy: 0.9954 - val_loss: 1.2471 - val_categorical_accuracy: 0.6150\n","\n","Epoch 00092: val_categorical_accuracy did not improve from 0.62717\n","Epoch 93/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2109 - categorical_accuracy: 0.9970 - val_loss: 1.2600 - val_categorical_accuracy: 0.6037\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.62717\n","Epoch 94/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2010 - categorical_accuracy: 0.9957 - val_loss: 1.2620 - val_categorical_accuracy: 0.6137\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.62717\n","Epoch 95/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2036 - categorical_accuracy: 0.9976 - val_loss: 1.2618 - val_categorical_accuracy: 0.5964\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.62717\n","Epoch 96/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1917 - categorical_accuracy: 0.9994 - val_loss: 1.2627 - val_categorical_accuracy: 0.5890\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.62717\n","Epoch 97/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.2065 - categorical_accuracy: 0.9946 - val_loss: 1.2778 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.62717\n","Epoch 98/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.2030 - categorical_accuracy: 0.9971 - val_loss: 1.2702 - val_categorical_accuracy: 0.5985\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.62717\n","Epoch 99/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1798 - categorical_accuracy: 0.9997 - val_loss: 1.2683 - val_categorical_accuracy: 0.5929\n","\n","Epoch 00099: val_categorical_accuracy did not improve from 0.62717\n","Epoch 100/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1963 - categorical_accuracy: 0.9971 - val_loss: 1.2492 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.62717\n","Epoch 101/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1837 - categorical_accuracy: 0.9976 - val_loss: 1.2619 - val_categorical_accuracy: 0.5951\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.62717\n","Epoch 102/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1803 - categorical_accuracy: 0.9986 - val_loss: 1.2456 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.62717\n","Epoch 103/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1883 - categorical_accuracy: 0.9943 - val_loss: 1.2558 - val_categorical_accuracy: 0.6020\n","\n","Epoch 00103: val_categorical_accuracy did not improve from 0.62717\n","Epoch 104/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1800 - categorical_accuracy: 0.9966 - val_loss: 1.2533 - val_categorical_accuracy: 0.6024\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.62717\n","Epoch 105/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1715 - categorical_accuracy: 0.9988 - val_loss: 1.2502 - val_categorical_accuracy: 0.6098\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.62717\n","Epoch 106/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1728 - categorical_accuracy: 0.9955 - val_loss: 1.2428 - val_categorical_accuracy: 0.6159\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.62717\n","Epoch 107/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1734 - categorical_accuracy: 0.9942 - val_loss: 1.2472 - val_categorical_accuracy: 0.5977\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.62717\n","Epoch 108/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1664 - categorical_accuracy: 0.9988 - val_loss: 1.2537 - val_categorical_accuracy: 0.5933\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.62717\n","Epoch 109/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1717 - categorical_accuracy: 0.9966 - val_loss: 1.2452 - val_categorical_accuracy: 0.6141\n","\n","Epoch 00109: val_categorical_accuracy did not improve from 0.62717\n","Epoch 110/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1635 - categorical_accuracy: 0.9973 - val_loss: 1.2256 - val_categorical_accuracy: 0.6076\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.62717\n","Epoch 111/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1665 - categorical_accuracy: 0.9979 - val_loss: 1.2444 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.62717\n","Epoch 112/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1669 - categorical_accuracy: 0.9974 - val_loss: 1.2451 - val_categorical_accuracy: 0.6029\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.62717\n","Epoch 113/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1622 - categorical_accuracy: 0.9971 - val_loss: 1.2564 - val_categorical_accuracy: 0.6072\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.62717\n","Epoch 114/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1607 - categorical_accuracy: 0.9981 - val_loss: 1.2500 - val_categorical_accuracy: 0.6011\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.62717\n","Epoch 115/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1681 - categorical_accuracy: 0.9971 - val_loss: 1.2512 - val_categorical_accuracy: 0.6150\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.62717\n","Epoch 116/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1605 - categorical_accuracy: 0.9924 - val_loss: 1.2514 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.62717\n","Epoch 117/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1517 - categorical_accuracy: 0.9985 - val_loss: 1.2397 - val_categorical_accuracy: 0.6068\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.62717\n","Epoch 118/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1635 - categorical_accuracy: 0.9976 - val_loss: 1.2422 - val_categorical_accuracy: 0.5981\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.62717\n","Epoch 119/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1573 - categorical_accuracy: 0.9972 - val_loss: 1.2409 - val_categorical_accuracy: 0.6068\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.62717\n","Epoch 120/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1510 - categorical_accuracy: 0.9966 - val_loss: 1.2499 - val_categorical_accuracy: 0.6076\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.62717\n","Epoch 121/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1524 - categorical_accuracy: 0.9966 - val_loss: 1.2564 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.62717\n","Epoch 122/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1569 - categorical_accuracy: 0.9937 - val_loss: 1.2601 - val_categorical_accuracy: 0.6176\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.62717\n","Epoch 123/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1487 - categorical_accuracy: 0.9919 - val_loss: 1.2417 - val_categorical_accuracy: 0.6163\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.62717\n","Epoch 124/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1419 - categorical_accuracy: 0.9987 - val_loss: 1.2484 - val_categorical_accuracy: 0.6068\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.62717\n","Epoch 125/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1447 - categorical_accuracy: 0.9975 - val_loss: 1.2356 - val_categorical_accuracy: 0.6102\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.62717\n","Epoch 126/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1453 - categorical_accuracy: 0.9972 - val_loss: 1.2435 - val_categorical_accuracy: 0.6063\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.62717\n","Epoch 127/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1347 - categorical_accuracy: 0.9991 - val_loss: 1.2509 - val_categorical_accuracy: 0.5920\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.62717\n","Epoch 128/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1436 - categorical_accuracy: 0.9956 - val_loss: 1.2438 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.62717\n","Epoch 129/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1403 - categorical_accuracy: 0.9949 - val_loss: 1.2428 - val_categorical_accuracy: 0.6185\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.62717\n","Epoch 130/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1373 - categorical_accuracy: 0.9956 - val_loss: 1.2420 - val_categorical_accuracy: 0.6181\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.62717\n","Epoch 131/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1392 - categorical_accuracy: 0.9993 - val_loss: 1.2464 - val_categorical_accuracy: 0.5990\n","\n","Epoch 00131: val_categorical_accuracy did not improve from 0.62717\n","Epoch 132/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1345 - categorical_accuracy: 0.9982 - val_loss: 1.2490 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.62717\n","Epoch 133/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1341 - categorical_accuracy: 0.9982 - val_loss: 1.2327 - val_categorical_accuracy: 0.6181\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.62717\n","Epoch 134/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1341 - categorical_accuracy: 0.9958 - val_loss: 1.2409 - val_categorical_accuracy: 0.6159\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.62717\n","Epoch 135/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1339 - categorical_accuracy: 0.9959 - val_loss: 1.2352 - val_categorical_accuracy: 0.6055\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.62717\n","Epoch 136/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1373 - categorical_accuracy: 0.9967 - val_loss: 1.2387 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.62717\n","Epoch 137/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1334 - categorical_accuracy: 0.9928 - val_loss: 1.2298 - val_categorical_accuracy: 0.6241\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.62717\n","Epoch 138/150\n","42/42 [==============================] - 0s 8ms/step - loss: 0.1325 - categorical_accuracy: 0.9982 - val_loss: 1.2495 - val_categorical_accuracy: 0.6046\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.62717\n","Epoch 139/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1274 - categorical_accuracy: 0.9966 - val_loss: 1.2334 - val_categorical_accuracy: 0.6098\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.62717\n","Epoch 140/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1281 - categorical_accuracy: 0.9949 - val_loss: 1.2437 - val_categorical_accuracy: 0.6168\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.62717\n","Epoch 141/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1245 - categorical_accuracy: 0.9980 - val_loss: 1.2481 - val_categorical_accuracy: 0.5998\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.62717\n","Epoch 142/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1236 - categorical_accuracy: 0.9962 - val_loss: 1.2441 - val_categorical_accuracy: 0.6163\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.62717\n","Epoch 143/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1263 - categorical_accuracy: 0.9935 - val_loss: 1.2300 - val_categorical_accuracy: 0.6233\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.62717\n","Epoch 144/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1197 - categorical_accuracy: 0.9975 - val_loss: 1.2398 - val_categorical_accuracy: 0.6059\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.62717\n","Epoch 145/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1215 - categorical_accuracy: 0.9973 - val_loss: 1.2492 - val_categorical_accuracy: 0.6085\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.62717\n","Epoch 146/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1144 - categorical_accuracy: 0.9981 - val_loss: 1.2340 - val_categorical_accuracy: 0.6155\n","\n","Epoch 00146: val_categorical_accuracy did not improve from 0.62717\n","Epoch 147/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1310 - categorical_accuracy: 0.9930 - val_loss: 1.2425 - val_categorical_accuracy: 0.6172\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.62717\n","Epoch 148/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1163 - categorical_accuracy: 0.9981 - val_loss: 1.2350 - val_categorical_accuracy: 0.6124\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.62717\n","Epoch 149/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1187 - categorical_accuracy: 0.9974 - val_loss: 1.2361 - val_categorical_accuracy: 0.6072\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.62717\n","Epoch 150/150\n","42/42 [==============================] - 0s 7ms/step - loss: 0.1145 - categorical_accuracy: 0.9971 - val_loss: 1.2311 - val_categorical_accuracy: 0.6098\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.62717\n","72/72 [==============================] - 0s 2ms/step - loss: 1.2602 - categorical_accuracy: 0.6272\n","72/72 [==============================] - 0s 1ms/step\n","\n","================================================================================================================================\n","Model training starts for data with 75 samples from each class in training set\n","=================================================================================================================================\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20, 20, 64)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 20, 20, 64)   4160        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 20, 20, 64)   256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 20, 20, 64)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 20, 20, 8)    584         lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 20, 20, 8)    584         lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 20, 20, 8)    584         lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 20, 20, 8)    584         lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 20, 20, 8)    584         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 20, 20, 8)    584         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 20, 20, 8)    584         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 20, 20, 8)    0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 20, 20, 8)    584         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 20, 20, 8)    584         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 20, 20, 8)    584         lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 20, 20, 8)    584         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 20, 20, 8)    584         lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 20, 20, 8)    584         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 20, 20, 8)    584         lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 20, 20, 8)    584         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 20, 20, 64)   0           conv2d_1[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","                                                                 conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","                                                                 conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 20, 20, 64)   256         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20, 20, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None, 20, 20, 8, 8) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose (TFOpLam (None, 20, 20, 8, 8) 0           tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.reverse (TFOpLambda)         (None, 20, 20, 8, 8) 0           tf.compat.v1.transpose[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None, 20, 20, 64)   0           tf.reverse[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 20, 20, 64)   256         tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 20, 20, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 20, 20, 128)  8320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 20, 20, 128)  8320        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 20, 20, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 20, 20, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 20, 20, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 20, 20, 128)  0           activation_3[0][0]               \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 20, 20, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 20, 20, 128)  16512       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 20, 20, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 20, 20, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 20, 20, 16)   2320        lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 20, 20, 16)   2320        lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 16)   2320        lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 16)   2320        lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 20, 20, 16)   0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 20, 20, 16)   2320        lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 20, 20, 16)   2320        lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 20, 20, 16)   2320        lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 16)   2320        lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 16)   2320        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_20[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","                                                                 conv2d_24[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","                                                                 conv2d_28[0][0]                  \n","                                                                 conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 20, 20, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 20, 20, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","tf.reshape_2 (TFOpLambda)       (None, 20, 20, 8, 16 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","tf.compat.v1.transpose_1 (TFOpL (None, 20, 20, 16, 8 0           tf.reshape_2[0][0]               \n","__________________________________________________________________________________________________\n","tf.reverse_1 (TFOpLambda)       (None, 20, 20, 16, 8 0           tf.compat.v1.transpose_1[0][0]   \n","__________________________________________________________________________________________________\n","tf.reshape_3 (TFOpLambda)       (None, 20, 20, 128)  0           tf.reverse_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 20, 20, 128)  512         tf.reshape_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 20, 20, 128)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 256)  33024       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 256)  33024       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 20, 20, 256)  1024        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 20, 20, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 20, 20, 256)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 20, 20, 256)  0           activation_9[0][0]               \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 20, 20, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           activation_11[0][0]              \n","==================================================================================================\n","Total params: 155,200\n","Trainable params: 152,512\n","Non-trainable params: 2,688\n","__________________________________________________________________________________________________\n","Samples per class: [270, 101, 251, 215, 269, 269, 259, 203, 314, 248, 276, 133, 241, 95]\n","Total number of samples 3144.\n","\n","Total number of samples in training set 1050.\n","unique classes in training set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in training set: [75 75 75 75 75 75 75 75 75 75 75 75 75 75]\n","\n","Total number of samples in test set 2094.\n","unique classes in test set: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","Samples per class in test set: [195  26 176 140 194 194 184 128 239 173 201  58 166  20]\n","\n","X_train_transfer => (1050, 256)\n","X_test_transfer  => (2094, 256)\n","y_train => (1050, 14)\n","y_test  => (2094, 14)\n","\n","Model: \"fine_tune\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         [(None, 256)]             0         \n","_________________________________________________________________\n","fc_256 (Dense)               (None, 256)               65792     \n","_________________________________________________________________\n","fc14 (Dense)                 (None, 14)                3598      \n","=================================================================\n","Total params: 69,390\n","Trainable params: 69,390\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/150\n","53/53 [==============================] - 1s 9ms/step - loss: 4.1096 - categorical_accuracy: 0.1399 - val_loss: 2.3813 - val_categorical_accuracy: 0.2321\n","\n","Epoch 00001: val_categorical_accuracy improved from -inf to 0.23209, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 2/150\n","53/53 [==============================] - 0s 7ms/step - loss: 2.0855 - categorical_accuracy: 0.3361 - val_loss: 2.2693 - val_categorical_accuracy: 0.1652\n","\n","Epoch 00002: val_categorical_accuracy did not improve from 0.23209\n","Epoch 3/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.8591 - categorical_accuracy: 0.4142 - val_loss: 2.1643 - val_categorical_accuracy: 0.1691\n","\n","Epoch 00003: val_categorical_accuracy did not improve from 0.23209\n","Epoch 4/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.6696 - categorical_accuracy: 0.4866 - val_loss: 1.9967 - val_categorical_accuracy: 0.2732\n","\n","Epoch 00004: val_categorical_accuracy improved from 0.23209 to 0.27316, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 5/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.5433 - categorical_accuracy: 0.6058 - val_loss: 1.8990 - val_categorical_accuracy: 0.3720\n","\n","Epoch 00005: val_categorical_accuracy improved from 0.27316 to 0.37202, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 6/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.4316 - categorical_accuracy: 0.6676 - val_loss: 1.8531 - val_categorical_accuracy: 0.4599\n","\n","Epoch 00006: val_categorical_accuracy improved from 0.37202 to 0.45989, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 7/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.3896 - categorical_accuracy: 0.6603 - val_loss: 1.7841 - val_categorical_accuracy: 0.3797\n","\n","Epoch 00007: val_categorical_accuracy did not improve from 0.45989\n","Epoch 8/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.2536 - categorical_accuracy: 0.7083 - val_loss: 1.7840 - val_categorical_accuracy: 0.4360\n","\n","Epoch 00008: val_categorical_accuracy did not improve from 0.45989\n","Epoch 9/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.2260 - categorical_accuracy: 0.7701 - val_loss: 1.7355 - val_categorical_accuracy: 0.4155\n","\n","Epoch 00009: val_categorical_accuracy did not improve from 0.45989\n","Epoch 10/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.1653 - categorical_accuracy: 0.8001 - val_loss: 1.6983 - val_categorical_accuracy: 0.4771\n","\n","Epoch 00010: val_categorical_accuracy improved from 0.45989 to 0.47708, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 11/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.1156 - categorical_accuracy: 0.8277 - val_loss: 1.6796 - val_categorical_accuracy: 0.4117\n","\n","Epoch 00011: val_categorical_accuracy did not improve from 0.47708\n","Epoch 12/150\n","53/53 [==============================] - 0s 7ms/step - loss: 1.0598 - categorical_accuracy: 0.8289 - val_loss: 1.6406 - val_categorical_accuracy: 0.4895\n","\n","Epoch 00012: val_categorical_accuracy improved from 0.47708 to 0.48949, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 13/150\n","53/53 [==============================] - 0s 6ms/step - loss: 1.0344 - categorical_accuracy: 0.8541 - val_loss: 1.5843 - val_categorical_accuracy: 0.5110\n","\n","Epoch 00013: val_categorical_accuracy improved from 0.48949 to 0.51098, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 14/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.9504 - categorical_accuracy: 0.8823 - val_loss: 1.6366 - val_categorical_accuracy: 0.4742\n","\n","Epoch 00014: val_categorical_accuracy did not improve from 0.51098\n","Epoch 15/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9234 - categorical_accuracy: 0.8888 - val_loss: 1.5364 - val_categorical_accuracy: 0.5134\n","\n","Epoch 00015: val_categorical_accuracy improved from 0.51098 to 0.51337, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 16/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.9013 - categorical_accuracy: 0.9077 - val_loss: 1.5891 - val_categorical_accuracy: 0.4456\n","\n","Epoch 00016: val_categorical_accuracy did not improve from 0.51337\n","Epoch 17/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8615 - categorical_accuracy: 0.8855 - val_loss: 1.5082 - val_categorical_accuracy: 0.5229\n","\n","Epoch 00017: val_categorical_accuracy improved from 0.51337 to 0.52292, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 18/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.8269 - categorical_accuracy: 0.9245 - val_loss: 1.4849 - val_categorical_accuracy: 0.4967\n","\n","Epoch 00018: val_categorical_accuracy did not improve from 0.52292\n","Epoch 19/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.8056 - categorical_accuracy: 0.9237 - val_loss: 1.5056 - val_categorical_accuracy: 0.5330\n","\n","Epoch 00019: val_categorical_accuracy improved from 0.52292 to 0.53295, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 20/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7752 - categorical_accuracy: 0.9100 - val_loss: 1.5009 - val_categorical_accuracy: 0.5096\n","\n","Epoch 00020: val_categorical_accuracy did not improve from 0.53295\n","Epoch 21/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7627 - categorical_accuracy: 0.9076 - val_loss: 1.4355 - val_categorical_accuracy: 0.5287\n","\n","Epoch 00021: val_categorical_accuracy did not improve from 0.53295\n","Epoch 22/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.7219 - categorical_accuracy: 0.9443 - val_loss: 1.4779 - val_categorical_accuracy: 0.5234\n","\n","Epoch 00022: val_categorical_accuracy did not improve from 0.53295\n","Epoch 23/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6731 - categorical_accuracy: 0.9512 - val_loss: 1.4074 - val_categorical_accuracy: 0.5535\n","\n","Epoch 00023: val_categorical_accuracy improved from 0.53295 to 0.55349, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 24/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6865 - categorical_accuracy: 0.9563 - val_loss: 1.4392 - val_categorical_accuracy: 0.5282\n","\n","Epoch 00024: val_categorical_accuracy did not improve from 0.55349\n","Epoch 25/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6663 - categorical_accuracy: 0.9541 - val_loss: 1.3595 - val_categorical_accuracy: 0.5683\n","\n","Epoch 00025: val_categorical_accuracy improved from 0.55349 to 0.56829, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 26/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6301 - categorical_accuracy: 0.9672 - val_loss: 1.3829 - val_categorical_accuracy: 0.5702\n","\n","Epoch 00026: val_categorical_accuracy improved from 0.56829 to 0.57020, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 27/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.6370 - categorical_accuracy: 0.9682 - val_loss: 1.3938 - val_categorical_accuracy: 0.5516\n","\n","Epoch 00027: val_categorical_accuracy did not improve from 0.57020\n","Epoch 28/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6244 - categorical_accuracy: 0.9799 - val_loss: 1.3846 - val_categorical_accuracy: 0.5439\n","\n","Epoch 00028: val_categorical_accuracy did not improve from 0.57020\n","Epoch 29/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.6004 - categorical_accuracy: 0.9722 - val_loss: 1.3526 - val_categorical_accuracy: 0.5583\n","\n","Epoch 00029: val_categorical_accuracy did not improve from 0.57020\n","Epoch 30/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5876 - categorical_accuracy: 0.9652 - val_loss: 1.3397 - val_categorical_accuracy: 0.5778\n","\n","Epoch 00030: val_categorical_accuracy improved from 0.57020 to 0.57784, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 31/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5533 - categorical_accuracy: 0.9674 - val_loss: 1.3192 - val_categorical_accuracy: 0.5774\n","\n","Epoch 00031: val_categorical_accuracy did not improve from 0.57784\n","Epoch 32/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.5489 - categorical_accuracy: 0.9744 - val_loss: 1.3439 - val_categorical_accuracy: 0.5425\n","\n","Epoch 00032: val_categorical_accuracy did not improve from 0.57784\n","Epoch 33/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5314 - categorical_accuracy: 0.9717 - val_loss: 1.3298 - val_categorical_accuracy: 0.5544\n","\n","Epoch 00033: val_categorical_accuracy did not improve from 0.57784\n","Epoch 34/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5063 - categorical_accuracy: 0.9806 - val_loss: 1.3065 - val_categorical_accuracy: 0.5888\n","\n","Epoch 00034: val_categorical_accuracy improved from 0.57784 to 0.58883, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 35/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.5179 - categorical_accuracy: 0.9809 - val_loss: 1.3212 - val_categorical_accuracy: 0.5774\n","\n","Epoch 00035: val_categorical_accuracy did not improve from 0.58883\n","Epoch 36/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4969 - categorical_accuracy: 0.9740 - val_loss: 1.3150 - val_categorical_accuracy: 0.5568\n","\n","Epoch 00036: val_categorical_accuracy did not improve from 0.58883\n","Epoch 37/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4839 - categorical_accuracy: 0.9717 - val_loss: 1.3460 - val_categorical_accuracy: 0.5712\n","\n","Epoch 00037: val_categorical_accuracy did not improve from 0.58883\n","Epoch 38/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4738 - categorical_accuracy: 0.9826 - val_loss: 1.3078 - val_categorical_accuracy: 0.5731\n","\n","Epoch 00038: val_categorical_accuracy did not improve from 0.58883\n","Epoch 39/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4718 - categorical_accuracy: 0.9780 - val_loss: 1.3117 - val_categorical_accuracy: 0.5664\n","\n","Epoch 00039: val_categorical_accuracy did not improve from 0.58883\n","Epoch 40/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4566 - categorical_accuracy: 0.9850 - val_loss: 1.2709 - val_categorical_accuracy: 0.5922\n","\n","Epoch 00040: val_categorical_accuracy improved from 0.58883 to 0.59217, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 41/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4163 - categorical_accuracy: 0.9887 - val_loss: 1.2824 - val_categorical_accuracy: 0.5716\n","\n","Epoch 00041: val_categorical_accuracy did not improve from 0.59217\n","Epoch 42/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4091 - categorical_accuracy: 0.9849 - val_loss: 1.2496 - val_categorical_accuracy: 0.5864\n","\n","Epoch 00042: val_categorical_accuracy did not improve from 0.59217\n","Epoch 43/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.4319 - categorical_accuracy: 0.9793 - val_loss: 1.2568 - val_categorical_accuracy: 0.5950\n","\n","Epoch 00043: val_categorical_accuracy improved from 0.59217 to 0.59503, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 44/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4233 - categorical_accuracy: 0.9810 - val_loss: 1.2827 - val_categorical_accuracy: 0.5798\n","\n","Epoch 00044: val_categorical_accuracy did not improve from 0.59503\n","Epoch 45/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.4059 - categorical_accuracy: 0.9827 - val_loss: 1.2618 - val_categorical_accuracy: 0.5745\n","\n","Epoch 00045: val_categorical_accuracy did not improve from 0.59503\n","Epoch 46/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3893 - categorical_accuracy: 0.9886 - val_loss: 1.2653 - val_categorical_accuracy: 0.5850\n","\n","Epoch 00046: val_categorical_accuracy did not improve from 0.59503\n","Epoch 47/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3892 - categorical_accuracy: 0.9807 - val_loss: 1.2448 - val_categorical_accuracy: 0.5879\n","\n","Epoch 00047: val_categorical_accuracy did not improve from 0.59503\n","Epoch 48/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3953 - categorical_accuracy: 0.9832 - val_loss: 1.2377 - val_categorical_accuracy: 0.6012\n","\n","Epoch 00048: val_categorical_accuracy improved from 0.59503 to 0.60124, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 49/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3601 - categorical_accuracy: 0.9858 - val_loss: 1.2512 - val_categorical_accuracy: 0.6003\n","\n","Epoch 00049: val_categorical_accuracy did not improve from 0.60124\n","Epoch 50/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3657 - categorical_accuracy: 0.9803 - val_loss: 1.2374 - val_categorical_accuracy: 0.6012\n","\n","Epoch 00050: val_categorical_accuracy did not improve from 0.60124\n","Epoch 51/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3593 - categorical_accuracy: 0.9779 - val_loss: 1.2229 - val_categorical_accuracy: 0.6117\n","\n","Epoch 00051: val_categorical_accuracy improved from 0.60124 to 0.61175, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 52/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3394 - categorical_accuracy: 0.9854 - val_loss: 1.2351 - val_categorical_accuracy: 0.6036\n","\n","Epoch 00052: val_categorical_accuracy did not improve from 0.61175\n","Epoch 53/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3446 - categorical_accuracy: 0.9838 - val_loss: 1.2292 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00053: val_categorical_accuracy did not improve from 0.61175\n","Epoch 54/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3175 - categorical_accuracy: 0.9895 - val_loss: 1.2056 - val_categorical_accuracy: 0.6170\n","\n","Epoch 00054: val_categorical_accuracy improved from 0.61175 to 0.61700, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 55/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3214 - categorical_accuracy: 0.9825 - val_loss: 1.2488 - val_categorical_accuracy: 0.6003\n","\n","Epoch 00055: val_categorical_accuracy did not improve from 0.61700\n","Epoch 56/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3333 - categorical_accuracy: 0.9775 - val_loss: 1.1949 - val_categorical_accuracy: 0.6356\n","\n","Epoch 00056: val_categorical_accuracy improved from 0.61700 to 0.63563, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 57/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3283 - categorical_accuracy: 0.9861 - val_loss: 1.2110 - val_categorical_accuracy: 0.6433\n","\n","Epoch 00057: val_categorical_accuracy improved from 0.63563 to 0.64327, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 58/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.3146 - categorical_accuracy: 0.9877 - val_loss: 1.2079 - val_categorical_accuracy: 0.6141\n","\n","Epoch 00058: val_categorical_accuracy did not improve from 0.64327\n","Epoch 59/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2919 - categorical_accuracy: 0.9826 - val_loss: 1.2121 - val_categorical_accuracy: 0.6223\n","\n","Epoch 00059: val_categorical_accuracy did not improve from 0.64327\n","Epoch 60/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.3038 - categorical_accuracy: 0.9830 - val_loss: 1.2101 - val_categorical_accuracy: 0.6705\n","\n","Epoch 00060: val_categorical_accuracy improved from 0.64327 to 0.67049, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 61/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2903 - categorical_accuracy: 0.9882 - val_loss: 1.2248 - val_categorical_accuracy: 0.6089\n","\n","Epoch 00061: val_categorical_accuracy did not improve from 0.67049\n","Epoch 62/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2902 - categorical_accuracy: 0.9903 - val_loss: 1.2094 - val_categorical_accuracy: 0.6060\n","\n","Epoch 00062: val_categorical_accuracy did not improve from 0.67049\n","Epoch 63/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2774 - categorical_accuracy: 0.9916 - val_loss: 1.1845 - val_categorical_accuracy: 0.6681\n","\n","Epoch 00063: val_categorical_accuracy did not improve from 0.67049\n","Epoch 64/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2685 - categorical_accuracy: 0.9881 - val_loss: 1.1719 - val_categorical_accuracy: 0.6304\n","\n","Epoch 00064: val_categorical_accuracy did not improve from 0.67049\n","Epoch 65/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2789 - categorical_accuracy: 0.9885 - val_loss: 1.2126 - val_categorical_accuracy: 0.6094\n","\n","Epoch 00065: val_categorical_accuracy did not improve from 0.67049\n","Epoch 66/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2769 - categorical_accuracy: 0.9847 - val_loss: 1.1624 - val_categorical_accuracy: 0.6714\n","\n","Epoch 00066: val_categorical_accuracy improved from 0.67049 to 0.67144, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 67/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2680 - categorical_accuracy: 0.9838 - val_loss: 1.1919 - val_categorical_accuracy: 0.6299\n","\n","Epoch 00067: val_categorical_accuracy did not improve from 0.67144\n","Epoch 68/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2606 - categorical_accuracy: 0.9899 - val_loss: 1.1944 - val_categorical_accuracy: 0.6146\n","\n","Epoch 00068: val_categorical_accuracy did not improve from 0.67144\n","Epoch 69/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2636 - categorical_accuracy: 0.9865 - val_loss: 1.1756 - val_categorical_accuracy: 0.6280\n","\n","Epoch 00069: val_categorical_accuracy did not improve from 0.67144\n","Epoch 70/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2521 - categorical_accuracy: 0.9892 - val_loss: 1.1698 - val_categorical_accuracy: 0.6471\n","\n","Epoch 00070: val_categorical_accuracy did not improve from 0.67144\n","Epoch 71/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2448 - categorical_accuracy: 0.9915 - val_loss: 1.2005 - val_categorical_accuracy: 0.6160\n","\n","Epoch 00071: val_categorical_accuracy did not improve from 0.67144\n","Epoch 72/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2494 - categorical_accuracy: 0.9888 - val_loss: 1.1808 - val_categorical_accuracy: 0.6796\n","\n","Epoch 00072: val_categorical_accuracy improved from 0.67144 to 0.67956, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 73/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2459 - categorical_accuracy: 0.9881 - val_loss: 1.1823 - val_categorical_accuracy: 0.6332\n","\n","Epoch 00073: val_categorical_accuracy did not improve from 0.67956\n","Epoch 74/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2379 - categorical_accuracy: 0.9833 - val_loss: 1.1623 - val_categorical_accuracy: 0.6480\n","\n","Epoch 00074: val_categorical_accuracy did not improve from 0.67956\n","Epoch 75/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2325 - categorical_accuracy: 0.9876 - val_loss: 1.1819 - val_categorical_accuracy: 0.6328\n","\n","Epoch 00075: val_categorical_accuracy did not improve from 0.67956\n","Epoch 76/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2265 - categorical_accuracy: 0.9901 - val_loss: 1.1776 - val_categorical_accuracy: 0.6686\n","\n","Epoch 00076: val_categorical_accuracy did not improve from 0.67956\n","Epoch 77/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2340 - categorical_accuracy: 0.9896 - val_loss: 1.1928 - val_categorical_accuracy: 0.6137\n","\n","Epoch 00077: val_categorical_accuracy did not improve from 0.67956\n","Epoch 78/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2291 - categorical_accuracy: 0.9914 - val_loss: 1.1556 - val_categorical_accuracy: 0.6772\n","\n","Epoch 00078: val_categorical_accuracy did not improve from 0.67956\n","Epoch 79/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2191 - categorical_accuracy: 0.9933 - val_loss: 1.1325 - val_categorical_accuracy: 0.6858\n","\n","Epoch 00079: val_categorical_accuracy improved from 0.67956 to 0.68577, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 80/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2212 - categorical_accuracy: 0.9864 - val_loss: 1.1569 - val_categorical_accuracy: 0.6652\n","\n","Epoch 00080: val_categorical_accuracy did not improve from 0.68577\n","Epoch 81/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2166 - categorical_accuracy: 0.9832 - val_loss: 1.1873 - val_categorical_accuracy: 0.6466\n","\n","Epoch 00081: val_categorical_accuracy did not improve from 0.68577\n","Epoch 82/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2126 - categorical_accuracy: 0.9926 - val_loss: 1.1958 - val_categorical_accuracy: 0.6194\n","\n","Epoch 00082: val_categorical_accuracy did not improve from 0.68577\n","Epoch 83/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1982 - categorical_accuracy: 0.9960 - val_loss: 1.1513 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00083: val_categorical_accuracy did not improve from 0.68577\n","Epoch 84/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2136 - categorical_accuracy: 0.9900 - val_loss: 1.1608 - val_categorical_accuracy: 0.6380\n","\n","Epoch 00084: val_categorical_accuracy did not improve from 0.68577\n","Epoch 85/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2038 - categorical_accuracy: 0.9940 - val_loss: 1.1414 - val_categorical_accuracy: 0.6862\n","\n","Epoch 00085: val_categorical_accuracy improved from 0.68577 to 0.68625, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 86/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.2026 - categorical_accuracy: 0.9949 - val_loss: 1.1458 - val_categorical_accuracy: 0.6891\n","\n","Epoch 00086: val_categorical_accuracy improved from 0.68625 to 0.68911, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 87/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1960 - categorical_accuracy: 0.9896 - val_loss: 1.1590 - val_categorical_accuracy: 0.6390\n","\n","Epoch 00087: val_categorical_accuracy did not improve from 0.68911\n","Epoch 88/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1984 - categorical_accuracy: 0.9935 - val_loss: 1.1519 - val_categorical_accuracy: 0.6471\n","\n","Epoch 00088: val_categorical_accuracy did not improve from 0.68911\n","Epoch 89/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2000 - categorical_accuracy: 0.9874 - val_loss: 1.1525 - val_categorical_accuracy: 0.6843\n","\n","Epoch 00089: val_categorical_accuracy did not improve from 0.68911\n","Epoch 90/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1943 - categorical_accuracy: 0.9941 - val_loss: 1.1800 - val_categorical_accuracy: 0.6113\n","\n","Epoch 00090: val_categorical_accuracy did not improve from 0.68911\n","Epoch 91/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1849 - categorical_accuracy: 0.9933 - val_loss: 1.1733 - val_categorical_accuracy: 0.6156\n","\n","Epoch 00091: val_categorical_accuracy did not improve from 0.68911\n","Epoch 92/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.2076 - categorical_accuracy: 0.9821 - val_loss: 1.1433 - val_categorical_accuracy: 0.6910\n","\n","Epoch 00092: val_categorical_accuracy improved from 0.68911 to 0.69102, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 93/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1839 - categorical_accuracy: 0.9870 - val_loss: 1.1365 - val_categorical_accuracy: 0.6461\n","\n","Epoch 00093: val_categorical_accuracy did not improve from 0.69102\n","Epoch 94/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1811 - categorical_accuracy: 0.9898 - val_loss: 1.1500 - val_categorical_accuracy: 0.6418\n","\n","Epoch 00094: val_categorical_accuracy did not improve from 0.69102\n","Epoch 95/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1851 - categorical_accuracy: 0.9877 - val_loss: 1.1370 - val_categorical_accuracy: 0.6738\n","\n","Epoch 00095: val_categorical_accuracy did not improve from 0.69102\n","Epoch 96/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1812 - categorical_accuracy: 0.9950 - val_loss: 1.1368 - val_categorical_accuracy: 0.6562\n","\n","Epoch 00096: val_categorical_accuracy did not improve from 0.69102\n","Epoch 97/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1833 - categorical_accuracy: 0.9925 - val_loss: 1.1359 - val_categorical_accuracy: 0.6691\n","\n","Epoch 00097: val_categorical_accuracy did not improve from 0.69102\n","Epoch 98/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1641 - categorical_accuracy: 0.9978 - val_loss: 1.1413 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00098: val_categorical_accuracy did not improve from 0.69102\n","Epoch 99/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1666 - categorical_accuracy: 0.9974 - val_loss: 1.1233 - val_categorical_accuracy: 0.6987\n","\n","Epoch 00099: val_categorical_accuracy improved from 0.69102 to 0.69866, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 100/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1635 - categorical_accuracy: 0.9938 - val_loss: 1.1560 - val_categorical_accuracy: 0.6757\n","\n","Epoch 00100: val_categorical_accuracy did not improve from 0.69866\n","Epoch 101/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1678 - categorical_accuracy: 0.9909 - val_loss: 1.1382 - val_categorical_accuracy: 0.6915\n","\n","Epoch 00101: val_categorical_accuracy did not improve from 0.69866\n","Epoch 102/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1665 - categorical_accuracy: 0.9942 - val_loss: 1.1370 - val_categorical_accuracy: 0.6824\n","\n","Epoch 00102: val_categorical_accuracy did not improve from 0.69866\n","Epoch 103/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1659 - categorical_accuracy: 0.9911 - val_loss: 1.1298 - val_categorical_accuracy: 0.6991\n","\n","Epoch 00103: val_categorical_accuracy improved from 0.69866 to 0.69914, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 104/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1620 - categorical_accuracy: 0.9954 - val_loss: 1.1285 - val_categorical_accuracy: 0.6800\n","\n","Epoch 00104: val_categorical_accuracy did not improve from 0.69914\n","Epoch 105/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1593 - categorical_accuracy: 0.9954 - val_loss: 1.1128 - val_categorical_accuracy: 0.6925\n","\n","Epoch 00105: val_categorical_accuracy did not improve from 0.69914\n","Epoch 106/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1582 - categorical_accuracy: 0.9918 - val_loss: 1.1344 - val_categorical_accuracy: 0.6920\n","\n","Epoch 00106: val_categorical_accuracy did not improve from 0.69914\n","Epoch 107/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1557 - categorical_accuracy: 0.9941 - val_loss: 1.1125 - val_categorical_accuracy: 0.6839\n","\n","Epoch 00107: val_categorical_accuracy did not improve from 0.69914\n","Epoch 108/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1552 - categorical_accuracy: 0.9933 - val_loss: 1.1442 - val_categorical_accuracy: 0.6834\n","\n","Epoch 00108: val_categorical_accuracy did not improve from 0.69914\n","Epoch 109/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1440 - categorical_accuracy: 0.9975 - val_loss: 1.1068 - val_categorical_accuracy: 0.7053\n","\n","Epoch 00109: val_categorical_accuracy improved from 0.69914 to 0.70535, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 110/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1583 - categorical_accuracy: 0.9929 - val_loss: 1.1410 - val_categorical_accuracy: 0.6829\n","\n","Epoch 00110: val_categorical_accuracy did not improve from 0.70535\n","Epoch 111/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1464 - categorical_accuracy: 0.9940 - val_loss: 1.1363 - val_categorical_accuracy: 0.6939\n","\n","Epoch 00111: val_categorical_accuracy did not improve from 0.70535\n","Epoch 112/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1483 - categorical_accuracy: 0.9941 - val_loss: 1.1322 - val_categorical_accuracy: 0.6963\n","\n","Epoch 00112: val_categorical_accuracy did not improve from 0.70535\n","Epoch 113/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1414 - categorical_accuracy: 0.9937 - val_loss: 1.1318 - val_categorical_accuracy: 0.6877\n","\n","Epoch 00113: val_categorical_accuracy did not improve from 0.70535\n","Epoch 114/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1390 - categorical_accuracy: 0.9978 - val_loss: 1.1171 - val_categorical_accuracy: 0.6925\n","\n","Epoch 00114: val_categorical_accuracy did not improve from 0.70535\n","Epoch 115/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1453 - categorical_accuracy: 0.9932 - val_loss: 1.1265 - val_categorical_accuracy: 0.6867\n","\n","Epoch 00115: val_categorical_accuracy did not improve from 0.70535\n","Epoch 116/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1429 - categorical_accuracy: 0.9945 - val_loss: 1.1329 - val_categorical_accuracy: 0.6686\n","\n","Epoch 00116: val_categorical_accuracy did not improve from 0.70535\n","Epoch 117/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1354 - categorical_accuracy: 0.9951 - val_loss: 1.1176 - val_categorical_accuracy: 0.6753\n","\n","Epoch 00117: val_categorical_accuracy did not improve from 0.70535\n","Epoch 118/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1344 - categorical_accuracy: 0.9955 - val_loss: 1.1284 - val_categorical_accuracy: 0.6862\n","\n","Epoch 00118: val_categorical_accuracy did not improve from 0.70535\n","Epoch 119/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1449 - categorical_accuracy: 0.9937 - val_loss: 1.1357 - val_categorical_accuracy: 0.6901\n","\n","Epoch 00119: val_categorical_accuracy did not improve from 0.70535\n","Epoch 120/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1389 - categorical_accuracy: 0.9951 - val_loss: 1.1199 - val_categorical_accuracy: 0.6815\n","\n","Epoch 00120: val_categorical_accuracy did not improve from 0.70535\n","Epoch 121/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1436 - categorical_accuracy: 0.9915 - val_loss: 1.1328 - val_categorical_accuracy: 0.6748\n","\n","Epoch 00121: val_categorical_accuracy did not improve from 0.70535\n","Epoch 122/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1283 - categorical_accuracy: 0.9946 - val_loss: 1.1191 - val_categorical_accuracy: 0.7001\n","\n","Epoch 00122: val_categorical_accuracy did not improve from 0.70535\n","Epoch 123/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1318 - categorical_accuracy: 0.9962 - val_loss: 1.1380 - val_categorical_accuracy: 0.6710\n","\n","Epoch 00123: val_categorical_accuracy did not improve from 0.70535\n","Epoch 124/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1253 - categorical_accuracy: 0.9962 - val_loss: 1.1162 - val_categorical_accuracy: 0.7011\n","\n","Epoch 00124: val_categorical_accuracy did not improve from 0.70535\n","Epoch 125/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1275 - categorical_accuracy: 0.9923 - val_loss: 1.1412 - val_categorical_accuracy: 0.6495\n","\n","Epoch 00125: val_categorical_accuracy did not improve from 0.70535\n","Epoch 126/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1249 - categorical_accuracy: 0.9973 - val_loss: 1.1398 - val_categorical_accuracy: 0.6657\n","\n","Epoch 00126: val_categorical_accuracy did not improve from 0.70535\n","Epoch 127/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1282 - categorical_accuracy: 0.9984 - val_loss: 1.1256 - val_categorical_accuracy: 0.6848\n","\n","Epoch 00127: val_categorical_accuracy did not improve from 0.70535\n","Epoch 128/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1197 - categorical_accuracy: 0.9954 - val_loss: 1.1193 - val_categorical_accuracy: 0.6858\n","\n","Epoch 00128: val_categorical_accuracy did not improve from 0.70535\n","Epoch 129/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1268 - categorical_accuracy: 0.9960 - val_loss: 1.1499 - val_categorical_accuracy: 0.6810\n","\n","Epoch 00129: val_categorical_accuracy did not improve from 0.70535\n","Epoch 130/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1217 - categorical_accuracy: 0.9949 - val_loss: 1.1191 - val_categorical_accuracy: 0.6925\n","\n","Epoch 00130: val_categorical_accuracy did not improve from 0.70535\n","Epoch 131/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1186 - categorical_accuracy: 0.9970 - val_loss: 1.1018 - val_categorical_accuracy: 0.7120\n","\n","Epoch 00131: val_categorical_accuracy improved from 0.70535 to 0.71203, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 132/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1263 - categorical_accuracy: 0.9908 - val_loss: 1.1250 - val_categorical_accuracy: 0.6872\n","\n","Epoch 00132: val_categorical_accuracy did not improve from 0.71203\n","Epoch 133/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1206 - categorical_accuracy: 0.9944 - val_loss: 1.1099 - val_categorical_accuracy: 0.7068\n","\n","Epoch 00133: val_categorical_accuracy did not improve from 0.71203\n","Epoch 134/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1264 - categorical_accuracy: 0.9907 - val_loss: 1.1177 - val_categorical_accuracy: 0.7006\n","\n","Epoch 00134: val_categorical_accuracy did not improve from 0.71203\n","Epoch 135/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1171 - categorical_accuracy: 0.9970 - val_loss: 1.1093 - val_categorical_accuracy: 0.7053\n","\n","Epoch 00135: val_categorical_accuracy did not improve from 0.71203\n","Epoch 136/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1198 - categorical_accuracy: 0.9923 - val_loss: 1.1152 - val_categorical_accuracy: 0.6901\n","\n","Epoch 00136: val_categorical_accuracy did not improve from 0.71203\n","Epoch 137/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1185 - categorical_accuracy: 0.9978 - val_loss: 1.1252 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00137: val_categorical_accuracy did not improve from 0.71203\n","Epoch 138/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1188 - categorical_accuracy: 0.9927 - val_loss: 1.1186 - val_categorical_accuracy: 0.6901\n","\n","Epoch 00138: val_categorical_accuracy did not improve from 0.71203\n","Epoch 139/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1119 - categorical_accuracy: 0.9922 - val_loss: 1.1222 - val_categorical_accuracy: 0.6972\n","\n","Epoch 00139: val_categorical_accuracy did not improve from 0.71203\n","Epoch 140/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1171 - categorical_accuracy: 0.9930 - val_loss: 1.1240 - val_categorical_accuracy: 0.6905\n","\n","Epoch 00140: val_categorical_accuracy did not improve from 0.71203\n","Epoch 141/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1075 - categorical_accuracy: 0.9960 - val_loss: 1.1178 - val_categorical_accuracy: 0.7063\n","\n","Epoch 00141: val_categorical_accuracy did not improve from 0.71203\n","Epoch 142/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1102 - categorical_accuracy: 0.9950 - val_loss: 1.1015 - val_categorical_accuracy: 0.7006\n","\n","Epoch 00142: val_categorical_accuracy did not improve from 0.71203\n","Epoch 143/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1129 - categorical_accuracy: 0.9940 - val_loss: 1.1222 - val_categorical_accuracy: 0.6929\n","\n","Epoch 00143: val_categorical_accuracy did not improve from 0.71203\n","Epoch 144/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1103 - categorical_accuracy: 0.9929 - val_loss: 1.1284 - val_categorical_accuracy: 0.6972\n","\n","Epoch 00144: val_categorical_accuracy did not improve from 0.71203\n","Epoch 145/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1139 - categorical_accuracy: 0.9972 - val_loss: 1.1151 - val_categorical_accuracy: 0.6968\n","\n","Epoch 00145: val_categorical_accuracy did not improve from 0.71203\n","Epoch 146/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1097 - categorical_accuracy: 0.9966 - val_loss: 1.1170 - val_categorical_accuracy: 0.7130\n","\n","Epoch 00146: val_categorical_accuracy improved from 0.71203 to 0.71299, saving model to /content/drive/My Drive/Hyperspectral_Image_Classification/V1//SGCNN_12//Trained_models//transferred_models/fine_tune_on_botswana_with_75_samples_from_each_class_in_training_set_and_200_source_training_samples_per_class_used_in_pretraining.h5\n","Epoch 147/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1078 - categorical_accuracy: 0.9951 - val_loss: 1.1055 - val_categorical_accuracy: 0.6939\n","\n","Epoch 00147: val_categorical_accuracy did not improve from 0.71299\n","Epoch 148/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1026 - categorical_accuracy: 0.9978 - val_loss: 1.1183 - val_categorical_accuracy: 0.7044\n","\n","Epoch 00148: val_categorical_accuracy did not improve from 0.71299\n","Epoch 149/150\n","53/53 [==============================] - 0s 7ms/step - loss: 0.1048 - categorical_accuracy: 0.9956 - val_loss: 1.1113 - val_categorical_accuracy: 0.7030\n","\n","Epoch 00149: val_categorical_accuracy did not improve from 0.71299\n","Epoch 150/150\n","53/53 [==============================] - 0s 6ms/step - loss: 0.1011 - categorical_accuracy: 0.9980 - val_loss: 1.1063 - val_categorical_accuracy: 0.6944\n","\n","Epoch 00150: val_categorical_accuracy did not improve from 0.71299\n","66/66 [==============================] - 0s 3ms/step - loss: 1.1170 - categorical_accuracy: 0.7130\n","66/66 [==============================] - 0s 1ms/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VdgxRQRP0_mp"},"source":["# Transfer Learning results on Botswana"]},{"cell_type":"code","metadata":{"id":"R_WJcBsGjtRA","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1615788191997,"user_tz":420,"elapsed":376,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"b342f642-be12-4bf1-bdfb-ecf5795a158d"},"source":["transfer_results"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training samples per class finetuning</th>\n","      <th>Training Samples per class pretraining</th>\n","      <th>Training Samples</th>\n","      <th>Test Samples</th>\n","      <th>Test_Accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15</td>\n","      <td>200</td>\n","      <td>210</td>\n","      <td>2934</td>\n","      <td>62.92</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>30</td>\n","      <td>200</td>\n","      <td>420</td>\n","      <td>2724</td>\n","      <td>62.92</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45</td>\n","      <td>200</td>\n","      <td>630</td>\n","      <td>2514</td>\n","      <td>63.22</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60</td>\n","      <td>200</td>\n","      <td>840</td>\n","      <td>2304</td>\n","      <td>63.22</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>75</td>\n","      <td>200</td>\n","      <td>1050</td>\n","      <td>2094</td>\n","      <td>63.60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Training samples per class finetuning  ...  Test_Accuracies\n","0                                     15  ...            62.92\n","1                                     30  ...            62.92\n","2                                     45  ...            63.22\n","3                                     60  ...            63.22\n","4                                     75  ...            63.60\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"1o6mCjHJ01PG"},"source":["# Classification accuracies per class for each model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"BjFASZ9hw-gi","executionInfo":{"status":"ok","timestamp":1615788288884,"user_tz":420,"elapsed":373,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"544d1a02-50ac-4f2c-e0fe-0518082ec300"},"source":["confusion_matrixes[0]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>204</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>80.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>63</td>\n","      <td>69</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29.66</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>155</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>54</td>\n","      <td>89</td>\n","      <td>51</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.04</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>17.72</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>210</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86.07</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>5</td>\n","      <td>89</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24.47</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>268</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>89.63</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>139</td>\n","      <td>0</td>\n","      <td>94</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40.34</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>59</td>\n","      <td>202</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77.39</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>86.28</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>64</td>\n","      <td>80.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>255</td>\n","      <td>86</td>\n","      <td>236</td>\n","      <td>200</td>\n","      <td>254</td>\n","      <td>254</td>\n","      <td>244</td>\n","      <td>188</td>\n","      <td>299</td>\n","      <td>233</td>\n","      <td>261</td>\n","      <td>118</td>\n","      <td>226</td>\n","      <td>80</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              204   0    0    0  ...    0    0   0                      80.0\n","1                0  86    0    0  ...    0    0   0                     100.0\n","2                0   0   70   20  ...    0    0   0                     29.66\n","3                0   0   14  155  ...    0    0   0                      77.5\n","4                7  16    0   54  ...    0    0   0                     35.04\n","5                0   7    1   11  ...   12   32   0                     17.72\n","6               34   0    0    0  ...    0    0   0                     86.07\n","7                0   0    1    0  ...   89    0   0                     24.47\n","8                0   0    0    0  ...    0    0   0                     89.63\n","9                0   0    0    0  ...    0    0   0                     40.34\n","10               0   0    0    0  ...    0    0   0                     77.39\n","11               0   0    0    0  ...  118    0   0                     100.0\n","12               0   0    0    0  ...   31  195   0                     86.28\n","13               0  14    0    2  ...    0    0  64                      80.0\n","Total Samples  255  86  236  200  ...  118  226  80                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"rh3wq7nYxm1U","executionInfo":{"status":"ok","timestamp":1615788302483,"user_tz":420,"elapsed":498,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"2d39eba2-f6dc-482d-c71f-e188f7b0a322"},"source":["confusion_matrixes[1]"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>190</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>79.17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>71</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>80</td>\n","      <td>59</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17.65</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>176</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>95.14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>109</td>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45.61</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>18.41</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>85.15</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>38</td>\n","      <td>78</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16.18</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>268</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94.37</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>68</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31.19</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>194</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>78.86</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>103</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>188</td>\n","      <td>0</td>\n","      <td>89.1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>75.38</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>240</td>\n","      <td>71</td>\n","      <td>221</td>\n","      <td>185</td>\n","      <td>239</td>\n","      <td>239</td>\n","      <td>229</td>\n","      <td>173</td>\n","      <td>284</td>\n","      <td>218</td>\n","      <td>246</td>\n","      <td>103</td>\n","      <td>211</td>\n","      <td>65</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...   12   13  14  classfication_accuracies\n","0              190   0    0    0  ...    0    0   0                     79.17\n","1                0  71    0    0  ...    0    0   0                     100.0\n","2                0   0   39   29  ...    0    0   0                     17.65\n","3                0   0    0  176  ...    0    0   0                     95.14\n","4                8  12    0   70  ...    0    0   0                     45.61\n","5                0   0    0   35  ...    8   50   0                     18.41\n","6               34   0    0    0  ...    0    0   0                     85.15\n","7                0   0    0    5  ...   78    0   0                     16.18\n","8                0   0    0    0  ...    0    0   0                     94.37\n","9                0   0    0    0  ...    0    0   0                     31.19\n","10               0   0    0    0  ...    0    0   0                     78.86\n","11               0   0    0    0  ...  103    0   0                     100.0\n","12               0   0    0    0  ...   23  188   0                      89.1\n","13               0  13    0    3  ...    0    0  49                     75.38\n","Total Samples  240  71  221  185  ...  103  211  65                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"0DyVuVJbyY9Q","executionInfo":{"status":"ok","timestamp":1615788305911,"user_tz":420,"elapsed":416,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"d484e528-55d0-467f-f1fa-0ce390cd5362"},"source":["confusion_matrixes[2]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>187</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83.11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>60</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>21.84</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>147</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86.47</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>117</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>19</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>52.23</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>36</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>92</td>\n","      <td>51</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>16.07</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>194</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90.65</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>83</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9.49</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>258</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>95.91</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>138</td>\n","      <td>0</td>\n","      <td>65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32.02</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>80.09</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>87.76</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>225</td>\n","      <td>56</td>\n","      <td>206</td>\n","      <td>170</td>\n","      <td>224</td>\n","      <td>224</td>\n","      <td>214</td>\n","      <td>158</td>\n","      <td>269</td>\n","      <td>203</td>\n","      <td>231</td>\n","      <td>88</td>\n","      <td>196</td>\n","      <td>50</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              187   0    0    0  ...   0    0   0                     83.11\n","1                0  56    0    0  ...   0    0   0                     100.0\n","2                0   0   45   15  ...   0    0   0                     21.84\n","3                0   0    0  147  ...   0    0   0                     86.47\n","4               10  11    0   44  ...   0    0   0                     52.23\n","5                0   3    0    0  ...   5   37   0                     16.07\n","6               20   0    0    0  ...   0    0   0                     90.65\n","7                0   0    0    0  ...  35    0   0                      9.49\n","8                0   0    0    0  ...   0    0   0                     95.91\n","9                0   0    0    0  ...   0    0   0                     32.02\n","10               0   0    0    0  ...   0    0   0                     80.09\n","11               0   0    0    0  ...  88    0   0                     100.0\n","12               0   0    0    0  ...  24  172   0                     87.76\n","13               0  16    0    0  ...   0    0  34                      68.0\n","Total Samples  225  56  206  170  ...  88  196  50                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"zxx7uWOPyb4r","executionInfo":{"status":"ok","timestamp":1615788308757,"user_tz":420,"elapsed":331,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"49c83a4e-e983-4c6e-c6c4-7c5a20d92bf8"},"source":["confusion_matrixes[3]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>81.9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>37</td>\n","      <td>83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>28.8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>47</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>49.03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>143</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>68.42</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>97</td>\n","      <td>38</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>11.48</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>90.45</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>95</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>236</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>92.91</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96</td>\n","      <td>0</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48.94</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>79.63</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>89.5</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>54.29</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>210</td>\n","      <td>41</td>\n","      <td>191</td>\n","      <td>155</td>\n","      <td>209</td>\n","      <td>209</td>\n","      <td>199</td>\n","      <td>143</td>\n","      <td>254</td>\n","      <td>188</td>\n","      <td>216</td>\n","      <td>73</td>\n","      <td>181</td>\n","      <td>35</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              172   0    0    0  ...   0    0   0                      81.9\n","1                0  41    0    0  ...   0    0   0                     100.0\n","2                0   0   55    5  ...   0    0   0                      28.8\n","3                0   0    0   76  ...   0    0   0                     49.03\n","4                9   6    0   22  ...   0    0   0                     68.42\n","5                0   3    0    0  ...   5   42   0                     11.48\n","6               19   0    0    0  ...   0    0   0                     90.45\n","7                0   0    0    0  ...  23    0   0                       0.0\n","8                0   0    0    0  ...   0    0   0                     92.91\n","9                0   0    0    0  ...   0    0   0                     48.94\n","10               0   0    0    0  ...   0    0   0                     79.63\n","11               0   0    0    0  ...  73    0   0                     100.0\n","12               0   0    0    0  ...  19  162   0                      89.5\n","13               0  16    0    0  ...   0    0  19                     54.29\n","Total Samples  210  41  191  155  ...  73  181  35                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"CkclPakQyc_X","executionInfo":{"status":"ok","timestamp":1615788311274,"user_tz":420,"elapsed":409,"user":{"displayName":"Shubhankar Kulkarni","photoUrl":"","userId":"06931175960113502123"}},"outputId":"213bbec7-2c7c-4d6f-b0a5-29368cade01d"},"source":["confusion_matrixes[4]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>classfication_accuracies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.05</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>56</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31.82</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>61.43</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>138</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.13</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>61</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>5.67</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>88.04</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>107</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83.59</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>226</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94.56</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>152</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>87.86</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>163</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>81.09</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>144</td>\n","      <td>0</td>\n","      <td>86.75</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>Total Samples</th>\n","      <td>195</td>\n","      <td>26</td>\n","      <td>176</td>\n","      <td>140</td>\n","      <td>194</td>\n","      <td>194</td>\n","      <td>184</td>\n","      <td>128</td>\n","      <td>239</td>\n","      <td>173</td>\n","      <td>201</td>\n","      <td>58</td>\n","      <td>166</td>\n","      <td>20</td>\n","      <td>-</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 1   2    3    4  ...  12   13  14  classfication_accuracies\n","0              160   0    3    0  ...   0    0   0                     82.05\n","1                0  26    0    0  ...   0    0   0                     100.0\n","2                0   0   56   25  ...   0    0   0                     31.82\n","3                0   0    0   86  ...   0    0   0                     61.43\n","4               13   6    0   18  ...   0    0   0                     71.13\n","5                0   6    0    0  ...   5   46   0                      5.67\n","6               22   0    0    0  ...   0    0   0                     88.04\n","7                0   0    0    0  ...   9    0   0                     83.59\n","8                0   0    0    0  ...   0    0   0                     94.56\n","9                0   0    0    0  ...   0    0   0                     87.86\n","10               0   0    0    0  ...   0    0   0                     81.09\n","11               0   0    0    0  ...  58    0   0                     100.0\n","12               0   0    0    0  ...  22  144   0                     86.75\n","13               0  16    0    0  ...   0    0   4                      20.0\n","Total Samples  195  26  176  140  ...  58  166  20                         -\n","\n","[15 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"LihPwReQyd_1"},"source":[""],"execution_count":null,"outputs":[]}]}